{
  "schemeVersion": 7,
  "cc_licence": "Content of this file is licensed under a CC BY-NC-SA 4.0 license. For details see https://creativecommons.org/licenses/by-nc-sa/4.0/",
  "conference": {
    "id": 10102,
    "shortName": "MobileHCI",
    "displayShortName": "",
    "year": 2023,
    "startDate": 1695686400000,
    "endDate": 1695945600000,
    "fullName": "25th International ACM Conference on Mobile Human-Computer Interaction",
    "location": "Athens, Greece",
    "timeZoneOffset": 180,
    "timeZoneName": "Europe/Athens",
    "logoUrl": "https://files.sigchi.org/conference/logo/10102/6bb769fa-413c-463f-4782-fa3750e65393.png",
    "addons": {
      "Closing Keynote": {
        "order": 1,
        "title": "Closing Keynote: The Mobile As a Probe for Collocated Sociality | Maria Roussou",
        "type": "video",
        "url": "https://www.youtube.com/watch?v=BdHf1YddjeQ"
      },
      "Opening Keynote": {
        "order": 0,
        "title": "Opening Keynote: Colliding with Robots | Steve Benford",
        "type": "video",
        "url": "https://www.youtube.com/watch?v=UGd-m_U4g4c"
      }
    },
    "name": "MobileHCI 2023"
  },
  "publicationInfo": {
    "hideLinksBeforeConference": false,
    "version": 20,
    "publicationStatus": "PUBLISHED",
    "isProgramEnabled": true,
    "isDraft": false,
    "isRegistrationEnabled": false,
    "publicationDate": "2023-10-19 19:04:16+00"
  },
  "sponsors": [],
  "sponsorLevels": [
    {
      "id": 10256,
      "name": "Sponsors",
      "rank": 1,
      "isDefault": true
    }
  ],
  "floors": [
    {
      "id": 10193,
      "name": "Ground Floor",
      "roomIds": [
        11298
      ]
    },
    {
      "id": 10194,
      "name": "1st Floor",
      "roomIds": [
        11308,
        11297,
        11304,
        11328,
        11327,
        11326
      ]
    },
    {
      "id": 10195,
      "name": "2nd Floor",
      "roomIds": [
        11305
      ]
    }
  ],
  "rooms": [
    {
      "id": 11297,
      "name": "Auditorium",
      "setup": "THEATRE",
      "typeId": 13014
    },
    {
      "id": 11298,
      "name": "Registration Desk",
      "setup": "SPECIAL",
      "typeId": 13070
    },
    {
      "id": 11304,
      "name": "1st Floor Peristyle",
      "setup": "SPECIAL",
      "typeId": 13066
    },
    {
      "id": 11305,
      "name": "2nd Floor Peristyle",
      "setup": "SPECIAL",
      "typeId": 13012
    },
    {
      "id": 11308,
      "name": "Planetarium",
      "setup": "SPECIAL",
      "typeId": 13012
    },
    {
      "id": 11326,
      "name": "Meeting Room",
      "setup": "CLASSROOM",
      "typeId": 13073
    },
    {
      "id": 11327,
      "name": "Conference Hall",
      "setup": "CLASSROOM",
      "typeId": 13017
    },
    {
      "id": 11328,
      "name": "Ceremonies Hall",
      "setup": "CLASSROOM",
      "typeId": 13017
    }
  ],
  "tracks": [
    {
      "id": 12309,
      "name": "MobileHCI 2023 Papers",
      "typeId": 13014
    },
    {
      "id": 12325,
      "name": "MobileHCI 2023 Late-Breaking Work",
      "typeId": 13013
    },
    {
      "id": 12326,
      "name": "MobileHCI 2023 Doctoral Consortium",
      "typeId": 13011
    },
    {
      "id": 12327,
      "name": "MobileHCI 2023 Industrial Perspectives",
      "typeId": 13065
    },
    {
      "id": 12328,
      "name": "MobileHCI 2023 Tutorials",
      "typeId": 13073
    },
    {
      "id": 12329,
      "name": "MobileHCI 2023 Demos",
      "typeId": 13010
    },
    {
      "id": 12330,
      "name": "MobileHCI 2023 Workshops",
      "typeId": 13017
    }
  ],
  "contentTypes": [
    {
      "id": 13009,
      "name": "Course",
      "color": "#66c2a4",
      "duration": 90,
      "displayName": "Courses"
    },
    {
      "id": 13010,
      "name": "Demo",
      "color": "#006d2c",
      "duration": 1,
      "displayName": "Demos"
    },
    {
      "id": 13011,
      "name": "Doctoral Consortium",
      "color": "#6baed6",
      "duration": 0
    },
    {
      "id": 13012,
      "name": "Event",
      "color": "#ffc034",
      "duration": 0,
      "displayName": "Events"
    },
    {
      "id": 13013,
      "name": "Late-Breaking Work",
      "color": "#8e008b",
      "duration": 1
    },
    {
      "id": 13014,
      "name": "Paper",
      "color": "#0d42cc",
      "duration": 15,
      "displayName": "Papers"
    },
    {
      "id": 13015,
      "name": "Poster",
      "color": "#ff7a00",
      "duration": 5,
      "displayName": "Posters"
    },
    {
      "id": 13016,
      "name": "Work-in-Progress",
      "color": "#26e5f1",
      "duration": 5
    },
    {
      "id": 13017,
      "name": "Workshop",
      "color": "#f60000",
      "duration": 240,
      "displayName": "Workshops"
    },
    {
      "id": 13018,
      "name": "Break",
      "color": "#7f6aff",
      "duration": 5
    },
    {
      "id": 13065,
      "name": "Industry Talk",
      "color": "#969696",
      "duration": 15,
      "displayName": "Industry Talks"
    },
    {
      "id": 13066,
      "name": "Poster Or Demo",
      "color": "#969696",
      "duration": 0
    },
    {
      "id": 13067,
      "name": "Keynotes",
      "color": "#969696",
      "duration": 60
    },
    {
      "id": 13068,
      "name": "Opening",
      "color": "#969696",
      "duration": 30
    },
    {
      "id": 13069,
      "name": "Closing",
      "color": "#969696",
      "duration": 60
    },
    {
      "id": 13070,
      "name": "Registration",
      "color": "#969696",
      "duration": 60
    },
    {
      "id": 13073,
      "name": "Tutorial",
      "color": "#969696",
      "duration": 0,
      "displayName": "Tutorials"
    }
  ],
  "timeSlots": [
    {
      "id": 13279,
      "type": "SESSION",
      "startDate": 1695801600000,
      "endDate": 1695805200000
    },
    {
      "id": 13280,
      "type": "SESSION",
      "startDate": 1695807000000,
      "endDate": 1695810600000
    },
    {
      "id": 13281,
      "type": "BREAK",
      "startDate": 1695812400000,
      "endDate": 1695814200000
    },
    {
      "id": 13282,
      "type": "SESSION",
      "startDate": 1695814200000,
      "endDate": 1695821400000
    },
    {
      "id": 13283,
      "type": "LUNCH",
      "startDate": 1695821400000,
      "endDate": 1695825000000
    },
    {
      "id": 13284,
      "type": "SESSION",
      "startDate": 1695825000000,
      "endDate": 1695830400000
    },
    {
      "id": 13285,
      "type": "BREAK",
      "startDate": 1695830400000,
      "endDate": 1695832200000
    },
    {
      "id": 13286,
      "type": "SESSION",
      "startDate": 1695832200000,
      "endDate": 1695837600000
    },
    {
      "id": 13287,
      "type": "SESSION",
      "startDate": 1695888000000,
      "endDate": 1695891600000
    },
    {
      "id": 13288,
      "type": "SESSION",
      "startDate": 1695891600000,
      "endDate": 1695895200000
    },
    {
      "id": 13289,
      "type": "SESSION",
      "startDate": 1695898800000,
      "endDate": 1695900600000
    },
    {
      "id": 13290,
      "type": "SESSION",
      "startDate": 1695900600000,
      "endDate": 1695907800000
    },
    {
      "id": 13291,
      "type": "LUNCH",
      "startDate": 1695907800000,
      "endDate": 1695911400000
    },
    {
      "id": 13292,
      "type": "SESSION",
      "startDate": 1695911400000,
      "endDate": 1695916800000
    },
    {
      "id": 13293,
      "type": "BREAK",
      "startDate": 1695916800000,
      "endDate": 1695918600000
    },
    {
      "id": 13294,
      "type": "SESSION",
      "startDate": 1695918600000,
      "endDate": 1695925800000
    },
    {
      "id": 13295,
      "type": "SESSION",
      "startDate": 1695974400000,
      "endDate": 1695978000000
    },
    {
      "id": 13296,
      "type": "SESSION",
      "startDate": 1695978000000,
      "endDate": 1695981600000
    },
    {
      "id": 13297,
      "type": "BREAK",
      "startDate": 1695985200000,
      "endDate": 1695987000000
    },
    {
      "id": 13298,
      "type": "SESSION",
      "startDate": 1695987000000,
      "endDate": 1695994200000
    },
    {
      "id": 13299,
      "type": "LUNCH",
      "startDate": 1695994200000,
      "endDate": 1695997800000
    },
    {
      "id": 13300,
      "type": "SESSION",
      "startDate": 1695997800000,
      "endDate": 1696001400000
    },
    {
      "id": 13303,
      "type": "SESSION",
      "startDate": 1695715200000,
      "endDate": 1695718800000
    },
    {
      "id": 13304,
      "type": "BREAK",
      "startDate": 1695726000000,
      "endDate": 1695727800000
    },
    {
      "id": 13307,
      "type": "LUNCH",
      "startDate": 1695735000000,
      "endDate": 1695738600000
    },
    {
      "id": 13308,
      "type": "BREAK",
      "startDate": 1695744000000,
      "endDate": 1695745800000
    },
    {
      "id": 13312,
      "type": "SESSION",
      "startDate": 1695810600000,
      "endDate": 1695812400000
    },
    {
      "id": 13313,
      "type": "SESSION",
      "startDate": 1695895200000,
      "endDate": 1695898800000
    },
    {
      "id": 13323,
      "type": "SESSION",
      "startDate": 1695918600000,
      "endDate": 1695922200000
    },
    {
      "id": 13324,
      "type": "SESSION",
      "startDate": 1695922200000,
      "endDate": 1695925800000
    },
    {
      "id": 13325,
      "type": "SESSION",
      "startDate": 1695981600000,
      "endDate": 1695985200000
    },
    {
      "id": 13326,
      "type": "SESSION",
      "startDate": 1695805200000,
      "endDate": 1695807000000
    },
    {
      "id": 13369,
      "type": "SESSION",
      "startDate": 1695718800000,
      "endDate": 1695726000000
    },
    {
      "id": 13370,
      "type": "SESSION",
      "startDate": 1695727800000,
      "endDate": 1695735000000
    },
    {
      "id": 13371,
      "type": "SESSION",
      "startDate": 1695738600000,
      "endDate": 1695744000000
    },
    {
      "id": 13372,
      "type": "SESSION",
      "startDate": 1695745800000,
      "endDate": 1695754800000
    }
  ],
  "sessions": [
    {
      "id": 121259,
      "name": "Blending Realities",
      "isParallelPresentation": false,
      "importedId": "3833150a-3dde-423b-8832-c88cc72a07fb",
      "typeId": 13014,
      "roomId": 11297,
      "chairIds": [
        121058
      ],
      "contentIds": [
        121231,
        121243,
        121227,
        121253,
        121220,
        121216,
        121232,
        121228
      ],
      "source": "SYS",
      "timeSlotId": 13282
    },
    {
      "id": 121860,
      "name": "Navigating the Future",
      "isParallelPresentation": false,
      "importedId": "e5412cf2-ba7a-4a1f-af82-8cc65031fa55",
      "typeId": 13014,
      "roomId": 11297,
      "chairIds": [
        122082
      ],
      "contentIds": [
        121236,
        121250,
        121223,
        121254,
        121233,
        121257
      ],
      "source": "SYS",
      "timeSlotId": 13284
    },
    {
      "id": 121861,
      "name": "Empathy in Design",
      "isParallelPresentation": false,
      "importedId": "0977073d-8584-4488-bf24-7e84cb09ffbb",
      "typeId": 13014,
      "roomId": 11297,
      "chairIds": [
        122083
      ],
      "contentIds": [
        121248,
        121245,
        121252,
        121229,
        121251,
        121230
      ],
      "source": "SYS",
      "timeSlotId": 13286
    },
    {
      "id": 121862,
      "name": "Touch, Gesture, Voice",
      "isParallelPresentation": false,
      "importedId": "166491e2-f6b8-456c-923e-4378b54d6abe",
      "typeId": 13014,
      "roomId": 11297,
      "chairIds": [
        122080
      ],
      "contentIds": [
        121222,
        121237,
        121224,
        121225,
        121234,
        121244,
        121242,
        121241
      ],
      "source": "SYS",
      "timeSlotId": 13290
    },
    {
      "id": 121863,
      "name": "Measuring Success",
      "isParallelPresentation": false,
      "importedId": "88559968-8624-4094-94b4-83e159fa8238",
      "typeId": 13014,
      "roomId": 11297,
      "chairIds": [
        122084
      ],
      "contentIds": [
        121255,
        121235,
        121247,
        121226,
        121219,
        121238
      ],
      "source": "SYS",
      "timeSlotId": 13292
    },
    {
      "id": 121864,
      "name": "Crafting Seamless Experiences",
      "isParallelPresentation": false,
      "importedId": "61dbead3-3216-4c6a-81b8-0f90778c6853",
      "typeId": 13014,
      "roomId": 11297,
      "chairIds": [
        122081
      ],
      "contentIds": [
        121221,
        121217,
        121240,
        121249,
        121258,
        121218,
        121239,
        121246
      ],
      "source": "SYS",
      "timeSlotId": 13298
    }
  ],
  "events": [
    {
      "id": 121869,
      "name": "Welcome Reception",
      "isParallelPresentation": false,
      "importedId": "e3875fae-4865-4be0-a947-01cb815f6463",
      "typeId": 13012,
      "roomId": 11305,
      "chairIds": [],
      "contentIds": [],
      "startDate": 1695844800000,
      "endDate": 1695855600000,
      "presenterIds": [],
      "source": "SYS"
    },
    {
      "id": 121870,
      "name": "Conference Dinner",
      "isParallelPresentation": false,
      "importedId": "18ee614e-01fa-44f2-8b12-e77d0d9e325e",
      "typeId": 13012,
      "chairIds": [],
      "contentIds": [],
      "startDate": 1695931200000,
      "endDate": 1695945540000,
      "location": "Royal Olympic Hotel",
      "presenterIds": [],
      "source": "SYS"
    },
    {
      "id": 121871,
      "name": "Opening Keynote: Colliding with Robots",
      "addons": {
        "Keynote": {
          "title": "Colliding with Robots",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=UGd-m_U4g4c"
        }
      },
      "isParallelPresentation": false,
      "importedId": "6e9fc28a-4681-4fa4-95b2-56cc7241f604",
      "typeId": 13012,
      "roomId": 11297,
      "chairIds": [
        121179
      ],
      "contentIds": [],
      "startDate": 1695807000000,
      "endDate": 1695810600000,
      "description": "Steve Benford, University of Nottingham",
      "presenterIds": [
        125707
      ],
      "source": "SYS"
    },
    {
      "id": 121872,
      "name": "Keynote: Voice Interfaces: Holy Grail or Pandora's Box?",
      "isParallelPresentation": false,
      "importedId": "ddcb17c9-172a-4430-9305-7c78d5b827d7",
      "typeId": 13012,
      "roomId": 11297,
      "chairIds": [
        121073
      ],
      "contentIds": [],
      "startDate": 1695891600000,
      "endDate": 1695895200000,
      "description": "Cosmin Munteanu, University of Waterloo",
      "presenterIds": [
        125706
      ],
      "source": "SYS"
    },
    {
      "id": 121873,
      "name": "Closing Keynote: The mobile as a probe for collocated sociality in cultural contexts",
      "addons": {
        "Keynote": {
          "title": "The mobile as a probe for collocated sociality in cultural contexts",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=BdHf1YddjeQ"
        }
      },
      "isParallelPresentation": false,
      "importedId": "25117adc-8cb7-4096-92fb-aa2d8ccbf930",
      "typeId": 13012,
      "roomId": 11297,
      "chairIds": [
        121143
      ],
      "contentIds": [],
      "startDate": 1695978000000,
      "endDate": 1695981600000,
      "description": "Maria Roussou, University of Athens",
      "presenterIds": [
        121078
      ],
      "source": "SYS"
    },
    {
      "id": 121881,
      "name": "Planetarium Show",
      "isParallelPresentation": true,
      "importedId": "39cbbf11-8a8d-4637-870b-1f93106c387d",
      "typeId": 13012,
      "roomId": 11308,
      "chairIds": [],
      "contentIds": [],
      "startDate": 1695839400000,
      "endDate": 1695843000000,
      "presenterIds": [],
      "source": "SYS"
    },
    {
      "id": 121883,
      "name": "Acropolis VR Tour",
      "isParallelPresentation": false,
      "importedId": "999b165e-943d-41c5-93fd-1d515b96ff44",
      "typeId": 13012,
      "chairIds": [],
      "contentIds": [],
      "startDate": 1696005000000,
      "endDate": 1696014000000,
      "location": "Acropolis Archaeological Site",
      "presenterIds": [],
      "source": "SYS"
    },
    {
      "id": 121889,
      "name": "Conference Opening",
      "isParallelPresentation": false,
      "importedId": "495dcf72-ce00-49cb-b902-b47abaca4dca",
      "typeId": 13012,
      "roomId": 11297,
      "chairIds": [],
      "contentIds": [],
      "startDate": 1695805200000,
      "endDate": 1695807000000,
      "description": "Chairs' welcome to the conference and greeting by the ACM President, prof. Y. Ioannidis.",
      "presenterIds": [
        122176,
        125709,
        125710
      ],
      "source": "SYS"
    },
    {
      "id": 121890,
      "name": "Madness Session",
      "isParallelPresentation": false,
      "importedId": "73603c0f-d8ae-4289-9060-8deaf12e8cf8",
      "typeId": 13012,
      "roomId": 11297,
      "chairIds": [
        122270
      ],
      "contentIds": [
        122226,
        122231,
        122235,
        122215,
        122229,
        122227,
        122218,
        122234,
        122236,
        122219,
        122216,
        122237,
        122217,
        122232,
        122223,
        122222,
        122220,
        122224,
        122221,
        122233,
        122230,
        122225,
        122228,
        122309,
        122322,
        122319,
        122313,
        122307
      ],
      "startDate": 1695810600000,
      "endDate": 1695812400000,
      "description": "1-minute presentation of all posters and demos at the conference",
      "presenterIds": [],
      "source": "SYS"
    },
    {
      "id": 121891,
      "name": "Registration (Tue)",
      "isParallelPresentation": false,
      "importedId": "528ad717-c5e8-42c0-bf57-784553c48d67",
      "typeId": 13012,
      "roomId": 11298,
      "chairIds": [],
      "contentIds": [],
      "startDate": 1695715200000,
      "endDate": 1695718800000,
      "description": "Conference registration (badge pick-up and on-site registrations). The registration desk will be open until 14:30.",
      "presenterIds": [],
      "source": "SYS"
    },
    {
      "id": 121892,
      "name": "Registration (Wed)",
      "isParallelPresentation": false,
      "importedId": "d66f3035-318d-4725-9b1d-42fb7a4d6bc1",
      "typeId": 13012,
      "roomId": 11298,
      "chairIds": [],
      "contentIds": [],
      "startDate": 1695801600000,
      "endDate": 1695805200000,
      "description": "Conference registration (badge pick-up and on-site registrations). The registration desk will be open until 16:30.",
      "presenterIds": [],
      "source": "SYS"
    },
    {
      "id": 121893,
      "name": "Registration (Thu)",
      "isParallelPresentation": false,
      "importedId": "63cbe736-8828-4a7f-9fe7-f9273bb9dc44",
      "typeId": 13012,
      "roomId": 11298,
      "chairIds": [],
      "contentIds": [],
      "startDate": 1695888000000,
      "endDate": 1695891600000,
      "description": "Conference registration (badge pick-up and on-site registrations). The registration desk will be open until 16:30 each day.",
      "presenterIds": [],
      "source": "SYS"
    },
    {
      "id": 121894,
      "name": "Registration (Fri)",
      "isParallelPresentation": false,
      "importedId": "d8695ef6-0fd5-47f1-b756-b6b6772b414d",
      "typeId": 13012,
      "roomId": 11298,
      "chairIds": [],
      "contentIds": [],
      "startDate": 1695974400000,
      "endDate": 1695978000000,
      "description": "Conference registration (badge pick-up and on-site registrations). The registration desk will be open until 11:30.",
      "presenterIds": [],
      "source": "SYS"
    },
    {
      "id": 121895,
      "name": "Industry Perspectives",
      "isParallelPresentation": false,
      "importedId": "7d9e54b0-5501-4802-aa79-138f6aa18325",
      "typeId": 13012,
      "roomId": 11297,
      "chairIds": [
        122136
      ],
      "contentIds": [
        122312,
        122308,
        122306,
        122310
      ],
      "startDate": 1695895200000,
      "endDate": 1695898800000,
      "description": "testing a <br> break",
      "presenterIds": [],
      "source": "SYS"
    },
    {
      "id": 121896,
      "name": "Town Hall",
      "isParallelPresentation": false,
      "importedId": "9c691775-22b3-4195-979b-fbef9d589fd7",
      "typeId": 13012,
      "roomId": 11304,
      "chairIds": [],
      "contentIds": [],
      "startDate": 1695922200000,
      "endDate": 1695925800000,
      "presenterIds": [],
      "source": "SYS"
    },
    {
      "id": 121897,
      "name": "Dedicated Poster & Demo Session",
      "isParallelPresentation": false,
      "importedId": "54fdabcb-6c6f-483d-bfb3-eb4d8e887f5f",
      "typeId": 13012,
      "roomId": 11304,
      "chairIds": [],
      "contentIds": [],
      "startDate": 1695918600000,
      "endDate": 1695922200000,
      "description": "A longer poster & demo session to allow more time to interact with authors.",
      "presenterIds": [],
      "source": "SYS"
    },
    {
      "id": 121898,
      "name": "Doctoral Consortium",
      "isParallelPresentation": false,
      "importedId": "cf933a14-1899-4851-b059-e1cfee37607a",
      "typeId": 13012,
      "roomId": 11297,
      "chairIds": [
        121073,
        127780,
        127781
      ],
      "contentIds": [
        122304,
        122311,
        122314,
        122303,
        122320,
        122305
      ],
      "startDate": 1695918600000,
      "endDate": 1695925800000,
      "description": "This event is only open to registered DC students.",
      "presenterIds": [],
      "source": "SYS"
    },
    {
      "id": 121899,
      "name": "Sponsor Perspectives",
      "isParallelPresentation": false,
      "importedId": "e2a3ebc3-a771-4d5e-9363-de88afd6f874",
      "typeId": 13012,
      "roomId": 11297,
      "chairIds": [
        124731
      ],
      "contentIds": [],
      "startDate": 1695981600000,
      "endDate": 1695985200000,
      "description": "Invited talks from MobileHCI'23 sponsors.",
      "presenterIds": [],
      "source": "SYS"
    },
    {
      "id": 121900,
      "name": "Coffee Break with Posters & Demos",
      "isParallelPresentation": false,
      "importedId": "e48592ce-b5ee-4b54-83a8-e45775a55137",
      "typeId": 13012,
      "roomId": 11304,
      "chairIds": [],
      "contentIds": [],
      "startDate": 1695812400000,
      "endDate": 1695814200000,
      "presenterIds": [],
      "source": "SYS"
    },
    {
      "id": 121901,
      "name": "Coffee Break with Posters & Demos",
      "isParallelPresentation": false,
      "importedId": "9e1fd0ca-e17e-47ab-a959-1e65c5711551",
      "typeId": 13012,
      "roomId": 11304,
      "chairIds": [],
      "contentIds": [],
      "startDate": 1695898800000,
      "endDate": 1695900600000,
      "description": "Visit the posters and demos during the morning coffee break for a chance to interact with their authors and presenters.",
      "presenterIds": [],
      "source": "SYS"
    },
    {
      "id": 121902,
      "name": "Coffee Break with Posters & Demos",
      "isParallelPresentation": false,
      "importedId": "2921db25-37c0-416b-a914-b26633f542f1",
      "typeId": 13012,
      "chairIds": [],
      "contentIds": [],
      "startDate": 1695985200000,
      "endDate": 1695987000000,
      "description": "Visit the posters and demos during the morning coffee break for a chance to interact with their authors and presenters.",
      "presenterIds": [],
      "source": "SYS"
    },
    {
      "id": 122326,
      "name": "Coffee Break with Posters & Demos",
      "isParallelPresentation": false,
      "importedId": "62d2008b-5c21-4972-845c-7f2e7a373e35",
      "typeId": 13012,
      "roomId": 11304,
      "chairIds": [],
      "contentIds": [],
      "startDate": 1695916800000,
      "endDate": 1695918600000,
      "presenterIds": [],
      "source": "SYS"
    },
    {
      "id": 122327,
      "name": "Coffee Break with Posters & Demos",
      "isParallelPresentation": false,
      "importedId": "449fac7e-61e7-40fc-8a2f-b3b92e123436",
      "typeId": 13012,
      "roomId": 11304,
      "chairIds": [],
      "contentIds": [],
      "startDate": 1695830400000,
      "endDate": 1695832200000,
      "presenterIds": [],
      "source": "SYS"
    },
    {
      "id": 122328,
      "name": "Afternoon Coffee Break",
      "isParallelPresentation": false,
      "importedId": "185b9c48-22b6-4b60-b280-dab01ced7b9b",
      "typeId": 13012,
      "roomId": 11304,
      "chairIds": [],
      "contentIds": [],
      "startDate": 1695744000000,
      "endDate": 1695745800000,
      "presenterIds": [],
      "source": "SYS"
    },
    {
      "id": 122329,
      "name": "Morning Coffee Break",
      "isParallelPresentation": false,
      "importedId": "75511fec-fcff-42ea-8c99-a763e0ab7542",
      "typeId": 13012,
      "roomId": 11304,
      "chairIds": [],
      "contentIds": [],
      "startDate": 1695726000000,
      "endDate": 1695727800000,
      "presenterIds": [],
      "source": "SYS"
    },
    {
      "id": 122330,
      "name": "(T) Smartphone based on-device computing for societal applications",
      "isParallelPresentation": false,
      "importedId": "3061438e-0d8d-445e-a602-1feb5554b80b",
      "typeId": 13012,
      "roomId": 11297,
      "chairIds": [],
      "contentIds": [
        122316
      ],
      "startDate": 1695738600000,
      "endDate": 1695753000000,
      "presenterIds": [
        122275
      ],
      "source": "SYS"
    },
    {
      "id": 122331,
      "name": "(W) Mobility and Utility in Robot Mediated Interaction: An Interactive Workshop for the Identification of Use Cases and Affordances of Telepresence Robots",
      "isParallelPresentation": false,
      "importedId": "68144e8e-999f-4963-87e6-193ab09b6e98",
      "typeId": 13012,
      "roomId": 11327,
      "chairIds": [],
      "contentIds": [
        122318
      ],
      "startDate": 1695718800000,
      "endDate": 1695735000000,
      "link": {
        "href": "https://sites.google.com/view/mobilehci23-telepresence-ws/",
        "label": "Workshop website"
      },
      "presenterIds": [],
      "source": "SYS"
    },
    {
      "id": 122332,
      "name": "(W) Accessibility and Multimodal Interaction Design Approaches in Museums for People with Impairments",
      "isParallelPresentation": false,
      "importedId": "cb6e491e-ac97-49c2-b476-590c1d751dd6",
      "typeId": 13012,
      "roomId": 11327,
      "chairIds": [],
      "contentIds": [
        122323
      ],
      "startDate": 1695738600000,
      "endDate": 1695754800000,
      "link": {
        "href": "http://amidworkshop.ece.upatras.gr/",
        "label": "Workshop website"
      },
      "presenterIds": [],
      "source": "SYS"
    },
    {
      "id": 122333,
      "name": "(W) The Future of Cognitive Personal Informatics",
      "isParallelPresentation": false,
      "importedId": "93c7cc73-c21c-45b4-92af-6877c6de3a11",
      "typeId": 13012,
      "roomId": 11326,
      "chairIds": [],
      "contentIds": [
        122315
      ],
      "startDate": 1695718800000,
      "endDate": 1695751200000,
      "link": {
        "href": "https://brain-data-uon.gitlab.io/events/mobilehci23-workshop.html",
        "label": "Workshop website"
      },
      "presenterIds": [],
      "source": "SYS"
    },
    {
      "id": 122334,
      "name": "(W) Advances of Mobile and Wearable Biometrics",
      "isParallelPresentation": false,
      "importedId": "42a9b3f7-5b96-4582-8503-a81c6539b055",
      "typeId": 13012,
      "roomId": 11297,
      "chairIds": [],
      "contentIds": [
        122317
      ],
      "startDate": 1695718800000,
      "endDate": 1695735000000,
      "link": {
        "href": "https://sites.google.com/view/wamwb/",
        "label": "Workshop website"
      },
      "presenterIds": [],
      "source": "SYS"
    }
  ],
  "contents": [
    {
      "id": 121216,
      "typeId": 13014,
      "title": "An Asymmetric Multiplayer Learning Environment for Room-Scale Virtual Reality and a Handheld Device",
      "addons": {},
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23a-1163",
      "source": "PCS",
      "trackId": 12309,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        121259
      ],
      "eventIds": [],
      "abstract": "Many different digital learning environments are currently in use. In combination with virtual reality (VR) technologies, these allow the creation of engaging hands-on experiences. While VR environments can deeply immerse the person wearing the headset, spectators are often not actively involved or are not even considered in the design phase. This is an issue for learning environments, as learning often takes place in pairs or groups. We propose a novel system that enables more than one person to join the VR world in a co-located space to overcome this problem. In addition to the classic VR headset, the asymmetric VR system features a position-tracked tablet. To evaluate this asymmetric VR concept, we conducted a study with 14 students to explore the user experience and motivation, the social presence, and possible further fields of application. The results indicate that users in both perspectives feel that they can control the virtual world.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Austria",
              "state": "",
              "city": "Graz",
              "institution": "TU Graz",
              "dsl": ""
            }
          ],
          "personId": 121163
        },
        {
          "affiliations": [
            {
              "country": "Austria",
              "state": "",
              "city": "Graz",
              "institution": "TU Graz",
              "dsl": ""
            }
          ],
          "personId": 121171
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Munich",
              "institution": "LMU",
              "dsl": ""
            },
            {
              "country": "Austria",
              "state": "",
              "city": "Graz",
              "institution": "TU Graz",
              "dsl": ""
            }
          ],
          "personId": 121117
        }
      ]
    },
    {
      "id": 121217,
      "typeId": 13014,
      "title": "[Don't] Let The Bodies HIIT The Floor: Fostering Body Awareness in Fast-Paced Physical Activity Using Body-Worn Sensors",
      "addons": {},
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23a-1043",
      "source": "PCS",
      "trackId": 12309,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        121864
      ],
      "eventIds": [],
      "abstract": "Technologies have become an integral part of physical activity. Yet, the majority of popular programs do not focus on promoting a genuine understanding of how sport affects our bodies. As apps and trackers persuade users to exercise more, lack of body awareness can be detrimental to health.\r\nIn this work, we propose and evaluate the concept of in-session reflective feedback as a means to support informed exercise routines by design.\r\nWe designed and implemented REPLAY, a system which presents users with a visualization of physiological signals (heart rate, movement) from body-worn sensors during high-intensity interval training (HIIT).\r\nOur evaluation showed that participants gained a better understanding of how their body reacted to physical activity, allowing them to understand its effect and recognize own weaknesses. Further, our work demonstrates how the type of feedback can significantly moderate a user's perceived exhaustion.\r\nWe highlight how in-session reflective feedback using bodily signals can promote healthy and effective workouts through creating a deeper understanding of one's own body physiology and limits.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Munich",
              "institution": "LMU Munich",
              "dsl": ""
            }
          ],
          "personId": 121209
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Munich",
              "institution": "LMU Munich",
              "dsl": ""
            }
          ],
          "personId": 121169
        },
        {
          "affiliations": [
            {
              "country": "Sweden",
              "state": "",
              "city": "Gothenburg",
              "institution": "Chalmers University of Technology",
              "dsl": ""
            }
          ],
          "personId": 121101
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Munich",
              "institution": "LMU Munich",
              "dsl": ""
            }
          ],
          "personId": 121191
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Kaiserslautern",
              "institution": "German Research Center for Artificial Intelligence",
              "dsl": ""
            },
            {
              "country": "Germany",
              "state": "",
              "city": "Kaiserslautern",
              "institution": "TU Kaiserslautern",
              "dsl": ""
            }
          ],
          "personId": 121046
        }
      ]
    },
    {
      "id": 121218,
      "typeId": 13014,
      "title": "Scanning or Simply Unengaged in Reading? Opportune Moments for Pushed News Notifications and Their Relationship with Smartphone Users’ Choice of News-reading Modes",
      "addons": {},
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23a-1087",
      "source": "PCS",
      "trackId": 12309,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        121864
      ],
      "eventIds": [],
      "abstract": "News notifications on smartphones provide a convenient way to stay informed, but their delivery timing can influence user engagement. Despite this, research on the impact of notification timing on reading behavior remains limited. Therefore, we developed NewsMoment, a news aggregation app that monitors user reading patterns and sends news notifications. Our experience sampling study with 46 NewsMoment users revealed four distinct reading modes: typical, comprehensive, scanning, and unengaged. Deep reading, encompassing typical and comprehensive modes, more often occurred during self-initiated browsing rather than through pushed news. Interestingly, shallow reading modes - unengaged and scanning - showed varying prevalence, associated triggers, and engagement, despite their similarities. Importantly, unengaged reading persisted regardless of users' perceived moment opportuneness, whereas scanning reading was more common during inopportune moments. These findings suggest that identifying opportune moments for news reading may primarily reduce scanning reading, without substantially impacting unengaged reading.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Taiwan",
              "state": "",
              "city": "Hsinchu",
              "institution": "National Yang Ming Chiao Tung University",
              "dsl": "Department of Computer Science"
            }
          ],
          "personId": 121174
        },
        {
          "affiliations": [
            {
              "country": "Taiwan",
              "state": "",
              "city": "Hsinchu",
              "institution": "National Yang Ming Chiao Tung University",
              "dsl": "Department of Computer Science"
            }
          ],
          "personId": 121118
        },
        {
          "affiliations": [
            {
              "country": "Taiwan",
              "state": "",
              "city": "Hsinchu",
              "institution": "National Tsing Hua University",
              "dsl": "Institute of Service Science"
            }
          ],
          "personId": 121204
        },
        {
          "affiliations": [
            {
              "country": "Taiwan",
              "state": "",
              "city": "Hsinchu",
              "institution": "National Yang Ming Chiao Tung University",
              "dsl": "Department of Industrial Engineering and Management"
            }
          ],
          "personId": 121177
        },
        {
          "affiliations": [
            {
              "country": "Taiwan",
              "state": "",
              "city": "Hsinchu",
              "institution": "National Yang Ming Chiao Tung University",
              "dsl": "Department of Information Management and Finance"
            }
          ],
          "personId": 121119
        },
        {
          "affiliations": [
            {
              "country": "Taiwan",
              "state": "",
              "city": "Hsinchu",
              "institution": "National Yang Ming Chiao Tung University",
              "dsl": "Institute of Computer Science and Engineering"
            }
          ],
          "personId": 121133
        },
        {
          "affiliations": [
            {
              "country": "Taiwan",
              "state": "",
              "city": "Hsinchu",
              "institution": "National Yang Ming Chiao Tung University",
              "dsl": "Department of Computer Science"
            },
            {
              "country": "Taiwan",
              "state": "",
              "city": "Hsinchu",
              "institution": "National Yang Ming Chiao Tung University",
              "dsl": "Institute of Communication Studies"
            }
          ],
          "personId": 121137
        }
      ]
    },
    {
      "id": 121219,
      "typeId": 13014,
      "title": "Beyond Hiding and Revealing: Exploring Effects of Visibility and Form of Interaction on the Witness Experience",
      "addons": {
        "Presentation": {
          "title": "Beyond Hiding and Revealing: Exploring Effects of Visibility and Form of Interaction on the Witness Experience",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=zQq4V_fnNOU"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23a-1186",
      "source": "PCS",
      "trackId": 12309,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        121863
      ],
      "eventIds": [],
      "abstract": "Our interactions with technology do not just shape our individual experiences. They also affect people around us. Although previous research has addressed such “witness” experiences, the actual effect of interaction design on the witness experience remains largely unknown. In an online study (n = 407), we explored how witnesses perceive mid-air gesture-based interactions with a hearing aid, using four video vignettes. We studied witnesses’ subjective visibility of manipulations and effects (following Reeves and colleagues’ taxonomy), perceived form of interaction, subjective experience, and relationships between these measures. Although visibility patterns matched the intended form, they did not lead to the supposed experience (i.e., “suspenseful” gestures did not lead to suspenseful experiences). The paper illustrates gaps in current research about witness experiences, demonstrates the need to overcome basic hiding/revealing profiles, and indicates a path forward by focusing on aesthetic forms and experiences.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Siegen",
              "institution": "University of Siegen",
              "dsl": "Ubiquitous Design / Experience & Interaction"
            }
          ],
          "personId": 121144
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Siegen",
              "institution": "University Siegen",
              "dsl": "Ubiquitous Design / Experience & Interaction"
            }
          ],
          "personId": 121193
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Siegen",
              "institution": "University of Siegen",
              "dsl": "Ubiquitous Design / Experience & Interaction"
            }
          ],
          "personId": 121057
        }
      ]
    },
    {
      "id": 121220,
      "typeId": 13014,
      "title": "BeeAR: Augmented Reality Beeline Navigation for Spatial Knowledge Acquisition",
      "addons": {
        "Presentation": {
          "title": "BeeAR: Augmented Reality Beeline Navigation for Spatial Knowledge Acquisition",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=QIAXGHYeG7g"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23a-1120",
      "source": "PCS",
      "trackId": 12309,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        121259
      ],
      "eventIds": [],
      "abstract": "Navigation assistance systems have become integral to our daily routines, helping us to find our way through unfamiliar environments. However, their use may come at a price, as empirical evidence suggests a potentially harmful impact of these systems on our spatial abilities, including the acquisition of spatial knowledge. This could be remedied by giving users more freedom and involving them in the decision-making process. Therefore, we present a navigation system that combines augmented reality and Beeline Navigation (BeeAR). Here, the location of the destination is overlaid with a digital landmark and permanently displayed to the user via a visual, translucent AR display (without a map). Since the digital content is integrated into the real world, no mapping between the device and reality is required, potentially lowering the workload. Making one's own decisions along the route is expected to increase engagement with the environment, leading to increased acquisition of spatial knowledge. We compare BeeAR with findings from a previous study comparing Free Choice Navigation (FCN) and Turn-by-Turn (TBT) navigation conducted along the same routes on the outskirts of Vienna, Austria. Although BeeAR and FCN do not provide users with a map, BeeAR users could better retrace the walked route and remembered more points of interest along the route than FCN users. Participants of all three navigation conditions achieved a high configuration similarity between drawn points of interest and their true locations, albeit only one navigation condition included a map.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Austria",
              "state": "",
              "city": "Vienna",
              "institution": "Research Group Geoinformation",
              "dsl": "Vienna University Of Technology (TU WIEN)"
            }
          ],
          "personId": 121094
        },
        {
          "affiliations": [
            {
              "country": "Austria",
              "state": "",
              "city": "Wien",
              "institution": "Vienna University Of Technology",
              "dsl": "Geoinformation "
            }
          ],
          "personId": 121122
        },
        {
          "affiliations": [
            {
              "country": "Austria",
              "state": "",
              "city": "Vienna",
              "institution": "Vienna University of Technology",
              "dsl": "Department of Geodesy and Geoinformation/Geoinformation Group/Spatial HCI Lab"
            }
          ],
          "personId": 121058
        }
      ]
    },
    {
      "id": 121221,
      "typeId": 13014,
      "title": "Typing Behavior is About More than Speed: Users' Strategies for Choosing Word Suggestions Despite Slower Typing Rates",
      "addons": {
        "Presentation": {
          "title": "Typing Behavior is About More than Speed: Users' Strategies for Choosing Word Suggestions Despite Slower Typing Rates",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=5kPgwinOpHw"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23a-1161",
      "source": "PCS",
      "trackId": 12309,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        121864
      ],
      "eventIds": [],
      "abstract": "Mobile word suggestions can slow down typing, yet are still widely used. To investigate the apparent benefits beyond speed, we analyzed typing behavior of 15,162 users of mobile devices. Controlling for natural typing speed (a confounding factor not considered by prior work), we statistically show that slower typists use suggestions more often but are slowed down by doing so. To better understand how these typists leverage suggestions -- if not to improve their speed -- we extract eight usage strategies, including completion, correction, and next-word prediction. We find that word characteristics, such as length or frequency, along with the strategy, are predictive of whether a user will select a suggestion. We show how to operationalize our findings by building and evaluating a predictive model of suggestion selection. Such a model could be used to augment existing suggestion algorithms to consider people's strategic use of word predictions beyond speed and keystroke savings.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Bayreuth",
              "institution": "University of Bayreuth",
              "dsl": "Department of Computer Science"
            }
          ],
          "personId": 121213
        },
        {
          "affiliations": [
            {
              "country": "Switzerland",
              "state": "",
              "city": "Zurich",
              "institution": "ETH Zurich",
              "dsl": ""
            }
          ],
          "personId": 121068
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Bayreuth",
              "institution": "University of Bayreuth",
              "dsl": "Department of Computer Science"
            }
          ],
          "personId": 121121
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Saarbrücken",
              "institution": "Saarland University, Saarland Informatics Campus",
              "dsl": "Computational Interaction Lab"
            }
          ],
          "personId": 121109
        }
      ]
    },
    {
      "id": 121222,
      "typeId": 13014,
      "title": "Studying the Visual Representation of Microgestures",
      "addons": {
        "Presentation": {
          "title": "Studying the Visual Representation of Microgestures",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=eyyLyt5Fcas"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23a-1062",
      "source": "PCS",
      "trackId": 12309,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        121862
      ],
      "eventIds": [],
      "abstract": "The representations of microgestures are essentials for researchers presenting their results through academic papers and system designers proposing tutorials to novice users. However, those representations remain disparate and inconsistent.\r\nAs a first attempt to investigate how to best graphically represent microgestures, we created 21 designs, each depicting static and dynamic versions of 4 commonly used microgestures (tap, swipe, flex and hold). \r\nWe first studied these designs in a quantitative online experiment with 45 participants. We then conducted a qualitative laboratory experiment in Augmented Reality with 16 participants. \r\nBased on the results, we provide design guidelines on which elements of a microgesture should be represented and how.\r\nIn particular, it is recommended to represent the actuator and the trajectory of a microgesture.\r\nAlso, although preferred by users, dynamic representations are not considered better than their static counterparts for depicting a microgesture and do not necessarily result in a better user recognition.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "France",
              "state": "",
              "city": "Grenoble",
              "institution": "Laboratoire d'Informatique de Grenoble",
              "dsl": "IIHM"
            }
          ],
          "personId": 121124
        },
        {
          "affiliations": [
            {
              "country": "France",
              "state": "",
              "city": "Grenoble",
              "institution": "Laboratoire d'Informatique de Grenoble",
              "dsl": ""
            }
          ],
          "personId": 121081
        },
        {
          "affiliations": [
            {
              "country": "France",
              "state": "",
              "city": "Grenoble",
              "institution": "Université Grenoble Alpes",
              "dsl": ""
            }
          ],
          "personId": 121214
        },
        {
          "affiliations": [
            {
              "country": "France",
              "state": "",
              "city": "F-59000 Lille",
              "institution": "Univ. Lille, Inria, CNRS, Centrale Lille",
              "dsl": "UMR 9189 - CRIStAL"
            }
          ],
          "personId": 121138
        },
        {
          "affiliations": [
            {
              "country": "France",
              "state": "",
              "city": "Grenoble",
              "institution": "Université Grenoble Alpes",
              "dsl": "Equipe IIHM du Laboratoire d'Informatique de Grenoble"
            }
          ],
          "personId": 121182
        }
      ]
    },
    {
      "id": 121223,
      "typeId": 13014,
      "title": "Reality Anchors: Bringing Cues from Reality to Increase Acceptance of Immersive Technologies in Transit",
      "addons": {
        "Presentation": {
          "title": "Reality Anchors: Bringing Cues from Reality to Increase Acceptance of Immersive Technologies in Transit",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=aWHEUaDW4g4"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23a-1041",
      "source": "PCS",
      "trackId": 12309,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        121860
      ],
      "eventIds": [],
      "abstract": "Immersive technologies allow us to control and customise how we experience reality, but are not widely used in transit due to safety, social acceptability, and comfort barriers. We propose that cues from reality can create reference points in virtuality, which we call Reality Anchors, will reduce these barriers. We used simulated public transportation journeys in a lab setting to explore Reality Anchors using speculative methods in two studies. Our first study (N=20) explored how elements of reality like objects, furniture, and people could be used as anchors, demonstrating that visibility of other passengers and personal belongings could reduce barriers. Our second study (N=19) focused on journey types that emerged from the first study - self-managed vs. externally managed journeys - revealing that self-managed journeys increased the need for anchors. We conclude that Reality Anchors can reduce concerns associated with immersive technology use in transit, especially for self-managed journeys.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "",
              "city": "Glasgow",
              "institution": "University of Glasgow",
              "dsl": "School of Computing Science"
            }
          ],
          "personId": 121210
        },
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "",
              "city": "Glasgow",
              "institution": "University of Glasgow",
              "dsl": "School of Computing Science"
            }
          ],
          "personId": 121192
        },
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "",
              "city": "Glasgow",
              "institution": "University of Glasgow",
              "dsl": "School of Computing Science"
            }
          ],
          "personId": 121143
        }
      ]
    },
    {
      "id": 121224,
      "typeId": 13014,
      "title": "Exploring Visual Signifier Characteristics to Improve the Perception of Affordances of In-Place Touch Inputs",
      "addons": {
        "Presentation": {
          "title": "Exploring Visual Signifier Characteristics to Improve the Perception of Affordances of In-Place Touch Inputs",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=_JkWlmCiGHI"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23a-1006",
      "source": "PCS",
      "trackId": 12309,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        121862
      ],
      "eventIds": [],
      "abstract": "Touch screens supporting different inputs such as `Tap’, `Dwell’, `Double Tap’ and `Force Press' are omnipresent in modern devices and yet this variety of interaction opportunities is rarely communicated to the user. Without visual signifiers, these potentially useful inputs remain unknown or underutilised. We propose a design space of visual signifier characteristics that may impact the perception of in-place one finger inputs. We generated 36 designs and investigated their perception in an online survey (N=32) and an interactive experiment (N=24). The results suggest that visual signifiers increase the perception of input possibilities beyond `Tap’, and reduce perceived mental effort for participants, who also prefer added visual signifiers over a baseline. Our work informs how future touch-based interfaces could be designed to better communicate in-place single finger input possibilities.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "France",
              "state": "",
              "city": "Lille",
              "institution": "Univ. Lille, Inria, CNRS, Centrale Lille, UMR 9189 CRIStAL",
              "dsl": ""
            }
          ],
          "personId": 121158
        },
        {
          "affiliations": [
            {
              "country": "France",
              "state": "",
              "city": "Lille",
              "institution": "Univ. Lille, CNRS, Inria, Centrale Lille, UMR 9189 CRIStAL",
              "dsl": ""
            }
          ],
          "personId": 121051
        },
        {
          "affiliations": [
            {
              "country": "France",
              "state": "",
              "city": "Lille",
              "institution": "Univ. Lille, Inria, CNRS, Centrale Lille, UMR 9189 CRIStAL",
              "dsl": ""
            }
          ],
          "personId": 121138
        }
      ]
    },
    {
      "id": 121225,
      "typeId": 13014,
      "title": "Single-tap Latency Reduction with Single- or Double- tap Prediction",
      "addons": {
        "Presentation": {
          "title": "Single-tap Latency Reduction with Single- or Double- tap Prediction",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=fQLjymncWAU"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23a-1104",
      "source": "PCS",
      "trackId": 12309,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        121862
      ],
      "eventIds": [],
      "abstract": "Touch surfaces are widely utilized for smartphones, tablet PCs, and laptops (touchpad), and single and double taps are the most basic and common operations on them.\r\nThe detection of single or double taps causes the {\\it single-tap latency problem}, which creates a bottleneck in terms of the sensitivity of touch inputs. \r\nTo reduce {\\it the single-tap latency}, we propose a novel machine-learning-based tap prediction method called PredicTaps. \r\nOur method predicts whether a detected tap is a single tap or the first contact of a double tap without having to wait for the hundreds of milliseconds conventionally required. \r\nWe present three evaluations and one user evaluation that demonstrate its broad applicability and usability for various tap situations on two form factors (touchpad and smartphone). \r\nThe results showed PredicTaps reduces the {\\it single-tap latency} from 150--500 ms to 12 ms on laptops and to 17.6 ms on smartphones without reducing usability. ",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Japan",
              "state": "",
              "city": "Tokyo",
              "institution": "University of Tokyo",
              "dsl": "Rekimoto Lab"
            }
          ],
          "personId": 121131
        },
        {
          "affiliations": [
            {
              "country": "Japan",
              "state": "",
              "city": "Tokyo",
              "institution": "Yahoo Japan Corporation",
              "dsl": ""
            }
          ],
          "personId": 121172
        },
        {
          "affiliations": [
            {
              "country": "Japan",
              "state": "",
              "city": "Chiyoda-ku",
              "institution": "Yahoo Japan Corporation",
              "dsl": ""
            }
          ],
          "personId": 121099
        },
        {
          "affiliations": [
            {
              "country": "Japan",
              "state": "",
              "city": "Tokyo",
              "institution": "Yahoo Japan Corporation",
              "dsl": ""
            }
          ],
          "personId": 121089
        },
        {
          "affiliations": [
            {
              "country": "Japan",
              "state": "",
              "city": "Tokyo",
              "institution": "Yahoo Japan Corporation",
              "dsl": ""
            }
          ],
          "personId": 121041
        }
      ]
    },
    {
      "id": 121226,
      "typeId": 13014,
      "title": "Co-Designing with Users the Explanations for a Proactive Auto-Response Messaging Agent",
      "addons": {
        "Presentation": {
          "title": "Co-Designing with Users the Explanations for a Proactive Auto-Response Messaging Agent",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=M7FtX_RXhas"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23a-1189",
      "source": "PCS",
      "trackId": 12309,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        121863
      ],
      "eventIds": [],
      "abstract": "Explanations of AI Agents' actions are considered to be an important factor in improving users' trust in the decisions made by autonomous AI systems. However, as these autonomous systems evolve from reactive, i.e., acting on user input, to proactive, i.e., acting without requiring user intervention, there is a need to explore how the explanation for the actions of these agents should evolve. In this work, we explore the design of explanations through participatory design methods for a proactive auto-response messaging agent that can reduce perceived obligations and social pressure to respond quickly to incoming messages by providing unavailability-related context. We recruited 14 participants who worked in pairs during collaborative design sessions where they reasoned about the agent's design and actions. We qualitatively analyzed the data collected through these sessions and found that participants' reasoning about agent actions led them to speculate heavily on its design. These speculations significantly influenced participants' desire for explanations and the controls they sought to inform the agents' behavior. Our findings indicate a need to transform users' speculations into accurate mental models of agent design. Further, since the agent acts as a mediator in human-human communication, it is also necessary to account for social norms in its explanation design. Finally, user expertise in understanding their habits and behaviors allows the agent to learn from the user their preferences when justifying its actions.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Pennsylvania",
              "city": "Pittsburgh",
              "institution": "University of Pittsburgh",
              "dsl": "School of Computing and Information"
            }
          ],
          "personId": 121196
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Pennsylvania",
              "city": "Pittsburgh",
              "institution": "University of Pittsburgh",
              "dsl": "School of Computing and Information"
            }
          ],
          "personId": 121127
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Pennsylvania",
              "city": "Pittsburgh",
              "institution": "University of Pittsburgh",
              "dsl": "Department of Computer Science"
            }
          ],
          "personId": 121215
        }
      ]
    },
    {
      "id": 121227,
      "typeId": 13014,
      "title": "Drawing Connections: Designing Situated Links for Immersive Maps",
      "addons": {
        "Presentation": {
          "title": "Drawing Connections: Designing Situated Links for Immersive Maps",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=21YIeEp9ajo"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23a-1024",
      "source": "PCS",
      "trackId": 12309,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        121259
      ],
      "eventIds": [],
      "abstract": "We explore the design of situated visual links in outdoor augmented reality (AR) for connecting miniature buildings on a virtual map to their real-world counterparts. We first distill design criteria from prior work, then conduct two user studies to evaluate a set of proposed link designs to better understand users’ preferences for different design choices of the links. In two user studies we evaluated, respectively, a set of link geometries in a virtual environment and a refined AR prototype in two different outdoor environments. The studies reveal that links help in identifying buildings in the environments. Participants prefer straight rather than curved links, simple and thin links to avoid information occlusion, and links and maps aligned with their direction of view. We recommend using a consistent color with a strong contrast to the background color for all links in a scene. To improve visibility, the diameter of links should grow with distance to the viewer and optional animated stripes can be placed on links. The findings of this study have the potential to bolster the development of various situated visualization applications, such as those used in urban planning, tourism, smart agriculture, and other fields.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Australia",
              "state": "Victoria",
              "city": "Melbourne",
              "institution": "Monash University",
              "dsl": "Information Technology"
            }
          ],
          "personId": 121166
        },
        {
          "affiliations": [
            {
              "country": "Australia",
              "state": "",
              "city": "Melbourne",
              "institution": "Monash University",
              "dsl": "Faculty of Information Technology"
            }
          ],
          "personId": 121159
        },
        {
          "affiliations": [
            {
              "country": "Australia",
              "state": "WA",
              "city": "Kensington",
              "institution": "CSIRO",
              "dsl": "Data61"
            }
          ],
          "personId": 121108
        },
        {
          "affiliations": [
            {
              "country": "Australia",
              "state": "",
              "city": "Melbourne",
              "institution": "Monash University",
              "dsl": ""
            }
          ],
          "personId": 121048
        }
      ]
    },
    {
      "id": 121228,
      "typeId": 13014,
      "title": "PAWS: Personalized Arm and Wrist Movements With Sensitivity Mappings for Controller-Free Locomotion in Virtual Reality",
      "addons": {
        "Presentation": {
          "title": "PAWS: Personalized Arm and Wrist Movements With Sensitivity Mappings for Controller-Free Locomotion in Virtual Reality",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=34YjsNb7BkU"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23a-1069",
      "source": "PCS",
      "trackId": 12309,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        121259
      ],
      "eventIds": [],
      "abstract": "Virtual Reality (VR) headsets equipped with multiple cameras enable hands-only teleportation techniques without requiring any physical controller. Hands-only teleportation is an effective alternative to controllers for navigation tasks in virtual reality - allowing users to move from one point to another instantaneously. However, the current implementation of hands-only techniques does not consider users’ physical attributes (e.g., arm’s reach). Thus, a hands-only teleportation technique can lead to different user experiences based on physical attributes. We propose PAWS, a personalized arm and wrist-based teleportation technique that incorporates users’ physical attributes for improved teleportation experiences. We first evaluate different degrees of teleportation personalization with no-, partial, and full personalization. We find that full personalization offers faster locomotion – but at the cost of degraded performances with distant targets due to increased sensitivity. We hence further explore different combinations of mapping functions (e.g., sigmoid, quadratic) to personalize motor movements and find that asymmetric functions result in improved performance. Overall, our results show that PAWS helps users to navigate quickly in virtual environments.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Canada",
              "state": "British Columbia",
              "city": "Kelowna",
              "institution": "University of British Columbia",
              "dsl": ""
            }
          ],
          "personId": 121141
        },
        {
          "affiliations": [
            {
              "country": "France",
              "state": "",
              "city": "Bidart",
              "institution": "ESTIA",
              "dsl": "ESTIA Research"
            }
          ],
          "personId": 121066
        },
        {
          "affiliations": [
            {
              "country": "Canada",
              "state": "British Columbia",
              "city": "Kelowna",
              "institution": "University of British Columbia (Okanagan)",
              "dsl": "Department of Computer Science"
            }
          ],
          "personId": 121168
        },
        {
          "affiliations": [
            {
              "country": "Canada",
              "state": "British Columbia",
              "city": "Kelowna",
              "institution": "University of British Columbia",
              "dsl": ""
            }
          ],
          "personId": 121112
        }
      ]
    },
    {
      "id": 121229,
      "typeId": 13014,
      "title": "Tap to Sign: Towards using American Sign Language for text entry on smartphones",
      "addons": {
        "Presentation": {
          "title": "Tap to Sign: Towards using American Sign Language for text entry on smartphones",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=hyDtfJhe_aU"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23a-1124",
      "source": "PCS",
      "trackId": 12309,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        121861
      ],
      "eventIds": [],
      "abstract": "Soon, smartphones may be capable of allowing American Sign Language (ASL) signing and/or fingerspelling for text entry. To explore the usefulness of this approach, we compared emulated fingerspelling recognition with a virtual keyboard for 12 Deaf participants. With practice, fingerspelling is faster (42.5 wpm), potentially has fewer errors (4.02\\% corrected error rate) and higher throughput (14.2 bits/second),  and is as desired as virtual keyboard texting (31.9 wpm; 6.46\\% corrected error rate; 10.9 bits/second throughput). Our second study recruits another 12 Deaf users at the 2022 National Association for the Deaf conference to compare the walk-up usability of fingerspelling alone, signing, and virtual keyboard text entry for interacting with an emulated mobile assistant. Both signing and virtual keyboard text entry were preferred over fingerspelling.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Louisiana",
              "city": "New Orleans",
              "institution": "Tulane University",
              "dsl": "Department of Computer Science"
            }
          ],
          "personId": 121181
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "District of Columbia",
              "city": "Washington",
              "institution": "Gallaudet University",
              "dsl": "Technology Access Program"
            }
          ],
          "personId": 121102
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Missouri",
              "city": "Rochester",
              "institution": "Rochester Institute of Technology",
              "dsl": ""
            }
          ],
          "personId": 121145
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Georgia",
              "city": "Atlanta",
              "institution": "Google Research",
              "dsl": ""
            }
          ],
          "personId": 121164
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Michigan",
              "city": "Ferndale",
              "institution": "DPAN",
              "dsl": ""
            }
          ],
          "personId": 121113
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Michigan",
              "city": "Ferndale",
              "institution": "DPAN",
              "dsl": ""
            }
          ],
          "personId": 121128
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "Mountain View",
              "institution": "Google Research",
              "dsl": "Google"
            }
          ],
          "personId": 121129
        }
      ]
    },
    {
      "id": 121230,
      "typeId": 13014,
      "title": "ViGather: Inclusive Virtual Conferencing with a Joint Experience Across Traditional Screen Devices and Mixed Reality Headsets",
      "addons": {
        "Presentation": {
          "title": "ViGather: Inclusive Virtual Conferencing with a Joint Experience Across Traditional Screen Devices and Mixed Reality Headsets",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=tyUudZgeA9A"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23a-1121",
      "source": "PCS",
      "trackId": 12309,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        121861
      ],
      "eventIds": [],
      "abstract": "Teleconferencing is poised to become one of the most frequent use cases of immersive platforms, since it supports high levels of presence and embodiment in collaborative settings. On desktop and mobile platforms, teleconferencing solutions are already among the most popular apps and accumulate significant usage time---not least due to the pandemic or as a desirable substitute for air travel or commuting.\r\n\r\nIn this paper, we present ViGather, an immersive teleconferencing system that integrates users of all platform types into a joint experience via equal representation and a first-person experience. ViGather renders all participants as embodied avatars in one shared scene to establish co-presence and elicit natural behavior during collocated conversations, including nonverbal communication cues such as eye contact between participants as well as body language such as turning one's body to another person or using hand gestures to emphasize parts of a conversation during the virtual hangout. Since each user embodies an avatar and experiences situated meetings from an egocentric perspective no matter the device they join from, ViGather alleviates potential concerns about self-perception and appearance while mitigating potential `Zoom fatigue', as users' self-views are not shown. For participants in Mixed Reality, our system leverages the rich sensing and reconstruction capabilities of today's headsets. For users of tablets, laptops, or PCs, ViGather reconstructs the user's pose from the device's front-facing camera, estimates eye contact with other participants, and relates these non-verbal cues to immediate avatar animations in the shared scene.\r\n\r\nOur evaluation compared participants' behavior and impressions while videoconferencing in groups of four inside ViGather with those in Meta Horizon as a baseline for a social VR setting. Participants who participated on traditional screen devices (e.g., laptops and desktops) using ViGather reported a significantly higher sense of physical, spatial, and self-presence than when using Horizon, while all perceived similar levels of active social presence when using Virtual Reality headsets. Our follow-up study confirmed the importance of representing users on traditional screen devices as reconstructed avatars for perceiving self-presence.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Switzerland",
              "state": "",
              "city": "Zurich",
              "institution": "ETH Zürich",
              "dsl": "Department of Computer Science"
            }
          ],
          "personId": 121035
        },
        {
          "affiliations": [
            {
              "country": "Switzerland",
              "state": "",
              "city": "Zurich",
              "institution": "ETH Zürich",
              "dsl": "Department of Computer Science"
            }
          ],
          "personId": 121173
        },
        {
          "affiliations": [
            {
              "country": "Switzerland",
              "state": "",
              "city": "Zurich",
              "institution": "ETH Zürich",
              "dsl": "Department of Computer Science"
            }
          ],
          "personId": 121095
        },
        {
          "affiliations": [
            {
              "country": "Switzerland",
              "state": "",
              "city": "Zurich",
              "institution": "ETH Zürich",
              "dsl": "Department of Computer Science"
            }
          ],
          "personId": 121093
        },
        {
          "affiliations": [
            {
              "country": "Switzerland",
              "state": "",
              "city": "Zurich",
              "institution": "ETH Zürich",
              "dsl": "Department of Computer Science"
            }
          ],
          "personId": 121069
        }
      ]
    },
    {
      "id": 121231,
      "typeId": 13014,
      "title": "SensCon: Embedding Physiological Sensing into Virtual Reality Controllers",
      "addons": {
        "Presentation": {
          "title": "SensCon: Embedding Physiological Sensing into Virtual Reality Controllers",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=OsqxF7ShxnU"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23a-1022",
      "source": "PCS",
      "trackId": 12309,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        121259
      ],
      "eventIds": [],
      "abstract": "Virtual reality experiences increasingly use physiological data for virtual environment adaptations to evaluate user experience and immersion. Previous research required complex medical-grade equipment to collect physiological data, limiting real-world applicability. To overcome this, we present SensCon for skin conductance and heart rate data acquisition. To identify the optimal sensor location in the controller, we conducted a first study investigating users' controller grasp behavior. In a second study, we evaluated the performance of SensCon against medical-grade devices in six scenarios regarding user experience and signal quality. Users subjectively preferred SensCon in terms of usability and user experience. Moreover, the signal quality evaluation showed satisfactory accuracy across static, dynamic, and cognitive scenarios. Therefore, SensCon reduces the complexity of capturing and adapting the environment via real-time physiological data. By open-sourcing SensCon, we enable researchers and practitioners to adapt their virtual reality environment effortlessly. Finally, we discuss possible use cases for virtual reality-embedded physiological sensing.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Munich",
              "institution": "LMU Munich",
              "dsl": ""
            }
          ],
          "personId": 121054
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Berlin",
              "institution": "HU Berlin",
              "dsl": ""
            }
          ],
          "personId": 121184
        },
        {
          "affiliations": [
            {
              "country": "Italy",
              "state": "",
              "city": "Rovereto",
              "institution": "University of Trento",
              "dsl": "Department of Psychology and Cognitive Science"
            }
          ],
          "personId": 121151
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Munich",
              "institution": "LMU Munich",
              "dsl": ""
            }
          ],
          "personId": 121120
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Munich",
              "institution": "LMU Munich",
              "dsl": ""
            }
          ],
          "personId": 121104
        }
      ]
    },
    {
      "id": 121232,
      "typeId": 13014,
      "title": "A First Exploration on the Use of Head-Mounted Augmented Reality in the Context of the Portuguese Military",
      "addons": {
        "Presentation": {
          "title": "A First Exploration on the Use of Head-Mounted Augmented Reality in the Context of the Portuguese Military",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=CDeNCUM2Xyw"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23a-1066",
      "source": "PCS",
      "trackId": 12309,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        121259
      ],
      "eventIds": [],
      "abstract": "In this paper, we present the design and implementation of a first iteration of an augmented reality (AR) system for dismounted soldiers in the Portuguese military. We started the work via a survey of 86 members of the military to better understand their experience, needs, and preferences with current Command & Control (C2) systems. We then assessed the effects of our prototype on the performance, situational awareness, and perceived usability and workload of 13 participants from a local Commando Regiment. We compared our results to a representative baseline using a paper map and radio in a hostage extraction simulation and found that our first AR iteration, despite a short practice session, increased the quality of the information available and decreased the complexity, temporal demands, and effort required to complete the study tasks; leading to an overall decrease in perceived workload. Overall, participants described the AR experience as more user-friendly. We conclude our case study with research ideas for further iterations of our prototype.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Portugal",
              "state": "",
              "city": "Lisbon",
              "institution": "Academia Militar",
              "dsl": ""
            }
          ],
          "personId": 121040
        },
        {
          "affiliations": [
            {
              "country": "Portugal",
              "state": "",
              "city": "Lisbon",
              "institution": "Instituto Universitário Militar",
              "dsl": ""
            }
          ],
          "personId": 121062
        },
        {
          "affiliations": [
            {
              "country": "Portugal",
              "state": "",
              "city": "Lisbon",
              "institution": "Instituto Superior Técnico, University of Lisbon",
              "dsl": "ITI / LARSyS"
            }
          ],
          "personId": 121085
        }
      ]
    },
    {
      "id": 121233,
      "typeId": 13014,
      "title": "Effects of Urgency and Cognitive Load on Modality Usage in Highly Automated Vehicles",
      "addons": {},
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23a-1088",
      "source": "PCS",
      "trackId": 12309,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        121860
      ],
      "eventIds": [],
      "abstract": "In highly automated vehicles, passengers can engage in non-driving-related activities. Additionally, the technical advancement allows for novel interaction possibilities such as voice, gesture, gaze, touch, or multimodal interaction, both to refer to in-vehicle and outside objects (e.g., thermostat or restaurant). \r\nThis interaction can be characterized by levels of urgency (e.g., based on late detection of objects) and cognitive load (e.g., because of watching a movie or working). \r\nTherefore, we implemented a Virtual Reality simulation and conducted a within-subjects study with N=11 participants evaluating the effects of urgency and cognitive load on modality usage in automated vehicles.\r\nWe found that while all modalities were possible to use, participants relied on touch the most. This was followed by gaze, especially for external referencing. This work helps to further understand multimodal interaction and the requirements this poses on natural interaction in (automated) vehicles. ",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Ulm",
              "institution": "Ulm University",
              "dsl": "Institute of Media Informatics"
            }
          ],
          "personId": 121198
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Ulm",
              "institution": "Universität Ulm",
              "dsl": ""
            }
          ],
          "personId": 121039
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Ulm",
              "institution": "Ulm University",
              "dsl": "Institute of Media Informatics"
            }
          ],
          "personId": 121079
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Ulm",
              "institution": "University of Ulm",
              "dsl": ""
            }
          ],
          "personId": 121146
        }
      ]
    },
    {
      "id": 121234,
      "typeId": 13014,
      "title": "UnifiedSense: Enabling Without-Device Gesture Interactions Using Over-the-shoulder Training Between Redundant Wearable Sensors",
      "addons": {
        "Presentation": {
          "title": "UnifiedSense: Enabling Without-Device Gesture Interactions Using Over-the-shoulder Training Between Redundant Wearable Sensors",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=rvb1-wz2lS4"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23a-1067",
      "source": "PCS",
      "trackId": 12309,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        121862
      ],
      "eventIds": [],
      "abstract": "Wearable devices allow quick and convenient interactions for controlling mobile computers. However, these interactions are often device-dependent, and users cannot control devices in a way they are familiar with if they do not wear the same wearable device. This paper proposes a new method, UnifiedSense, to enable device-dependent gestures even when the device that detects such gestures is missing by utilizing sensors on other wearable devices. UnifiedSense achieves this without explicit gesture training for different devices, by training its recognition model while users naturally perform gestures. The recognizer uses the gestures detected on the primary device (i.e., a device that reliably detects gestures) as labels for training samples and collects sensor data from all other available devices on the user. We conducted a technical evaluation with data collected from 15 participants with four types of wearable devices. It showed that UnifiedSense could correctly recognize 5 gestures (5 gestures × 5 configurations) with an accuracy of 90.9% (SD = 1.9%) without the primary device present.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Virginia",
              "city": "Charlottesville",
              "institution": "University of Virginia",
              "dsl": "Department of Computer Science"
            }
          ],
          "personId": 121188
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Virginia",
              "city": "Charlottesville",
              "institution": "University of Virginia",
              "dsl": "Department of Computer Science"
            }
          ],
          "personId": 121116
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Virginia",
              "city": "Charlottesville",
              "institution": "University of Virginia",
              "dsl": "Department of Computer Science"
            }
          ],
          "personId": 121154
        }
      ]
    },
    {
      "id": 121235,
      "typeId": 13014,
      "title": "Adapting Visual Complexity Based on Electrodermal Activity Improves Performance in Virtual Reality",
      "addons": {
        "Presentation": {
          "title": "Adapting Visual Complexity Based on Electrodermal Activity Improves Performance in Virtual Reality",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=Yi0Gso_WnGc"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23a-1045",
      "source": "PCS",
      "trackId": 12309,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        121863
      ],
      "eventIds": [],
      "abstract": "Biocybernetic loops encompass users' state detection and system adaptation based on physiological signals. Current adaptive systems limit the adaptation to task features such as task difficulty or multitasking demands. However, virtual reality allows the manipulation of task-irrelevant elements in the environment. We present a physiologically adaptive system that adjusts the virtual environment based on physiological arousal, i.e., electrodermal activity. We conducted a user study with our adaptive system in social virtual reality to verify improved performance. Here, participants completed an n-back task, and we adapted the visual complexity of the environment by changing the number of non-player characters. Our results show that an adaptive virtual reality can control users' comfort, performance, and workload by adapting the visual complexity based on physiological arousal. Thus, our physiologically adaptive system improves task performance and perceived workload. Finally, we embed our findings in physiological computing and discuss applications in various scenarios.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Munich",
              "institution": "LMU Munich",
              "dsl": ""
            }
          ],
          "personId": 121054
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Munich",
              "institution": "LMU Munich",
              "dsl": ""
            }
          ],
          "personId": 121132
        },
        {
          "affiliations": [
            {
              "country": "Finland",
              "state": "",
              "city": "Helsinki",
              "institution": "Aalto University",
              "dsl": ""
            }
          ],
          "personId": 121098
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Munich",
              "institution": "LMU Munich",
              "dsl": ""
            }
          ],
          "personId": 121104
        }
      ]
    },
    {
      "id": 121236,
      "typeId": 13014,
      "title": "Please, Go Ahead! Fostering Prosocial Driving with Sympathy-Eliciting Automated Vehicle External Displays",
      "addons": {
        "Presentation": {
          "title": "Please, Go Ahead! Fostering Prosocial Driving with Sympathy-Eliciting Automated Vehicle External Displays",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=B3G_G_m574E"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23a-1152",
      "source": "PCS",
      "trackId": 12309,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        121860
      ],
      "eventIds": [],
      "abstract": "Road traffic is strongly regulated, however informal communication is essential whenever formal rules are flexibly treated. Consequently, conflict-avoidant automated vehicles (AVs) can be disadvantaged when humans do not behave prosocially towards them. This can lead to disruptions of mixed traffic, where human and automated driving co-exists. Equipping AVs with sympathy-eliciting external Human-Machine Interfaces (eHMI) mimicking informal communication cues could mitigate this challenge by fostering the prosocial behavior of drivers. This work contributes video vignettes that are experimentally validated in an online survey (N=90). While we found participants to not behave differently towards human-controlled and baseline automated vehicles, eHMIs were potent in eliciting sympathy and encouraged yielding behavior. This effect was more pronounced when the interface signaled an urgent situation or indicated prolonged waiting times. Non-yielding behavior was rationalized based on priority rules. These results emphasize how fostering prosocial behavior in traffic can be achieved via sympathy-eliciting external displays.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "Germany",
              "city": "Oldenburg",
              "institution": "University Oldenburg",
              "dsl": "Media Informatics and Multimedia Systems"
            }
          ],
          "personId": 121075
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Oldenburg",
              "institution": "Carl von Ossietzky University of Oldenburg",
              "dsl": "Media Informatics and Multimedia Systems"
            }
          ],
          "personId": 121047
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Oldenburg",
              "institution": "OFFIS - Institute for Information Technology",
              "dsl": ""
            }
          ],
          "personId": 121203
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Oldenburg",
              "institution": "University of Oldenburg",
              "dsl": "Media Informatics and Multimedia Systems"
            }
          ],
          "personId": 121175
        }
      ]
    },
    {
      "id": 121237,
      "typeId": 13014,
      "title": "Frappé: An Ultra Lightweight Mobile UI Framework for Rapid API-based Prototyping and Environmental Deployment",
      "addons": {
        "Presentation": {
          "title": "Frappé: An Ultra Lightweight Mobile UI Framework for Rapid API-based Prototyping and Environmental Deployment",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=71uQOvhyJ8Y"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23a-1130",
      "source": "PCS",
      "trackId": 12309,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        121862
      ],
      "eventIds": [],
      "abstract": "QR codes have been used as an inexpensive means to connect users to digital platforms such as websites and mobile applications. However, despite their ubiquity, QR codes are limited in purpose and can only redirect users to the URL contained within it, thereby making their use heavily network dependent which can be unsuitable for use in ephemeral scenarios and areas with limited connectivity. In this paper, we introduce Frappé, a framework capable of deploying ultra lightweight UIs to mobile devices directly through QR codes, without requiring any network connectivity. This is achieved by decomposing the UI into metadata and storing it inside the QR code, while offloading the UI functionality to API calls. We also introduce enFrappé, a WYSIWYG tool for building Frappé UIs. We demonstrate the lightweight nature of our framework through a technical evaluation, whereas the usability of our UI builder tool is demonstrated through a user study.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Virginia",
              "city": "Charlottesville",
              "institution": "University of Virginia",
              "dsl": "Department of Computer Science"
            }
          ],
          "personId": 121116
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Virginia",
              "city": "Charlottesville",
              "institution": "University of Virginia",
              "dsl": "Department of Computer Science"
            }
          ],
          "personId": 121154
        }
      ]
    },
    {
      "id": 121238,
      "typeId": 13014,
      "title": "A Minimalistic Approach to Predict and Understand the Relation of App Usage with Students’ Academic Performance",
      "addons": {},
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23a-1097",
      "source": "PCS",
      "trackId": 12309,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        121863
      ],
      "eventIds": [],
      "abstract": "Due to usage of self-reported data which may contain biasness, the existing studies may not unveil the exact relation between academic grades and app categories such as Video. Additionally, the existing systems’ requirement for data of prolonged period to predict grades may not facilitate early intervention to improve it.  Thus, we presented an app that retrieves past 7 days’ actual app usage data within a second (Mean=0.31s, SD=1.1s). Our analysis on 124 Bangladeshi students’ real-time data demonstrates app usage sessions have a significant (p<0.05) negative association with CGPA. However, the Productivity and Books categories have a significant positive association whereas Video has a significant negative association. Moreover, the high and low CGPA holders have significantly different app usage behavior. Leveraging only the instantly accessed data, our machine learning model predicts CGPA within ±0.36 of the actual CGPA. We discuss the design implications that can be potential for students to improve grades.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Bangladesh",
              "state": "",
              "city": "Dhaka",
              "institution": "North South University",
              "dsl": "Design Inclusion and Access Lab"
            }
          ],
          "personId": 121211
        },
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "Cardiff",
              "city": "Cardiff",
              "institution": "PhD Student and Researcher, Cardiff University",
              "dsl": "School of Computer Science and Informatics"
            }
          ],
          "personId": 121077
        },
        {
          "affiliations": [
            {
              "country": "Canada",
              "state": "British Columbia",
              "city": "Kelowna",
              "institution": "University of British Columbia",
              "dsl": "Computer Science"
            }
          ],
          "personId": 121153
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New York",
              "city": "Rochester",
              "institution": "University of Rochester",
              "dsl": "University of Rochester, ROCHCI "
            }
          ],
          "personId": 121105
        },
        {
          "affiliations": [
            {
              "country": "Bangladesh",
              "state": "Dhaka",
              "city": "Dhaka",
              "institution": "North South University",
              "dsl": "Department of Electrical and Computer Engineering"
            }
          ],
          "personId": 121052
        }
      ]
    },
    {
      "id": 121239,
      "typeId": 13014,
      "title": "NaCanva: Exploring and Enabling the Nature-Inspired Creativity for Children",
      "addons": {},
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23a-1032",
      "source": "PCS",
      "trackId": 12309,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        121864
      ],
      "eventIds": [],
      "abstract": "Nature has been a bountiful source of materials, replenishment, inspiration, and creativity. Nature collage, as a crafting technique, offers children a fun and educational way to explore nature and express their creativity. However, the collection of raw material has been limited to static objects like leaves, ignoring inspiration from nature’s sounds and dynamic elements such as babbling creeks. To address this limitation, we have developed a mobile application with the aim of encouraging children’s creativity through renewed material collection and careful observation in nature. To explore the possibility of this approach, we conducted a formative study with children (N=20) and a design workshop with experts (N=6). With the results of these studies, we formulate NaCanva, an AI-assisted multi-modal collage creation system for children. Drawing upon the interactive relationship between children and nature, NaCanva facillitates a multi-modal material collection, including images, sound, and videos, which differs our system from traditional collages. We validated this system with a between-subject user study (N =30), and the results indicated that NaCanva enhances children’s multidimensional observation and engagement with nature, thereby unleashing their creativity in the creation of nature collages.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Beijing",
              "institution": "Tsinghua University",
              "dsl": ""
            }
          ],
          "personId": 121201
        },
        {
          "affiliations": [
            {
              "country": "China",
              "state": "Zhejiang",
              "city": "Hangzhou",
              "institution": "Zhejiang University",
              "dsl": "State Key Lab of CAD&CG"
            }
          ],
          "personId": 121134
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Washington",
              "city": "Seattle",
              "institution": "University of Washington",
              "dsl": "Human-Centered Design and Engineering"
            }
          ],
          "personId": 121185
        },
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Hangzhou",
              "institution": "Zhejiang University",
              "dsl": ""
            }
          ],
          "personId": 121076
        },
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Hangzhou",
              "institution": "Zhejiang University",
              "dsl": ""
            }
          ],
          "personId": 121103
        },
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Hangzhou",
              "institution": "Zhejiang University",
              "dsl": "State Key Lab of CAD&CG"
            }
          ],
          "personId": 121126
        },
        {
          "affiliations": [
            {
              "country": "China",
              "state": "Zhejiang",
              "city": "Hangzhou",
              "institution": "Zhejiang University",
              "dsl": "State Key Lab of CAD&CG"
            }
          ],
          "personId": 121212
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "Los Angeles",
              "institution": "UCLA",
              "dsl": "HCI Research"
            }
          ],
          "personId": 121197
        },
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Hangzhou",
              "institution": "Zhejiang University",
              "dsl": ""
            }
          ],
          "personId": 121061
        },
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Beijing",
              "institution": "Tsinghua University",
              "dsl": ""
            }
          ],
          "personId": 121084
        }
      ]
    },
    {
      "id": 121240,
      "typeId": 13014,
      "title": "Don’t Forget to Disinfect: Understanding Technology-Supported Hand Disinfection Stations",
      "addons": {},
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23a-1050",
      "source": "PCS",
      "trackId": 12309,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        121864
      ],
      "eventIds": [],
      "abstract": "The global COVID-19 pandemic created a constant need for hand disinfection. While it is still essential, disinfection use is declining with the decrease in perceived personal risk (e.g., as a result of vaccination). Thus this work explores using different visual cues to act as reminders for hand disinfection. We investigated different public display designs using (1) paper-based only, adding (2) screen-based, or (3) projection-based visual cues. To gain insights into these designs, we conducted semi-structured interviews with passersby (N=30). Our results show that the screen- and projection-based conditions were perceived as more engaging. Furthermore, we conclude that the disinfection process consists of four steps that can be supported: drawing attention to the disinfection station, supporting the (subconscious) understanding of the interaction, motivating hand disinfection, and performing the action itself. We conclude with design implications for technology-supported disinfection.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Essen",
              "institution": "University of Duisburg-Essen",
              "dsl": "HCI Group"
            }
          ],
          "personId": 121114
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Essen",
              "institution": "University of Duisburg-Essen",
              "dsl": "HCI Group"
            }
          ],
          "personId": 121130
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Essen",
              "institution": "University of Duisburg-Essen",
              "dsl": "Human Computer Interaction"
            }
          ],
          "personId": 121147
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Essen",
              "institution": "University of Duisburg-Essen",
              "dsl": "HCI Group"
            }
          ],
          "personId": 121071
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Essen",
              "institution": "University of Duisburg-Essen",
              "dsl": "HCI Group"
            }
          ],
          "personId": 121087
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Essen",
              "institution": "University of Duisburg-Essen",
              "dsl": "HCI Group"
            }
          ],
          "personId": 121063
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Essen",
              "institution": "University of Duisburg-Essen",
              "dsl": "HCI Group"
            }
          ],
          "personId": 121179
        }
      ]
    },
    {
      "id": 121241,
      "typeId": 13014,
      "title": "GeShort: One-Handed Mobile Text Editing and Formatting with Gestural Shortcuts and a Floating Clipboard",
      "addons": {
        "Presentation": {
          "title": "GeShort: One-Handed Mobile Text Editing and Formatting with Gestural Shortcuts and a Floating Clipboard",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=DJFiB-1zzQ8"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23a-1091",
      "source": "PCS",
      "trackId": 12309,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        121862
      ],
      "eventIds": [],
      "abstract": "GeShort is a novel method for one-handed text editing and formatting on mobile devices. It uses simple rules to facilitate direct cursor positioning, gestural shortcuts inspired by keyboard hotkeys for editing and formatting, and a floating clipboard to enable delayed, repeated, and block editing. A comparison between GeShort and the default Google keyboard revealed that users perform editing and formatting tasks about 11% and 22% faster, respectively, with GeShort. This is achieved by significantly reducing selection time by 11% and action time by 17%. A second study comparing the clipboard features of the two methods revealed that users perform advanced editing tasks 34% faster with GeShort. Besides, participants find GeShort less onerous in mental demand, physical demand, and effort, which likely contribute to the overall performance gain. They also perceive GeShort as faster and easier to use, feel that its functions are better integrated, thus want to keep using it on their devices.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "Merced",
              "institution": "University of California, Merced",
              "dsl": "Inclusive Interaction Lab"
            }
          ],
          "personId": 121096
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "Merced",
              "institution": "University of California, Merced",
              "dsl": "Inclusive Interaction Lab"
            }
          ],
          "personId": 121190
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "Merced",
              "institution": "University of California, Merced",
              "dsl": "Inclusive Interaction Lab"
            }
          ],
          "personId": 121135
        }
      ]
    },
    {
      "id": 121242,
      "typeId": 13014,
      "title": "RingVKB: A Ring-Shaped Virtual Keyboard Using Low-Cost IMU",
      "addons": {
        "Presentation": {
          "title": "RingVKB: A Ring-Shaped Virtual Keyboard Using Low-Cost IMU",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=HvKyOVs73l8"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23a-1138",
      "source": "PCS",
      "trackId": 12309,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        121862
      ],
      "eventIds": [],
      "abstract": "Wearable devices have been important components for ubiquitous computing. However, text input remains challenging on wearables due to the lack of a physical keyboard. In this paper, we propose a novel ring-shaped virtual keyboard system named RingVKB for convenient text input using low-cost IMUs available on any wearables. At the core of RingVKB are two novel designs: 1) A circular keyboard layout with 12 equal sectors, which assembles all common keys on classical keyboards while allowing users to type with only one finger effectively, and 2) an error control algorithm that calculates the relative displacement of keystrokes from the noisy IMU sensor data. The two components, coupled together, enable high-accuracy and efficient text input for ubiquitous scenarios. We implement RingVKB using a small device consisting of a microcontroller and a MEMS sensor, which can be attached to the user's index finger. Experimental results show that RingVKB can effectively improve the relative displacement estimation accuracy, and achieves an overall keystroke recognition accuracy of 93% for 25 key positions. A user study also shows that RingVKB is easy to learn and use. Using only low-cost IMU sensors, RingVKB provides a virtual keyboard solution that can be widely adopted on wearables.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Guangzhou",
              "institution": "South China University of Technology",
              "dsl": ""
            }
          ],
          "personId": 121195
        },
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Guangzhou",
              "institution": "South China University of Technology",
              "dsl": ""
            }
          ],
          "personId": 121042
        },
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Hong Kong",
              "institution": "University of Hong Kong",
              "dsl": ""
            }
          ],
          "personId": 121111
        }
      ]
    },
    {
      "id": 121243,
      "typeId": 13014,
      "title": "A Mobile Augmented Reality App for Creating, Controlling, Recommending Automations in Smart Homes",
      "addons": {
        "Presentation": {
          "title": "A Mobile Augmented Reality App for Creating, Controlling, Recommending Automations in Smart Homes",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=GYvTjrYeLJU"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23a-1117",
      "source": "PCS",
      "trackId": 12309,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        121259
      ],
      "eventIds": [],
      "abstract": "Automations in the context of smart homes have been adopted more and more frequently; thus, users should be able to control them and create automations most suitable to their needs. Current solutions for this purpose are based on visual apps with conceptual representations of possible automation elements. However, they tend to be static, abstract, and detached from the user’s real context. In this paper, we propose a novel solution based on mobile augmented reality, which provides situated, dynamic representations associated with the physical objects available in the current users’ context while they are freely moving about. It allows direct interaction with the objects of interest, monitoring nearby objects' automations while moving, and creating new automations or modifying existing ones. It also supports users with recommendations of object and service configurations relevant to complete the editing of the new automations. The paper also reports on a user test, which provided positive feedback.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Italy",
              "state": "",
              "city": "Pisa",
              "institution": "CNR-ISTI",
              "dsl": "HIIS Laboratory"
            },
            {
              "country": "Italy",
              "state": "",
              "city": "Pisa",
              "institution": "University of Pisa",
              "dsl": "Department of Information Engineering"
            }
          ],
          "personId": 121183
        },
        {
          "affiliations": [
            {
              "country": "Italy",
              "state": "",
              "city": "Pisa",
              "institution": "CNR-ISTI",
              "dsl": "HIIS Laboratory"
            }
          ],
          "personId": 121073
        }
      ]
    },
    {
      "id": 121244,
      "typeId": 13014,
      "title": "Imperfect Surrogate Users: Understanding Performance Implications of Augmentative and Alternative Communication Systems through Bounded Rationality, Human Error, and Interruption Modeling",
      "addons": {
        "Presentation": {
          "title": "Imperfect Surrogate Users: Understanding Performance Implications of Augmentative and Alternative Communication Systems through Bounded Rationality, Human Error, and Interruption Modeling",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=JoaVJQlOxxs"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23a-1114",
      "source": "PCS",
      "trackId": 12309,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        121862
      ],
      "eventIds": [],
      "abstract": "Nonspeaking individuals with motor disabilities frequently rely on augmentative and alternative communication (AAC) systems that allow users to communicate through a text entry interface coupled with a speech synthesizer. Such systems are notoriously difficult to evaluate with end-users. However, recent research has proposed envelope analysis as a method to estimate text entry rates and keystroke savings by simulating the interaction of an expert surrogate user entering sentences on a conceptual word-predictive text entry system. While only a part of the evaluation process of an AAC system, this method enables AAC designers to benefit from quantitative insights early on in the design process. This paper extends prior work by (1) demonstrating how to incorporate natural language generation, such as sentence generation, in such analyses; (2) presenting a model of an imperfect surrogate user that incorporates bounded rationality, human error, and interruptions to provide a more realistic simulation of text entry behavior; and (3) demonstrating how to estimate model parameters by observing users' actual typing behavior. We validate the model with data collected from eight participants using an AAC system on a touchscreen.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "Cambridge",
              "city": "University of Cambridge",
              "institution": "Department of Engineering",
              "dsl": ""
            }
          ],
          "personId": 121055
        },
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "",
              "city": "Cambridge",
              "institution": "University of Cambridge",
              "dsl": "Department of Engineering"
            }
          ],
          "personId": 121080
        }
      ]
    },
    {
      "id": 121245,
      "typeId": 13014,
      "title": "VR-Hiking: Physical Exertion Benefits Mindfulness and Positive Emotions in Virtual Reality",
      "addons": {
        "Presentation": {
          "title": "VR-Hiking: Physical Exertion Benefits Mindfulness and Positive Emotions in Virtual Reality",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=hl4Ej3oxtcY"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23a-1037",
      "source": "PCS",
      "trackId": 12309,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        121861
      ],
      "eventIds": [],
      "abstract": "Exploring the great outdoors offers physical and mental health benefits. Hiking is healthy, provides a sense of accomplishment, and offers an opportunity to relax. However, a nature trip is not always possible, and there is a lack of evidence showing how these beneficial experiences can be replicated in Virtual Reality (VR). In response, we recruited (N=24) participants to explore a virtual mountain landscape in a within-subjects study with different levels of exertion: walking, using a chairlift, and teleporting. We found that physical exertion when walking produced significantly more positive emotions and mindfulness than other conditions. Our research shows that physically demanding outdoor activities in VR can be beneficial for the user and that the achievement of hiking up a virtual mountain on a treadmill positively impacts wellbeing. We demonstrate how physical exertion can be used to add mindfulness and positive affect to VR experiences and discuss consequences for VR designers.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Munich",
              "institution": "LMU Munich",
              "dsl": ""
            },
            {
              "country": "Germany",
              "state": "",
              "city": "Munich",
              "institution": "Munich Center for Machine Learning (MCML)",
              "dsl": ""
            }
          ],
          "personId": 121086
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Munich",
              "institution": "LMU Munich",
              "dsl": ""
            }
          ],
          "personId": 121100
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Munich",
              "institution": "LMU Munich",
              "dsl": ""
            }
          ],
          "personId": 121199
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Munich",
              "institution": "LMU Munich",
              "dsl": ""
            }
          ],
          "personId": 121191
        },
        {
          "affiliations": [
            {
              "country": "Sweden",
              "state": "",
              "city": "Gothenburg",
              "institution": "Chalmers University of Technology",
              "dsl": ""
            }
          ],
          "personId": 121101
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Munich",
              "institution": "LMU Munich",
              "dsl": ""
            }
          ],
          "personId": 121036
        }
      ]
    },
    {
      "id": 121246,
      "typeId": 13014,
      "title": "VPRNet: Voxel-based Efficient and Partial-to-Partial Point Cloud Registration on Mobile Devices",
      "addons": {
        "Presentation": {
          "title": "VPRNet: Voxel-based Efficient and Partial-to-Partial Point Cloud Registration on Mobile Devices",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=QP25A7qYCeM"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23a-1112",
      "source": "PCS",
      "trackId": 12309,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        121864
      ],
      "eventIds": [],
      "abstract": "With the popularity of embedded devices such as LIDAR sensors and depth cameras, the resulting point clouds become the main data format for representing the 3D world and spawn various smart mobile applications. A key technology for enabling these applications to furnish high-quality services is real-time point cloud registration on mobile devices, which synthesizes a complete model or a large-scale scene from multiple partial scans. It aims to deliver increasing sensing range, faster 3D reconstruction and more robust robot navigation. Unfortunately, the performance of these applications is limited by the scale and partial loss of raw point cloud frame. The existing solutions for point cloud registration are difficult to deploy on mobile devices due to their complex models and assumptions about point cloud pairs with large overlap, which cause significant delay and inaccuracy. This paper proposes VPRNet - the first voxel-based registration solution that can achieve real-time partial-to-partial registration with competitive registration quality while being more advantageous for large-scale point clouds on mobile devices. We conduct real-world experiments and extensive simulations cross various datasets and platforms to validate the efficacy of VPRNet and further compare the performance with state-of-the-art approaches.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Xi'an, Shaanxi",
              "institution": "Northwestern Polytechnical University",
              "dsl": ""
            }
          ],
          "personId": 121178
        },
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Xi'an",
              "institution": "Northwestern Polytechnical University",
              "dsl": ""
            }
          ],
          "personId": 121059
        },
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Xi'an",
              "institution": "Northwestern Polytechnical University",
              "dsl": ""
            }
          ],
          "personId": 121107
        },
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "xian",
              "institution": "northwestern polytechnical univ.",
              "dsl": ""
            }
          ],
          "personId": 121200
        }
      ]
    },
    {
      "id": 121247,
      "typeId": 13014,
      "title": "An empirical comparison of Moderated and Unmoderated Gesture Elicitation Studies on soft surfaces and objects for smart home control.",
      "addons": {
        "Presentation": {
          "title": "An empirical comparison of Moderated and Unmoderated Gesture Elicitation Studies on soft surfaces and objects for smart home control.",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=w7xRk0BLLic"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23a-1156",
      "source": "PCS",
      "trackId": 12309,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        121863
      ],
      "eventIds": [],
      "abstract": "Conducting gesture elicitation studies (GES) in personal spaces such as smart homes is crucial to achieving high ecological validity of elicited gestures.\r\nHowever, supervising such studies is considered intrusive and negatively affects the results' quality.\r\nThe alternative is to conduct unsupervised GES under similar conditions, but more side-by-side comparisons documenting the similarities and differences between both approaches are necessary.\r\nConsequently, we need more data describing the preferred approach and whether the differences or similarities in the results are so significant to cause concern.\r\nThis research distributed a DIY observation kit, which 30 participants assembled and used to propose gestures for controlling elements in a smart living room using a pillow’s surface, with and without supervision.\r\nOur results show that gestures from supervised and unsupervised studies differ in quantity and max-consensus but not in gesture Agreement Scores. Our results also show that participants preferred conducting unsupervised studies but proposed fewer gesture sets in this condition.\r\n",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Oldenburg",
              "institution": "University of Oldenburg",
              "dsl": "Media Informatics and Multimedia Systems Group"
            }
          ],
          "personId": 121053
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Oldenburg",
              "institution": "University of Oldenburg",
              "dsl": ""
            }
          ],
          "personId": 121167
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Oldenburg ",
              "institution": "University of Oldenburg",
              "dsl": ""
            }
          ],
          "personId": 121044
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Oldenburg",
              "institution": "University of Oldenburg",
              "dsl": ""
            }
          ],
          "personId": 121189
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Oldenburg",
              "institution": "University of Oldenburg",
              "dsl": "Media Informatics and Multimedia Systems"
            }
          ],
          "personId": 121175
        }
      ]
    },
    {
      "id": 121248,
      "typeId": 13014,
      "title": "A Mixed-Method Exploration into the Mobile Phone Rabbit Hole",
      "addons": {
        "Presentation": {
          "title": "A Mixed-Method Exploration into the Mobile Phone Rabbit Hole",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=UMGMCxZ4cVE"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23a-1035",
      "source": "PCS",
      "trackId": 12309,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        121861
      ],
      "eventIds": [],
      "abstract": "Smartphones provide various functions supporting users in their daily lives. However, the temptation of getting distracted and tuning out is high leading to so-called rabbit holes. To quantify rabbit hole behavior, we developed an Android tracking application that collects smartphone usage enriched with experience sampling questionnaires. We analyzed 14,395 smartphone use sessions from 21 participants, collected over two weeks, showing that rabbit hole sessions are significantly longer and contain more user interaction, revealing a certain level of restlessness in use. The context of rabbit hole sessions and subjective results revealed different triggers for spending more time on the phone. Next, we conduct an expert focus group (N=6) to put the gained insights into perspective and formulate a definition of the mobile phone rabbit hole. Our results form the foundation for predicting and communicating the mobile phone rabbit hole, especially when prolonged smartphone use results in regret.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Munich",
              "institution": "LMU Munich",
              "dsl": ""
            }
          ],
          "personId": 121037
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Munich",
              "institution": "LMU Munich",
              "dsl": ""
            }
          ],
          "personId": 121170
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Munich",
              "institution": "LMU Munich",
              "dsl": ""
            }
          ],
          "personId": 121043
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Munich",
              "institution": "LMU Munich",
              "dsl": ""
            }
          ],
          "personId": 121104
        }
      ]
    },
    {
      "id": 121249,
      "typeId": 13014,
      "title": "SyncLabeling: A Synchronized Audio Segmentation Interface for Mobile Devices",
      "addons": {
        "Presentation": {
          "title": "SyncLabeling: A Synchronized Audio Segmentation Interface for Mobile Devices",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=S8tiZlxGcQM"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23a-1058",
      "source": "PCS",
      "trackId": 12309,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        121864
      ],
      "eventIds": [],
      "abstract": "Manual audio segmentation is a time-consuming process, especially when there is more than one sound playing simultaneously that needs to be segmented and annotated (e.g., target and background sounds). In conventional audio annotation interfaces, users need to repeatedly pause and replay the audio to complete an overlap segmentation task, which is very inefficient. In this paper, we propose “SyncLabeling,” a synchronized audio segmentation interface for smartphones that allows users to segment and annotate two overlapping sounds in a single audio stream at a time using a game-like labeling interface on mobile devices. We conducted a user study to compare the proposed SyncLabeling interface with a conventional audio annotation interface on four types of audio segmentation tasks. The results showed that the proposed interface is much more efficient than the conventional interface (2.4× faster) under comparable annotation accuracy in most tasks. In addition, more than half of the participants enjoyed using the proposed SyncLabeling interface and showed willingness to use it. ",
      "authors": [
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Jilin",
              "institution": "Jilin University",
              "dsl": ""
            }
          ],
          "personId": 121202
        },
        {
          "affiliations": [
            {
              "country": "Japan",
              "state": "",
              "city": "Tokyo",
              "institution": "The University of Tokyo",
              "dsl": ""
            }
          ],
          "personId": 121186
        },
        {
          "affiliations": [
            {
              "country": "China",
              "state": "Jilin",
              "city": "Changchun",
              "institution": "Jilin University",
              "dsl": ""
            }
          ],
          "personId": 121194
        },
        {
          "affiliations": [
            {
              "country": "Japan",
              "state": "",
              "city": "Tokyo",
              "institution": "The University of Tokyo",
              "dsl": ""
            }
          ],
          "personId": 121067
        }
      ]
    },
    {
      "id": 121250,
      "typeId": 13014,
      "title": "Designing for Collaborative Non-Driving Related Activities in Future Cars: Fairness and Team Performance",
      "addons": {},
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23a-1135",
      "source": "PCS",
      "trackId": 12309,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        121860
      ],
      "eventIds": [],
      "abstract": "With the gradual transition towards assisted and automated driving, the car will transform into a more social environment where passengers and drivers engage in Non-Driving-Related Activities (NDRA). To support collaboration among occupants in future vehicles, research suggests interactive systems controlled by several users at once. In this paper, we explore five concepts for the collaborative performance of NDRA with the use-case of music playlist creation. While prior work investigated the effect on social connectedness, we expand insights towards team performance and fairness. Results from a mixed-subject experiment (N=27) show that the concepts have major consequences on team performance and fairness. Certain concepts can promote or hinder coordination effectiveness and, in turn, impact intra-vehicular collaboration. Our observations also indicate that fairness is key to fostering social collaboration in AVs, while it does not naturally define a high team performance. Subsequently, we provide recommendations to guide future designs of collaborative NDRAs in vehicles.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Netherlands",
              "state": "",
              "city": "Eindhoven",
              "institution": "Eindhoven University of Technology",
              "dsl": ""
            },
            {
              "country": "Austria",
              "state": "",
              "city": "Neumarkt",
              "institution": "ruwido austria gmbh",
              "dsl": ""
            }
          ],
          "personId": 121142
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New York",
              "city": "New York",
              "institution": "Cornell Tech",
              "dsl": ""
            }
          ],
          "personId": 121091
        },
        {
          "affiliations": [
            {
              "country": "Netherlands",
              "state": "",
              "city": "Eindhoven",
              "institution": "Eindhoven University of Technology",
              "dsl": ""
            }
          ],
          "personId": 121149
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Freiberg",
              "institution": "TU Bergakademie Freiberg",
              "dsl": ""
            }
          ],
          "personId": 121136
        },
        {
          "affiliations": [
            {
              "country": "Netherlands",
              "state": "",
              "city": "Eindhoven",
              "institution": "Eindhoven University of Technology",
              "dsl": ""
            },
            {
              "country": "Austria",
              "state": "",
              "city": "Neumarkt",
              "institution": "ruwido Austria gmbh",
              "dsl": ""
            }
          ],
          "personId": 121155
        }
      ]
    },
    {
      "id": 121251,
      "typeId": 13014,
      "title": "Senior Technology Learning Preferences Model for Mobile Technology",
      "addons": {
        "Presentation": {
          "title": "Senior Technology Learning Preferences Model for Mobile Technology",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=lVTzS88ZM2I"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23a-1176",
      "source": "PCS",
      "trackId": 12309,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        121861
      ],
      "eventIds": [],
      "abstract": "Far more older adults are using mobile devices now than a decade ago. However, the applications they use continue to lag in depth (features) and breadth (diversity). Despite the large body of research on designing technology with older adults and identifying their adoption difficulties, we know little about how older users prefer to learn or troubleshoot mobile technology following an initial adoption and ownership. In this paper, we first review the existing models of technology adoption by older adults that consider learning as a factor and discuss their limitations. Then we interview older adults who use mobile technology (n = 23) and younger adults who help them (n = 17), to identify how older adults prefer to learn and troubleshoot nowadays.  Our participants represent three different cultures, North American, South Asian, and Middle Eastern. Findings suggest that in addition to mobile device proficiency, older adults' technology identity---different from their attitude toward technology---determines their learning preferences. We identify two types of learning preferences: self-exploration and social learning, and two types of support, general and social. Social support plays a role in both social learning and learning by self-exploration. Finally, we propose the senior technology learning preferences model for mobile technology (STELE) to describe how different learning preferences and support types influence older adults' mobile technology acceptance and use.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Illinois",
              "city": "Chicago",
              "institution": "University of Illinois at Chicago",
              "dsl": "Computer Science"
            }
          ],
          "personId": 121050
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Illinois",
              "city": "Chicago",
              "institution": "University of Illinois at Chicago",
              "dsl": "Computer Science"
            }
          ],
          "personId": 121156
        }
      ]
    },
    {
      "id": 121252,
      "typeId": 13014,
      "title": "The Loop and How to Break It: Investigating Infinite Scrolling Behaviour in Social Media Applications and Reasons to Stop",
      "addons": {},
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23a-1077",
      "source": "PCS",
      "trackId": 12309,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        121861
      ],
      "eventIds": [],
      "abstract": "Today's social media (SM) platforms are toolkits consisting of features with different use cases, some strongly related to habitual and regretful use. Especially Infinite Scrolling (IS) has been reported to make users feel like they are being caught in a loop, regretfully elongating SM sessions. We investigated and defined this loop while unveiling the processes that make users break it. Based on a one-week-long field study (N=46), we unfolded and categorized general reasons for leaving social media and related those to IS. In light of our findings, we argue that interventions - tackling regretful use - should not only focus on the app but incorporate the user's context, as most reasons to break SM sessions were not related to the app but the user's general context. Our findings and prior work also indicate the coexistence of multiple loops, which we define as inner (intra-session) loops surrounded by an outer (habitual) loop.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Ulm",
              "institution": "Institute of Media Informatics",
              "dsl": "Ulm University"
            }
          ],
          "personId": 121083
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Ulm",
              "institution": "Institute of Media Informatics",
              "dsl": "Ulm University"
            }
          ],
          "personId": 121065
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Ulm",
              "institution": "Universität Ulm",
              "dsl": ""
            }
          ],
          "personId": 121038
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Ulm",
              "institution": "Ulm University",
              "dsl": "Institute of Media Informatics"
            }
          ],
          "personId": 121198
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "Baden-Württemberg",
              "city": "Ulm",
              "institution": "University of Ulm",
              "dsl": ""
            }
          ],
          "personId": 121150
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Ulm",
              "institution": "Ulm University",
              "dsl": ""
            }
          ],
          "personId": 121074
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Ulm",
              "institution": "University of Ulm",
              "dsl": ""
            }
          ],
          "personId": 121146
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Darmstadt",
              "institution": "TU-Darmstadt",
              "dsl": ""
            }
          ],
          "personId": 121205
        }
      ]
    },
    {
      "id": 121253,
      "typeId": 13014,
      "title": "User-Aware Rendering: Merging the Strengths of Device- and User-Perspective Rendering in Handheld AR",
      "addons": {
        "Presentation": {
          "title": "User-Aware Rendering: Merging the Strengths of Device- and User-Perspective Rendering in Handheld AR",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=jkQXR0P0Jg8"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23a-1099",
      "source": "PCS",
      "trackId": 12309,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        121259
      ],
      "eventIds": [],
      "abstract": "In handheld AR, users have only a small screen to see the augmented scene, making decisions about scene layout and rendering techniques crucial. Traditional device-perspective rendering (DPR) uses the device camera's full field of view, enabling fast scene exploration, but ignoring what the user sees around the device screen. In contrast, user-perspective rendering (UPR) emulates the feeling of looking through the device like a glass pane, which enhances depth perception, but severely limits the field of view in which virtual objects are displayed, impeding scene exploration and search.\r\n\r\nWe introduce the notion of User-Aware Rendering. By following the principles of UPR, but pretending the device is larger than it actually is, it combines the strengths of UPR and DPR. We present two studies showing that User-Aware AR imitating a 50% larger device successfully achieves both enhanced depth perception and fast scene exploration in typical search and selection tasks.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Aachen",
              "institution": "RWTH Aachen University",
              "dsl": ""
            }
          ],
          "personId": 121115
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Aachen",
              "institution": "RWTH Aachen University",
              "dsl": ""
            }
          ],
          "personId": 121090
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Aachen",
              "institution": "RWTH Aachen University",
              "dsl": ""
            }
          ],
          "personId": 121045
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Aachen",
              "institution": "RWTH Aachen University",
              "dsl": ""
            }
          ],
          "personId": 121176
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Aachen",
              "institution": "RWTH Aachen University",
              "dsl": ""
            }
          ],
          "personId": 121123
        }
      ]
    },
    {
      "id": 121254,
      "typeId": 13014,
      "title": "DrivingVibe: Enhancing VR Driving Experience using Inertia-based Vibrotactile Feedback around the Head",
      "addons": {
        "Presentation": {
          "title": "DrivingVibe: Enhancing VR Driving Experience using Inertia-based Vibrotactile Feedback around the Head",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=p2vUqXgVacg"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23a-1078",
      "source": "PCS",
      "trackId": 12309,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        121860
      ],
      "eventIds": [],
      "abstract": "We present DrivingVibe, which explores vibrotactile feedback designs around the head to enhance VR driving motion experiences. We propose two approaches that use a 360-degree vibrotactile headband: 1) mirroring and 2) 3D inertia-based.The mirroring approach extends the vibrotactile patterns of handheld controllers to actuate the entire headband uniformly. The 3D inertia-based approach uses the acceleration telemetry data that driving games/simulators export to motion platforms to generate directional vibration patterns, including: i) centrifugal forces, ii) horizontal acceleration/deceleration, and iii) vertical motion due to rough terrain. The two approaches are complementary as the mirroring approach supports all driving games because it does not require telemetry data, while the 3D inertia-based approach provides higher feedback fidelity for games that provide such data. We conducted a 24-person user experience evaluation in both passive passenger mode and active driving mode. Study results showed that both DrivingVibe designs significantly improved realism, immersion, and enjoyment (p<.01) with large effect sizes for the VR driving experiences. For overall preference, 88% (21/24) of participants preferred DrivingVibe, with a 2:1 preference for 3D inertia-based vs. mirroring designs (14 vs. 7 participants). For immersion and enjoyment, 96% (23/24) of participants preferred DrivingVibe, with nearly a 3:1 preference (17 vs. 6 participants) for the 3D inertia-based design.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Taiwan",
              "state": "",
              "city": "Taipei",
              "institution": "National Taiwan University of Science and Technology",
              "dsl": "Department of Design"
            }
          ],
          "personId": 121106
        },
        {
          "affiliations": [
            {
              "country": "Taiwan",
              "state": "",
              "city": "Taipei",
              "institution": "National Taiwan University of Science and Technology ",
              "dsl": "Department of Design"
            }
          ],
          "personId": 121070
        },
        {
          "affiliations": [
            {
              "country": "Taiwan",
              "state": "",
              "city": "Taipei",
              "institution": "Department of Computer Science, National Taiwan University",
              "dsl": ""
            }
          ],
          "personId": 121088
        },
        {
          "affiliations": [
            {
              "country": "Taiwan",
              "state": "",
              "city": "Taipei",
              "institution": "National Taiwan University",
              "dsl": ""
            }
          ],
          "personId": 121092
        },
        {
          "affiliations": [
            {
              "country": "Taiwan",
              "state": "",
              "city": "Taipei",
              "institution": "National Taiwan University",
              "dsl": ""
            }
          ],
          "personId": 121056
        },
        {
          "affiliations": [
            {
              "country": "Taiwan",
              "state": "",
              "city": "Taipei",
              "institution": "National Taiwan University of Science and Technology",
              "dsl": "Department of Design"
            }
          ],
          "personId": 121049
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New York",
              "city": "New York",
              "institution": "Pratt Institute",
              "dsl": "Information Experience Design"
            }
          ],
          "personId": 121139
        },
        {
          "affiliations": [
            {
              "country": "Taiwan",
              "state": "",
              "city": "Taipei City",
              "institution": "National Taiwan University",
              "dsl": ""
            }
          ],
          "personId": 121125
        },
        {
          "affiliations": [
            {
              "country": "Taiwan",
              "state": "",
              "city": "Taipei",
              "institution": "National Taiwan University",
              "dsl": ""
            }
          ],
          "personId": 121140
        },
        {
          "affiliations": [
            {
              "country": "Taiwan",
              "state": "",
              "city": "Taipei",
              "institution": "National Taiwan University",
              "dsl": ""
            }
          ],
          "personId": 121064
        }
      ]
    },
    {
      "id": 121255,
      "typeId": 13014,
      "title": "Exploring Digital Communication Needs of Local Communities and Self-organized Collectives",
      "addons": {
        "Presentation": {
          "title": "Exploring Digital Communication Needs of Local Communities and Self-organized Collectives",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=t98XxlHv6VU"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23a-1012",
      "source": "PCS",
      "trackId": 12309,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        121863
      ],
      "eventIds": [],
      "abstract": " Recent work in HCI has explored the use of ICTs for the mobilisation and organisation of values-led communities and social movements. This paper extends this line of work by exploring the design of a communication system for informal, place-based citizen collectives—also referred to as Social Solidarity Movements. The distinctive characteristics of such collectives, namely their decentralised, bottom-up and self-organised organisation, and their lack of monetary resources, pose interesting challenges for communication technology design. The work reported in this paper sought to explore how the values and practices of such collectives can be embodied in mobile communication tools. A system was designed to mirror on-the-ground informal organisational structures, its primary goal being to serve as a probe for research and discussion. Our findings highlight the diversity of channels and organisational structures prevailing in these contexts, their participatory nature, and issues of temporality, anonymity, privacy, and trust, all of which must be considered when designing technologies to support cooperative work. We contribute methodological insights and design implications for mobile technologies underpinning the work of social collectives and their practices.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Greece",
              "state": "",
              "city": "Nafplio",
              "institution": "University of the Peloponnese",
              "dsl": "Department of Performing and Digital Arts"
            },
            {
              "country": "Greece",
              "state": "",
              "city": "Athens ",
              "institution": "Athena Research Center",
              "dsl": ""
            }
          ],
          "personId": 121206
        },
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "",
              "city": "Newcastle upon Tyne",
              "institution": "Newcastle University",
              "dsl": "Open Lab"
            }
          ],
          "personId": 121207
        },
        {
          "affiliations": [
            {
              "country": "Greece",
              "state": "",
              "city": "Athens",
              "institution": "National and Kapodistrian University of Athens",
              "dsl": "Department of Informatics and Telecommunications"
            }
          ],
          "personId": 121078
        },
        {
          "affiliations": [
            {
              "country": "Australia",
              "state": "VIC",
              "city": "Melbourne",
              "institution": "Monash University",
              "dsl": "Action Lab"
            }
          ],
          "personId": 121165
        },
        {
          "affiliations": [
            {
              "country": "Australia",
              "state": "VIC",
              "city": "Melbourne",
              "institution": "Monash University",
              "dsl": "Action Lab"
            }
          ],
          "personId": 121148
        },
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "",
              "city": "Cambridge",
              "institution": "Samsung AI Center",
              "dsl": ""
            }
          ],
          "personId": 121060
        }
      ]
    },
    {
      "id": 121256,
      "typeId": 13014,
      "title": "PACMHCI V7, MHCI, September 2023 Editorial",
      "addons": {},
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23a-1206",
      "source": "PCS",
      "trackId": 12309,
      "tags": [],
      "keywords": [],
      "sessionIds": [],
      "eventIds": [],
      "abstract": "tba",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Luxembourg",
              "state": "",
              "city": "Esch-sur-Alzette",
              "institution": "University of Luxembourg",
              "dsl": ""
            }
          ],
          "personId": 121161
        },
        {
          "affiliations": [
            {
              "country": "Italy",
              "state": "",
              "city": "Milano",
              "institution": "Politecnico di Milano",
              "dsl": "Dipartimento di Elettronica, Informazione e Bioingegneria"
            }
          ],
          "personId": 121162
        },
        {
          "affiliations": [
            {
              "country": "Switzerland",
              "state": "",
              "city": "St. Gallen",
              "institution": "University of St. Gallen",
              "dsl": ""
            }
          ],
          "personId": 121082
        }
      ]
    },
    {
      "id": 121257,
      "typeId": 13014,
      "title": "My Eyes Speak: Improving Perceived Sociability of Autonomous Vehicles in Shared Spaces Through Emotional Robotic Eyes",
      "addons": {},
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23a-1107",
      "source": "PCS",
      "trackId": 12309,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        121860
      ],
      "eventIds": [],
      "abstract": "The ability of autonomous vehicles (AVs) to interact socially with pedestrians poses a significant impact on their integration with urban traffic. This is particularly important for vehicle-pedestrian shared spaces due to increased social requirements in comparison to vehicular roads. Current pedestrian experience in shared spaces suffers from negative attitudes towards AVs and the consequently low acceptability of AVs in these spaces. HRI work shows that the acceptability of robots in public spaces can be positively impacted by their perceived sociability (i.e., possessing social skills), which can be enhanced by their ability to express emotions. Inspired by this approach, we follow a systematic process to design emotional expressions for AVs using the headlight (``eye'') area and investigate their impact on perceived sociability of AVs in shared spaces, by conducting expert focus groups (N=12) and an online video-based user study (N=106). Our findings confirm that the perceived sociability of AVs can be enhanced by emotional expressions indicated through emotional eyes. We further discuss implications of our findings for improving pedestrian experience and attitude in shared spaces and highlight opportunities to use AVs' emotional expressions as a new external communication strategy for future research.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Australia",
              "state": "",
              "city": "Sydney",
              "institution": "The University of Sydney",
              "dsl": "Design Lab, School of Architecture, Design and Planning"
            }
          ],
          "personId": 121180
        },
        {
          "affiliations": [
            {
              "country": "Australia",
              "state": "",
              "city": "Camperdown",
              "institution": "The University of Sydney",
              "dsl": ""
            }
          ],
          "personId": 121160
        },
        {
          "affiliations": [
            {
              "country": "Australia",
              "state": "NSW",
              "city": "Sydney",
              "institution": "School of Architecture, Design and Planning, The University of Sydney",
              "dsl": "Design Lab"
            }
          ],
          "personId": 121034
        },
        {
          "affiliations": [
            {
              "country": "Australia",
              "state": "New South Wales",
              "city": "Sydney",
              "institution": "The University of Sydney",
              "dsl": "Design Lab, School of Architecture, Design and Planning"
            }
          ],
          "personId": 121208
        },
        {
          "affiliations": [
            {
              "country": "Australia",
              "state": "NSW",
              "city": "Sydney",
              "institution": "University of Sydney",
              "dsl": "Australian Centre for Field Robotics"
            }
          ],
          "personId": 121072
        },
        {
          "affiliations": [
            {
              "country": "Australia",
              "state": "NSW",
              "city": "Sydney",
              "institution": "The University of Technology Sydney",
              "dsl": "Transdisciplinary School"
            },
            {
              "country": "Australia",
              "state": "NSW",
              "city": "Sydney",
              "institution": "The University of Sydney",
              "dsl": "Design Lab, School of Architecture, Design and Planning"
            }
          ],
          "personId": 121152
        }
      ]
    },
    {
      "id": 121258,
      "typeId": 13014,
      "title": "Exploring Opportunities for Multimodality and Multiple Devices in Food Journaling",
      "addons": {
        "Presentation": {
          "title": "Exploring Opportunities for Multimodality and Multiple Devices in Food Journaling",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=Xg3mYk349AM"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23a-1129",
      "source": "PCS",
      "trackId": 12309,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        121864
      ],
      "eventIds": [],
      "abstract": "Digital food journaling can support personal goals, such as weight loss and developing healthy eating behaviors. However, traditional manual tracking demands great effort, often leading to lapses or abandonment. We explore opportunities for journaling with multiple input modalities and devices, leveraging people's daily interactions with a range of technologies. We report on an extended analysis of 15 participants' experiences with ModEat, a prototype supporting journaling with several input modalities on phone, computer, and voice assistants. Participants' modality and device preferences were largely influenced by their goals, but they frequently deviated from those preferences depending on device availability, perceived affordances, and characteristics of foods eaten. Participants rarely combined input modalities in entries, but some described that doing so allowed for more detailed journaling or serve as a placeholder for later. We discuss advantages and drawbacks of multimodal tracking and potential strategies for improving interactions.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "Irvine",
              "institution": "University of California, Irvine",
              "dsl": ""
            }
          ],
          "personId": 121097
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "Irvine",
              "institution": "University of California, Irvine",
              "dsl": ""
            }
          ],
          "personId": 121157
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "Irvine",
              "institution": "University of California, Irvine",
              "dsl": ""
            }
          ],
          "personId": 121110
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "Irvine",
              "institution": "University of California, Irvine",
              "dsl": "Informatics"
            }
          ],
          "personId": 121187
        }
      ]
    },
    {
      "id": 122215,
      "typeId": 13013,
      "title": "DianTea: Designing and Evaluating an Immersive Virtual Reality Game to Enhance Youth Tea Culture Learning",
      "addons": {
        "Presentation": {
          "title": "DianTea: Designing and Evaluating an Immersive Virtual Reality Game to Enhance Youth Tea Culture Learning",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=ElxLZhXARi8"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23b-6091",
      "source": "PCS",
      "trackId": 12325,
      "tags": [],
      "keywords": [],
      "sessionIds": [],
      "eventIds": [
        121890
      ],
      "abstract": "As an intangible cultural heritage of China, dian cha is a unique tea-drinking ritual in traditional Chinese tea culture. The ritual comprises various tea-drinking utensils and a specific tea art performance. Nowadays, many young Chinese increasingly ignore traditional Chinese cultural activities because of their high work pressures and fast-paced lives. To broaden the audience for traditional Chinese tea ceremonies and stimulate young people’s interest in learning tea culture, we propose “DianTea” as an immersive virtual reality tea-drinking game where remote players can practice the traditional dian cha ritual. The game design also includes a virtual teacher, multimodal interaction, social scene, and game-based learning. In this paper, we also perform an intersubject user study of the game’s interactive and browsing versions. The results show that the interactive game can significantly enhance learners’ knowledge acquisition, interactive experience, and sense of participation in the dian cha ritual.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Shanghai",
              "institution": "Tongji University",
              "dsl": "College of Design and Innovation"
            },
            {
              "country": "China",
              "state": "",
              "city": "Qingdao",
              "institution": "Qingdao University",
              "dsl": "School of Fine Art"
            }
          ],
          "personId": 122205
        },
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Qingdao",
              "institution": "Qingdao University",
              "dsl": "School of Fine Art"
            }
          ],
          "personId": 122191
        },
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Qingdao",
              "institution": "Qingdao University",
              "dsl": "School of Fine Art"
            }
          ],
          "personId": 122140
        },
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Qingdao",
              "institution": "Qingdao University",
              "dsl": "School of Computer Science"
            }
          ],
          "personId": 122143
        },
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Qingdao",
              "institution": "Qingdao University",
              "dsl": "School of Fine Art"
            }
          ],
          "personId": 122193
        },
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Qingdao",
              "institution": "Qingdao University",
              "dsl": "School of Fine Art"
            }
          ],
          "personId": 122188
        },
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Shanghai",
              "institution": "Tongji University",
              "dsl": "College of Design and Innovation"
            }
          ],
          "personId": 122179
        }
      ]
    },
    {
      "id": 122216,
      "typeId": 13013,
      "title": "\"I Can Feel What I Used\": A Diary Study of Smartwatch Features and Emotional Experiences",
      "addons": {
        "Presentation": {
          "title": "\"I Can Feel What I Used\": A Diary Study of Smartwatch Features and Emotional Experiences",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=djoWBohbh_Y"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23b-6818",
      "source": "PCS",
      "trackId": 12325,
      "tags": [],
      "keywords": [],
      "sessionIds": [],
      "eventIds": [
        121890
      ],
      "abstract": "This study focuses on the usability of the smartwatch device in long-term use. Five participants were asked to wear the smartwatch every day and write daily diary entries for 30 days. This study aims to understand how people use and interact with the smartwatch features and how this affects their emotional experience. We found a significant relationship between smartwatch features and emotional experience: smartwatch features are positively and negatively related to users’ emotional experience. The results show that participants primarily use mental health and well-being, and contextual alert features to enhance their performance and increase productivity. Participants respond to the renewal event with immediate response, body health monitoring, and physical activity tracking features. When participants experience burnout and discomfort, they take the smartwatch off. This study contributes to the evaluation of the design of further smartwatch technologies by improving the user experience and interaction.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Korea, Republic of",
              "state": "",
              "city": "Daegu",
              "institution": "Daegu Gyeongbuk Institute of Science and Technology (DGIST)",
              "dsl": ""
            },
            {
              "country": "Korea, Republic of",
              "state": "",
              "city": "Daegu",
              "institution": "Daegu Gyeongbuk Institute of Science and Technology (DGIST)",
              "dsl": ""
            }
          ],
          "personId": 122161
        },
        {
          "affiliations": [
            {
              "country": "Korea, Republic of",
              "state": "",
              "city": "Daegu",
              "institution": "Daegu Gyeongbuk Institute of Science and Technology (DGIST)",
              "dsl": ""
            },
            {
              "country": "Korea, Republic of",
              "state": "",
              "city": "Daegu",
              "institution": "Daegu Gyeongbuk Institute of Science and Technology (DGIST)",
              "dsl": ""
            }
          ],
          "personId": 122196
        }
      ]
    },
    {
      "id": 122217,
      "typeId": 13013,
      "title": "Investigating the User Experience and Challenges of Food Delivery Applications for the Blind and Visually Impaired",
      "addons": {
        "Presentation": {
          "title": "Investigating the User Experience and Challenges of Food Delivery Applications for the Blind and Visually Impaired",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=bY94o8ZJm1s"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23b-2926",
      "source": "PCS",
      "trackId": 12325,
      "tags": [],
      "keywords": [],
      "sessionIds": [],
      "eventIds": [
        121890
      ],
      "abstract": "In recent years, the revenue of food delivery services has grown rapidly, and the market has continued to expand. However, most of the current research on food delivery services has been focused on the commercial sector and was aimed at the general population. However, there are only limited studies on the user experience and challenges of food delivery services by people who are blind or visually impaired (BVI). To address this gap, this preliminary study conducted an online survey with 166 participants and a semistructured interview with 12 BVI individuals. The study results revealed the basic usage habits of BVI people experiencing food delivery services and they have been summarized into two major challenges: 1. usability and accessibility of food delivery apps, 2. service design issues. Limitations and various implications for future research on food delivery services are also discussed.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New York",
              "city": "Rochester",
              "institution": "Rochester Institute of Technology",
              "dsl": ""
            }
          ],
          "personId": 122150
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New York",
              "city": "Rochester",
              "institution": "Rochester Institute of Technology",
              "dsl": "School of Information"
            }
          ],
          "personId": 122184
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New York",
              "city": "Rochester",
              "institution": "Rochester Institute of Technology",
              "dsl": ""
            }
          ],
          "personId": 122162
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New York",
              "city": "Rochester",
              "institution": "Rochester Institute of Technology",
              "dsl": ""
            }
          ],
          "personId": 122178
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New York",
              "city": "Rochester",
              "institution": "Rochester Institute of Technology",
              "dsl": "School of Information"
            }
          ],
          "personId": 122152
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New York",
              "city": "Rochester",
              "institution": "Rochester Institute of Technology",
              "dsl": "School of Information "
            }
          ],
          "personId": 122153
        }
      ]
    },
    {
      "id": 122218,
      "typeId": 13013,
      "title": "Exploring Real-Time Collaborative Heart Rate Displays for Cycling Partners",
      "addons": {
        "Presentation": {
          "title": "Exploring Real-Time Collaborative Heart Rate Displays for Cycling Partners",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=rEA9yl-IQDM"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23b-5912",
      "source": "PCS",
      "trackId": 12325,
      "tags": [],
      "keywords": [],
      "sessionIds": [],
      "eventIds": [
        121890
      ],
      "abstract": "Training with a partner is beneficial for promoting enjoyment and persistence. However, there has been little research on real-time collaborative displays that enable co-located training partners to share data, such as heart rate (HR). We developed a prototype interface that enables cycling partners to view each others' HRs both as beats per minute and as percentage of each user's maximum HR. In a pilot study with six participants, we found that the real-time display may be particularly helpful for less experienced recreational cyclists, and highly experienced cyclists find it  useful when road conditions are dynamic. We also observed that real-time collaborative data may facilitate more social dialogue. All participants indicated that they would use this app in the future. This study highlights the importance of future research on real-time interfaces for exercise, with the goal of enabling more users to integrate physical activity into their lives through successful collaboration.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Florida",
              "city": "Gainesville",
              "institution": "University of Florida",
              "dsl": ""
            }
          ],
          "personId": 122148
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Florida",
              "city": "Gainesville",
              "institution": "University of Florida",
              "dsl": ""
            }
          ],
          "personId": 122151
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Florida",
              "city": "Gainesville",
              "institution": "University of Florida",
              "dsl": "Computer & Information Science & Engineering"
            }
          ],
          "personId": 122165
        }
      ]
    },
    {
      "id": 122219,
      "typeId": 13013,
      "title": "How to Notify Team Members during Asynchronous Remote Collaboration supported by Mixed Reality: Comparing Visual, Audio and Tactile Notifications",
      "addons": {
        "Presentation": {
          "title": "How to Notify Team Members during Asynchronous Remote Collaboration supported by Mixed Reality: Comparing Visual, Audio and Tactile Notifications",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=fuQsVR7cy0U"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23b-1466",
      "source": "PCS",
      "trackId": 12325,
      "tags": [],
      "keywords": [],
      "sessionIds": [],
      "eventIds": [
        121890
      ],
      "abstract": "Solutions exploring Mixed Reality (MR) have been applied to remote scenarios, allowing to create a common ground. Literature reports that most studies focus on synchronous scenarios (team members interact in real-time). Therefore, an opportunity exists for asynchronous situations, in which collaborative actions occur at different moments and in which content is created/shared for later consumption. Hence, team members require notification methods to call their attention when new content is available. This work explored three notification cues: visual; audio; tactile, to comprehend which one captures the attention of team members easily. A user study was conducted with 26 participants to evaluate these conditions during asynchronous remote maintenance. The study was divided into two parts, focusing on the remote and on-site roles, given that both require methods to enhance their awareness. We report the results obtained, suggesting tactile cues represent the predominant condition for both roles. ",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Portugal",
              "state": "",
              "city": "Aveiro",
              "institution": "Universidade de Aveiro",
              "dsl": "DETI-IEETA"
            }
          ],
          "personId": 122195
        },
        {
          "affiliations": [
            {
              "country": "Portugal",
              "state": "",
              "city": "Aveiro",
              "institution": "Universidade de Aveiro",
              "dsl": "DEGEIT - Department of Economics, Management, Industrial Engineering and Tourism"
            },
            {
              "country": "Portugal",
              "state": "",
              "city": "Aveiro",
              "institution": "Universidade de Aveiro",
              "dsl": "IEETA - Institute of Electronics and Informatics Engineering of Aveiro"
            }
          ],
          "personId": 122145
        },
        {
          "affiliations": [
            {
              "country": "Portugal",
              "state": "",
              "city": "Aveiro",
              "institution": "DETI / IEETA, University of Aveiro",
              "dsl": ""
            }
          ],
          "personId": 122201
        },
        {
          "affiliations": [
            {
              "country": "Portugal",
              "state": "",
              "city": "Aveiro",
              "institution": "University of Aveiro",
              "dsl": "DETI - Department of Electronics Telecommunication and Informatics"
            },
            {
              "country": "Portugal",
              "state": "",
              "city": "Aveiro",
              "institution": "University of Aveiro",
              "dsl": "IEETA - Institute of Electronics and Informatics Engineering of Aveiro"
            }
          ],
          "personId": 122138
        },
        {
          "affiliations": [
            {
              "country": "Portugal",
              "state": "",
              "city": "Aveiro",
              "institution": "University of Aveiro",
              "dsl": "DETI - Department of Electronics, Telecommunications and Informatics"
            },
            {
              "country": "Portugal",
              "state": "",
              "city": "Aveiro",
              "institution": "University of Aveiro",
              "dsl": "IEETA- Institute of Electronics and Informatics Engineering of Aveiro"
            }
          ],
          "personId": 122209
        }
      ]
    },
    {
      "id": 122220,
      "typeId": 13013,
      "title": "RoboType: Realistic Mobile Text Entry Evaluations with Synthetic Users",
      "addons": {
        "Presentation": {
          "title": "RoboType: Realistic Mobile Text Entry Evaluations with Synthetic Users",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=pa0OrMtNLfU"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23b-9916",
      "source": "PCS",
      "trackId": 12325,
      "tags": [],
      "keywords": [],
      "sessionIds": [],
      "eventIds": [
        121890
      ],
      "abstract": "Mobile text entry research is contingent on user-based evaluations, which are frequently carried out in small-scale lab experiments. Recruitment and execution of experiments are costly in terms of time and effort required. Further, the results are hard to generalise, because of the small number of participants in the experiments. Studies are sometimes replicable, but not reproducible. RoboType is a realistic open-source simulator for mobile text entry, written in Python and based on the consolidation of state-of-the-art understanding of human behaviour during entry tasks. It aims to aid researchers to produce fast and accurate evaluations of mobile text entry ideas with fully reproducible results. It can be used to significantly reduce time required to explore the design space of new prototypes on various user bases, or as a benchmark to compare results with other researchers. This paper presents an early implementation of RoboType and demonstrate its promising potential.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Greece",
              "state": "Achaea",
              "city": "Patras",
              "institution": "University of Patras",
              "dsl": "Computer Engineering & Informatics"
            }
          ],
          "personId": 122176
        }
      ]
    },
    {
      "id": 122221,
      "typeId": 13013,
      "title": "“They know that it works because we are looking for ourselves” – LGBTQ+ TikTok Users’ Perceptions and Experiences of Queerbaiting",
      "addons": {
        "Presentation": {
          "title": "“They know that it works because we are looking for ourselves” – LGBTQ+ TikTok Users’ Perceptions and Experiences of Queerbaiting",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=SlSpiY4hEE0"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23b-1573",
      "source": "PCS",
      "trackId": 12325,
      "tags": [],
      "keywords": [],
      "sessionIds": [],
      "eventIds": [
        121890
      ],
      "abstract": "LGBTQ+ people often find refuge and community in online spaces. However, with the increasingly monetized experience of social media creation, these spaces are sometimes infiltrated by non-LGBTQ+ people in order to profit off of a new audience. We found that on the social media platform TikTok, there is a large diversity of experiences LGBTQ+ people have with this phenomenon, which is sometimes referred to as queerbaiting. Despite the differences in experience, reactions are often very similar. Typically there is a feeling of deception or disappointment followed by acts of disengagement, such as swiping away from the content or blocking the creator. We attempt to capture these tactics as recommendations for technology design.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Washington",
              "city": "Seattle",
              "institution": "University of Washington",
              "dsl": "Human Centered Design & Engineering"
            }
          ],
          "personId": 122182
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Washington",
              "city": "Seattle",
              "institution": "University of Washington",
              "dsl": "Human Centered Design & Engineering"
            }
          ],
          "personId": 122204
        }
      ]
    },
    {
      "id": 122222,
      "typeId": 13013,
      "title": "Preferred Reading Formats for Mobile Devices: Results from Readability Studies",
      "addons": {
        "Presentation": {
          "title": "Preferred Reading Formats for Mobile Devices: Results from Readability Studies",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=7uFHdhMA-bE"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23b-1800",
      "source": "PCS",
      "trackId": 12325,
      "tags": [],
      "keywords": [],
      "sessionIds": [],
      "eventIds": [
        121890
      ],
      "abstract": "The shift towards reading on mobile screens presents opportunities for tailoring text formats to readers with different needs, yet navigating reading controls proves challenging for readers. Prior work recommends presenting readers with reading themes: a small but diverse set of pre-bundled settings of font with character, word, and line spacing. This work extends this approach to mobile screens, while additionally considering color and contrast adjustments, and digital reading rulers that have been shown to positively impact digital reading. While validating text format guidelines that hold across desktop and mobile reading themes, we find some subtle differences in recommended reading formats for mobile screens. Additionally, we discuss the benefits of providing readers with color and contrast adjustments and reading rulers as additional customizable extenions on top of the proposed reading themes.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "San Francisco",
              "institution": "Adobe Research",
              "dsl": ""
            },
            {
              "country": "United States",
              "state": "California",
              "city": "San Francisco",
              "institution": "Adobe Research",
              "dsl": ""
            }
          ],
          "personId": 122142
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "San Jose",
              "institution": "Adobe Inc.",
              "dsl": ""
            },
            {
              "country": "United States",
              "state": "California",
              "city": "San Jose",
              "institution": "Adobe Inc.",
              "dsl": ""
            }
          ],
          "personId": 122156
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "San Francisco",
              "institution": "Adobe",
              "dsl": ""
            },
            {
              "country": "United States",
              "state": "California",
              "city": "San Francisco",
              "institution": "Adobe",
              "dsl": ""
            }
          ],
          "personId": 122185
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Massachusetts",
              "city": "Lexington",
              "institution": "Adobe",
              "dsl": ""
            },
            {
              "country": "United States",
              "state": "Massachusetts",
              "city": "Lexington",
              "institution": "Adobe",
              "dsl": ""
            }
          ],
          "personId": 122155
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Massachusetts",
              "city": "Cambridge",
              "institution": "Adobe Research",
              "dsl": ""
            },
            {
              "country": "United States",
              "state": "Massachusetts",
              "city": "Cambridge",
              "institution": "Adobe Research",
              "dsl": ""
            }
          ],
          "personId": 122207
        }
      ]
    },
    {
      "id": 122223,
      "typeId": 13013,
      "title": "Predicting Users' Attention Breakpoints During Mobile Text Entry",
      "addons": {
        "Presentation": {
          "title": "Predicting Users' Attention Breakpoints During Mobile Text Entry",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=s2AUHVa_8HY"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23b-5006",
      "source": "PCS",
      "trackId": 12325,
      "tags": [],
      "keywords": [],
      "sessionIds": [],
      "eventIds": [
        121890
      ],
      "abstract": "During mobile text entry, users must shift their gaze from the keyboard to the entry area to check for errors. Many of these shifts are wasteful, since users have not committed any errors in the input stream. This waste might be reduced if, for example, on-keyboard visual feedback about the presence or absence of errors could be provided to users during text entry. However, constant feedback might result in visual clutter disruptive to the input process. We aim to address the challenge of predicting opportune moments (breakpoints) in user's attention to the keyboard to deliver such feedback, utilizing open gaze data collected from 30 participants while typing a) using the index finger of user’s dominant hand and b) using both thumbs. We find that our model achieves promising results in predicting attention breakpoints under both typing conditions and, particularly, during text entry with both thumbs.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Greece",
              "state": "",
              "city": "Rio",
              "institution": "University of Patras",
              "dsl": "Computer Engineering & Informatics"
            }
          ],
          "personId": 122210
        },
        {
          "affiliations": [
            {
              "country": "Greece",
              "state": "Achaea",
              "city": "Patras",
              "institution": "University of Patras",
              "dsl": "Computer Engineering & Informatics"
            }
          ],
          "personId": 122176
        }
      ]
    },
    {
      "id": 122224,
      "typeId": 13013,
      "title": "The State of Algorithmic Fairness in Mobile Human-Computer Interaction",
      "addons": {
        "Presentation": {
          "title": "The State of Algorithmic Fairness in Mobile Human-Computer Interaction",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=3uH2CVD8GLo"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23b-6402",
      "source": "PCS",
      "trackId": 12325,
      "tags": [],
      "keywords": [],
      "sessionIds": [],
      "eventIds": [
        121890
      ],
      "abstract": "This paper explores the intersection of Artificial Intelligence and Machine Learning (AI/ML) fairness and mobile human-computer interaction (MobileHCI). Through a comprehensive analysis of MobileHCI proceedings published between 2017 and 2022, we first aim to understand the current state of algorithmic fairness in the community. By manually analyzing 90 papers, we found that only a small portion (5%) thereof adheres to modern fairness reporting, such as analyses conditioned on demographic breakdowns. At the same time, the overwhelming majority draws its findings from highly-educated, employed, and Western populations. We situate these findings within recent efforts to capture the current state of algorithmic fairness in mobile and wearable computing, and envision that our results will serve as an open invitation to the design and development of fairer ubiquitous technologies.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Greece",
              "state": "",
              "city": "Thessaloniki",
              "institution": "Aristotle University of Thessaloniki",
              "dsl": "School of Informatics"
            },
            {
              "country": "Greece",
              "state": "",
              "city": "Thessaloniki",
              "institution": "Aristotle University of Thessaloniki",
              "dsl": "School of Informatics"
            }
          ],
          "personId": 122144
        },
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "",
              "city": "Cambridge",
              "institution": "Nokia Bell Labs",
              "dsl": ""
            },
            {
              "country": "United Kingdom",
              "state": "",
              "city": "London",
              "institution": "University College London",
              "dsl": "Computer Science"
            }
          ],
          "personId": 122186
        },
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "Cambridgeshire",
              "city": "Cambridge",
              "institution": "Nokia Bell Labs",
              "dsl": ""
            },
            {
              "country": "United Kingdom",
              "state": "",
              "city": "Cambridge",
              "institution": "University of Cambridge",
              "dsl": ""
            }
          ],
          "personId": 122136
        },
        {
          "affiliations": [
            {
              "country": "Greece",
              "state": "",
              "city": "Thessaloniki",
              "institution": "Aristotle University of Thessaloniki",
              "dsl": "School of Informatics"
            }
          ],
          "personId": 122175
        },
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "",
              "city": "Cambridge",
              "institution": "Nokia Bell Labs",
              "dsl": ""
            }
          ],
          "personId": 122202
        },
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "",
              "city": "Cambridge",
              "institution": "Cambridge",
              "dsl": "Nokia Bell Labs"
            }
          ],
          "personId": 122157
        }
      ]
    },
    {
      "id": 122225,
      "typeId": 13013,
      "title": "Understanding the AI-intervened User Interfaces of Online Health Consultation Platforms",
      "addons": {
        "Presentation": {
          "title": "Understanding the AI-intervened User Interfaces of Online Health Consultation Platforms",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=kXahuhgS_xY"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23b-1028",
      "source": "PCS",
      "trackId": 12325,
      "tags": [],
      "keywords": [],
      "sessionIds": [],
      "eventIds": [
        121890
      ],
      "abstract": "This paper aims to investigate patient perceptions (i.e. social presence and trust) of online health consultation (OHC) interfaces with a focus on artificial intelligence (AI) intervention. It describes two studies, which are part of a larger body of research that aims to explore how AI interventions and their interfaces should be designed so that AI can better support the mobile health experience. Study 1 (n=10) was an interview study, which yielded four categories of design features of OHC interfaces. Three categories have been, or would be, strongly intervened by AI and were viewed to have influenced on user perceptions to different extents. Study 2 (n=18) focused on exploring one AI-intervened feature and found that the interface design of AI interventions influenced user perceptions. Our contributions to HCI include empirical insights into how interfaces of AI-intervened OHCs could influence the perceptions of their users, with design implications.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Nanjing",
              "institution": "Nanjing University of Aeronautics and Astronautics",
              "dsl": ""
            }
          ],
          "personId": 122208
        },
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Nanjing",
              "institution": "Nanjing University of Aeronautics and Astronautics",
              "dsl": ""
            }
          ],
          "personId": 122180
        },
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Nanjing",
              "institution": "Nanjing University of Aeronautics and Astronautics",
              "dsl": ""
            }
          ],
          "personId": 122192
        },
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Hong Kong",
              "institution": "Hong Kong Baptist University",
              "dsl": ""
            }
          ],
          "personId": 122189
        }
      ]
    },
    {
      "id": 122226,
      "typeId": 13013,
      "title": "Attentive Notifications: Minimizing Distractions of Mobile Notifications Through Gaze Tracking",
      "addons": {
        "Presentation": {
          "title": "Attentive Notifications: Minimizing Distractions of Mobile Notifications Through Gaze Tracking",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=gpFPdsS94wY"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23b-8922",
      "source": "PCS",
      "trackId": 12325,
      "tags": [],
      "keywords": [],
      "sessionIds": [],
      "eventIds": [
        121890
      ],
      "abstract": "Notifications on smartphones typically appear at the top of the screen, resulting in interruptions caused by content overlaps of toolbars and potential accidental activation of a notification. As returning to a workflow which got interrupted proves difficult for the general user, interface designers should thoughtfully design the visual disruption caused by notifications. We explore possible designs of gaze-attentive notifications to overcome this issue. By placing the notification banner as far from the user's current gazing point as possible they result in less visual overlap and our study participants experienced them as less distracting.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Aachen",
              "institution": "RWTH Aachen University",
              "dsl": ""
            }
          ],
          "personId": 121115
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Aachen",
              "institution": "RWTH Aachen University",
              "dsl": ""
            }
          ],
          "personId": 122146
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Aachen",
              "institution": "RWTH Aachen University",
              "dsl": ""
            }
          ],
          "personId": 121123
        }
      ]
    },
    {
      "id": 122227,
      "typeId": 13013,
      "title": "Ethical Awareness of UXers in the Loop & Ethical Issues in the Uxer-AI Collaboration Process from a UX Perspective",
      "addons": {
        "Presentation": {
          "title": "Ethical Awareness of UXers in the Loop & Ethical Issues in the Uxer-AI Collaboration Process from a UX Perspective",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=fkX4RFofm5w"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23b-2588",
      "source": "PCS",
      "trackId": 12325,
      "tags": [],
      "keywords": [],
      "sessionIds": [],
      "eventIds": [
        121890
      ],
      "abstract": "Artificial Intelligence (AI) has emerged as a prominent collaborative tool across diverse domains, driving innovation in various tasks. However, this human–AI process brings forth a range of ethical considerations that require careful examination. This study investigates the ethical concerns that arise during the user experience designer (UXer)–AI co-creation process and the evolving role of UXers. Employing a mixed methods approach, combining observational task performance experiments and in-depth interviews, the study captures UXers' perceptions of ethical issues in the UXer-AI co-creation process. The findings shed light on three prominent ethical challenges in the UXer–AI co-creation process: reliability, bias, and unemployment. Consequently, this study emphasizes the crucial role of UXers, such as fact-checking, empathy-based decision making, and effective communication with AI, mitigating these ethical challenges. These findings enhance our understanding of UXers' responsibilities and shed light on the potential of leveraging AI as an effective collaborative tool for task completion.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Korea, Republic of",
              "state": "",
              "city": "Seoul",
              "institution": "Yonsei University",
              "dsl": ""
            },
            {
              "country": "Korea, Republic of",
              "state": "",
              "city": "Seoul",
              "institution": "Yonsei University",
              "dsl": ""
            }
          ],
          "personId": 122170
        },
        {
          "affiliations": [
            {
              "country": "Korea, Republic of",
              "state": "",
              "city": "Seoul",
              "institution": "Yonsei University",
              "dsl": "Graduate School of Communication and Arts"
            },
            {
              "country": "Korea, Republic of",
              "state": "",
              "city": "Seoul",
              "institution": "Yonsei University",
              "dsl": "Graduate School of Communication and Arts"
            }
          ],
          "personId": 122169
        }
      ]
    },
    {
      "id": 122228,
      "typeId": 13013,
      "title": "V-ir-Net: A Novel Neural Network for Pupil and Corneal Reflection Detection trained on Simulated Light Distributions",
      "addons": {
        "Presentation": {
          "title": "V-ir-Net: A Novel Neural Network for Pupil and Corneal Reflection Detection trained on Simulated Light Distributions",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=_ZaZ6PJYJvE"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23b-3791",
      "source": "PCS",
      "trackId": 12325,
      "tags": [],
      "keywords": [],
      "sessionIds": [],
      "eventIds": [
        121890
      ],
      "abstract": "Deep learning has shown promise for gaze estimation in Virtual Reality (VR) and other head-mounted applications, but such models are hard to train due to lack of available data. \r\nHere we introduce a novel method to train neural networks for gaze estimation using synthetic images that model the light distributions captured in a P-CR setup.\r\nWe tested our model on a dataset of real eye images from a VR setup, achieving 76% accuracy which is close to the state-of-the-art model which was trained on the dataset itself. The localization error for CRs was 1.56 pixels and 2.02 pixels for the pupil, which is on par with state-of-the-art.\r\nOur approach allowed inference on the whole dataset without sacrificing data for model training. Our method provides a cost-efficient and lightweight training alternative, eliminating the need for hand-labeled data. It offers flexible customization, e.g. adapting to different illuminator configurations, with minimal code changes.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "Bavaria",
              "city": "Munich",
              "institution": "Technical University of Munich",
              "dsl": "Human-Centered Technologies for Learning"
            }
          ],
          "personId": 122163
        },
        {
          "affiliations": [
            {
              "country": "Italy",
              "state": "",
              "city": "Lucca",
              "institution": "IMT Lucca",
              "dsl": "MoMiLab, IMT School for Advanced Studies Lucca"
            }
          ],
          "personId": 122200
        },
        {
          "affiliations": [
            {
              "country": "Sweden",
              "state": "",
              "city": "Lund",
              "institution": "Lund University Humanities Lab",
              "dsl": ""
            }
          ],
          "personId": 122203
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Munich",
              "institution": "Technical University of Munich",
              "dsl": ""
            }
          ],
          "personId": 122177
        },
        {
          "affiliations": [
            {
              "country": "Sweden",
              "state": "",
              "city": "Lund",
              "institution": "Lund University",
              "dsl": ""
            }
          ],
          "personId": 122164
        }
      ]
    },
    {
      "id": 122229,
      "typeId": 13013,
      "title": "EmoFlow: Visualizing Emotional Changes in Video Chat - Preliminary Study",
      "addons": {
        "Presentation": {
          "title": "EmoFlow: Visualizing Emotional Changes in Video Chat - Preliminary Study",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=nmRYObvHFlM"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23b-9668",
      "source": "PCS",
      "trackId": 12325,
      "tags": [],
      "keywords": [],
      "sessionIds": [],
      "eventIds": [
        121890
      ],
      "abstract": "We propose EmoFlow, a prototype service that can recognize the emotional changes of users in video chat and provide a text-based summary along with various visualizations. We present design concepts to represent users’ emotional flow on the mobile messenger application in three types: Emoji, Color, and Shape visualizations. Through a user study with 60 voluntary participants, we found that the Emoji type received the highest score in terms of conveying emotions and design preferences. Also, 65 percent of the participants responded they are willing to use the proposed service if several points are enhanced in the future. The survey results suggest that the proposed service would help users understand and manage their emotional status.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Korea, Republic of",
              "state": "",
              "city": "Seoul",
              "institution": "Seoul National University of Science and Technology",
              "dsl": ""
            }
          ],
          "personId": 122187
        },
        {
          "affiliations": [
            {
              "country": "Korea, Republic of",
              "state": "",
              "city": "Seoul",
              "institution": "Seoul National University of Science and Technology",
              "dsl": ""
            }
          ],
          "personId": 122194
        },
        {
          "affiliations": [
            {
              "country": "Korea, Republic of",
              "state": "",
              "city": "Seoul",
              "institution": "Seoul National University of Science and Technology",
              "dsl": ""
            }
          ],
          "personId": 122212
        },
        {
          "affiliations": [
            {
              "country": "Korea, Republic of",
              "state": "",
              "city": "Seoul",
              "institution": "Seoul National University of Science and Technology",
              "dsl": ""
            }
          ],
          "personId": 122166
        }
      ]
    },
    {
      "id": 122230,
      "typeId": 13013,
      "title": "Understanding Stress in Children with ASD and Their Caregivers in Daily Life: A Feasibility Study Using Mobile Devices",
      "addons": {
        "Presentation": {
          "title": "Understanding Stress in Children with ASD and Their Caregivers in Daily Life: A Feasibility Study Using Mobile Devices",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=HeMtzLk5Av0"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23b-3363",
      "source": "PCS",
      "trackId": 12325,
      "tags": [],
      "keywords": [],
      "sessionIds": [],
      "eventIds": [
        121890
      ],
      "abstract": "Caregivers of children with ASD experience more parenting stress than caregivers of typically developing children. Parenting stress is traditionally evaluated through questionnaires, which do not catch details about when and what exact stressful events occur during a day. This article introduces a data recording framework using mobileHCI based self-report and physiological signal collection to fill this gap. We designed an EasyConnect mobile app to allow caregivers of ASD to conveniently log stressful events using an e-survey. Meanwhile, a wearable physiological sensor was applied to collect Photoplethysmography (PPG) and Electrodermal Activity (EDA) signals. These signals were synchronized with the self-reports to analyze if there was any relation between physiological patterns and self-reported stress. Results collected from 8 families showed that: 1) the proposed framework successfully facilitated data collection; 2) EDA-based stress indicators were detected and associated with stress self-reports. Practical aspects and indications for future works are also discussed.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New York",
              "city": "Rochester",
              "institution": "Rochester Institute of Technology",
              "dsl": "Biomedical Engineering"
            }
          ],
          "personId": 122141
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New York",
              "city": "Rochester",
              "institution": "Rochester Institute of Technology",
              "dsl": "Biomedical & Chemical Engineering"
            }
          ],
          "personId": 122159
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New York",
              "city": "Rochester",
              "institution": "University of Rochester Medical Center",
              "dsl": ""
            }
          ],
          "personId": 122137
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New York",
              "city": "Rochester",
              "institution": "University of Rochester ",
              "dsl": "Developmental and Behavioral Pediatrics"
            }
          ],
          "personId": 122190
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New York",
              "city": "Rochester",
              "institution": "University of Rochester",
              "dsl": "Warner School of Education & Human Development"
            }
          ],
          "personId": 122199
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New York",
              "city": "Rochester",
              "institution": "University of Rochester Medical Center",
              "dsl": ""
            }
          ],
          "personId": 122147
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New York",
              "city": "Rochester",
              "institution": "Rochester Institute of Technology",
              "dsl": ""
            }
          ],
          "personId": 122158
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New York",
              "city": "Rochester ",
              "institution": "Rochester Institute of Technology ",
              "dsl": ""
            }
          ],
          "personId": 122173
        }
      ]
    },
    {
      "id": 122231,
      "typeId": 13013,
      "title": "CrowdFi: A Communication Efficient Multi-device Wi-Fi Sensing System",
      "addons": {
        "Presentation": {
          "title": "CrowdFi: A Communication Efficient Multi-device Wi-Fi Sensing System",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=8tkNHOrbTok"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23b-5575",
      "source": "PCS",
      "trackId": 12325,
      "tags": [],
      "keywords": [],
      "sessionIds": [],
      "eventIds": [
        121890
      ],
      "abstract": "In this paper, we propose a novel multi-device wireless sensing system, called CrowdFi, to balance the sensing performance and the transmission cost. In the CrowdFi, from the perspectives of devices, data, and bits, we propose the adaptive priority based transmission scheme for the heterogeneous data importance and time-varying channel of each device. Moreover, we design a two-stage training procedure and the loss functions to achieve a good tradeoff between the sensing accuracy and the transmission delay. We develop a prototype of the CrowdFi, and validate its performance by employing gait recognition as the application case. Experimental results demonstrate that the proposed CrowdFi system can reduce the transmission delay by 86.9%, while achieving the comparable or even improved recognition accuracy. ",
      "authors": [
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Xi'an",
              "institution": "Northwestern Polytechnical University",
              "dsl": "School of Computer Science"
            }
          ],
          "personId": 122214
        },
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Xi'an",
              "institution": "Northwestern Polytechnical University",
              "dsl": "School of Computer Science"
            }
          ],
          "personId": 122160
        },
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Xi'an",
              "institution": "Northwestern Polytechnical University",
              "dsl": "School of Computer Science"
            }
          ],
          "personId": 121107
        },
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Xi'an",
              "institution": "Northwestern Polytechnical University",
              "dsl": "School of Computer Science"
            }
          ],
          "personId": 122171
        },
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Xi'an",
              "institution": "Northwestern Polytechnical University",
              "dsl": "School of Computer Science"
            }
          ],
          "personId": 121200
        }
      ]
    },
    {
      "id": 122232,
      "typeId": 13013,
      "title": "Nudging Users Towards Conscious Social Media Use",
      "addons": {
        "Presentation": {
          "title": "Nudging Users Towards Conscious Social Media Use",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=HUUhBt5H-s4"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23b-7059",
      "source": "PCS",
      "trackId": 12325,
      "tags": [],
      "keywords": [],
      "sessionIds": [],
      "eventIds": [
        121890
      ],
      "abstract": "Social networks, especially on mobile interfaces, can potentially undermine users' digital wellbeing promoting passive and excessive use. Previous attempts to support users' self-control either focus on restricting use, e.g., through usage timers and blockers, or removing functionality, e.g., by hiding recommendations. In an attempt to avoid these generic and drastic methods, this paper builds on the idea of using nudging mechanisms to make users recognize those design patterns in a social network app that are deliberately adopted to capture attention, the so-called Attention-Capture Damaging Patterns (ACDPs). Being engineered to make users lose their sense of time and control, we hypothesize that making them visible can trigger conscious decisions and more meaningful usage sessions.  \r\n\r\nThanks to a co-design study with six mobile users, we designed two nudges for two different ACDPs commonly used on mobile social networks - infinite scroll and pull-to-refresh. Then, we implemented the two nudges in a mobile app, asking 17 users to try them in a 2-week exploratory study. Results show that the implemented nudges made participants feel more in control of their social media use and partially impacted their quantitative smartphone behaviors. Overall, our work points to exploring alternative - less intrusive - nudging methods to support users in self-regulating their smartphone use.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Italy",
              "state": "",
              "city": "Torino",
              "institution": "Politecnico di Torino",
              "dsl": "Dipartimento di Automatica e Informatica"
            }
          ],
          "personId": 122198
        },
        {
          "affiliations": [
            {
              "country": "Italy",
              "state": "",
              "city": "Torino",
              "institution": "Politecnico di Torino",
              "dsl": "Dipartimento di Automatica e Informatica"
            }
          ],
          "personId": 122167
        }
      ]
    },
    {
      "id": 122233,
      "typeId": 13013,
      "title": "Towards Efficient Interaction for Personal Health Data Queries on Smartwatches",
      "addons": {
        "Presentation": {
          "title": "Towards Efficient Interaction for Personal Health Data Queries on Smartwatches",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=aRkEmGEvY6s"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23b-6582",
      "source": "PCS",
      "trackId": 12325,
      "tags": [],
      "keywords": [],
      "sessionIds": [],
      "eventIds": [
        121890
      ],
      "abstract": "The smartwatch is rapidly becoming a go-to personal health tracking device, allowing for the collection of a broad range of personal health data. Yet, access to this data is often limited to discrete glanceable visualizations. This in part is due to a lack in our understanding of the queries desired to access such data. Thus, as practitioners and application designers, our ability to enable efficient exploratory interactions is limited. In this work, through analysis of a public dataset, we characterize personal health data queries desired for exploration on the smartwatch across multiple dimensions: (i) data requested and attributes of this data, (ii) aggregation methods, (iii) mechanisms for filtering, and (iv) interrogatives used. We conclude with discussion around our findings that can be utilized in future works aimed toward enabling efficient interaction with personal health data on the smartwatch.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Canada",
              "state": "British Columbia",
              "city": "Kelowna",
              "institution": "University of British Columbia",
              "dsl": "Computer Science"
            }
          ],
          "personId": 122211
        },
        {
          "affiliations": [
            {
              "country": "Canada",
              "state": "British Columbia",
              "city": "Kelowna",
              "institution": "University of British Columbia",
              "dsl": "Computer Science"
            }
          ],
          "personId": 122181
        },
        {
          "affiliations": [
            {
              "country": "Canada",
              "state": "British Columbia",
              "city": "Kelowna",
              "institution": "University of British Columbia (Okanagan)",
              "dsl": "Department of Computer Science"
            }
          ],
          "personId": 121168
        }
      ]
    },
    {
      "id": 122234,
      "typeId": 13013,
      "title": "Gesture and Speech Interaction in a Game Tackling Gender Stereotypes",
      "addons": {
        "Presentation": {
          "title": "Gesture and Speech Interaction in a Game Tackling Gender Stereotypes",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=z4G9CK_DVDc"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23b-8036",
      "source": "PCS",
      "trackId": 12325,
      "tags": [],
      "keywords": [],
      "sessionIds": [],
      "eventIds": [
        121890
      ],
      "abstract": "One of the biggest challenges facing society today is gender equality. At the European level, the European Index on Gender Equality  indicates slow progress in this area, meaning that it would take at least 60 years to reach full equality in domains such as work, money, knowledge, power, time and health. In this paper, we address this issue through our research on the Gender Game (GG) , an interactive, gamified, fun quiz with board-game elements, which contributes to deconstructing gender stereotypes and promoting science to a wider audience. It is rooted in the social sciences and aims to reach out to the public specifically about gender equality by presenting scientific results, mainly from research projects. In the paper, we describe an explorative user study with 72 children (8-12 years old), who played the GG. Their participation in the game was recorded on video, and we present our qualitative results based on video observations of the gestures and overall social behavior. These results provide insights into gamification and mobile computing.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Luxembourg",
              "state": "",
              "city": "Esch-sur-Alzette",
              "institution": "LIST",
              "dsl": ""
            }
          ],
          "personId": 122183
        },
        {
          "affiliations": [
            {
              "country": "Luxembourg",
              "state": "",
              "city": "Esch-sur-Alzette / Belval",
              "institution": "Luxembourg Institute of Socio-Economic Research",
              "dsl": ""
            }
          ],
          "personId": 122154
        },
        {
          "affiliations": [
            {
              "country": "Luxembourg",
              "state": "",
              "city": "Esch-sur-Alzette",
              "institution": "Luxembourg Institute of Science and Technology",
              "dsl": ""
            }
          ],
          "personId": 122197
        }
      ]
    },
    {
      "id": 122235,
      "typeId": 13013,
      "title": "Decoding Emotional Valence from Wearables: Can Our Data Reveal Our True Feelings?",
      "addons": {
        "Presentation": {
          "title": "Decoding Emotional Valence from Wearables: Can Our Data Reveal Our True Feelings?",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=PzhqMlQw7mw"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23b-5382",
      "source": "PCS",
      "trackId": 12325,
      "tags": [],
      "keywords": [],
      "sessionIds": [],
      "eventIds": [
        121890
      ],
      "abstract": "Automatic detection and tracking of emotional states has the potential for helping individuals with various mental health conditions. While previous studies have captured physiological signals using wearable devices in laboratory settings, providing valuable insights into the relationship between physiological responses and mental states, the transfer of these findings to real-life scenarios is still in its nascent stages.\r\nOur research aims to bridge the gap between laboratory-based studies and real-life settings by leveraging consumer-grade wearables and self-report measures. We conducted a preliminary study involving 15 healthy participants to assess the efficacy of wearables in capturing user valence in real-world settings. In this paper, we present the initial analysis of the collected data, focusing primarily on the results of valence classification. Our findings demonstrate promising results in distinguishing between high and low positive valence, achieving an F1 score of 0.65. This research opens up avenues for future research in the field of mobile mental health interventions.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Poland",
              "state": "",
              "city": "Cracow",
              "institution": "Sano Centre for Computational Medicine",
              "dsl": ""
            }
          ],
          "personId": 122206
        },
        {
          "affiliations": [
            {
              "country": "Poland",
              "state": "",
              "city": "Poznan",
              "institution": "Poznan University of Technology",
              "dsl": ""
            }
          ],
          "personId": 122139
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Massachusetts",
              "city": "Boston",
              "institution": "Massachusetts General Hospital, Harvard Medical School",
              "dsl": ""
            }
          ],
          "personId": 122172
        },
        {
          "affiliations": [
            {
              "country": "Poland",
              "state": "",
              "city": "Poznan",
              "institution": "Poznan University of Technology",
              "dsl": ""
            }
          ],
          "personId": 122168
        }
      ]
    },
    {
      "id": 122236,
      "typeId": 13013,
      "title": "Heterogeneous User Responses to Privacy Risks in Mobile Apps: Understanding the Dualistic Role of Privacy Risk Perceptions ",
      "addons": {
        "Presentation": {
          "title": "Heterogeneous User Responses to Privacy Risks in Mobile Apps: Understanding the Dualistic Role of Privacy Risk Perceptions",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=GPgwiQ2I1sE"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23b-4581",
      "source": "PCS",
      "trackId": 12325,
      "tags": [],
      "keywords": [],
      "sessionIds": [],
      "eventIds": [
        121890
      ],
      "abstract": "Building upon the Protection Motivation Theory (PMT) and the Cognitive Appraisals Theory (CAT), the present study built and tested a comprehensive research model about mobile app users' responses to privacy risks using data collected from 382 users in the United States. The findings show that perceived vulnerability and severity of privacy risks lead to privacy concerns, which in turn is positively associated with privacy protection behaviors and negatively with information disclosure intentions when using mobile apps. Notably, heightened privacy risk perceptions can also paradoxically result in increased information disclosure, particularly when users adopt maladaptive responses such as privacy resignation. Furthermore, privacy self-efficacy beliefs were found to be crucial for both promoting privacy protection behaviors and reducing privacy resignation. The present study specifies distinct theoretical pathways through which privacy risk perceptions have contrasting implications for information disclosure via mobile apps. Theoretical and practical implications are discussed.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Singapore",
              "state": "",
              "city": "Singapore",
              "institution": "National University of Singapore",
              "dsl": ""
            }
          ],
          "personId": 122149
        }
      ]
    },
    {
      "id": 122237,
      "typeId": 13013,
      "title": "Integrating Real-Time Health Status into Everyday Objects: A Design Case Study on Enhancing Diabetic Health Monitoring with Artistic Creations",
      "addons": {
        "Presentation": {
          "title": "Integrating Real-Time Health Status into Everyday Objects: A Design Case Study on Enhancing Diabetic Health Monitoring with Artistic Creations",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=BeH9tVa9lC0"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23b-7286",
      "source": "PCS",
      "trackId": 12325,
      "tags": [],
      "keywords": [],
      "sessionIds": [],
      "eventIds": [
        121890
      ],
      "abstract": "How can everyday objects interact or change based on a person's real-time health status? In the following design case study, we bring together the fields of health and technology with art in the context of diabetic health monitoring. Specifically, we combine smart sock wearable diabetic monitoring technology with home decor (dynamic artwork) as well as artistically designed changing smartwatch faces. The aim is to allow for health awareness for both diabetic patients and their caregivers/relatives in an ambient living context. By creating subtly changing artworks as well as changing smartwatch faces that are based on health status, we can allow for gentle non-emergent notifications to the diabetic and their caregivers/relatives to create health status awareness in order to positively impact the quality of their health and home-life experience.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Canada",
              "state": "Quebec",
              "city": "Montreal",
              "institution": "Concordia University",
              "dsl": "Applied Perception Lab"
            },
            {
              "country": "Canada",
              "state": "Quebec",
              "city": "Montreal",
              "institution": "Concordia University",
              "dsl": "Applied Perception Lab"
            }
          ],
          "personId": 122174
        },
        {
          "affiliations": [
            {
              "country": "Canada",
              "state": "Quebec",
              "city": "Montreal",
              "institution": "Concordia University",
              "dsl": "Computer Science and Software Engineering"
            },
            {
              "country": "Canada",
              "state": "Quebec",
              "city": "Montreal",
              "institution": "Concordia University",
              "dsl": "Computer Science and Software Engineering"
            }
          ],
          "personId": 122213
        }
      ]
    },
    {
      "id": 122303,
      "typeId": 13011,
      "title": "User-Centered Design of a Mobile Augmented Reality HMI for Virtual Stops",
      "addons": {},
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23g-2313",
      "source": "PCS",
      "trackId": 12326,
      "tags": [],
      "keywords": [],
      "sessionIds": [],
      "eventIds": [
        121898
      ],
      "abstract": "Shared automated mobility on-demand (SAMOD) might be an efficient and convenient mode of transportation in the future. The new concept of a virtual stop (vStop) will coordinate the road users during its dynamic pick-up scenarios. Users need to walk to the pick-up locations in order to board the automated shuttle bus (ASB). Here, users want to find the location, which has no references in the real world, effortlessly. Then, users desire trouble-free identification of the ASB. This doctoral research project aims at designing a human-machine interface (HMI) for vStops with methods of user-centered\r\ndesign. The HMI displays important information in relation to the road environment using augmented reality (AR). This provides users with high rates of user experience, high rates of acceptance and low rates of cognitive workload when solving the tasks. First results show the positive perception of a vStop HMI and the advantages of AR for the selected use case. The doctoral research contributes to widespread deployment of SAMOD in the future and to the change towards more sustainable mobility solutions.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Berlin",
              "institution": "German Aerospace Center (DLR)",
              "dsl": ""
            }
          ],
          "personId": 122277
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Braunschweig",
              "institution": "German Aerospace Center (DLR)",
              "dsl": ""
            }
          ],
          "personId": 122272
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Berlin",
              "institution": "German Aerospace Center (DLR)",
              "dsl": ""
            }
          ],
          "personId": 122257
        }
      ]
    },
    {
      "id": 122304,
      "typeId": 13011,
      "title": "Designing, Developing, and Evaluating AI-driven Text Entry Systems for Augmentative and Alternative Communication Users and Researchers",
      "addons": {},
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23g-9506",
      "source": "PCS",
      "trackId": 12326,
      "tags": [],
      "keywords": [],
      "sessionIds": [],
      "eventIds": [
        121898
      ],
      "abstract": "Non-speaking individuals with motor disabilities heavily rely on augmentative and alternative communication (AAC) text entry systems to communicate. However, designing, developing, and evaluating AAC text entry systems for users and researchers gives rise to several challenges, such as the difficulty of eliciting requirements for a highly heterogeneous user population using a wide variety of assistive devices. This research aims to address such challenges and bridge the gaps between AAC stakeholders while exploring the potential of artificial intelligence (AI)-powered AAC systems to cater to diverse AAC needs and wants. To achieve these goals, we propose an imperfect surrogate user model for AAC system design and evaluation, develop a dedicated machine learning language model for AAC purposes, and design an AI-driven text entry system Tinkerable AAC (TAAC) which is ready for user testing. The objective of these efforts is to ultimately reduce the communication gap between AAC users and their speaking partners.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "Cambridge",
              "city": "University of Cambridge",
              "institution": "Department of Engineering",
              "dsl": ""
            }
          ],
          "personId": 121055
        },
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "",
              "city": "Cambridge",
              "institution": "University of Cambridge",
              "dsl": "Department of Engineering"
            }
          ],
          "personId": 121080
        }
      ]
    },
    {
      "id": 122305,
      "typeId": 13011,
      "title": "Using body sensors in evaluations of the impact of smart cycling technologies on cycling experience",
      "addons": {},
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23g-8646",
      "source": "PCS",
      "trackId": 12326,
      "tags": [],
      "keywords": [],
      "sessionIds": [],
      "eventIds": [
        121898
      ],
      "abstract": "“Smart cycling technologies” (SCTs) that support cyclists while cycling outdoors are on the rise, and it is important to evaluate their impact on cycling experiences. This research therefore aims to develop a framework that guides evaluations of the impact of SCTs on cycling experience. A key question is if and how wearable body sensors can deliver valuable input for such evaluations. Research methods are a systematic literature review, research through design, and empirical studies. Results so far are a conceptualization of the framework, a study about measuring and supporting shared flow in cyclists, and a study about predicting pleasantness ratings from data about brain oxygen consumption. Next steps are to develop a mixed method sensor system to measure experiences with an SCT, and to develop a data analysis method that moves beyond understanding correlations towards cause-effect relationships in experiences with SCTs.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Netherlands",
              "state": "",
              "city": "Enschede",
              "institution": "University of Twente",
              "dsl": "Transport Engineering and Management, Faculty of Engineering Technology"
            }
          ],
          "personId": 122259
        },
        {
          "affiliations": [
            {
              "country": "Netherlands",
              "state": "",
              "city": "Enschede",
              "institution": "University of Twente",
              "dsl": "Transport Engineering and Management, Faculty of Engineering Technology"
            }
          ],
          "personId": 122239
        },
        {
          "affiliations": [
            {
              "country": "Netherlands",
              "state": "",
              "city": "Enschede",
              "institution": "University of Twente",
              "dsl": "Transport Engineering and Management, Faculty of Engineering Technology"
            }
          ],
          "personId": 122252
        },
        {
          "affiliations": [
            {
              "country": "Netherlands",
              "state": "",
              "city": "Enschede",
              "institution": "Universiteit Twente",
              "dsl": "Pervasive Systems Group"
            }
          ],
          "personId": 122295
        }
      ]
    },
    {
      "id": 122306,
      "typeId": 13065,
      "title": "Intervention Study Design in Mobile Research",
      "addons": {
        "Presentation": {
          "title": "Intervention Study Design in Mobile Research",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=GOGn7KqeWeM"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23f-1005",
      "source": "PCS",
      "trackId": 12327,
      "tags": [],
      "keywords": [],
      "sessionIds": [],
      "eventIds": [
        121895
      ],
      "abstract": "Experimental design is vital for evaluating changes in user mental models and behaviors. In this UX research case study, we take inspiration from clinical research and employ an ABA (baseline-intervention-extinction) and AB/BA crossover experimental design to understand user perception, usage, and adoption of a new smartphone feature (\"new phone feature\"). We describe how we employed the ABA and AB/BA Crossover experiment paradigms in a series of studies over 4 months and the insights gleaned. ",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "Newark",
              "institution": "Google",
              "dsl": ""
            }
          ],
          "personId": 122251
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "Mountain View",
              "institution": "Google",
              "dsl": ""
            }
          ],
          "personId": 122280
        }
      ]
    },
    {
      "id": 122307,
      "typeId": 13010,
      "title": "The V-Lab VR Educational Application Framework",
      "addons": {
        "Presentation": {
          "title": "The V-Lab VR Educational Application Framework",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=AZffPGs75Bg"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23d-1580",
      "source": "PCS",
      "trackId": 12329,
      "tags": [],
      "keywords": [],
      "sessionIds": [],
      "eventIds": [
        121890
      ],
      "abstract": "This paper presents the V-Lab, a VR application development framework for educational scenarios mainly involving scientific processes executed in laboratory environments such as chemistry and biology laboratories. This work is an extension of the Onlabs simulator which has been developed by the Hellenic Open University as a distance teaching enabler for similar subjects, helping to alleviate the need for access to the physical laboratory infrastructure; thus, shortening training periods of students in the laboratory and making their training during the periods of physical presence more productive and secure. The extensions of the Onlabs to deliver an enhanced and modular framework that can be extended to multiple educational scenarios is the work performed within the context of the European project XR2Learn (Leveraging the European XR industry technologies to empower immersive learning and training).",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Greece",
              "state": "",
              "city": "Patras",
              "institution": "Hellenic Open University",
              "dsl": "School of Science and Technology"
            }
          ],
          "personId": 122244
        },
        {
          "affiliations": [
            {
              "country": "Greece",
              "state": "",
              "city": "Patras",
              "institution": "Hellenic Open University",
              "dsl": "School of Science and Technology"
            }
          ],
          "personId": 122288
        },
        {
          "affiliations": [
            {
              "country": "Greece",
              "state": "",
              "city": "Patras",
              "institution": "Hellenic Open University",
              "dsl": "School of Science and Technology"
            }
          ],
          "personId": 122293
        },
        {
          "affiliations": [
            {
              "country": "Greece",
              "state": "",
              "city": "Patras",
              "institution": "Hellenic Open University",
              "dsl": "School of Science and Technology"
            }
          ],
          "personId": 122268
        },
        {
          "affiliations": [
            {
              "country": "Greece",
              "state": "",
              "city": "Patras",
              "institution": "Hellenic Open University",
              "dsl": "School of Science and Technology"
            }
          ],
          "personId": 122256
        },
        {
          "affiliations": [
            {
              "country": "Greece",
              "state": "",
              "city": "Patras",
              "institution": "Hellenic Open University",
              "dsl": "School of Science and Technology"
            }
          ],
          "personId": 122269
        }
      ]
    },
    {
      "id": 122308,
      "typeId": 13065,
      "title": "Design Principles for AI UX Delivering User Value for Samsung Galaxy",
      "addons": {
        "Presentation": {
          "title": "Design Principles for AI UX Delivering User Value for Samsung Galaxy",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=h5Q98opBU5k"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23f-1006",
      "source": "PCS",
      "trackId": 12327,
      "tags": [],
      "keywords": [],
      "sessionIds": [],
      "eventIds": [
        121895
      ],
      "abstract": "In a collaboration between Samsung Electronics' Mobile UX and Research Institutes of Sweden (RISE) we created a teaching material on how to design with AI. The material is aimed for UX-designer and consists of design principles, example designs, UX-values, ethics and a business proposition motivating why and where to use AI in the Galaxy UX.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Sweden",
              "state": "",
              "city": "Stockholm",
              "institution": "RISE, Research Institutes of Sweden",
              "dsl": ""
            }
          ],
          "personId": 122283
        },
        {
          "affiliations": [
            {
              "country": "Sweden",
              "state": "",
              "city": "Kista",
              "institution": "RISE Research Institute of Sweden",
              "dsl": ""
            }
          ],
          "personId": 122248
        },
        {
          "affiliations": [
            {
              "country": "Sweden",
              "state": "",
              "city": "Stockholm",
              "institution": "Stockholm University",
              "dsl": "Computer and Systems Sciences"
            }
          ],
          "personId": 122290
        },
        {
          "affiliations": [
            {
              "country": "Korea, Republic of",
              "state": "",
              "city": "Seoul",
              "institution": "Samsung Electronics",
              "dsl": ""
            }
          ],
          "personId": 122242
        }
      ]
    },
    {
      "id": 122309,
      "typeId": 13010,
      "title": "AI-Augmented Feature to Edit and Design Mobile Applications",
      "addons": {
        "Presentation": {
          "title": "AI-Augmented Feature to Edit and Design Mobile Applications",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=sSdJQc2sKFM"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23d-8596",
      "source": "PCS",
      "trackId": 12329,
      "tags": [],
      "keywords": [],
      "sessionIds": [],
      "eventIds": [
        121890
      ],
      "abstract": "We are developing an AI assistance platform that enables individuals with a limited technical background, such as children, to create mobile applications from natural language input. The platform is based on MIT App Inventor and allows users to easily edit the interface and functionality of the components of their app using textual commands. The goal of the platform is to empower children and others without a background in coding with the ability to create their own mobile applications and foster their creativity and problem-solving skills in a fun and interactive way.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Massachusetts",
              "city": "Cambridge",
              "institution": "Massachusetts Institute of Technology",
              "dsl": "Computer Science and Artificial Intelligence Laboratory"
            }
          ],
          "personId": 122276
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Massachusetts",
              "city": "Cambridge",
              "institution": "MIT",
              "dsl": "Computer Science and Artificial Intelligence Laboratory"
            }
          ],
          "personId": 122299
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Massachusetts",
              "city": "Cambridge",
              "institution": "Massachusetts Institute of Technology",
              "dsl": "Computer Science and Artificial Intelligence Lab"
            }
          ],
          "personId": 122287
        }
      ]
    },
    {
      "id": 122310,
      "typeId": 13065,
      "title": "New Data Collection Approach to Investigate Touch Based Errors: A Case Study of Smartphone System Navigation",
      "addons": {
        "Presentation": {
          "title": "New Data Collection Approach to Investigate Touch Based Errors: A Case Study of Smartphone System Navigation",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=3zX6_xUKJks"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23f-1004",
      "source": "PCS",
      "trackId": 12327,
      "tags": [],
      "keywords": [],
      "sessionIds": [],
      "eventIds": [
        121895
      ],
      "abstract": "Studying touch based errors on mobile devices (e.g. swipes not registering or misregistering…) is challenging due to the difficulty of obtaining user intention along with high-fidelity touch event data. In a recent three-week longitudinal study investigating smartphone system navigation errors, we preinstalled custom data collection software on test phones. The software allowed 53 US-based participants to generate error reports containing their intention, outcome, screenshots, and touch data for the last three minutes. We adhered to strict ethical data collection practices. Participants could exit the study at any time and request all their data deleted. Only participants could generate error reports, could cancel when desired, and were warned of what data was being saved. Participants also submitted video diary entries. Both touch event and diary data revealed consistent and insightful findings on the causes of gesture errors. Our approach can help usability professionals meet similar challenges by analyzing touch event data and user intention to accurately identify the root causes of errors. ",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "Mountain View",
              "institution": "Google Inc.",
              "dsl": ""
            }
          ],
          "personId": 122253
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "Mountain View",
              "institution": "Google",
              "dsl": ""
            }
          ],
          "personId": 122280
        }
      ]
    },
    {
      "id": 122311,
      "typeId": 13011,
      "title": "Modelling human behavior during text entry",
      "addons": {},
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23g-1700",
      "source": "PCS",
      "trackId": 12326,
      "tags": [],
      "keywords": [],
      "sessionIds": [],
      "eventIds": [
        121898
      ],
      "abstract": "Mobile text entry, used in several contexts and done in a variety of ways, has been a topic of ongoing research. Research in mobile text entry has largely depended on empirical evaluations with human participants, where users are asked to complete specific tasks to measure their performance. Until recently, metrics used for study results were based on solely users’ touch input, while ignoring other factors involved in the process of text entry. We aim to develop novel metrics and models of behavior during text entry, which will incorporate aspects of human motor and cognitive processes, by adopting new technologies, to enhance current text entry research and meliorate our understanding of users’ text entry behaviors.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Greece",
              "state": "Achaea",
              "city": "Rio",
              "institution": "University of Patras",
              "dsl": "Computer Engineering & Informatics Department"
            }
          ],
          "personId": 122210
        },
        {
          "affiliations": [
            {
              "country": "Greece",
              "state": "Achaea",
              "city": "Rio",
              "institution": "University of Patras",
              "dsl": "Computer Engineering & Informatics Department"
            }
          ],
          "personId": 122176
        }
      ]
    },
    {
      "id": 122312,
      "typeId": 13065,
      "title": "Designing for Diverse Populations in Mobile Research",
      "addons": {
        "Presentation": {
          "title": "Designing for Diverse Populations in Mobile Research",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=MBas69bAuzc"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23f-1001",
      "source": "PCS",
      "trackId": 12327,
      "tags": [],
      "keywords": [],
      "sessionIds": [],
      "eventIds": [
        121895
      ],
      "abstract": "Companies are adapting to fast-changing business environments and reduced product life cycle time with targeted scope and priorities. UX researchers working in tandem with product teams are also adapting by focusing on our core consumer populations with our study design and recruitment targets. Yet, our mobile user base is composed of many diverse populations. We describe how, by studying diverse samples with an inclusive design approach followed by an evaluative approach to quantify needs with core consumer samples, we meet the needs of all. We aim to demonstrate that inclusive design is complementary to supporting our business priorities in fast-paced environments, meaning we can design for all and achieve quality of findings within the constraints of reduced product life cycle time.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "Mountain View",
              "institution": "Google",
              "dsl": ""
            }
          ],
          "personId": 122258
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "Mountain View",
              "institution": "Google",
              "dsl": ""
            }
          ],
          "personId": 122245
        }
      ]
    },
    {
      "id": 122313,
      "typeId": 13010,
      "title": "The Magic XRoom: A Flexible VR Platform for Controlled Emotion Elicitation and Recognition",
      "addons": {
        "Presentation": {
          "title": "The Magic XRoom: A Flexible VR Platform for Controlled Emotion Elicitation and Recognition",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=N4rpaol5b1Q"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23d-1303",
      "source": "PCS",
      "trackId": 12329,
      "tags": [],
      "keywords": [],
      "sessionIds": [],
      "eventIds": [
        121890
      ],
      "abstract": "Affective computing has recently gained popularity, especially in the field of human-computer interaction systems, where effectively evoking and detecting emotions is of paramount importance to enhance users' experience. However, several issues are hindering progress in the field. In fact, the complexity of emotions makes it difficult to understand their triggers and control their elicitation. Additionally, effective emotion recognition requires analyzing multiple sensor data, such as facial expressions and physiological signals. These factors combined make it hard to collect high-quality datasets that can be used for research purposes (e.g., development of emotion recognition algorithms). Despite these challenges, Virtual Reality (VR) holds promise as a solution. By providing a controlled and immersive environment, VR enables the replication of real-world emotional experiences and facilitates the tracking of signals indicative of emotional states. However, controlling emotion elicitation remains a challenging task also within VR. This research paper introduces the Magic Xroom, a VR platform designed to enhance control over emotion elicitation by leveraging the theory of flow. This theory establishes a mapping between an individual's skill levels, task difficulty, and perceived emotions. In the Magic Xroom, the user's skill level is continuously assessed, and task difficulty is adjusted accordingly to evoke specific emotions. Furthermore, user signals are collected using sensors, and virtual panels are utilized to determine the ground truth emotional states, making the Magic Xroom an ideal platform for collecting extensive datasets. The paper provides detailed implementation information, highlights the main properties of the Magic Xroom, and presents examples of virtual scenarios to illustrate its abilities and capabilities.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Switzerland",
              "state": "Viganello",
              "city": "Lugano",
              "institution": "University of Applied Sciences and Arts of Southern Switzerland",
              "dsl": "Department of innovative technologies"
            }
          ],
          "personId": 122301
        },
        {
          "affiliations": [
            {
              "country": "Switzerland",
              "state": "Viganello",
              "city": "Lugano",
              "institution": "University of Applied Sciences and Arts of Southern Switzerland",
              "dsl": "Department of innovative technologies"
            }
          ],
          "personId": 122278
        },
        {
          "affiliations": [
            {
              "country": "Switzerland",
              "state": "Viganello",
              "city": "Lugano",
              "institution": "University of Applied Sciences and Arts of Southern Switzerland",
              "dsl": "Department of innovative technologies"
            }
          ],
          "personId": 122250
        },
        {
          "affiliations": [
            {
              "country": "Switzerland",
              "state": "Viganello",
              "city": "Lugano",
              "institution": "University of Applied Sciences and Arts of Southern Switzerland",
              "dsl": "Department of innovative technologies"
            }
          ],
          "personId": 122261
        },
        {
          "affiliations": [
            {
              "country": "Switzerland",
              "state": "Viganello",
              "city": "Lugano",
              "institution": "University of Applied Sciences and Arts of Southern Switzerland",
              "dsl": "Department of innovative technologies"
            }
          ],
          "personId": 122285
        }
      ]
    },
    {
      "id": 122314,
      "typeId": 13011,
      "title": "Representing microgestures interaction for wearable computing",
      "addons": {},
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23g-2109",
      "source": "PCS",
      "trackId": 12326,
      "tags": [],
      "keywords": [],
      "sessionIds": [],
      "eventIds": [
        121898
      ],
      "abstract": "Microgestures, i.e. fast and subtle movements of the fingers, offer always available and versatile interaction that makes them promising for wearable computing. While research has been done to define sets of microgestures and sensing systems, we do not know how to best represent microgestures and their associated commands which is essential for the adoption of microgesture interaction. Thus, this thesis focuses on how microgestures and their corresponding commands can be represented to users and discovered by them.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "France",
              "state": "",
              "city": "Grenoble",
              "institution": "Université Grenoble Alpes",
              "dsl": "Equipe IIHM, Laboratoire d'Informatique de Grenoble"
            },
            {
              "country": "France",
              "state": "",
              "city": "Grenoble",
              "institution": "Université Grenoble Alpes",
              "dsl": "Equipe IIHM, Laboratoire d'Informatique de Grenoble"
            }
          ],
          "personId": 121124
        }
      ]
    },
    {
      "id": 122315,
      "typeId": 13017,
      "title": "The Future of Cognitive Personal Informatics",
      "addons": {},
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23c-1030",
      "source": "PCS",
      "trackId": 12330,
      "tags": [],
      "keywords": [],
      "sessionIds": [],
      "eventIds": [
        122333
      ],
      "abstract": "While Human-Computer Interaction (HCI) has contributed to demonstrating that physiological measures can be used to detect cognitive changes, engineering and machine learning will bring these to application in consumer wearable technology. For HCI, many open questions remain, such as: What happens when this becomes a cognitive form of personal informatics? What goals do we have for our daily cognitive activity? How should such a complex concept be conveyed to users to be useful in their everyday life? How can we mitigate potential ethical concerns? These issues are different from physiologically controlled interactions, such as BCIs, to a time when we have new data about ourselves. This workshop will be the first to directly address the future of Cognitive Personal Informatics (CPI), by bringing together design, BCI and physiological data, ethics, and personal informatics researchers to discuss and set the research agenda in this inevitable future before it arrives.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Netherlands",
              "state": "",
              "city": "Delft",
              "institution": "TU Delft",
              "dsl": "IDE"
            }
          ],
          "personId": 122255
        },
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "",
              "city": "Nottingham",
              "institution": "University of Nottingham",
              "dsl": "School of Computer Science"
            }
          ],
          "personId": 122282
        },
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "",
              "city": "Nottingham",
              "institution": "University of Nottingham",
              "dsl": "Horizon Digital Economy Research Institute"
            }
          ],
          "personId": 122264
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Munich",
              "institution": "LMU Munich",
              "dsl": ""
            }
          ],
          "personId": 121054
        },
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "",
              "city": "London",
              "institution": "University College London",
              "dsl": "UCL Interaction Centre"
            }
          ],
          "personId": 122286
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Utah",
              "city": "Salt Lake City",
              "institution": "University of Utah",
              "dsl": "School of Computing"
            }
          ],
          "personId": 122254
        }
      ]
    },
    {
      "id": 122316,
      "typeId": 13073,
      "title": "Smartphone based on-device computing for societal applications",
      "addons": {},
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23e-1008",
      "source": "PCS",
      "trackId": 12328,
      "tags": [],
      "keywords": [],
      "sessionIds": [],
      "eventIds": [
        122330
      ],
      "abstract": "The past few years have witnessed a tremendous rise in human-smartphone interactions. Users download and interact with millions of applications ranging from productivity, entertainment to health, including physical and mental. Usually, a server at the edge or cloud is a computing device for many applications. However, the processing power of smartphones is at par with desktop PCs thanks to the quad-core and hexa-core processors and faster clock speeds. In this tutorial, we first discuss the evolution of smartphone computing power over the past decade. We then present the experimental design and on-device computing challenges through two case studies namely - smartphone-based indoor localization based on ambient magnetic fields and a mental health tracking application. We follow the discussion with some user experience study findings of both apps. The presentation will conclude with open research challenges in such studies.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "India",
              "state": "",
              "city": "Gandhinagar",
              "institution": "DAIICT",
              "dsl": "Computer Science"
            }
          ],
          "personId": 122275
        }
      ]
    },
    {
      "id": 122317,
      "typeId": 13017,
      "title": "Workshop on Advances of Mobile and Wearable Biometrics (WAMWB)",
      "addons": {},
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23c-1033",
      "source": "PCS",
      "trackId": 12330,
      "tags": [],
      "keywords": [],
      "sessionIds": [],
      "eventIds": [
        122334
      ],
      "abstract": "Biometrics is defined as the automated recognition of individuals based on their biological and behavioural characteristics. It represents a fundamental aspect of mobile Human-Computer Interaction (HCI), as mobile devices such as smartphones and wearables are designed to capture, process and transmit biometric data. While people benefit from the innumerable applications of biometric data in the context of HCI, new concerns have raised in relation with the performance, reliability, protection of privacy, bias, misuse, regulations, and their impact on society.\r\nThe Workshop on Advances of Mobile and Wearable Biometrics (WAMWB) aims to highlight recent developments with respect to such challenges and risks.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Spain",
              "state": "",
              "city": "Madrid",
              "institution": "Universidad Autonoma de Madrid",
              "dsl": ""
            }
          ],
          "personId": 122240
        },
        {
          "affiliations": [
            {
              "country": "Spain",
              "state": "",
              "city": "Madrid",
              "institution": "Universidad Autonoma de Madrid",
              "dsl": ""
            }
          ],
          "personId": 122238
        },
        {
          "affiliations": [
            {
              "country": "Spain",
              "state": "",
              "city": "Madrid",
              "institution": "Universidad Autonoma de Madrid",
              "dsl": ""
            }
          ],
          "personId": 122291
        }
      ]
    },
    {
      "id": 122318,
      "typeId": 13017,
      "title": "Mobility and Utility in Robot Mediated Interaction: An Interactive Workshop for the Identification of Use Cases and Affordances of Telepresence Robots",
      "addons": {},
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23c-1023",
      "source": "PCS",
      "trackId": 12330,
      "tags": [],
      "keywords": [],
      "sessionIds": [],
      "eventIds": [
        122331
      ],
      "abstract": "In recent years virtual meetings have become the predominant alternative to face-to-face meetings. Ongoing efforts in the design of telepresence robots promise remote access to physical settings and a greater sense of presence, leading to improved remote collaboration. However, a comparable sense of physical presence and utility has yet to be achieved. Mobile telepresence still provides limited ways to interact with remote users (e.g., with the environment and other people). This workshop aims to re-imagine telepresence robots, moving away from the decades-old `iPad-on-a-stick' paradigm. Using interactive activities involving existing telepresence robots and a hybrid workshop format, we hope to ideate ways of expanding the capabilities of mobile telepresence robots through a range of mechanisms (e.g., mobile and wearable technology, Augmented Reality, Internet of Things, etc.) and to inform the future design of these devices to provide additional affordances. In doing so, we plan to identify use cases for which mobile telepresence robots can provide additional value through their locomotive capabilities compared to current screen-based remote interactions. Lastly, we aim to identify scenarios for future research in Mobile HCI using use cases and affordances identified during the workshop to support more equitable participation for remote users.\r\n",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "",
              "city": "Nottingham",
              "institution": "University of Nottingham",
              "dsl": "School of Computer Science"
            }
          ],
          "personId": 122284
        },
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "",
              "city": "Nottingham ",
              "institution": "University of Nottingham",
              "dsl": "Mixed Reality Laboratory, School of Computer Science"
            }
          ],
          "personId": 122266
        },
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "",
              "city": "Nottingham",
              "institution": "University of Nottingham",
              "dsl": "Mixed Reality Lab - School of Computer Science"
            }
          ],
          "personId": 122249
        },
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "",
              "city": "Nottingham",
              "institution": "The University of Nottingham",
              "dsl": "Mixed Reality Laboratory"
            }
          ],
          "personId": 122267
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Indiana",
              "city": "Bloomington",
              "institution": "Indiana University",
              "dsl": "School of Informatics, Computing, and Engineering"
            }
          ],
          "personId": 122279
        },
        {
          "affiliations": [
            {
              "country": "Denmark",
              "state": "",
              "city": "Aarhus",
              "institution": "Aarhus University",
              "dsl": "Department of Computer Science"
            }
          ],
          "personId": 122300
        },
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "",
              "city": "Cambridge",
              "institution": "Microsoft Research",
              "dsl": ""
            }
          ],
          "personId": 122297
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Massachusetts",
              "city": "Amherst",
              "institution": "UMass Amherst",
              "dsl": "CICS"
            }
          ],
          "personId": 122281
        }
      ]
    },
    {
      "id": 122319,
      "typeId": 13010,
      "title": "INTERACT: An authoring tool that facilitates the creation of human centric interaction with 3d objects in virtual reality",
      "addons": {
        "Presentation": {
          "title": "INTERACT: An authoring tool that facilitates the creation of human centric interaction with 3d objects in virtual reality",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=pQ-pYghV2bQ"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23d-5708",
      "source": "PCS",
      "trackId": 12329,
      "tags": [],
      "keywords": [],
      "sessionIds": [],
      "eventIds": [
        121890
      ],
      "abstract": "A widespread adoption of Virtual, Augmented, and Mixed Reality (VR/AR/MR), collectively referred to as Extended Reality (XR), has become a tangible possibility to revolutionize educational and training scenarios by offering immersive, interactive experiences. In this paper we present INTERACT, an authoring tool for creating advanced 3D physics-based Intelligent Tutoring Systems (ITS) by individual developers or small-scale development teams. INTERACT is based on a cutting edge physics engine allowing realistic interactions such as collision detection and ergonomic evaluations. We demonstrate the benefits of INTERACT by developing a set of training scenarios for a use case of a Laser cutting machine. The use case illustrates the numerous possibilities such as creating interaction with objects, ease of configuring a scenario and how to design the visual effects to the machine.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "France",
              "state": "",
              "city": "Paris",
              "institution": "LS Group",
              "dsl": ""
            }
          ],
          "personId": 122289
        },
        {
          "affiliations": [
            {
              "country": "France",
              "state": "",
              "city": "Paris",
              "institution": "LS Group",
              "dsl": ""
            }
          ],
          "personId": 122247
        },
        {
          "affiliations": [
            {
              "country": "France",
              "state": "",
              "city": "Paris",
              "institution": "LS Group",
              "dsl": ""
            }
          ],
          "personId": 122298
        },
        {
          "affiliations": [
            {
              "country": "Italy",
              "state": "RM",
              "city": "Rome",
              "institution": "Sapienza University of Rome",
              "dsl": ""
            }
          ],
          "personId": 122270
        }
      ]
    },
    {
      "id": 122320,
      "typeId": 13011,
      "title": "User-Centered Privacy to Improve User Quantification using Smartphone Sensing",
      "addons": {},
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23g-5560",
      "source": "PCS",
      "trackId": 12326,
      "tags": [],
      "keywords": [],
      "sessionIds": [],
      "eventIds": [
        121898
      ],
      "abstract": "Mobile sensing technologies enable adaptive and context-aware applications. At the same time, they raise a range of privacy concerns. Thus, to reduce privacy concerns today apps are restricted from accessing certain information hindering to deliver full personalization and novel adaptive use cases.\r\nI investigate this issue by shedding light on the privacy concerns that arise from state-of-the-art mobile sensing data, studying the users' perspective on mobile smartphone privacy, and proposing concepts that protect the users' privacy while keeping the resulting data usable.\r\nI found that there is a lack of user-centered privacy design and that control features play a key role to give the users more agency.\r\nMy results motivate the proliferation of control-enhancing privacy features in mobile applications. I show that the benefits of trust and system adoption surpass any impairments that control features might bring to the data.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Munich",
              "institution": "LMU Munich",
              "dsl": ""
            }
          ],
          "personId": 121170
        }
      ]
    },
    {
      "id": 122321,
      "typeId": 13073,
      "title": "QTrobot Tutorial: Social Robotics and Ethics",
      "addons": {},
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23e-1010",
      "source": "PCS",
      "trackId": 12328,
      "tags": [],
      "keywords": [],
      "sessionIds": [],
      "eventIds": [],
      "abstract": "",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Luxembourg",
              "state": "",
              "city": "Luxembourg",
              "institution": "LuxAI",
              "dsl": ""
            }
          ],
          "personId": 122265
        },
        {
          "affiliations": [
            {
              "country": "Luxembourg",
              "state": "",
              "city": "Luxembourg",
              "institution": "LuxAI",
              "dsl": ""
            }
          ],
          "personId": 122273
        }
      ]
    },
    {
      "id": 122322,
      "typeId": 13010,
      "title": "FaceWard: Face Anonymization in Group Photos",
      "addons": {
        "Presentation": {
          "title": "FaceWard: Face Anonymization in Group Photos",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=hxvaiopnVXQ"
        }
      },
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23d-6173",
      "source": "PCS",
      "trackId": 12329,
      "tags": [],
      "keywords": [],
      "sessionIds": [],
      "eventIds": [
        121890
      ],
      "abstract": "Sharing photos on social media and messaging services often result in a vast amount of personal data being made public online. As a result, it has become increasingly vital to devise measures that ensure privacy protection, especially for people who want to maintain social boundaries by hiding their faces in group photos. In this paper, we propose FaceWard, an automatic system for face anonymization of people different from a target person. FaceWard is based on a pattern matching algorithm and supports different anonymization policies such as blur or smiley overlays. Taken together, FaceWard yields a very efficient solution, eliminating the need for computationally expensive training of complex machine learning models, thus offering a practical trade-off between prediction accuracy and data availability. FaceWard is publicly available as open source software.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Luxembourg",
              "state": "",
              "city": "Esch-sur-Alzette",
              "institution": "University of Luxembourg",
              "dsl": ""
            }
          ],
          "personId": 122296
        },
        {
          "affiliations": [
            {
              "country": "Luxembourg",
              "state": "",
              "city": "Esch-sur-Alzette",
              "institution": "University of Luxembourg",
              "dsl": ""
            }
          ],
          "personId": 122262
        },
        {
          "affiliations": [
            {
              "country": "Luxembourg",
              "state": "",
              "city": "Esch-sur-Alzette",
              "institution": "University of Luxembourg",
              "dsl": ""
            }
          ],
          "personId": 121161
        }
      ]
    },
    {
      "id": 122323,
      "typeId": 13017,
      "title": "Accessibility and Multimodal Interaction Design Approaches in Museums for People with Impairments",
      "addons": {},
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "mobilehci23c-1029",
      "source": "PCS",
      "trackId": 12330,
      "tags": [],
      "keywords": [],
      "sessionIds": [],
      "eventIds": [
        122332
      ],
      "abstract": "The First International Workshop on Accessibility and Multimodal Interaction Design Approaches in Museums for People with Impairments (AMID) aims to bring together researchers and practitioners working on diverse topics related to understanding the issues connected with mobile HCI in museums for people with impairments. The workshop includes interdisciplinary contributions on various related topics across a broad range of contexts, such as Adaptation and Personalization, User Modeling, Human-centered Computing, and User Experience. This workshop focuses both on academia and industry and aims to attract the attention of an interdisciplinary audience between researchers and professionals working in the field. It will bring together scientists, students, ICT professionals, service providers and developers, designers, and end-users to exchange and share their experiences, new ideas and research results about all aspects (theory, applications, and tools) of HCI design approaches for people with impairments in museums. This summary gives a brief overview of AMID 2023, held both virtually and physically from Athens, Greece in conjunction with the Mobile HCI 2023, the ACM Conference on Mobile Human-Computer Interaction. ",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Greece",
              "state": "",
              "city": "Patra",
              "institution": "University of Patras",
              "dsl": "Cultural Technology Lab"
            }
          ],
          "personId": 122292
        },
        {
          "affiliations": [
            {
              "country": "Greece",
              "state": "Not Applicable",
              "city": "Serres",
              "institution": "International Hellenic University",
              "dsl": "Department of Surveying Engineering and Geoinformatics"
            }
          ],
          "personId": 122260
        },
        {
          "affiliations": [
            {
              "country": "Israel",
              "state": "",
              "city": "Haifa",
              "institution": "The University of Haifa",
              "dsl": "Information Systems"
            }
          ],
          "personId": 122246
        },
        {
          "affiliations": [
            {
              "country": "Cyprus",
              "state": "",
              "city": "Nicosia",
              "institution": "Research Centre on Interactive Media, Smart Systems and Emerging Technologies",
              "dsl": ""
            },
            {
              "country": "Cyprus",
              "state": "",
              "city": "Limassol",
              "institution": "Cyprus University of Technology",
              "dsl": ""
            }
          ],
          "personId": 122294
        },
        {
          "affiliations": [
            {
              "country": "Greece",
              "state": "CYCLADES",
              "city": "HERMOUPOLIS SYROS",
              "institution": "UNIVERSITY OF AEGEAN",
              "dsl": "DEPARTMENT OF PRODUCT AND SYSTEMS DESIGN ENGINEERING"
            }
          ],
          "personId": 122243
        },
        {
          "affiliations": [
            {
              "country": "Greece",
              "state": "",
              "city": "Tripoli",
              "institution": "University of the Peloponnese",
              "dsl": "ΓΑΒ LAB - Knowledge and Uncertainty Research Laboratory"
            }
          ],
          "personId": 122274
        },
        {
          "affiliations": [
            {
              "country": "Greece",
              "state": "",
              "city": "Patras",
              "institution": "University of Patras",
              "dsl": "Department of History and Archaeology"
            }
          ],
          "personId": 122271
        },
        {
          "affiliations": [
            {
              "country": "Greece",
              "state": "",
              "city": "Athens",
              "institution": "University of West Attica",
              "dsl": "Department of Archival, Library & Information Studies"
            }
          ],
          "personId": 122302
        },
        {
          "affiliations": [
            {
              "country": "Greece",
              "state": "Crete",
              "city": "Chania",
              "institution": "Technical University of Crete",
              "dsl": "Electrical and Computer Engineering"
            }
          ],
          "personId": 122263
        },
        {
          "affiliations": [
            {
              "country": "Netherlands",
              "state": "",
              "city": "Utrecht",
              "institution": "Utrecht University",
              "dsl": ""
            }
          ],
          "personId": 122241
        }
      ]
    }
  ],
  "people": [
    {
      "id": 121034,
      "firstName": "Marius",
      "lastName": "Hoggenmüller",
      "middleInitial": "",
      "importedId": "nwxBNWwxvwc5ala2wU0xSQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121035,
      "firstName": "Huajian",
      "lastName": "Qiu",
      "middleInitial": "",
      "importedId": "5dhtOF38wKuCZi7Pq4ZVpQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121036,
      "firstName": "Matthias",
      "lastName": "Hoppe",
      "middleInitial": "",
      "importedId": "Lkq0Iab9-No5KlhYyZuXNg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121037,
      "firstName": "Nađa",
      "lastName": "Terzimehić",
      "middleInitial": "",
      "importedId": "kx91fyss8r1B5FEFX842Lw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121038,
      "firstName": "Michael",
      "lastName": "Glöckler",
      "middleInitial": "",
      "importedId": "GzS3lo-KPIw-VKAE3HXwgQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121039,
      "firstName": "Cristina",
      "lastName": "Evangelista",
      "middleInitial": "",
      "importedId": "TAakXmIxQaBTNfTTmzLeAQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121040,
      "firstName": "Carlos",
      "lastName": "Gomes",
      "middleInitial": "",
      "importedId": "5KVMO6oumnKKhAhCh4BYcw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121041,
      "firstName": "Kota",
      "lastName": "Tsubouchi",
      "middleInitial": "",
      "importedId": "aSjHwXyRdwndAcyF_VlYkw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121042,
      "firstName": "Xinglin",
      "lastName": "Zhang",
      "middleInitial": "",
      "importedId": "YqzTA8ddXCJnmdBNhH3caw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121043,
      "firstName": "Miriam",
      "lastName": "Halsner",
      "middleInitial": "",
      "importedId": "Bdjdap9OnZB4TzAnYdjPgA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121044,
      "firstName": "Susanna",
      "lastName": "Kraemer",
      "middleInitial": "",
      "importedId": "jSuFuH0EeQQ3FCkLMmVLzw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121045,
      "firstName": "René",
      "lastName": "Schäfer",
      "middleInitial": "",
      "importedId": "jLVT47Zh2nHy-OAdXVrtPA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121046,
      "firstName": "Jakob",
      "lastName": "Karolus",
      "middleInitial": "",
      "importedId": "uS4ZLqmddQDCzjPrNQqp-w",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121047,
      "firstName": "Nina",
      "lastName": "Trilck",
      "middleInitial": "",
      "importedId": "obWrIh-1Stwi2DbeJuwCHw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121048,
      "firstName": "Bernhard",
      "lastName": "Jenny",
      "middleInitial": "",
      "importedId": "ADCTupIvNATrgP2EX8YVIA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121049,
      "firstName": "Tsai-Yuan",
      "lastName": "Huang",
      "middleInitial": "",
      "importedId": "v4DVS-TvkB87jiCj07yrEA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121050,
      "firstName": "Hasti",
      "lastName": "Sharifi",
      "middleInitial": "",
      "importedId": "ma9SXcA5Bt61xpYksKgdJQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121051,
      "firstName": "Géry",
      "lastName": "Casiez",
      "middleInitial": "",
      "importedId": "DIpebubG6g2BUtnvQQ6Pcg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121052,
      "firstName": "Nova",
      "lastName": "Ahmed",
      "middleInitial": "",
      "importedId": "XznpkGXkCOWMf3no7I_fJA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121053,
      "firstName": "Michael",
      "lastName": "Chamunorwa",
      "middleInitial": "",
      "importedId": "GmbnA9mpRS-5XWnt7rgRsA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121054,
      "firstName": "Francesco",
      "lastName": "Chiossi",
      "middleInitial": "",
      "importedId": "s1Xyc1j9ixsl9NOK4VT4lQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121055,
      "firstName": "Boyin",
      "lastName": "Yang",
      "middleInitial": "",
      "importedId": "luFRKnu_fCWriZYXUi3BQg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121056,
      "firstName": "Luca",
      "lastName": "Taglialatela",
      "middleInitial": "E.",
      "importedId": "k6ZRTIiCcbDJ0_W7u7Amxg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121057,
      "firstName": "Marc",
      "lastName": "Hassenzahl",
      "middleInitial": "",
      "importedId": "bOgi58e7cl97_39gPoCauA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121058,
      "firstName": "Ioannis",
      "lastName": "Giannopoulos",
      "middleInitial": "",
      "importedId": "RP72HG2LJG-4hWt6vMFTgw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121059,
      "firstName": "Chen",
      "lastName": "Qiu",
      "middleInitial": "",
      "importedId": "six-r0N-GjYwG4yPiT5qUQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121060,
      "firstName": "Andrew",
      "lastName": "Garbett",
      "middleInitial": "",
      "importedId": "qeDU-GfKR6NjCjH3-KoUPg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121061,
      "firstName": "Guanyun",
      "lastName": "Wang",
      "middleInitial": "",
      "importedId": "aNj3BsCl2b0b7FACxYJdKA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121062,
      "firstName": "Tiago",
      "lastName": "Guedes",
      "middleInitial": "",
      "importedId": "ZvuED0hYKueRNFvJIKiRUw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121063,
      "firstName": "Uwe",
      "lastName": "Gruenefeld",
      "middleInitial": "",
      "importedId": "oLvfjZm0xHwl7reMcJOYcA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121064,
      "firstName": "Mike",
      "lastName": "Chen",
      "middleInitial": "Y.",
      "importedId": "lHUnsX0Tf6ZdyKH8WPjT9w",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121065,
      "firstName": "Luca-Maxim",
      "lastName": "Meinhardt",
      "middleInitial": "",
      "importedId": "mlTpE3zPbJqkAdb0Bwyxuw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121066,
      "firstName": "William",
      "lastName": "Delamare",
      "middleInitial": "",
      "importedId": "GmdmiRIe73aK8dgrQYEEIA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121067,
      "firstName": "Takeo",
      "lastName": "Igarashi",
      "middleInitial": "",
      "importedId": "NliWHj4jVUv6t80JrxzoRQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121068,
      "firstName": "Itto",
      "lastName": "Kornecki",
      "middleInitial": "",
      "importedId": "8Do5huI4LosnvM4pOxbSIA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121069,
      "firstName": "Christian",
      "lastName": "Holz",
      "middleInitial": "",
      "importedId": "iLPlU_z1dah9YY__uEeXsw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121070,
      "firstName": "Shih-Yu",
      "lastName": "Ma",
      "middleInitial": "",
      "importedId": "9eCI6C9n2TA8RZbtuWolLQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121071,
      "firstName": "Jonathan",
      "lastName": "Liebers",
      "middleInitial": "",
      "importedId": "hjN3Tf8t6kx12-GGBe24TQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121072,
      "firstName": "Stewart",
      "lastName": "Worrall",
      "middleInitial": "",
      "importedId": "yaBqXJ9vP19SJXEzUT35iQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121073,
      "firstName": "Fabio",
      "lastName": "Paternò",
      "middleInitial": "",
      "importedId": "KnKTr0CmXVvzaE4nW3dyNg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121074,
      "firstName": "Anna",
      "lastName": "Schlothauer",
      "middleInitial": "",
      "importedId": "zu9jBhsTkqCgyYf24rYBIw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121075,
      "firstName": "Hatice",
      "lastName": "Şahin İppoliti",
      "middleInitial": "",
      "importedId": "NSQjJ9Vddn6FnwDFNTmG1g",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121076,
      "firstName": "Chao",
      "lastName": "Zhang",
      "middleInitial": "",
      "importedId": "p23VIGxUCGjO2IVOuQiFCg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121077,
      "firstName": "Rahat Jahangir",
      "lastName": "Rony",
      "middleInitial": "",
      "importedId": "7q0WJ1rkJh2T-0DAf98mew",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121078,
      "firstName": "Maria",
      "lastName": "Roussou",
      "middleInitial": "",
      "importedId": "XBKj6w51-g9JWpLG5pZONA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121079,
      "firstName": "Tito Daza",
      "lastName": "Rubiano",
      "middleInitial": "",
      "importedId": "aU_sM_GFrNqhWClZ1_aKDg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121080,
      "firstName": "Per Ola",
      "lastName": "Kristensson",
      "middleInitial": "",
      "importedId": "Pt7egBTd0PmDizY4N8kNDQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121081,
      "firstName": "Adrien",
      "lastName": "Chaffangeon Caillet",
      "middleInitial": "",
      "importedId": "qSOtzXlLWngLZr4I5Il9Mw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121082,
      "firstName": "Johannes",
      "lastName": "Schöning",
      "middleInitial": "",
      "importedId": "fc9sshp8L9i6K6CitF8edw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121083,
      "firstName": "Jan Ole",
      "lastName": "Rixen",
      "middleInitial": "",
      "importedId": "whR68NyE6Xgf4Yurv7aqLQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121084,
      "firstName": "Haipeng",
      "lastName": "Mi",
      "middleInitial": "",
      "importedId": "BDw8B7BArYd3guR0WQqY0w",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121085,
      "firstName": "Augusto",
      "lastName": "Esteves",
      "middleInitial": "",
      "importedId": "7f2iQ_8H8O1G87Aj2KDagw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121086,
      "firstName": "Luke",
      "lastName": "Haliburton",
      "middleInitial": "",
      "importedId": "ZZ0nXcevibFsMeHljX_SJw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121087,
      "firstName": "Roman",
      "lastName": "Heger",
      "middleInitial": "",
      "importedId": "AqLFdtQ9GBgoK4GHMYMqAg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121088,
      "firstName": "Cong Min",
      "lastName": "Lin",
      "middleInitial": "",
      "importedId": "vw9GuSCzUu5wnpHghgOOEQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121089,
      "firstName": "Shota",
      "lastName": "Yamanaka",
      "middleInitial": "",
      "importedId": "1Qctf2puZsJX-j0cIylfDg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121090,
      "firstName": "Johannes",
      "lastName": "Wilhelm",
      "middleInitial": "",
      "importedId": "xnfRpr2sCsTYHasXKIn1vQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121091,
      "firstName": "Debargha",
      "lastName": "Dey",
      "middleInitial": "",
      "importedId": "kzPMLFNA1oWb6zBsfMx8gg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121092,
      "firstName": "Chia-An",
      "lastName": "Fan",
      "middleInitial": "",
      "importedId": "oLDLKHEz-WGChAQl57XpiA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121093,
      "firstName": "Christoph",
      "lastName": "Gebhardt",
      "middleInitial": "",
      "importedId": "sqi8n0FfEM1tKtLA64ElSA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121094,
      "firstName": "Bartosz",
      "lastName": "Mazurkiewicz",
      "middleInitial": "",
      "importedId": "D4uM4bpTP0KGXU0lZsqATw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121095,
      "firstName": "Tiffany",
      "lastName": "Luong",
      "middleInitial": "",
      "importedId": "op7L1Kh7jn3NKLQnh8RnRA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121096,
      "firstName": "Gulnar",
      "lastName": "Rakhmetulla",
      "middleInitial": "",
      "importedId": "lYDVvTEiKfKSl6AYXdszZw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121097,
      "firstName": "Lucas",
      "lastName": "Silva",
      "middleInitial": "M.",
      "importedId": "0V0DXSrla_5sGM5BWAWi5g",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121098,
      "firstName": "Robin",
      "lastName": "Welsch",
      "middleInitial": "",
      "importedId": "ihQfOi4bvjFKwaO1MNw8Xw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121099,
      "firstName": "Junichi",
      "lastName": "Sato",
      "middleInitial": "",
      "importedId": "3vgvnKhkruRmNZcLKge5cA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121100,
      "firstName": "Benedikt",
      "lastName": "Pirker",
      "middleInitial": "",
      "importedId": "MGpEvsY9GpjdKaiV7gc9Tg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121101,
      "firstName": "Paweł W.",
      "lastName": "Woźniak",
      "middleInitial": "",
      "importedId": "VJzNdW_xniDVJjfrB8dpcQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121102,
      "firstName": "Abraham",
      "lastName": "Glasser",
      "middleInitial": "",
      "importedId": "OaBxo_6CGLV760cyIGnV1A",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121103,
      "firstName": "Qihang",
      "lastName": "Jin",
      "middleInitial": "",
      "importedId": "BQoEUURSefenntHdNs4iGA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121104,
      "firstName": "Sven",
      "lastName": "Mayer",
      "middleInitial": "",
      "importedId": "aGMdv_UqvRAFIxAEt3rNsw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121105,
      "firstName": "Ekram",
      "lastName": "Hossain",
      "middleInitial": "",
      "importedId": "ZUpuKSY_bNW-KPlqzHlUmQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121106,
      "firstName": "Neng-Hao",
      "lastName": "Yu",
      "middleInitial": "",
      "importedId": "nIxp3kNU3IdOBhaoioBWQQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121107,
      "firstName": "Zhiwen",
      "lastName": "Yu",
      "middleInitial": "",
      "importedId": "3PEKUe-_EIcQv9G6VS80mA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121108,
      "firstName": "Ulrich",
      "lastName": "Engelke",
      "middleInitial": "",
      "importedId": "X1D4iP6zZlV_OAd3rqgiPw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121109,
      "firstName": "Anna",
      "lastName": "Feit",
      "middleInitial": "Maria",
      "importedId": "fRUBGy6UaA-NDMjP-V3WGA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121110,
      "firstName": "Yuqi",
      "lastName": "Huai",
      "middleInitial": "",
      "importedId": "WfB8cNdqbg0Vn__k2PEZwQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121111,
      "firstName": "Chenshu",
      "lastName": "Wu",
      "middleInitial": "",
      "importedId": "AvVbicGKqLRKbaSmDuzgzw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121112,
      "firstName": "Khalad",
      "lastName": "Hasan",
      "middleInitial": "",
      "importedId": "7CkZjwYqftGmEzOEveetqw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121113,
      "firstName": "Sean",
      "lastName": "Forbes",
      "middleInitial": "",
      "importedId": "racn0nHCSTyepYYmMxBpZg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121114,
      "firstName": "Jonas",
      "lastName": "Keppel",
      "middleInitial": "",
      "importedId": "GMobdZOygcmzWBCZVIq1RQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121115,
      "firstName": "Sebastian",
      "lastName": "Hueber",
      "middleInitial": "",
      "importedId": "x1oLsptda6PLwLVBx-RTgw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121116,
      "firstName": "Adil",
      "lastName": "Rahman",
      "middleInitial": "",
      "importedId": "x4QSWXV3o5-SG4BTv_xfQA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121117,
      "firstName": "Johanna",
      "lastName": "Pirker",
      "middleInitial": "",
      "importedId": "lwND6YgAz-JXMzgXRIl3jQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121118,
      "firstName": "Chia-Chen",
      "lastName": "Wu",
      "middleInitial": "",
      "importedId": "gzMFoeg5MjyPy7Q4sZSJMg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121119,
      "firstName": "Yi-Ting",
      "lastName": "Ho",
      "middleInitial": "",
      "importedId": "fHwDdI-Xo_eJ7ljYncn2AA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121120,
      "firstName": "Steeven",
      "lastName": "Villa",
      "middleInitial": "",
      "importedId": "H9eoI_KhiFXgd9zP2Qn9EA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121121,
      "firstName": "Daniel",
      "lastName": "Buschek",
      "middleInitial": "",
      "importedId": "-PmisC4rRA8oAfHrwVVdYQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121122,
      "firstName": "Marcelo",
      "lastName": "Galvão",
      "middleInitial": "de Lima",
      "importedId": "SJVmefUrodt_f-IO7tCOYw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121123,
      "firstName": "Jan",
      "lastName": "Borchers",
      "middleInitial": "",
      "importedId": "cimyCe-7YmMY4moG3R4DqQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121124,
      "firstName": "Vincent",
      "lastName": "LAMBERT",
      "middleInitial": "",
      "importedId": "-kZ5PC5WJBlaSKm4xocVDg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121125,
      "firstName": "Yun-Ting",
      "lastName": "Cheng",
      "middleInitial": "",
      "importedId": "0iyBdGXyiUFaDitQkSmbeg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121126,
      "firstName": "Wei",
      "lastName": "Chen",
      "middleInitial": "",
      "importedId": "iUOcMFagLB7HxrfqOaJrZQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121127,
      "firstName": "Rosta",
      "lastName": "Farzan",
      "middleInitial": "",
      "importedId": "k1NTKISsa05LHXjxlhtyBw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121128,
      "firstName": "Nathan",
      "lastName": "Qualls",
      "middleInitial": "",
      "importedId": "kAY5aRTOmB0PlemuArvFTA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121129,
      "firstName": "Sam",
      "lastName": "Sepah",
      "middleInitial": "S.",
      "importedId": "VxLkEwlAmWAd0nvjTEsbcQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121130,
      "firstName": "Marvin",
      "lastName": "Strauss",
      "middleInitial": "",
      "importedId": "OU0V1qvhba-6CbOOf7suqg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121131,
      "firstName": "Naoto",
      "lastName": "Nishida",
      "middleInitial": "",
      "importedId": "aU2vy8rQ8eioC8yVntts2Q",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121132,
      "firstName": "Yagiz",
      "lastName": "Turgut",
      "middleInitial": "",
      "importedId": "GYJfLjN0Ye9l5vtxvyLc8A",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121133,
      "firstName": "CHIH-CHI",
      "lastName": "CHUNG",
      "middleInitial": "",
      "importedId": "O0eitujhIlH1mvjH1WIn5w",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121134,
      "firstName": "Yanhong",
      "lastName": "Wu",
      "middleInitial": "",
      "importedId": "VaVwyiYlRgmAJP8LZayGgg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121135,
      "firstName": "Ahmed",
      "lastName": "Arif",
      "middleInitial": "Sabbir",
      "importedId": "1x3KFFHHEe9u9l3Xl9LQxg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121136,
      "firstName": "Bastian",
      "lastName": "Pfleging",
      "middleInitial": "",
      "importedId": "ZdzVJV4BOj3f0X2rFLH9ew",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121137,
      "firstName": "Yung-Ju",
      "lastName": "Chang",
      "middleInitial": "",
      "importedId": "4fqA22UA7fOw_djjgasuxw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121138,
      "firstName": "Sylvain",
      "lastName": "Malacria",
      "middleInitial": "",
      "importedId": "-XkZNXaCRSB1PSPFzDJFkQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121139,
      "firstName": "Carolyn",
      "lastName": "Yu",
      "middleInitial": "",
      "importedId": "RRng4WGZRd5VyELTMICW_w",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121140,
      "firstName": "Ya Chi",
      "lastName": "Liao",
      "middleInitial": "",
      "importedId": "M8fwbiS9KaJaggDybDe2kA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121141,
      "firstName": "Sohan",
      "lastName": "Chowdhury",
      "middleInitial": "",
      "importedId": "CpV9hUrYFS67IQ-Oc05TUg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121142,
      "firstName": "Melanie",
      "lastName": "Berger",
      "middleInitial": "",
      "importedId": "fEGo6cYbiKO7rOhmGCprew",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121143,
      "firstName": "Julie",
      "lastName": "Williamson",
      "middleInitial": "R.",
      "importedId": "ZKH_-pB1OqX7SuMTQup9UQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121144,
      "firstName": "Alarith",
      "lastName": "Uhde",
      "middleInitial": "",
      "importedId": "QV8N1uHObWDh4j40QwPb5A",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121145,
      "firstName": "Max",
      "lastName": "Shengelia",
      "middleInitial": "",
      "importedId": "nbSvrUe2QFxilt9FCyO3EQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121146,
      "firstName": "Enrico",
      "lastName": "Rukzio",
      "middleInitial": "",
      "importedId": "FrzgGkMaoVPeiaBR8A7mbg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121147,
      "firstName": "Sarah",
      "lastName": "Faltaous",
      "middleInitial": "",
      "importedId": "bMNkeM9lm-UdOliilRCi8Q",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121148,
      "firstName": "Tom",
      "lastName": "Bartindale",
      "middleInitial": "",
      "importedId": "wvBt7uCZxu2puq9ZkPhGaA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121149,
      "firstName": "Bahareh",
      "lastName": "Barati",
      "middleInitial": "",
      "importedId": "FEB6oAWsAk0SqPNhQFR9XA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121150,
      "firstName": "Marius-Lukas",
      "lastName": "Ziegenbein",
      "middleInitial": "",
      "importedId": "g7E-lY4y5oG5DreQs5DWhA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121151,
      "firstName": "Luca",
      "lastName": "Menghini",
      "middleInitial": "",
      "importedId": "lyqs6dDwlCfhyMMrezV-Iw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121152,
      "firstName": "Martin",
      "lastName": "Tomitsch",
      "middleInitial": "",
      "importedId": "E1DYVnUEei3M_1K7t2iT9A",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121153,
      "firstName": "Mohammad",
      "lastName": "Hadi",
      "middleInitial": "Abdul",
      "importedId": "tGaEuwFEp5t2aVx2RKJqng",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121154,
      "firstName": "Seongkook",
      "lastName": "Heo",
      "middleInitial": "",
      "importedId": "8u6ENy5fbi7xGnVehduTFg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121155,
      "firstName": "Regina",
      "lastName": "Bernhaupt",
      "middleInitial": "",
      "importedId": "JWEnJDF_7PsmsjFbqVf9fQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121156,
      "firstName": "Debaleena",
      "lastName": "Chattopadhyay",
      "middleInitial": "",
      "importedId": "79QpbeOGjz7Q4UZmF7e2WA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121157,
      "firstName": "Elizabeth",
      "lastName": "Ankrah",
      "middleInitial": "",
      "importedId": "X-v8YJhYiLpx77KmRjNBGA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121158,
      "firstName": "Eva",
      "lastName": "Mackamul",
      "middleInitial": "",
      "importedId": "L351jmnnQTNh8MthwKetng",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121159,
      "firstName": "Barrett",
      "lastName": "Ens",
      "middleInitial": "",
      "importedId": "FM5AHP4blxjPPnJmhlwoag",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121160,
      "firstName": "Senuri",
      "lastName": "Wijenayake",
      "middleInitial": "",
      "importedId": "iYn-5mjUGT7rvK0Jaqenng",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121161,
      "firstName": "Luis",
      "lastName": "Leiva",
      "middleInitial": "A.",
      "importedId": "zEw1asvR5_8wPjGUPy5Fbg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121162,
      "firstName": "Maristella",
      "lastName": "Matera",
      "middleInitial": "",
      "importedId": "NckneH6RR4n2HP6A7d73ug",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121163,
      "firstName": "Michael",
      "lastName": "Holly",
      "middleInitial": "",
      "importedId": "WtxnizOMLLWCKrgnaohH9g",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121164,
      "firstName": "Thad",
      "lastName": "Starner",
      "middleInitial": "",
      "importedId": "sWKS6wUrUI9sUgYhmC3G8g",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121165,
      "firstName": "Patrick",
      "lastName": "Olivier",
      "middleInitial": "",
      "importedId": "yANaVp6sUaYMe6vrAiJLZQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121166,
      "firstName": "Zeinab",
      "lastName": "Ghaemi",
      "middleInitial": "",
      "importedId": "PHccEC-ripBOx9gouAa-2Q",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121167,
      "firstName": "Mikołaj",
      "lastName": "Woźniak",
      "middleInitial": "P.",
      "importedId": "SOVeT4ZsldKXrmrxfwUAQw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121168,
      "firstName": "Pourang",
      "lastName": "Irani",
      "middleInitial": "",
      "importedId": "zXAUstMVhPyPsWt6QQC9sQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121169,
      "firstName": "Marco",
      "lastName": "Philip",
      "middleInitial": "",
      "importedId": "h9xiezAkfLCZRdTl4opy2A",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121170,
      "firstName": "Florian",
      "lastName": "Bemmann",
      "middleInitial": "",
      "importedId": "neHRwhECQA471ocQV6_kYg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121171,
      "firstName": "Sebastian",
      "lastName": "Resch",
      "middleInitial": "",
      "importedId": "MdfpPUU-rdF9qcxTz2X0Rw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121172,
      "firstName": "Kaori",
      "lastName": "Ikematsu",
      "middleInitial": "",
      "importedId": "ydhDL2ZEmScGGp3dMOVqOw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121173,
      "firstName": "Paul",
      "lastName": "Streli",
      "middleInitial": "",
      "importedId": "iBBibiAD0taDgXYe3eG7Yw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121174,
      "firstName": "Chen-Chin",
      "lastName": "Lin",
      "middleInitial": "",
      "importedId": "9oCI8SonbTPLZ2QQiFYgzQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121175,
      "firstName": "Susanne",
      "lastName": "Boll",
      "middleInitial": "",
      "importedId": "h8Gk_22hVpBlCzdhLPLxZA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121176,
      "firstName": "Simon",
      "lastName": "Voelker",
      "middleInitial": "",
      "importedId": "fpJ-4KLb9de-ODnwNufy-A",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121177,
      "firstName": "Yu-Hsin",
      "lastName": "Lai",
      "middleInitial": "",
      "importedId": "BSeZk7OVodiqNxDJORUwVA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121178,
      "firstName": "Zihao",
      "lastName": "Yin",
      "middleInitial": "",
      "importedId": "62ABrEp5S9o1dA9iS3QMog",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121179,
      "firstName": "Stefan",
      "lastName": "Schneegass",
      "middleInitial": "",
      "importedId": "QMo-7Iuectu0tMAaNm6edg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121180,
      "firstName": "Yiyuan",
      "lastName": "Wang",
      "middleInitial": "",
      "importedId": "Tai6m3UNSWI-3rgdOS1M6Q",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121181,
      "firstName": "Saad",
      "lastName": "Hassan",
      "middleInitial": "",
      "importedId": "phATLND7nvxmKxusheOTLA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121182,
      "firstName": "Laurence",
      "lastName": "Nigay",
      "middleInitial": "",
      "importedId": "xY6CiO-bfiM5lkRMtAOhaA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121183,
      "firstName": "Andrea",
      "lastName": "Mattioli",
      "middleInitial": "",
      "importedId": "7GltvNvvRMkV3C9uE5XCpg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121184,
      "firstName": "Thomas",
      "lastName": "Kosch",
      "middleInitial": "",
      "importedId": "xNJhF8Um1cSTuL-8ebzsgg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121185,
      "firstName": "Danli",
      "lastName": "Luo",
      "middleInitial": "",
      "importedId": "kekpTaIpk8Hb8PNqThtoSQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121186,
      "firstName": "Chia-Ming",
      "lastName": "Chang",
      "middleInitial": "",
      "importedId": "aiJ5verWvtUnd1viC9qM7w",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121187,
      "firstName": "Daniel",
      "lastName": "Epstein",
      "middleInitial": "A.",
      "importedId": "uIyc5CWlT1-FXTBLQby8OQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121188,
      "firstName": "Md Aashikur Rahman",
      "lastName": "Azim",
      "middleInitial": "",
      "importedId": "ya5t-YOyLMtwf8RHdW5BYw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121189,
      "firstName": "Heiko",
      "lastName": "Müller",
      "middleInitial": "",
      "importedId": "sqVNgvf9-9Gdn40KvjX0ig",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121190,
      "firstName": "Yuan",
      "lastName": "Ren",
      "middleInitial": "",
      "importedId": "llUfhSjpnAwrb3i9LU3IWg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121191,
      "firstName": "Albrecht",
      "lastName": "Schmidt",
      "middleInitial": "",
      "importedId": "r8sh9GdFO7dA9XL50gpazA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121192,
      "firstName": "Stephen",
      "lastName": "Brewster",
      "middleInitial": "Anthony",
      "importedId": "5oR5tpEfy7_GSFNHxRxKQw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121193,
      "firstName": "Tim",
      "lastName": "zum Hoff",
      "middleInitial": "",
      "importedId": "TlIeOL__zukPx9yUa78KSA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121194,
      "firstName": "Xi",
      "lastName": "Yang",
      "middleInitial": "",
      "importedId": "D5n1I60650pRwUxSfWcCLQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121195,
      "firstName": "Zhenjiang",
      "lastName": "Li",
      "middleInitial": "",
      "importedId": "nz_hcAaSkAEcAEIEX-3F8Q",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121196,
      "firstName": "Pranut",
      "lastName": "Jain",
      "middleInitial": "",
      "importedId": "rbRLEWuzXVuvPLzmXk1-rA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121197,
      "firstName": "Xiang 'Anthony'",
      "lastName": "Chen",
      "middleInitial": "",
      "importedId": "KpO_0vxU-ZNKmw9QA3hTuw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121198,
      "firstName": "Mark",
      "lastName": "Colley",
      "middleInitial": "",
      "importedId": "k9GwjoFmtOKP1dRf6dW8sw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121199,
      "firstName": "Paolo",
      "lastName": "Holinski",
      "middleInitial": "",
      "importedId": "OrylNF2bGR0pCVnVUr-8Jw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121200,
      "firstName": "Bin",
      "lastName": "Guo",
      "middleInitial": "",
      "importedId": "3_yZusfsFJgT8kCSQcwHVQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121201,
      "firstName": "Zihan",
      "lastName": "Yan",
      "middleInitial": "",
      "importedId": "-3vsEkPAM8r6kMbo3_2q4g",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121202,
      "firstName": "Yi",
      "lastName": "Tang",
      "middleInitial": "",
      "importedId": "SZicHuOG25ANmT7uxiFJkA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121203,
      "firstName": "Marion",
      "lastName": "Koelle",
      "middleInitial": "",
      "importedId": "kEXDR06q99XOOFE0vFpI8w",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121204,
      "firstName": "Ping-Ju",
      "lastName": "Huang",
      "middleInitial": "",
      "importedId": "1Z4NfZb20Kl1djIC1UmM2w",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121205,
      "firstName": "Jan",
      "lastName": "Gugenheimer",
      "middleInitial": "",
      "importedId": "uzEWEil6Mz44r4ZcZ8T5GA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121206,
      "firstName": "Katerina",
      "lastName": "El Raheb",
      "middleInitial": "",
      "importedId": "mpTSRQYc71uilix0RLBegA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121207,
      "firstName": "Vasilis",
      "lastName": "Vlachokyriakos",
      "middleInitial": "",
      "importedId": "VWWWVB_zpVAg6503OlPHvw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121208,
      "firstName": "Luke",
      "lastName": "Hespanhol",
      "middleInitial": "",
      "importedId": "DTFspifs1pR40NprAwS0Yg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121209,
      "firstName": "Bettina",
      "lastName": "Eska",
      "middleInitial": "",
      "importedId": "LzpH3Gin2cmAc5yqIVO7ag",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121210,
      "firstName": "Laura",
      "lastName": "Bajorunaite",
      "middleInitial": "",
      "importedId": "sr0lrL3EBFrklhxSId39QA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121211,
      "firstName": "Md Sabbir",
      "lastName": "Ahmed",
      "middleInitial": "",
      "importedId": "oyHpX_Yd50GJZ-gvtonhXw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121212,
      "firstName": "Yingcai",
      "lastName": "Wu",
      "middleInitial": "",
      "importedId": "578wgyxUrFOd78ek47YfAQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121213,
      "firstName": "Florian",
      "lastName": "Lehmann",
      "middleInitial": "",
      "importedId": "Nf9XHogSmhkGkZjT1qUsyw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121214,
      "firstName": "Alix",
      "lastName": "Goguey",
      "middleInitial": "",
      "importedId": "D--hWgGqn0i-gnRBtXJ9Cw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 121215,
      "firstName": "Adam",
      "lastName": "Lee",
      "middleInitial": "J.",
      "importedId": "Tq-o4_oB_sCA440KheJZVg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122080,
      "firstName": "Mark",
      "lastName": "Dunlop",
      "importedId": "9b44fbd0-6853-4e15-af5a-b82a06537797",
      "source": "SYS",
      "affiliations": [
        {
          "country": "United Kingdom",
          "city": "Glasgow",
          "institution": "University of Strathclyde"
        }
      ]
    },
    {
      "id": 122081,
      "firstName": "Evropi",
      "lastName": "Stefanidi",
      "importedId": "3aa48a46-39ba-4d83-8b73-1d7f045ddca5",
      "source": "SYS",
      "affiliations": [
        {
          "country": "Switzerland",
          "city": "Geneva",
          "institution": "University of Geneva"
        }
      ]
    },
    {
      "id": 122082,
      "firstName": "Joel",
      "lastName": "Lanir",
      "importedId": "683082b1-bb9e-4e5a-9039-7d8af9b7d08d",
      "source": "SYS",
      "affiliations": [
        {
          "country": "Israel",
          "city": "Haifa",
          "institution": "University of Haifa"
        }
      ]
    },
    {
      "id": 122083,
      "firstName": "Schneegass",
      "lastName": "Christina",
      "importedId": "44ace3ed-23e0-4f48-9160-18feb3af6bc3",
      "source": "SYS",
      "affiliations": [
        {
          "country": "Netherlands",
          "city": "Delft",
          "institution": "TU Delft"
        }
      ]
    },
    {
      "id": 122084,
      "firstName": "Luigi",
      "lastName": "De Russis",
      "importedId": "be5e56dd-9b9f-4302-bc36-e2b9f577ad92",
      "source": "SYS",
      "affiliations": [
        {
          "country": "Turin",
          "city": "Italy",
          "institution": "Politecnico di Torino"
        }
      ]
    },
    {
      "id": 122136,
      "firstName": "Dimitris",
      "lastName": "Spathis",
      "middleInitial": "",
      "importedId": "mlAnjtZ2PgKekH98xMgb4A",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122137,
      "firstName": "Suzannah",
      "lastName": "Iadarola",
      "middleInitial": "",
      "importedId": "yfEOdfK-Rxy-rlY7tQPeUg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122138,
      "firstName": "Paulo",
      "lastName": "Dias",
      "middleInitial": "",
      "importedId": "ZgIlaSBbGrKmdkpEBh7fdg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122139,
      "firstName": "Anna",
      "lastName": "Lisowska",
      "middleInitial": "",
      "importedId": "tEf06qjimCel61NDJ-unOQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122140,
      "firstName": "Yaqing",
      "lastName": "Chai",
      "middleInitial": "",
      "importedId": "SR2jd-xLt3vJl_8lori6QQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122141,
      "firstName": "Zhiwei",
      "lastName": "Yu",
      "middleInitial": "",
      "importedId": "lDc9Cif6VUSPZaa2dAQO1g",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122142,
      "firstName": "Tianyuan",
      "lastName": "Cai",
      "middleInitial": "",
      "importedId": "Zvs8XBxHQMpBBym5TeYNcw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122143,
      "firstName": "Shizhen",
      "lastName": "Su",
      "middleInitial": "",
      "importedId": "82mxoXJeoj3e_4qyPZuqLg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122144,
      "firstName": "Sofia",
      "lastName": "Yfantidou",
      "middleInitial": "",
      "importedId": "13lwLqQ6v8z7NMfMBpnrKg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122145,
      "firstName": "Carlos",
      "lastName": "Ferreira",
      "middleInitial": "",
      "importedId": "Z4wvVw37vr25APzJsSLM7Q",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122146,
      "firstName": "Eunae",
      "lastName": "Jang",
      "middleInitial": "",
      "importedId": "v9PJbjC-E2cJya0XLik3bQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122147,
      "firstName": "Grace",
      "lastName": "Levine",
      "middleInitial": "",
      "importedId": "E4BgaSkLeRWsO9YdPSz9yg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122148,
      "firstName": "Maedeh",
      "lastName": "Agharazidermani",
      "middleInitial": "",
      "importedId": "JbErLkBomMts0ytqCw5Cgg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122149,
      "firstName": "Hichang",
      "lastName": "Cho",
      "middleInitial": "",
      "importedId": "iNJjujt22_Fg8A4Fvyd03w",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122150,
      "firstName": "Adit",
      "lastName": "Nair",
      "middleInitial": "",
      "importedId": "_uJioK4uq77O8bxDPvR-cw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122151,
      "firstName": "Lincoln",
      "lastName": "Lu",
      "middleInitial": "",
      "importedId": "A5qZCPKGieenej_KUeF82g",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122152,
      "firstName": "Pratheep Kumar",
      "lastName": "Chelladurai",
      "middleInitial": "",
      "importedId": "ymNEyabxw4jD9ni_88MIog",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122153,
      "firstName": "Tae",
      "lastName": "Oh",
      "middleInitial": "",
      "importedId": "taVd_kEsAYrz0aYCPB5GXg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122154,
      "firstName": "Carole",
      "lastName": "Blond-Hanten",
      "middleInitial": "",
      "importedId": "A4fJgIygeR8LDfje_M052Q",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122155,
      "firstName": "Michael",
      "lastName": "Kraley",
      "middleInitial": "",
      "importedId": "5OKSbId4ceTpar8cuvMzIQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122156,
      "firstName": "Aleena",
      "lastName": "Niklaus",
      "middleInitial": "Gertrudes",
      "importedId": "UloZZP1HjpW-rR9t2CX-Ng",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122157,
      "firstName": "Fahim",
      "lastName": "Kawsar",
      "middleInitial": "",
      "importedId": "g7v8B0tFVboBnT1rfa-Xnw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122158,
      "firstName": "Peter",
      "lastName": "Bajorski",
      "middleInitial": "",
      "importedId": "a9ZpyymjfvHu7DfQCWRdIw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122159,
      "firstName": "Mingma",
      "lastName": "Sherpa",
      "middleInitial": "Tendu",
      "importedId": "Q7Bw5SoLgeEwHSVErXdBoQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122160,
      "firstName": "Zhuo",
      "lastName": "Sun",
      "middleInitial": "",
      "importedId": "o64i7n7-J_5jNj4QJilDFA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122161,
      "firstName": "Frensen",
      "lastName": "Salim",
      "middleInitial": "",
      "importedId": "3reAIpJfF0-gdplYtEQ-Qg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122162,
      "firstName": "Zihao",
      "lastName": "Mei",
      "middleInitial": "",
      "importedId": "xH34_DPl1vJt5KkcfYS5bQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122163,
      "firstName": "Virmarie",
      "lastName": "Maquiling",
      "middleInitial": "",
      "importedId": "0ns4Vp-m4w9EpC1NTyffEg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122164,
      "firstName": "Diederick",
      "lastName": "Niehorster",
      "middleInitial": "C.",
      "importedId": "wR7rI4SDeBGl5HnxHdG8yw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122165,
      "firstName": "Kristy Elizabeth",
      "lastName": "Boyer",
      "middleInitial": "",
      "importedId": "pJU--BaC_SangOLWVf4JRQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122166,
      "firstName": "Jin-Woo",
      "lastName": "Jeong",
      "middleInitial": "",
      "importedId": "dy9LBRyBf0yblc3l3cg7Mg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122167,
      "firstName": "Luigi",
      "lastName": "De Russis",
      "middleInitial": "",
      "importedId": "bSoGz4pjXQs7zptorCrAzQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122168,
      "firstName": "Aneta",
      "lastName": "Lisowska",
      "middleInitial": "",
      "importedId": "P4oAjJt0651RGg_9cyPJiw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122169,
      "firstName": "Soojin",
      "lastName": "Jun",
      "middleInitial": "",
      "importedId": "_D2ubbc9in4AXZ8Hw3THcw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122170,
      "firstName": "Harin",
      "lastName": "Yoon",
      "middleInitial": "",
      "importedId": "czsYDpu6wOyKwwi5VUGE7w",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122171,
      "firstName": "Zhu",
      "lastName": "Wang",
      "middleInitial": "",
      "importedId": "qwWD1XKuRJhgfus8hyZTzA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122172,
      "firstName": "Arkadiusz",
      "lastName": "Sitek",
      "middleInitial": "",
      "importedId": "h9mwpVw3iZ25tcOuYNjmJQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122173,
      "firstName": "Zhi",
      "lastName": "Zheng",
      "middleInitial": "",
      "importedId": "UrfgwDAL4ldwOFhJVX5FzQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122174,
      "firstName": "Hamideh",
      "lastName": "Hosseini Toudeshky",
      "middleInitial": "",
      "importedId": "Gyyg8iJje6rYMUfSM_ut-A",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122175,
      "firstName": "Athena",
      "lastName": "Vakali",
      "middleInitial": "",
      "importedId": "gEdxf-7CMtdBvrZNVQFa-Q",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122176,
      "firstName": "Andreas",
      "lastName": "Komninos",
      "middleInitial": "",
      "importedId": "uKl3QszpsuuhtqbPQVensg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122177,
      "firstName": "Enkelejda",
      "lastName": "Kasneci",
      "middleInitial": "",
      "importedId": "w-Y3_-0lnRuNdG4CAkTJQA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122178,
      "firstName": "Rezylle",
      "lastName": "Milallos",
      "middleInitial": "",
      "importedId": "P51GzUAGw-gporSDYtmDYg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122179,
      "firstName": "Xiangyang",
      "lastName": "Xin",
      "middleInitial": "",
      "importedId": "7aDVsiwFdqHJVss4kvmDsg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122180,
      "firstName": "Jiani",
      "lastName": "Zhan",
      "middleInitial": "",
      "importedId": "TZtt47pOWk1HZCl8pNs3aw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122181,
      "firstName": "Charles-Olivier",
      "lastName": "Dufresne-Camaro",
      "middleInitial": "",
      "importedId": "2B9rkVPON2187mxoarKFGQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122182,
      "firstName": "Nicolaas",
      "lastName": "Moolenijzer",
      "middleInitial": "B",
      "importedId": "Y2-H3j1Zf_d8xq2AP0LlYQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122183,
      "firstName": "Dimitra",
      "lastName": "Anastasiou",
      "middleInitial": "",
      "importedId": "cHtr9AzEL7JwweUtw0CGcA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122184,
      "firstName": "Roshan",
      "lastName": "Mathew",
      "middleInitial": "",
      "importedId": "HUC24DET7_riu73mz2gRkA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122185,
      "firstName": "Bernard",
      "lastName": "Kerr",
      "middleInitial": "",
      "importedId": "EhUN8u-IajoXGMH4iTWNKw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122186,
      "firstName": "Marios",
      "lastName": "Constantinides",
      "middleInitial": "",
      "importedId": "nkGVw2ca5PUqN-KjzkeoTQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122187,
      "firstName": "Daun",
      "lastName": "Kim",
      "middleInitial": "",
      "importedId": "9kEfBBovSxypqk04HeiWZw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122188,
      "firstName": "Hongning",
      "lastName": "Shi",
      "middleInitial": "",
      "importedId": "upeRD5CVR9AS6hj5_L_-mQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122189,
      "firstName": "Verena",
      "lastName": "Kwok",
      "middleInitial": "Wai Wan",
      "importedId": "CXpkGjroHeE7J4duBib9fA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122190,
      "firstName": "Kenneth",
      "lastName": "Shamlian",
      "middleInitial": "",
      "importedId": "IPfO89SxURi-EMGgDLeFcg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122191,
      "firstName": "Zixia",
      "lastName": "Zheng",
      "middleInitial": "",
      "importedId": "BMc-S3rAfqRmW82A-goNqQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122192,
      "firstName": "Jingyi",
      "lastName": "Yang",
      "middleInitial": "",
      "importedId": "kpBxUan6NtudExY--oo0Zg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122193,
      "firstName": "Xiemin",
      "lastName": "Wei",
      "middleInitial": "",
      "importedId": "N5c7-MhG5lF44EadA_BJ7g",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122194,
      "firstName": "Ji Yeon",
      "lastName": "Oh",
      "middleInitial": "",
      "importedId": "KB8HUw52p7GOgNNLlbjVCg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122195,
      "firstName": "Bernardo",
      "lastName": "Marques",
      "middleInitial": "",
      "importedId": "NsTQ_P818lArhhYcKzG6yw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122196,
      "firstName": "Sunjun",
      "lastName": "Kim",
      "middleInitial": "",
      "importedId": "TIUjkZ9IJH98mZdEbS8qIQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122197,
      "firstName": "Marie",
      "lastName": "Gallais",
      "middleInitial": "",
      "importedId": "x7wpq2peZ0uhdz63LoQQ9A",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122198,
      "firstName": "Alberto",
      "lastName": "Monge Roffarello",
      "middleInitial": "",
      "importedId": "OpoVcE5QZgU3lSQzEw4HlA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122199,
      "firstName": "Samantha",
      "lastName": "Daley",
      "middleInitial": "",
      "importedId": "em7toTRyiD9F9Y0cgtOmvA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122200,
      "firstName": "Sean Anthony",
      "lastName": "Byrne",
      "middleInitial": "",
      "importedId": "Ab9EKBeBORaOT0wJAf-3Iw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122201,
      "firstName": "Samuel",
      "lastName": "Silva",
      "middleInitial": "",
      "importedId": "4lvfV8jLOCKyYXuNw-hoKw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122202,
      "firstName": "Daniele",
      "lastName": "Quercia",
      "middleInitial": "",
      "importedId": "WTGqrHzg4MtvxxZHYisuJw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122203,
      "firstName": "Marcus",
      "lastName": "Nyström",
      "middleInitial": "",
      "importedId": "g2gdF_lBJzZ1BAsTVH17Zg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122204,
      "firstName": "Kristin",
      "lastName": "Dew",
      "middleInitial": "",
      "importedId": "S9OeGiUdK1CeUuFTpD1JQg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122205,
      "firstName": "Jiajia",
      "lastName": "Li",
      "middleInitial": "",
      "importedId": "4m1AdDemtvQBjStVnw5ivg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122206,
      "firstName": "Michal",
      "lastName": "Grzeszczyk",
      "middleInitial": "K.",
      "importedId": "kDzCzUN0rsD_CqF1-hEPjQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122207,
      "firstName": "Zoya",
      "lastName": "Bylinskii",
      "middleInitial": "",
      "importedId": "SKGl1g9FJ7_HgyLCCDx8zw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122208,
      "firstName": "Lanyun",
      "lastName": "Zhang",
      "middleInitial": "",
      "importedId": "j8XhnxGDxQNoiO8IKzBpFA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122209,
      "firstName": "Beatriz Sousa",
      "lastName": "Santos",
      "middleInitial": "",
      "importedId": "64iY7Hm9BGAbtCE5Nv_1oA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122210,
      "firstName": "Ioulia",
      "lastName": "Simou",
      "middleInitial": "",
      "importedId": "UEWGFZ9Flpe07svW3wpnpA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122211,
      "firstName": "Bradley",
      "lastName": "Rey",
      "middleInitial": "",
      "importedId": "XqDmmuy_DCzwboAjedmHXQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122212,
      "firstName": "Jae-Yeop",
      "lastName": "Jeong",
      "middleInitial": "",
      "importedId": "tD-g2moCdCEstCGgUB65og",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122213,
      "firstName": "Marta",
      "lastName": "Kersten-Oertel",
      "middleInitial": "",
      "importedId": "YsgQCUTLhBLBxIBg5s4mGw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122214,
      "firstName": "Shoujie",
      "lastName": "Lei",
      "middleInitial": "",
      "importedId": "D6Rs7cMo3-7jhVdmHDaAhA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122238,
      "firstName": "Ruben",
      "lastName": "Vera-Rodriguez",
      "middleInitial": "",
      "importedId": "PL3ELozlgAtzwlxDJ1H8eA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122239,
      "firstName": "Baran",
      "lastName": "Ulak",
      "middleInitial": "",
      "importedId": "j60F4vpeRblsN4zVoFbdFA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122240,
      "firstName": "Giuseppe",
      "lastName": "Stragapede",
      "middleInitial": "",
      "importedId": "-mcavJIqH4DlkoNgaPetZg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122241,
      "firstName": "Ioanna",
      "lastName": "Lykourentzou",
      "middleInitial": "",
      "importedId": "DkW3v1baghXLkEZfUSUtmQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122242,
      "firstName": "Wonjun",
      "lastName": "Lee",
      "middleInitial": "",
      "importedId": "B7zojnVxKtPxfkcqJ4Gylw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122243,
      "firstName": "Panayiotis",
      "lastName": "Koutsabasis",
      "middleInitial": "",
      "importedId": "5sGSLxBr9iRqMHJzcFDE5w",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122244,
      "firstName": "Vasilis",
      "lastName": "Zafeiropoulos",
      "middleInitial": "",
      "importedId": "nk3iwxaf-5cRE-j9xGjKHQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122245,
      "firstName": "angie",
      "lastName": "park",
      "middleInitial": "",
      "importedId": "B1YauDq9DPbstNKZbG9QkQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122246,
      "firstName": "Tsvi",
      "lastName": "Kuflik",
      "middleInitial": "",
      "importedId": "PYti2xcGj_4LyHsRw3_zjw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122247,
      "firstName": "Benjamin",
      "lastName": "Capel",
      "middleInitial": "",
      "importedId": "LcDGq4O3bBde39jmQepeLQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122248,
      "firstName": "Kristina",
      "lastName": "Höök",
      "middleInitial": "",
      "importedId": "5CeZYHJTdW5rsfcLIb7Jtw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122249,
      "firstName": "Gisela",
      "lastName": "Reyes-Cruz",
      "middleInitial": "",
      "importedId": "auooOhBtWJ8iGFKv-rX65A",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122250,
      "firstName": "Davide",
      "lastName": "Andreoletti",
      "middleInitial": "",
      "importedId": "wXd2_17rhpap-1HTWS-u0A",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122251,
      "firstName": "Yue",
      "lastName": "Zhang",
      "middleInitial": "",
      "importedId": "3jHBrzwyRq6Gj4tTeQKjmA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122252,
      "firstName": "Karst",
      "lastName": "Geurs",
      "middleInitial": "",
      "importedId": "kibnVQOiVNVDMWq_gX7L-w",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122253,
      "firstName": "David",
      "lastName": "Chen",
      "middleInitial": "",
      "importedId": "bYuJSQHwm78vwApgoYNEhg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122254,
      "firstName": "Jason",
      "lastName": "Wiese",
      "middleInitial": "",
      "importedId": "z-YpdwLL2W0wtHkXuYkddg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122255,
      "firstName": "Christina",
      "lastName": "Schneegass",
      "middleInitial": "",
      "importedId": "vEDv2WmtV7iUlCKCXozGkQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122256,
      "firstName": "Anastasios",
      "lastName": "Fanariotis",
      "middleInitial": "",
      "importedId": "z_sfX-JGgqxmRRb-GAKIeA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122257,
      "firstName": "Michael",
      "lastName": "Ortgiese",
      "middleInitial": "",
      "importedId": "5Ax9dJsjypVbRqkS1YKh5A",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122258,
      "firstName": "Hyuniee",
      "lastName": "Jung",
      "middleInitial": "",
      "importedId": "gwdxUzqsPR38V4dqCTZP1Q",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122259,
      "firstName": "Mario",
      "lastName": "Boot",
      "middleInitial": "",
      "importedId": "NkHqHXrQQjH_jZ4c9wnRiw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122260,
      "firstName": "Stella",
      "lastName": "Sylaiou",
      "middleInitial": "",
      "importedId": "cRYZPdjgygmUYkZCRnbmbA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122261,
      "firstName": "Achille",
      "lastName": "Peternier",
      "middleInitial": "",
      "importedId": "QJ5qW98j1MuZPrVkS3xIgw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122262,
      "firstName": "Manasvi",
      "lastName": "Ponaka",
      "middleInitial": "",
      "importedId": "4VeQj9hiCxNDrx5sNg0u-A",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122263,
      "firstName": "Katerina",
      "lastName": "Mania",
      "middleInitial": "",
      "importedId": "mW_fD7j7mNy46DE36mTGbQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122264,
      "firstName": "Horia",
      "lastName": "Maior",
      "middleInitial": "A.",
      "importedId": "fxq38Fig3BbgXIM8fdKphA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122265,
      "firstName": "Sviatlana",
      "lastName": "Höhn",
      "middleInitial": "",
      "importedId": "jfxTuE6O7MsSxJkyoIJqPg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122266,
      "firstName": "Andriana",
      "lastName": "Boudouraki",
      "middleInitial": "",
      "importedId": "4b9Co-eeiiLEp1I2bL_BGQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122267,
      "firstName": "Juan Pablo",
      "lastName": "Martinez Avila",
      "middleInitial": "",
      "importedId": "-ocqNn3Iv9KlsDG1IA9bYg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122268,
      "firstName": "Dimitris",
      "lastName": "Kalles",
      "middleInitial": "",
      "importedId": "wYsXGziV_2yPevDhhV9mvA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122269,
      "firstName": "Vassilis",
      "lastName": "Fotopoulos",
      "middleInitial": "",
      "importedId": "FtrG0aa-pbPDqZ1yQ7sd6w",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122270,
      "firstName": "Ioannis",
      "lastName": "Chatzigiannakis",
      "middleInitial": "",
      "importedId": "id8KEo47yNScaKTRkJ348g",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122271,
      "firstName": "Dimitrios",
      "lastName": "Koukopoulos",
      "middleInitial": "",
      "importedId": "PPOoG2Z_hgSB2y3LeJ10kQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122272,
      "firstName": "Michael",
      "lastName": "Oehl",
      "middleInitial": "",
      "importedId": "bl8Rx7KrHn1Xv__aFLNmtQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122273,
      "firstName": "Ali",
      "lastName": "Paikan",
      "middleInitial": "",
      "importedId": "uEDJoY9B3eWB1k8oxuhxFg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122274,
      "firstName": "Manolis",
      "lastName": "Wallace",
      "middleInitial": "",
      "importedId": "0hxbjU2tLX9YFUvEplXvQw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122275,
      "firstName": "Kalyan",
      "lastName": "Sasidhar",
      "middleInitial": "",
      "importedId": "dq_uMcKA9Y65M_9MPtdTpQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122276,
      "firstName": "Ashley",
      "lastName": "Granquist",
      "middleInitial": "M",
      "importedId": "OG2ZfwI531oRz3GbmHL5ZA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122277,
      "firstName": "Fabian",
      "lastName": "Hub",
      "middleInitial": "",
      "importedId": "f9IMxCJNLtEpoIn6P42pjA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122278,
      "firstName": "Matteo",
      "lastName": "Besenzoni",
      "middleInitial": "",
      "importedId": "LKoRvSV6guyA_-jaERKupw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122279,
      "firstName": "Houda",
      "lastName": "Elmimouni",
      "middleInitial": "",
      "importedId": "66ZuVvMN8EX24BDHi2KUuA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122280,
      "firstName": "Yuan Hang",
      "lastName": "Li",
      "middleInitial": "",
      "importedId": "NkX3enA6C-CHbrKDoKSjDA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122281,
      "firstName": "Swapna",
      "lastName": "Joshi",
      "middleInitial": "",
      "importedId": "Cyui3pMpN9PGCTLuq92RdQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122282,
      "firstName": "Max",
      "lastName": "Wilson",
      "middleInitial": "L",
      "importedId": "C0bsqVkhBmuVsuw87-gWsQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122283,
      "firstName": "Anna",
      "lastName": "Ståhl",
      "middleInitial": "",
      "importedId": "v_eWudM8vFopoKu8gWdfMw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122284,
      "firstName": "Eike",
      "lastName": "Schneiders",
      "middleInitial": "",
      "importedId": "Diro3aYqe9FSgymyAhBCNg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122285,
      "firstName": "Silvia",
      "lastName": "Giordano",
      "middleInitial": "",
      "importedId": "K09J1n15cFQp9IKZr5AEvw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122286,
      "firstName": "Anna",
      "lastName": "Cox",
      "middleInitial": "L",
      "importedId": "Tc6Cz96hWQFn_CE9lBGZVg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122287,
      "firstName": "Evan",
      "lastName": "Patton",
      "middleInitial": "W",
      "importedId": "6lGceoaYIrehFKBsK6MTrw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122288,
      "firstName": "George",
      "lastName": "Anastassakis",
      "middleInitial": "",
      "importedId": "BNKUZvA67QgFg0Uxp4B7Jg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122289,
      "firstName": "Rama Krishnan Gopal Ramasamy",
      "lastName": "Thandapani",
      "middleInitial": "",
      "importedId": "InYoaJsHzaJXIczskRRcwQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122290,
      "firstName": "Sara",
      "lastName": "Eriksson",
      "middleInitial": "",
      "importedId": "Nn-9wKgd1g2QOM51X5VOVQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122291,
      "firstName": "Ruben",
      "lastName": "Tolosana",
      "middleInitial": "",
      "importedId": "jVAuuJE-kXChYTe1qrC3zw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122292,
      "firstName": "Christos",
      "lastName": "Fidas",
      "middleInitial": "",
      "importedId": "JTqeU-nQ_3BnTiDwMYC5Uw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122293,
      "firstName": "Theofanis",
      "lastName": "Orphanoudakis",
      "middleInitial": "",
      "importedId": "7AAAZyDVbsmKtB08k83UuQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122294,
      "firstName": "Fotis",
      "lastName": "Liarokapis",
      "middleInitial": "",
      "importedId": "udxIeXIAtghTPLACoek36g",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122295,
      "firstName": "Paul",
      "lastName": "Havinga",
      "middleInitial": "",
      "importedId": "ZUHJ2nsV0cVggWr34-TAiw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122296,
      "firstName": "Sena",
      "lastName": "Kilinç",
      "middleInitial": "",
      "importedId": "yfzdCvV4MgadB2J79fmucw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122297,
      "firstName": "Sean",
      "lastName": "Rintel",
      "middleInitial": "",
      "importedId": "iOxsSepdclHwk85UJVKveQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122298,
      "firstName": "Antoine",
      "lastName": "Lasnier",
      "middleInitial": "",
      "importedId": "8riKpqND-LCW1lN26wHCeQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122299,
      "firstName": "David",
      "lastName": "Kim",
      "middleInitial": "Y.J.",
      "importedId": "ev9XKc-6L3rdCiMD-7rOfQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122300,
      "firstName": "Jens Emil",
      "lastName": "Grønbæk",
      "middleInitial": "Sloth",
      "importedId": "_xd7AYtHUdhPVmBzB19MvQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122301,
      "firstName": "Seyed Muhammad Hossein",
      "lastName": "Mousavi",
      "middleInitial": "",
      "importedId": "2tkI9gICb0Lyi4OTytDCMA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 122302,
      "firstName": "Angeliki",
      "lastName": "Antoniou",
      "middleInitial": "",
      "importedId": "-kNtYZHvY7sciQ-aYjI3rA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 124731,
      "firstName": "Radu - Daniel",
      "lastName": "Vatavu",
      "importedId": "48df6c4c-bbfd-49fd-b3d0-3fc908a99257",
      "source": "SYS",
      "affiliations": [
        {
          "country": "Romania",
          "city": "Suceava",
          "institution": "\"Ștefan cel Mare\" University of Suceava"
        }
      ]
    },
    {
      "id": 125706,
      "firstName": "Cosmin",
      "lastName": "Munteanu",
      "importedId": "de669ac6-27dd-4ae1-a8f1-1ec2f7bd6dee",
      "source": "SYS",
      "affiliations": [
        {
          "country": "Canada",
          "state": "Ontario",
          "city": "Canada",
          "institution": "University of Waterloo"
        }
      ]
    },
    {
      "id": 125707,
      "firstName": "Steve",
      "lastName": "Benford",
      "importedId": "c59fe219-9248-40a6-8f89-0b94785baa3d",
      "source": "SYS",
      "affiliations": [
        {
          "country": "United Kingdom",
          "city": "Nottingham",
          "institution": "University of Nottingham"
        }
      ]
    },
    {
      "id": 125709,
      "firstName": "Carmen",
      "lastName": "Santoro",
      "importedId": "45b5d26d-8353-4ff3-8f5a-ae7241d4de57",
      "source": "SYS",
      "affiliations": [
        {
          "country": "Italy",
          "city": "Pisa",
          "institution": "ISTI-CNR"
        }
      ]
    },
    {
      "id": 125710,
      "firstName": "Damianos",
      "lastName": "Gavalas",
      "importedId": "58ade310-7059-42b7-97d1-c07be67ec613",
      "source": "SYS",
      "affiliations": [
        {
          "country": "Greece",
          "city": "Ermoupolis",
          "institution": "University of the Aegean"
        }
      ]
    },
    {
      "id": 127780,
      "firstName": "Nikolaos",
      "lastName": "Avouris",
      "importedId": "435e5e14-ee13-450c-b720-7b3983c30427",
      "source": "SYS",
      "affiliations": [
        {
          "country": "Greece",
          "city": "Patras",
          "institution": "University of Patras"
        }
      ]
    },
    {
      "id": 127781,
      "firstName": "Florian",
      "lastName": "Müller",
      "importedId": "71e6658e-e2e1-4451-9bdb-17fdd44d0e41",
      "source": "SYS",
      "affiliations": [
        {
          "country": "Australia",
          "city": "Melbourne",
          "institution": "Monash University"
        }
      ]
    }
  ],
  "recognitions": []
}