{
  "schemeVersion": 7,
  "cc_licence": "Content of this file is licensed under a CC BY-NC-SA 4.0 license. For details see https://creativecommons.org/licenses/by-nc-sa/4.0/",
  "conference": {
    "id": 10063,
    "shortName": "IMX",
    "year": 2021,
    "startDate": 1624233600000,
    "endDate": 1624406400000,
    "name": "IMX 2021",
    "fullName": "ACM International Conference on Interactive Media Experiences",
    "url": "https://imx.acm.org/2021/",
    "location": "Online",
    "timeZoneOffset": -240,
    "logoUrl": "https://files.sigchi.org/conference/logo/552a60de-bedc-15bc-c38c-a094b75d8ef0.png",
    "accessibilityFaqUrl": "https://files.sigchi.org/conference/accessibility/a1cfe54b-8c04-b04a-4efa-b32b8f9edba9.html",
    "noteToConference": "Beyond Entertainment",
    "timeZoneName": "America/New_York"
  },
  "sponsors": [
    {
      "id": 10147,
      "name": "Verizon Media",
      "logoUrl": "https://files.sigchi.org/conference/sponsor/logo/e5629e1c-2802-ffc3-1597-eeda097d9b43.png",
      "levelId": 10101,
      "order": 1
    },
    {
      "id": 10148,
      "name": "NJIT",
      "logoUrl": "https://files.sigchi.org/conference/sponsor/logo/707127d2-f950-1aa5-0364-5c2919e7b895.png",
      "levelId": 10102,
      "order": 2
    }
  ],
  "sponsorLevels": [
    {
      "id": 10097,
      "name": "Sponsors",
      "rank": 3,
      "isDefault": true
    },
    {
      "id": 10101,
      "name": "Platinum",
      "rank": 1,
      "isDefault": false
    },
    {
      "id": 10102,
      "name": "Bronze",
      "rank": 2,
      "isDefault": false
    }
  ],
  "floors": [
    {
      "id": 10090,
      "name": "OhYay Space",
      "mapImageUrl": "https://files.sigchi.org/conference/floor/536b8fc8-9836-4e67-7a60-0b2efd90192d.png",
      "roomIds": [
        10491,
        10493,
        10509,
        10489,
        10488
      ]
    }
  ],
  "rooms": [
    {
      "id": 10488,
      "name": "Showcase",
      "typeId": 11848,
      "setup": "Special",
      "capacity": "50",
      "note": "Virtual"
    },
    {
      "id": 10489,
      "name": "Workshops",
      "typeId": 11815,
      "setup": "Special",
      "capacity": "40",
      "note": "Virtual"
    },
    {
      "id": 10491,
      "name": "Social Break",
      "typeId": 11809,
      "setup": "Special",
      "capacity": "50",
      "note": "Virtual"
    },
    {
      "id": 10493,
      "name": "Main Hall",
      "typeId": 11813,
      "setup": "Theatre",
      "capacity": "150",
      "note": "Virtual"
    },
    {
      "id": 10509,
      "name": "Reception",
      "typeId": 11811,
      "setup": "Special",
      "capacity": "150",
      "note": "Virtual"
    }
  ],
  "tracks": [
    {
      "id": 11242,
      "name": "IMX 2021 Demos",
      "typeId": 11821
    },
    {
      "id": 11243,
      "name": "IMX 2021 Doctoral Consortium",
      "typeId": 11822
    },
    {
      "id": 11244,
      "name": "IMX 2021 Technical Papers",
      "typeId": 11813
    },
    {
      "id": 11245,
      "name": "IMX 2021 Work-in-Progress",
      "typeId": 11823
    },
    {
      "id": 11246,
      "name": "IMX 2021 IMX-in-Industry",
      "typeId": 11824
    },
    {
      "id": 11284,
      "typeId": 11835
    },
    {
      "id": 11285,
      "typeId": 11815
    },
    {
      "id": 11286,
      "typeId": 11836
    },
    {
      "id": 11287,
      "typeId": 11812
    }
  ],
  "contentTypes": [
    {
      "id": 11806,
      "name": "SIG",
      "color": "#7a0177",
      "duration": 90
    },
    {
      "id": 11807,
      "name": "Case Study",
      "color": "#993404",
      "duration": 20,
      "displayName": "Case Studies"
    },
    {
      "id": 11808,
      "name": "Course",
      "color": "#e6550d",
      "duration": 90,
      "displayName": "Courses"
    },
    {
      "id": 11809,
      "name": "Event",
      "color": "#fecc5c",
      "duration": 0,
      "displayName": "Events"
    },
    {
      "id": 11810,
      "name": "Invited Talk",
      "color": "#66c2a4",
      "duration": 90,
      "displayName": "Invited Talks"
    },
    {
      "id": 11811,
      "name": "Operations",
      "color": "#006d2c",
      "duration": 90
    },
    {
      "id": 11812,
      "name": "Panel",
      "color": "#6baed6",
      "duration": 60,
      "displayName": "Panels"
    },
    {
      "id": 11813,
      "name": "Paper",
      "color": "#08519c",
      "duration": 5,
      "displayName": "Papers"
    },
    {
      "id": 11814,
      "name": "Plenary",
      "color": "#756bb1",
      "duration": 90
    },
    {
      "id": 11815,
      "name": "Workshop",
      "color": "#de2d26",
      "duration": 180,
      "displayName": "Workshops"
    },
    {
      "id": 11821,
      "name": "Demos",
      "color": "#969696",
      "duration": 1
    },
    {
      "id": 11822,
      "name": "Doctoral Consortium - Poster PPT",
      "color": "#969696",
      "duration": 1
    },
    {
      "id": 11823,
      "name": "Work-in-Progress",
      "color": "#969696",
      "duration": 1
    },
    {
      "id": 11824,
      "name": "Industry Talk",
      "color": "#969696",
      "duration": 7,
      "displayName": "Industry Talks"
    },
    {
      "id": 11835,
      "name": "Keynote",
      "color": "#969696",
      "duration": 50
    },
    {
      "id": 11836,
      "name": "Doctoral Consortium - Mentor Program",
      "color": "#969696",
      "duration": 210
    },
    {
      "id": 11848,
      "name": "Posters & Demos",
      "color": "#969696",
      "duration": 0
    }
  ],
  "timeSlots": [
    {
      "id": 11959,
      "type": "SESSION",
      "startDate": 1624353300000,
      "endDate": 1624356000000
    },
    {
      "id": 11960,
      "type": "SESSION",
      "startDate": 1624444200000,
      "endDate": 1624446000000
    },
    {
      "id": 11961,
      "type": "SESSION",
      "startDate": 1624449600000,
      "endDate": 1624450500000
    },
    {
      "id": 11962,
      "type": "SESSION",
      "startDate": 1624356000000,
      "endDate": 1624356600000
    },
    {
      "id": 11963,
      "type": "SESSION",
      "startDate": 1624360500000,
      "endDate": 1624362300000
    },
    {
      "id": 11964,
      "type": "SESSION",
      "startDate": 1624442400000,
      "endDate": 1624444200000
    },
    {
      "id": 11965,
      "type": "SESSION",
      "startDate": 1624456800000,
      "endDate": 1624458600000
    },
    {
      "id": 11966,
      "type": "SESSION",
      "startDate": 1624370400000,
      "endDate": 1624372200000
    },
    {
      "id": 11967,
      "type": "SESSION",
      "startDate": 1624381200000,
      "endDate": 1624384800000
    },
    {
      "id": 11968,
      "type": "SESSION",
      "startDate": 1624446000000,
      "endDate": 1624449600000
    },
    {
      "id": 11969,
      "type": "SESSION",
      "startDate": 1624266000000,
      "endDate": 1624284000000
    },
    {
      "id": 11970,
      "type": "SESSION",
      "startDate": 1624266000000,
      "endDate": 1624276800000
    },
    {
      "id": 11971,
      "type": "SESSION",
      "startDate": 1624264200000,
      "endDate": 1624278600000
    },
    {
      "id": 11974,
      "type": "SESSION",
      "startDate": 1624287600000,
      "endDate": 1624291200000
    },
    {
      "id": 11975,
      "type": "SESSION",
      "startDate": 1624359600000,
      "endDate": 1624360500000
    },
    {
      "id": 11976,
      "type": "SESSION",
      "startDate": 1624362300000,
      "endDate": 1624363200000
    },
    {
      "id": 11977,
      "type": "SESSION",
      "startDate": 1624363200000,
      "endDate": 1624366800000
    },
    {
      "id": 11978,
      "type": "SESSION",
      "startDate": 1624366800000,
      "endDate": 1624370400000
    },
    {
      "id": 11979,
      "type": "SESSION",
      "startDate": 1624372200000,
      "endDate": 1624374000000
    },
    {
      "id": 11980,
      "type": "SESSION",
      "startDate": 1624375800000,
      "endDate": 1624377600000
    },
    {
      "id": 11981,
      "type": "SESSION",
      "startDate": 1624377600000,
      "endDate": 1624381200000
    },
    {
      "id": 11982,
      "type": "SESSION",
      "startDate": 1624450500000,
      "endDate": 1624453200000
    },
    {
      "id": 11983,
      "type": "SESSION",
      "startDate": 1624453200000,
      "endDate": 1624456800000
    },
    {
      "id": 11984,
      "type": "SESSION",
      "startDate": 1624458600000,
      "endDate": 1624462200000
    },
    {
      "id": 11985,
      "type": "SESSION",
      "startDate": 1624462200000,
      "endDate": 1624464000000
    },
    {
      "id": 11986,
      "type": "SESSION",
      "startDate": 1624464000000,
      "endDate": 1624467600000
    },
    {
      "id": 11987,
      "type": "SESSION",
      "startDate": 1624467600000,
      "endDate": 1624469400000
    },
    {
      "id": 11988,
      "type": "SESSION",
      "startDate": 1624356600000,
      "endDate": 1624359600000
    },
    {
      "id": 11989,
      "type": "SESSION",
      "startDate": 1624266000000,
      "endDate": 1624278600000
    },
    {
      "id": 11990,
      "type": "SESSION",
      "startDate": 1624266000000,
      "endDate": 1624277400000
    },
    {
      "id": 12024,
      "type": "SESSION",
      "startDate": 1624262400000,
      "endDate": 1624266000000
    },
    {
      "id": 12025,
      "type": "SESSION",
      "startDate": 1624440600000,
      "endDate": 1624442400000
    }
  ],
  "sessions": [
    {
      "id": 58454,
      "name": "Music, Art & Health",
      "addons": {
        "broadcastLink": {
          "duringSessionOnly": false,
          "type": "broadcastLink",
          "url": "https://ohyay.co/s/imx2021#scene_ihEE6Fpo"
        }
      },
      "typeId": 11813,
      "roomId": 10493,
      "chairIds": [
        58435
      ],
      "contentIds": [
        58447,
        58446,
        58451,
        58440,
        58443
      ],
      "timeSlotId": 11963,
      "note": ""
    },
    {
      "id": 58455,
      "name": "AI & Data",
      "addons": {
        "broadcastLink": {
          "duringSessionOnly": false,
          "type": "broadcastLink",
          "url": "https://ohyay.co/s/imx2021#scene_ihEE6Fpo"
        }
      },
      "typeId": 11813,
      "roomId": 10493,
      "chairIds": [
        58604
      ],
      "contentIds": [
        58449,
        58450,
        58437,
        58442
      ],
      "timeSlotId": 11964,
      "note": ""
    },
    {
      "id": 58456,
      "name": "Method & Framework",
      "addons": {
        "broadcastLink": {
          "duringSessionOnly": false,
          "type": "broadcastLink",
          "url": "https://ohyay.co/s/imx2021#scene_ihEE6Fpo"
        }
      },
      "typeId": 11813,
      "roomId": 10493,
      "chairIds": [
        58657
      ],
      "contentIds": [
        58452,
        58439,
        58441,
        58444,
        58608
      ],
      "timeSlotId": 11965,
      "note": ""
    },
    {
      "id": 58457,
      "name": "Social",
      "addons": {
        "broadcastLink": {
          "duringSessionOnly": false,
          "type": "broadcastLink",
          "url": "https://ohyay.co/s/imx2021#scene_ihEE6Fpo"
        }
      },
      "typeId": 11813,
      "roomId": 10493,
      "chairIds": [
        58635
      ],
      "contentIds": [
        58448,
        58453,
        58438,
        58445
      ],
      "timeSlotId": 11966,
      "note": ""
    },
    {
      "id": 58616,
      "name": "Showcase: Computer-Mediated Communication and Interaction (I)",
      "typeId": 11848,
      "roomId": 10488,
      "chairIds": [
        58635,
        58637
      ],
      "contentIds": [
        58591,
        58596,
        58578,
        58572,
        58585
      ],
      "timeSlotId": 11979,
      "note": ""
    },
    {
      "id": 58617,
      "name": "Showcase: Computer-Mediated Communication and Interaction (II)",
      "typeId": 11848,
      "roomId": 10488,
      "chairIds": [
        58633,
        58632,
        58635,
        58637
      ],
      "contentIds": [
        58593,
        58610,
        58571,
        58614,
        58615,
        58579
      ],
      "timeSlotId": 11979,
      "note": ""
    },
    {
      "id": 58618,
      "name": "Showcase: Live Streaming, Videos, Authoring Tools",
      "typeId": 11848,
      "roomId": 10488,
      "chairIds": [
        58631,
        58633,
        58632,
        58634,
        58635,
        58636,
        58637
      ],
      "contentIds": [
        58573,
        58611,
        58580,
        58569,
        58581,
        58583,
        58586
      ],
      "timeSlotId": 11979,
      "note": ""
    },
    {
      "id": 58619,
      "name": "Showcase: Health and Education",
      "typeId": 11848,
      "roomId": 10488,
      "chairIds": [
        58631,
        58633,
        58632,
        58634,
        58635,
        58636,
        58637
      ],
      "contentIds": [
        58607,
        58577,
        58597,
        58570,
        58612,
        58613,
        58589
      ],
      "timeSlotId": 11979,
      "note": ""
    },
    {
      "id": 58620,
      "name": "Showcase: Mixed-Reality (VR/AR)",
      "typeId": 11848,
      "roomId": 10488,
      "chairIds": [
        58631,
        58633,
        58632,
        58634,
        58635,
        58636,
        58637
      ],
      "contentIds": [
        58609,
        58594,
        58575,
        58595,
        58584,
        58588,
        58587,
        58590
      ],
      "timeSlotId": 11979,
      "note": ""
    },
    {
      "id": 58626,
      "name": "Showcase: AI/Autonomous Systems/IoT",
      "typeId": 11848,
      "roomId": 10488,
      "chairIds": [
        58631,
        58634,
        58635,
        58636,
        58637
      ],
      "contentIds": [
        58592,
        58574,
        58576,
        58582
      ],
      "timeSlotId": 11979,
      "note": ""
    },
    {
      "id": 58627,
      "name": "Showcase: Health and Education",
      "typeId": 11848,
      "roomId": 10488,
      "chairIds": [
        58631,
        58633,
        58632,
        58634,
        58635,
        58636,
        58637
      ],
      "contentIds": [
        58607,
        58577,
        58597,
        58570,
        58612,
        58613,
        58589
      ],
      "timeSlotId": 11982,
      "note": ""
    },
    {
      "id": 58628,
      "name": "Showcase: Computer-Mediated Communication and Interaction",
      "typeId": 11848,
      "roomId": 10488,
      "chairIds": [
        58635,
        58637
      ],
      "contentIds": [
        58591,
        58596,
        58578,
        58572,
        58585
      ],
      "timeSlotId": 11982,
      "note": ""
    },
    {
      "id": 58629,
      "name": "Showcase: Live Streaming, Videos, Authoring Tools",
      "typeId": 11848,
      "roomId": 10488,
      "chairIds": [
        58631,
        58633,
        58632,
        58634,
        58635,
        58636,
        58637
      ],
      "contentIds": [
        58573,
        58611,
        58580,
        58569,
        58581,
        58583,
        58586
      ],
      "timeSlotId": 11982,
      "note": ""
    },
    {
      "id": 58630,
      "name": "Showcase: Mixed-Reality (VR/AR)",
      "typeId": 11848,
      "roomId": 10488,
      "chairIds": [
        58631,
        58633,
        58632,
        58634,
        58635,
        58636,
        58637
      ],
      "contentIds": [
        58609,
        58594,
        58575,
        58595,
        58584,
        58588,
        58587,
        58590
      ],
      "timeSlotId": 11982,
      "note": ""
    },
    {
      "id": 58638,
      "name": "Showcase: Computer-Mediated Communication and Interaction (II)",
      "typeId": 11848,
      "roomId": 10488,
      "chairIds": [
        58633,
        58632,
        58635,
        58637
      ],
      "contentIds": [
        58593,
        58610,
        58571,
        58614,
        58615,
        58579
      ],
      "timeSlotId": 11982,
      "note": ""
    },
    {
      "id": 58639,
      "name": "Showcase: AI/Autonomous Systems/IoT",
      "typeId": 11848,
      "roomId": 10488,
      "chairIds": [
        58631,
        58634,
        58635,
        58636,
        58637
      ],
      "contentIds": [
        58592,
        58574,
        58576,
        58582
      ],
      "timeSlotId": 11982,
      "note": ""
    },
    {
      "id": 58642,
      "name": "Closing Keynote",
      "addons": {
        "broadcastLink": {
          "duringSessionOnly": false,
          "type": "broadcastLink",
          "url": "https://ohyay.co/s/imx2021#scene_ihEE6Fpo"
        }
      },
      "typeId": 11835,
      "roomId": 10493,
      "chairIds": [],
      "contentIds": [
        58641
      ],
      "timeSlotId": 11986
    },
    {
      "id": 59452,
      "name": "Opening Keynote",
      "addons": {
        "broadcastLink": {
          "duringSessionOnly": false,
          "type": "broadcastLink",
          "url": "https://ohyay.co/s/imx2021#scene_ihEE6Fpo"
        }
      },
      "typeId": 11835,
      "roomId": 10493,
      "chairIds": [],
      "contentIds": [
        59448
      ],
      "timeSlotId": 11988
    },
    {
      "id": 59453,
      "name": "XR in Games",
      "typeId": 11815,
      "roomId": 10489,
      "chairIds": [],
      "contentIds": [
        58662
      ],
      "timeSlotId": 11971
    },
    {
      "id": 59454,
      "name": "SensoryX",
      "typeId": 11815,
      "roomId": 10489,
      "chairIds": [],
      "contentIds": [
        58660
      ],
      "timeSlotId": 11969
    },
    {
      "id": 59455,
      "name": "LIQUE",
      "typeId": 11815,
      "roomId": 10489,
      "chairIds": [],
      "contentIds": [
        58661
      ],
      "timeSlotId": 11970
    },
    {
      "id": 59456,
      "name": "DataTV",
      "typeId": 11815,
      "roomId": 10489,
      "chairIds": [],
      "contentIds": [
        58663
      ],
      "timeSlotId": 11990
    },
    {
      "id": 59457,
      "name": "Doctoral Consortium - Mentor Program",
      "addons": {
        "broadcastLink": {
          "duringSessionOnly": false,
          "type": "broadcastLink",
          "url": "https://ohyay.co/s/imx2021#scene_Gi3pbkLD"
        }
      },
      "typeId": 11836,
      "roomId": 10489,
      "chairIds": [],
      "contentIds": [
        58664
      ],
      "timeSlotId": 11989
    },
    {
      "id": 59458,
      "name": "Inclusive Design",
      "addons": {
        "broadcastLink": {
          "duringSessionOnly": false,
          "type": "broadcastLink",
          "url": "https://ohyay.co/s/imx2021#scene_ihEE6Fpo"
        }
      },
      "typeId": 11812,
      "roomId": 10493,
      "chairIds": [],
      "contentIds": [
        59447
      ],
      "timeSlotId": 11977
    },
    {
      "id": 59459,
      "name": "State of Art on Gaming",
      "addons": {
        "broadcastLink": {
          "duringSessionOnly": false,
          "type": "broadcastLink",
          "url": "https://ohyay.co/s/imx2021#scene_ihEE6Fpo"
        }
      },
      "typeId": 11812,
      "roomId": 10493,
      "chairIds": [],
      "contentIds": [
        59449
      ],
      "timeSlotId": 11981
    },
    {
      "id": 59460,
      "name": "(Live) Entertainment on Immersive",
      "addons": {
        "broadcastLink": {
          "duringSessionOnly": false,
          "type": "broadcastLink",
          "url": "https://ohyay.co/s/imx2021#scene_ihEE6Fpo"
        }
      },
      "typeId": 11812,
      "roomId": 10493,
      "chairIds": [],
      "contentIds": [
        59451
      ],
      "timeSlotId": 11968
    },
    {
      "id": 59461,
      "name": "Future of Media",
      "addons": {
        "broadcastLink": {
          "duringSessionOnly": false,
          "type": "broadcastLink",
          "url": "https://ohyay.co/s/imx2021#scene_ihEE6Fpo"
        }
      },
      "typeId": 11812,
      "roomId": 10493,
      "chairIds": [],
      "contentIds": [
        59450
      ],
      "timeSlotId": 11984
    }
  ],
  "events": [
    {
      "id": 60225,
      "name": "Short Break",
      "typeId": 11809,
      "chairIds": [],
      "contentIds": [],
      "startDate": 1624359600000,
      "endDate": 1624360500000,
      "presenterIds": []
    },
    {
      "id": 60226,
      "name": "Welcome Notes",
      "typeId": 11809,
      "roomId": 10493,
      "chairIds": [
        58391,
        58394
      ],
      "contentIds": [],
      "startDate": 1624356000000,
      "endDate": 1624356600000,
      "presenterIds": []
    },
    {
      "id": 60227,
      "name": "OhYay! Registration.",
      "typeId": 11809,
      "roomId": 10509,
      "chairIds": [
        58605
      ],
      "contentIds": [],
      "startDate": 1624353300000,
      "endDate": 1624356000000,
      "description": "A time to come and get onboarded in OhYay! There will be some student volunteers to help you. If you are unable to get into OhYay, please send an email to support@imx2021.com",
      "presenterIds": []
    },
    {
      "id": 60228,
      "name": "Short Break",
      "typeId": 11809,
      "chairIds": [],
      "contentIds": [],
      "startDate": 1624362300000,
      "endDate": 1624363200000,
      "presenterIds": []
    },
    {
      "id": 60229,
      "name": "Lunch / Mukbang (pop-up social)!",
      "typeId": 11809,
      "roomId": 10491,
      "chairIds": [],
      "contentIds": [],
      "startDate": 1624366800000,
      "endDate": 1624370400000,
      "description": "Eat lunch with other conference attendees...or just watch other people eat; inspired by the South Korean eating webcast trend.",
      "presenterIds": []
    },
    {
      "id": 60230,
      "name": "Lunch",
      "typeId": 11809,
      "roomId": 10491,
      "chairIds": [],
      "contentIds": [],
      "startDate": 1624453200000,
      "endDate": 1624456800000,
      "presenterIds": []
    },
    {
      "id": 60231,
      "name": "Long Break / Yoga (pop-up social)!",
      "typeId": 11809,
      "roomId": 10491,
      "chairIds": [],
      "contentIds": [],
      "startDate": 1624375800000,
      "endDate": 1624377600000,
      "description": "Follow along as our host walks you through a series of yoga exercises. Strrrrrretch. Yeah that feels good.",
      "presenterIds": []
    },
    {
      "id": 60232,
      "name": "Reception (pop-up socials)!",
      "typeId": 11809,
      "roomId": 10491,
      "chairIds": [],
      "contentIds": [],
      "startDate": 1624381200000,
      "endDate": 1624384800000,
      "description": "One of two activities - Lip Sync Battle: Hate singing, but love karaoke? We got you. Take the stage and lip sync along with your favorite songs (you mime the words with your mouth while the song plays) OR Scavenger Hunt: ALERT, ALERT: student volunteers are lost in New York City! Help find them in this New York-themed scavenger hunt (it's like Where's Waldo and you get to see some popular New York landmarks).",
      "presenterIds": []
    },
    {
      "id": 60233,
      "name": "Long Break / NYC Puzzle (pop-up social)!",
      "typeId": 11809,
      "roomId": 10491,
      "chairIds": [],
      "contentIds": [],
      "startDate": 1624444200000,
      "endDate": 1624446000000,
      "presenterIds": []
    },
    {
      "id": 60234,
      "name": "Short Break",
      "typeId": 11809,
      "chairIds": [],
      "contentIds": [],
      "startDate": 1624449600000,
      "endDate": 1624450500000,
      "presenterIds": []
    },
    {
      "id": 60235,
      "name": "Long Break / NYC Puzzle (pop-up social)!",
      "typeId": 11809,
      "roomId": 10491,
      "chairIds": [],
      "contentIds": [],
      "startDate": 1624462200000,
      "endDate": 1624464000000,
      "description": "Fun, group-based puzzle activities. Want to socialize with people but don't know what to talk about? Go to this room.",
      "presenterIds": []
    },
    {
      "id": 60236,
      "name": "Awards, Where Next & Closing",
      "typeId": 11809,
      "roomId": 10493,
      "chairIds": [
        58394
      ],
      "contentIds": [],
      "startDate": 1624467600000,
      "endDate": 1624469400000,
      "presenterIds": []
    },
    {
      "id": 60237,
      "name": "Students Q&A",
      "typeId": 11809,
      "chairIds": [
        58391
      ],
      "contentIds": [],
      "startDate": 1624453200000,
      "endDate": 1624456800000,
      "presenterIds": []
    },
    {
      "id": 60238,
      "name": "Students' Event",
      "typeId": 11809,
      "roomId": 10491,
      "chairIds": [
        58633,
        58632
      ],
      "contentIds": [],
      "startDate": 1624287600000,
      "endDate": 1624291200000,
      "presenterIds": []
    },
    {
      "id": 60891,
      "name": "OhYay! Registration.",
      "typeId": 11809,
      "roomId": 10509,
      "chairIds": [
        58605
      ],
      "contentIds": [],
      "startDate": 1624440600000,
      "endDate": 1624442400000,
      "description": "A time to come and get onboarded in OhYay! There will be some student volunteers to help you. If you are unable to get into OhYay, please send an email to support@imx2021.com",
      "presenterIds": []
    },
    {
      "id": 60892,
      "name": "OhYay! Registration.",
      "typeId": 11809,
      "roomId": 10509,
      "chairIds": [
        58605
      ],
      "contentIds": [],
      "startDate": 1624262400000,
      "endDate": 1624266000000,
      "link": {
        "href": "https://ohyay.co/s/imx2021",
        "label": "IMX 2021 on OhYay"
      },
      "description": "A time to come and get onboarded in OhYay! There will be some student volunteers to help you. If you are unable to get into OhYay, please send an email to support@imx2021.com",
      "presenterIds": []
    }
  ],
  "contents": [
    {
      "id": 58437,
      "typeId": 11813,
      "title": "Stay Tuned! An Investigation of Content Substitution, the Listener as Curator and Other Innovations in Broadcast Radio",
      "addons": {
        "doi": {
          "type": "doiLink",
          "url": "https://doi.org/10.1145/3452918.3458793"
        },
        "Presentation Video": {
          "duration": 300,
          "title": "Stay Tuned! An Investigation of Content Substitution, the Listener as Curator and Other Innovations in Broadcast Radio",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=Q8moX83VQ8U"
        }
      },
      "trackId": 11244,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58455
      ],
      "eventIds": [],
      "abstract": "This paper demystifies listeners' wishes with respect to broadcast radio innovation (with a specific focus on radio-mediated music consumption). Our study encompasses an ideation workshop with radio experts, an exploratory survey and a mixed methods empirical evaluation. The empirical evaluation uses two concrete concepts (i.e., letting listeners on-the-fly replace radio content with preferred content and fostering participatory radio production by involving listeners as radio content curators) as a lens to zoom in on the questionable desirability of radio innovation. It is learned that a significant consumer group exists who will stay loyal to broadcast radio even if it does not evolve substantially, whereas others need disruptive incentives to start listening to radio (again). From our results we distill design recommendations to educate the radio production community about how best to approach radio innovation.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Belgium",
              "state": "",
              "city": "Hasselt",
              "institution": "Hasselt University -- tUL",
              "dsl": "Expertise centre for Digital Media"
            }
          ],
          "personId": 58417
        },
        {
          "affiliations": [
            {
              "country": "Belgium",
              "state": "",
              "city": "Hasselt",
              "institution": "Hasselt University -- tUL",
              "dsl": "Expertise centre for Digital Media"
            }
          ],
          "personId": 58420
        },
        {
          "affiliations": [
            {
              "country": "Belgium",
              "state": "",
              "city": "Hasselt",
              "institution": "Hasselt University -- tUL",
              "dsl": "Expertise centre for Digital Media"
            }
          ],
          "personId": 58430
        },
        {
          "affiliations": [
            {
              "country": "Belgium",
              "state": "",
              "city": "Hasselt",
              "institution": "Hasselt University -- tUL -- Flanders Make",
              "dsl": "Expertise centre for Digital Media"
            }
          ],
          "personId": 58418
        },
        {
          "affiliations": [
            {
              "country": "Belgium",
              "state": "",
              "city": "Hasselt",
              "institution": "Hasselt University -- tUL",
              "dsl": "Expertise centre for Digital Media"
            }
          ],
          "personId": 58409
        }
      ]
    },
    {
      "id": 58438,
      "typeId": 11813,
      "title": "To Use or Not to Use: Mediation and Limitation of Digital Screen Technologies within Nuclear Families",
      "addons": {
        "doi": {
          "type": "doiLink",
          "url": "https://doi.org/10.1145/3452918.3458808"
        },
        "Presentation Video": {
          "duration": 300,
          "title": "To Use or Not to Use: Mediation and Limitation of Digital Screen Technologies within Nuclear Families",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=eqzU_4N0inI"
        }
      },
      "trackId": 11244,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58457
      ],
      "eventIds": [],
      "abstract": "Today’s home environment is affected by multiple screen technologies designed for personal and home use, making family members audience of the omnipresent technologies. We investigate how the past decades' increasingly technology saturated home environment influences home practices and parents' mediation of their rules of conduct for children's access and use. We conducted a two-part interview study with parents from different nuclear families, and found parental mediation of screen technologies to have become a complex and emotional process with continuous mediation of when to use or not use screens. Despite a shared goal of decreasing the role of screen technology, the parents differentiated between rules, regulations, and limitations, which could provide tensions within the family and between different families if attitudes and/or practices were not consistent. As such, we argue internal family rules and regulations to be a continuous negotiation between parents and children, where personal principles and external expectations impact a family’s code of conduct. Our study contributes to a better understanding of screen technology practices, leading to design guidelines for screenbased home technology.  ",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Denmark",
              "state": "",
              "city": "Copenhagen",
              "institution": "The IT University of Copenhagen",
              "dsl": ""
            }
          ],
          "personId": 58401
        },
        {
          "affiliations": [
            {
              "country": "Denmark",
              "state": "",
              "city": "Copenhagen",
              "institution": "The IT University of Copenhagen",
              "dsl": ""
            }
          ],
          "personId": 58423
        }
      ]
    },
    {
      "id": 58439,
      "typeId": 11813,
      "title": "Context-Aware Question-Answer for Interactive Media Experiences",
      "addons": {
        "doi": {
          "type": "doiLink",
          "url": "https://doi.org/10.1145/3452918.3458795"
        },
        "Presentation Video": {
          "duration": 300,
          "title": "Context-Aware Question-Answer for Interactive Media Experiences",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=jwgp7r4Kjrc"
        }
      },
      "trackId": 11244,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58456
      ],
      "eventIds": [],
      "abstract": "Media content has become a primary source of information, entertainment, and even education.  The ability to provide video content querying as well as interactive experiences is a new challenge.  To this end, question answering (QA) systems such as Alexa and Google Assistant have become quite established in consumer markets but are limited to general information and lack context awareness.  In this paper, we propose Context-QA, a light-weight context-aware QA framework, to provide QA experiences on multimedia content.  The context awareness is achieved through our innovative Staged QA Controller algorithm that keeps the search for answers in the context most relevant to the question.  Our evaluation results show that Context-QA improves the quality of the answers by up to 49% and uses up to 56% less time compared to the conventional QA model. Subjective tests show Context-QA improved results over conventional QA models, with 90% reporting enjoying this new media form.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Canada",
              "state": "Alberta",
              "city": "Calgary",
              "institution": "University of Calgary",
              "dsl": ""
            }
          ],
          "personId": 58434
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Missouri",
              "city": "Columbia",
              "institution": "University of Missouri",
              "dsl": "ECE Department"
            }
          ],
          "personId": 58400
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "San Jose",
              "institution": "TCL Research America",
              "dsl": ""
            }
          ],
          "personId": 58433
        },
        {
          "affiliations": [
            {
              "country": "Canada",
              "state": "Alberta",
              "city": "Calgary",
              "institution": "University of Calgary",
              "dsl": ""
            }
          ],
          "personId": 58403
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Missouri",
              "city": "Columbia",
              "institution": "University of Missouri",
              "dsl": ""
            }
          ],
          "personId": 58404
        }
      ]
    },
    {
      "id": 58440,
      "typeId": 11813,
      "title": "Extending Music Notation as a Programming Language for Interactive Music",
      "addons": {
        "doi": {
          "type": "doiLink",
          "url": "https://doi.org/10.1145/3452918.3458807"
        },
        "Presentation Video": {
          "duration": 300,
          "title": "Extending Music Notation as a Programming Language for Interactive Music",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=HOnL4x2aq2A"
        }
      },
      "trackId": 11244,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58454
      ],
      "eventIds": [],
      "abstract": "This work describes a novel approach for composing and performing interactive music by extending the traditional staff notation to the programming language domain. The proposed syntax aims to describe the interaction between humans and computers in live-electronics music performance. Thus, both performers and machines will understand this new notation, creating a cohesive music representation for performance that is both human-readable and technology-independent. This paper starts by describing some critical issues related to live-electronics that make it challenging to build repertoire around this genre. Next, the proposed approach is detailed, along with some syntax examples. Finally, the last section describes the evaluation of the proposed approach, including a description of the software implementation and a set of short interactive-pieces.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Georgia",
              "city": "Atlanta",
              "institution": "Georgia Institute of Technology",
              "dsl": "Alumni"
            }
          ],
          "personId": 58413
        }
      ]
    },
    {
      "id": 58441,
      "typeId": 11813,
      "title": "Attention Guidance Technique Using Visual Subliminal Cues And Its Application On Videos",
      "addons": {
        "doi": {
          "type": "doiLink",
          "url": "https://doi.org/10.1145/3452918.3458800"
        },
        "Presentation Video": {
          "duration": 300,
          "title": "Attention Guidance Technique Using Visual Subliminal Cues And Its Application On Videos",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=R1WZ210i3g0"
        }
      },
      "trackId": 11244,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58456
      ],
      "eventIds": [],
      "abstract": "Attention is known to be shifted reflexively by subliminal cues in static environments, but their effect when applied in dynamic environments remains unclear. This study examines the effect of subliminal cues in both static and dynamic environments and presents a novel technique of applying subliminal cues within videos. Experiment 1 confirmed the effect of subliminal cues in guiding covert spatial attention in a static environment. Experiment 2 investigated the effect of subliminal cues in guiding overall gaze distribution in video context by manipulating the frequency of subliminal cues to bias the viewer’s gaze towards a specific side. There was no main effect of cue frequency, but additional findings showed the possibility that the effect of subliminal cues occurred differently between gender, and other factors such as gaze orientation bias influenced the viewer's gaze distribution. These results provide insights on application of subliminal cues in video contexts and render the directions for future studies.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Korea, Republic of",
              "state": "",
              "city": "Daejeon",
              "institution": "KAIST",
              "dsl": "Graduate School of Culture Technology"
            },
            {
              "country": "Korea, Republic of",
              "state": "",
              "city": "Daejeon",
              "institution": "KAIST",
              "dsl": "Graduate School of Culture Technology"
            }
          ],
          "personId": 58411
        },
        {
          "affiliations": [
            {
              "country": "Korea, Republic of",
              "state": "",
              "city": "Daejeon",
              "institution": "KAIST",
              "dsl": "Graduate School of Culture Technology"
            },
            {
              "country": "Korea, Republic of",
              "state": "",
              "city": "Daejeon",
              "institution": "KAIST",
              "dsl": "Graduate School of Culture Technology"
            }
          ],
          "personId": 58389
        }
      ]
    },
    {
      "id": 58442,
      "typeId": 11813,
      "title": "Data-driven Approaches for Discovery and Prediction of User-preferred Picture Settings on Smart TVs",
      "addons": {
        "doi": {
          "type": "doiLink",
          "url": "https://doi.org/10.1145/3452918.3458798"
        },
        "Presentation Video": {
          "duration": 300,
          "title": "Data-driven Approaches for Discovery and Prediction of User-preferred Picture Settings on Smart TVs",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=Y4eb2zLGmww"
        }
      },
      "trackId": 11244,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58455
      ],
      "eventIds": [],
      "abstract": "We discover user-preferred picture settings on smart TVs and investigate whether it is possible to predict the users' picture setting preferences through machine learning methods. We first perform K-means clustering on large-scale smart TV usage log data to understand how users fine-tune the factory default picture settings. Clustering results recognize 3-4 user groups who have reasonably different preferences toward the default settings. By characterizing these user preferences, we come up with new user-preferred picture settings. We perform an in-depth analysis of the newly discovered picture settings regarding diverse TV device characteristics. We also perform lab experiments to demonstrate how these new settings deliver different picture quality than the default. Next, we construct a deep learning-based classifier that learns and predicts the picture setting preferences of the users. The final trained model shows 86% accuracy in predicting users' decisions to choose a specific picture setting out of four available options.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "Irvine",
              "institution": "Samsung Research America",
              "dsl": "Digital Media Solutions Lab"
            }
          ],
          "personId": 58431
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "Irvine",
              "institution": "Samsung Research America",
              "dsl": "Digital Media Solutions Lab"
            }
          ],
          "personId": 58419
        }
      ]
    },
    {
      "id": 58443,
      "typeId": 11813,
      "title": "Coping, Hacking, and DIY: Reframing the Accessibility of Interactions with Television for People with Motor Impairments",
      "addons": {
        "doi": {
          "type": "doiLink",
          "url": "https://doi.org/10.1145/3452918.3458802"
        },
        "Presentation Video": {
          "duration": 300,
          "title": "Coping, Hacking, and DIY: Reframing the Accessibility of Interactions with Television for People with Motor Impairments",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=MfN5XyMCuPk"
        }
      },
      "trackId": 11244,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58454
      ],
      "eventIds": [],
      "abstract": "We conduct an examination of the accessibility challenges experienced by people with upper body motor impairments when interacting with television. We report findings from a study with N=41 people with motor impairments (spinal cord injury, cerebral palsy, muscular dystrophy) and document their challenges and coping strategies for using the TV remote control, but also their television watching experience and expectations of suitable assistive technology for television. Our results show that, despite several accessible remote control products available on the market, the majority of our participants preferred to DIY and hack, and to adopt coping strategies to be able to use conventional TV remote controls. We contrast their experience against that of a control group with N=41 people without impairments. We reflect about the DIY culture and people with motor impairments, and we propose future work directions to increase the accessibility of interactions with television.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Romania",
              "state": "",
              "city": "Suceava",
              "institution": "Ștefan cel Mare University of Suceava",
              "dsl": "MintViz Lab, MANSiD Research Center"
            }
          ],
          "personId": 58428
        },
        {
          "affiliations": [
            {
              "country": "Romania",
              "state": "",
              "city": "Suceava",
              "institution": "Ștefan cel Mare University of Suceava",
              "dsl": "MintViz Lab, MANSiD Research Center"
            }
          ],
          "personId": 58429
        }
      ]
    },
    {
      "id": 58444,
      "typeId": 11813,
      "title": "Camera Distances and Shot Sizes in Cinematic Virtual Reality",
      "addons": {
        "doi": {
          "type": "doiLink",
          "url": "https://doi.org/10.1145/3452918.3458804"
        },
        "Presentation Video": {
          "duration": 300,
          "title": "Camera Distances and Shot Sizes in Cinematic Virtual Reality",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=-HNc6RTBOjw"
        }
      },
      "trackId": 11244,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58456
      ],
      "eventIds": [],
      "abstract": "This paper describes the impact of different camera distances in cinematic virtual reality. For our findings, we took a closer look at proxemics, the study on how humans behave regarding space and distances. We explored the four proxemics distances (intimate,\r\npersonal, social, public) and adapted them to camera distances in cinematic virtual reality. For the user study, a stereoscopic movie with a speaking person was produced for four different distances. The results show that different distances cause different feelings in viewers similar to shot sizes in traditional movies. In our scenario - a person in a museum is speaking about an exhibit - the personal distance was preferred by the participants. As an outcome of this work, the proxemics distances were put in relation to well-known shot sizes used in traditional filmmaking.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Munich",
              "institution": "LMU Munich",
              "dsl": ""
            }
          ],
          "personId": 58416
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Munich",
              "institution": "LMU Munich",
              "dsl": ""
            }
          ],
          "personId": 58396
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Munich",
              "institution": "LMU Munich",
              "dsl": ""
            }
          ],
          "personId": 58405
        }
      ]
    },
    {
      "id": 58445,
      "typeId": 11813,
      "title": "Hugging from A Distance: Building Interpersonal Relationships in Social Virtual Reality",
      "addons": {
        "doi": {
          "type": "doiLink",
          "url": "https://doi.org/10.1145/3452918.3458805"
        },
        "Presentation Video": {
          "duration": 300,
          "title": "Hugging from A Distance: Building Interpersonal Relationships in Social Virtual Reality",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=Wp53BPFWLLk"
        }
      },
      "trackId": 11244,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58457
      ],
      "eventIds": [],
      "abstract": "This paper focuses on how the emerging social VR systems, as new and unique social interaction spaces that afford high-fidelity and multidimensional physical presence, may support building interpersonal relationships in a more nuanced, immersive, and embodied way. Based on 30 interviews, our investigation focuses on 1) the main reasons why people build and foster interpersonal relationships in social VR; 2) various novel activities through which users can foster relationships in social VR; and 3) the complicated influences of social VR mediated relationships on users' online and offline social lives. We contribute to better understanding mediated interactive experiences by shedding light on the novel role of social VR in transforming how people meet, interact, and establish connections with others compared to other forms of media. We also provide potential directions to inform the design of future social VR systems to better afford healthy, fulfilling, and supportive interpersonal relationships.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "South Carolina",
              "city": "Clemson",
              "institution": "Clemson University",
              "dsl": "School of Computing"
            }
          ],
          "personId": 58435
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "South Carolina",
              "city": "Clemson",
              "institution": "Clemson University",
              "dsl": "School of Computing"
            }
          ],
          "personId": 58432
        }
      ]
    },
    {
      "id": 58446,
      "typeId": 11813,
      "title": "Harassment Experiences of Women and LGBTQ Live Streamers and How They Handled Negativity",
      "addons": {
        "doi": {
          "type": "doiLink",
          "url": "https://doi.org/10.1145/3452918.3458794"
        },
        "Presentation Video": {
          "duration": 300,
          "title": "Harassment Experiences of Women and LGBTQ Live Streamers and How They Handled Negativity",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=sDwrv3x0NoA"
        }
      },
      "trackId": 11244,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58454
      ],
      "eventIds": [],
      "abstract": "Live streaming is a form of interactive media that potentially makes streamers more vulnerable to harassment due to the unique attributes of the technology that facilitates enhanced information sharing via video and audio. In this study, we document the harassment experiences of 25 live streamers on Twitch from underrepresented groups including women and/or LGBTQ streamers and investigate how they handle and prevent adversity. In particular, live streaming enables streamers to self-moderate their communities, so we delve into the methods of how they manage their communities from both a social and technical perspective. We found that technology can cover the basics for handling negativity, but much emotional and relational work is invested in moderation, community maintenance, and self-care.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New Jersey",
              "city": "Newark",
              "institution": "New Jersey Institute of Technology",
              "dsl": ""
            }
          ],
          "personId": 58399
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New Jersey",
              "city": "Newark",
              "institution": "New Jersey Institute of Technology",
              "dsl": ""
            }
          ],
          "personId": 58393
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New Jersey",
              "city": "Newark ",
              "institution": "New Jersey Institute of Technology",
              "dsl": ""
            }
          ],
          "personId": 58391
        }
      ]
    },
    {
      "id": 58447,
      "typeId": 11813,
      "title": "Visual Respiratory Feedback in Virtual Reality Exposure Therapy: A Pilot Study ",
      "addons": {
        "doi": {
          "type": "doiLink",
          "url": "https://doi.org/10.1145/3452918.3458799"
        },
        "Presentation Video": {
          "duration": 300,
          "title": "Visual Respiratory Feedback in Virtual Reality Exposure Therapy: A Pilot Study ",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=8wpgNlW9UF8"
        }
      },
      "trackId": 11244,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58454
      ],
      "eventIds": [],
      "abstract": "As the use of Virtual Reality (VR) expands across fields, new kinds of interaction methods are introduced. This study presents the Visual Heights VR experience that integrates natural breathing as an input method to provide visual respiratory feedback. Incorporating spatial audio, haptic feedback and breath visualisation, the experience aims to be highly immersive. This experience was made to be used as part of a controlled pilot study to see the effect of respiratory feedback on the user's anxiety levels. The user’s anxiety is assessed by their heart rate, brain electrical activity, skin conductance and respiratory rate. These biosignals are recorded within the experience; captured by external hardware. The pieces of hardware used were Galvanic Skin Response to measure skin conductance, photoplethysmogram to measure heart rate; Electroencephalogram to measure the electrical activity in the brain, and a prototype device that records airflow on an axis from -1 to 1 for respiratory rate. It was found that the aforementioned prototype was not sufficient for calculating the respiratory rate. Results of the controlled study showed that the Visual Heights VR experience delivered the expected positive correlation between skin conductance and perceived height (r=.491, p$<$.05, N=1543) which suggests it is plausible to be used as a material for further research. As the integration of user’s physiological signals and breathing for visual feedback can contribute to therapeutic uses of VR, research with bigger sample sizes will be conducted to better investigate the relationship between visual respiratory feedback and anxiety using the Visual Heights VR experience.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Ireland",
              "state": "Munster",
              "city": "Cork",
              "institution": "University College Cork",
              "dsl": "School of Computer Science and Information Technology"
            }
          ],
          "personId": 58436
        },
        {
          "affiliations": [
            {
              "country": "Ireland",
              "state": "",
              "city": "Cork",
              "institution": "University College Cork",
              "dsl": ""
            }
          ],
          "personId": 58425
        },
        {
          "affiliations": [
            {
              "country": "Ireland",
              "state": "",
              "city": "Cork",
              "institution": "University College Cork",
              "dsl": ""
            }
          ],
          "personId": 58407
        }
      ]
    },
    {
      "id": 58448,
      "typeId": 11813,
      "title": "AR-TV and AR-Diànshì: Cultural Differences in Users' Preferences for Augmented Reality Television",
      "addons": {
        "doi": {
          "type": "doiLink",
          "url": "https://doi.org/10.1145/3452918.3458801"
        },
        "Presentation Video": {
          "duration": 300,
          "title": "AR-TV and AR-Di√†nsh√¨: Cultural Differences in Users' Preferences for Augmented Reality Television",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=ckbGqch2vi8"
        }
      },
      "trackId": 11244,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58457
      ],
      "eventIds": [],
      "abstract": "As Augmented Reality television gains momentum, it is important to understand whether cultural differences among viewers favor different expectations and preferences for immersion in such new television environments. A previous study documented the preferences of 172 participants from various European countries for twenty application scenarios for ARTV, such as virtual objects coming out of the TV screen into the room. In this work, we conduct an empirical generalization of this previous study to understand potential cultural differences in users' preferences for and expectations of ARTV. To this end, we report insights from data collected from a sample of 147 participants from China, which we compare against the preferences expressed by the participants from Europe from the original study. Our findings reveal similarities, but also differences in terms of expectations of ARTV across the two cultural groups. We draw implications for future research on culturally-aware augmentations of the television watching experience.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Romania",
              "state": "",
              "city": "Suceava",
              "institution": "Ștefan cel Mare University of Suceava",
              "dsl": "MintViz Lab, MANSiD Research Center"
            }
          ],
          "personId": 58395
        },
        {
          "affiliations": [
            {
              "country": "Romania",
              "state": "",
              "city": "Suceava",
              "institution": "Ștefan cel Mare University of Suceava",
              "dsl": "MintViz Lab, MANSiD Research Center"
            }
          ],
          "personId": 58429
        },
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Beijing",
              "institution": "Beihang University",
              "dsl": "NLSDE Lab"
            }
          ],
          "personId": 58392
        },
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Beijing",
              "institution": "Beihang University",
              "dsl": "NLSDE Lab"
            }
          ],
          "personId": 58422
        }
      ]
    },
    {
      "id": 58449,
      "typeId": 11813,
      "title": "Evaluating AI assisted subtitling",
      "addons": {
        "doi": {
          "type": "doiLink",
          "url": "https://doi.org/10.1145/3452918.3458792"
        },
        "Presentation Video": {
          "duration": 300,
          "title": "Evaluating AI assisted subtitling",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=dr0lz_Ijna8"
        }
      },
      "trackId": 11244,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58455
      ],
      "eventIds": [],
      "abstract": "Recent advances in artificial intelligence (AI) have led to an increased focus on automating media production. One relevant application area for AI is using speech recognition to create subtitles and closed captions for videos. The AI methods based on machine learning are still not sufficiently reliable in terms of producing perfect or acceptable subtitles. To compensate for this unreliability, AI can be used to build tools that support, rather than replace, human efforts and to create semi-automated workflows. In this paper, we present a prototype for including automated speech recognition for subtitling in an existing production-grade video editing tool. We devised an experiment with 25 participants and tested the efficiency and effectiveness of this tool compared to a fully manual process. The results show that there is a significant increase in both effectiveness and efficiency for novices in subtitling. Furthermore, the participants found the augmented process to be more demanding. We identify some usability issues and design choices that pertain to making augmented subtitling easier.\r\n",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Norway",
              "state": "",
              "city": "Bergen",
              "institution": "University of Bergen",
              "dsl": ""
            }
          ],
          "personId": 58412
        },
        {
          "affiliations": [
            {
              "country": "Norway",
              "state": "",
              "city": "Bergen",
              "institution": "University of Bergen",
              "dsl": ""
            }
          ],
          "personId": 58421
        },
        {
          "affiliations": [
            {
              "country": "Norway",
              "state": "",
              "city": "BERGEN",
              "institution": "University of Bergen",
              "dsl": ""
            }
          ],
          "personId": 58408
        }
      ]
    },
    {
      "id": 58450,
      "typeId": 11813,
      "title": "Human Data Interaction in Data-Driven Media Experiences : An Exploration of Data Sensitive Responses to the Socio-Technical Challenges of Personal Data Leverage",
      "addons": {
        "doi": {
          "type": "doiLink",
          "url": "https://doi.org/10.1145/3452918.3458797"
        },
        "Presentation Video": {
          "duration": 300,
          "title": "Human Data Interaction in Data-Driven Media Experiences : An Exploration of Data Sensitive Responses to the Socio-Technical Challenges of Personal Data Leverage",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=B_cUTELoy9A"
        }
      },
      "trackId": 11244,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58455
      ],
      "eventIds": [],
      "abstract": "While explication of socio-technical challenges posed by personal data leverage in media research has been of interest recently, effective responses that alleviate them are yet to be studied. This paper reports the use of a Cross Media Profiler prototype supported by a Personal Data Store, that combines personal data from different media services for more holistic media recommendations. This prototype is used to probe and explore the integration of Human Data Interaction principles in media experiences, as a response to these challenges. Our focus groups reveal that users prefer the media service when supported by the PDS while highlighting improvements around transparency and control. The work leads to two outcomes : design recommendations for future media experiences to embody increased sensitivity to the implications of personal data leverage and a critique of the HDI agenda through the lens of data driven media, which scopes out potential for future IMX intervention.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "",
              "city": "Nottingham",
              "institution": "University of Nottingham",
              "dsl": "Horizon Digital Economy Hub"
            }
          ],
          "personId": 58414
        },
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "",
              "city": "Manchester ",
              "institution": "BBC",
              "dsl": ""
            }
          ],
          "personId": 58390
        },
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "Nottingham",
              "city": "Nottingham",
              "institution": "University of Nottingham",
              "dsl": "Horizon Digital Economy Research"
            }
          ],
          "personId": 58426
        }
      ]
    },
    {
      "id": 58451,
      "typeId": 11813,
      "title": "Musical Haptic Wearables for Synchronisation of Visually-impaired Performers: a Co-design Approach",
      "addons": {
        "doi": {
          "type": "doiLink",
          "url": "https://doi.org/10.1145/3452918.3458803"
        },
        "Presentation Video": {
          "duration": 300,
          "title": "Musical Haptic Wearables for Synchronisation of Visually-impaired Performers: a Co-design Approach",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=F8OSgoPhI48"
        }
      },
      "trackId": 11244,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58454
      ],
      "eventIds": [],
      "abstract": "The emergence of new technologies is providing opportunities to develop novel solutions that facilitate the integration of visually-impaired people in different activities of our daily life, including collective music making. This paper presents a study conducted with visually-impaired music performers, which involved a participatory approach to the design of accessible technologies for musical communication in group playing. We report on three workshops that were conducted together with members of an established ensemble of solely visually-impaired musicians. The first workshop focused on the identification of the participants' needs during the activity of playing in groups and how technology could satisfy such needs. The second and third workshops investigated, respectively, the activities of choir singing and instrument playing in ensemble, focusing on the key issue of synchronisation that was identified in the first workshop. The workshops involved prototypes of musical haptic wearables, which were co-designed and evaluated by the participants. Overall, results indicate that wireless tactile communication represents a promising avenue to cater effectively to the needs of visually-impaired performers.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Italy",
              "state": "",
              "city": "Trento",
              "institution": "University of Trento",
              "dsl": "Department of Information Engineering and Computer Science"
            }
          ],
          "personId": 58424
        },
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "",
              "city": "London",
              "institution": "University College London",
              "dsl": "Institute of Education"
            }
          ],
          "personId": 58427
        },
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "",
              "city": "London",
              "institution": "Queen Mary University of London",
              "dsl": "Electronic engineering and computer science"
            }
          ],
          "personId": 58402
        }
      ]
    },
    {
      "id": 58452,
      "typeId": 11813,
      "title": "Mixing Modalities of 3D Sketching and Speech for Interactive Model Retrieval in Virtual Reality",
      "addons": {
        "doi": {
          "type": "doiLink",
          "url": "https://doi.org/10.1145/3452918.3458806"
        },
        "Presentation Video": {
          "duration": 300,
          "title": "Mixing Modalities of 3D Sketching and Speech for Interactive Model Retrieval in Virtual Reality",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=1syZx_R_eWk"
        }
      },
      "trackId": 11244,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58456
      ],
      "eventIds": [],
      "abstract": "Sketch and speech are intuitive interaction methods that convey complementary information and have been independently used for 3D model retrieval in virtual environments. While sketch has been shown to be an effective retrieval method, not all collections are easily navigable using this modality alone. We design a new challenging database for sketch comprised of 3D chairs where each of the components (arms, legs, seat, back) are independently colored. To overcome this, we implement a multimodal interface for querying 3D model databases within a virtual environment. We base the sketch on the state-of-the-art for 3D Sketch Retrieval, and use a Wizard-of-Oz style experiment to process the voice input. In this way, we avoid the complexities of natural language processing which frequently requires fine-tuning to be robust. We conduct two user studies and show that hybrid search strategies emerge from the combination of interactions, fostering the advantages provided by both modalities.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "",
              "city": "London",
              "institution": "University College London",
              "dsl": "Computer Science"
            }
          ],
          "personId": 58410
        },
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "",
              "city": "London",
              "institution": "University College London",
              "dsl": "Computer Science"
            }
          ],
          "personId": 58398
        },
        {
          "affiliations": [
            {
              "country": "Italy",
              "state": "GE",
              "city": "Genoa",
              "institution": "Istituto Italiano di Tecnologia",
              "dsl": "Visual Geometry and Modelling Lab"
            },
            {
              "country": "United Kingdom",
              "state": "",
              "city": "London",
              "institution": "University College London (UCL)",
              "dsl": "Department of Computer Science"
            }
          ],
          "personId": 58406
        },
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "",
              "city": "London",
              "institution": "University College London",
              "dsl": "Department of Computer Science"
            }
          ],
          "personId": 58415
        }
      ]
    },
    {
      "id": 58453,
      "typeId": 11813,
      "title": "Moderation Visibility: Mapping  the Strategies of Volunteer Moderators  in Live Streaming Micro Communities",
      "addons": {
        "doi": {
          "type": "doiLink",
          "url": "https://doi.org/10.1145/3452918.3458796"
        },
        "Presentation Video": {
          "duration": 300,
          "title": "Moderation Visibility: Mapping  the Strategies of Volunteer Moderators  in Live Streaming Micro Communities",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=4n29Q3rLo9Y"
        }
      },
      "trackId": 11244,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58457
      ],
      "eventIds": [],
      "abstract": "Volunteer moderators actively engage in online content management, such as removing toxic content and sanctioning anti-normative behaviors in user-governed communities. The synchronicity and ephemerality of live-streaming communities pose unique moderation challenges. Based on interviews with 21 volunteer moderators on Twitch, we mapped out 13 moderation strategies and presented them in relation to the bad act, enabling us to categorize from proactive and reactive perspectives and identify communicative and technical interventions. We found that the act of moderation involves highly visible and performative activities in the chat and invisible activities involving coordination and sanction. The juxtaposition of real-time individual decision-making with collaborative discussions and the dual nature of visible and invisible activities of moderators provide a unique lens into a role that relies heavily on both the social and technical. We also discuss how the affordances of live-streaming contribute to these unique activities.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New Jersey",
              "city": "Newark",
              "institution": "New Jersey Institute of Technology",
              "dsl": ""
            }
          ],
          "personId": 58393
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New Jersey",
              "city": "Newark ",
              "institution": "New Jersey Institute of Technology",
              "dsl": ""
            }
          ],
          "personId": 58391
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New Jersey",
              "city": "Newark",
              "institution": "New Jersey Institute of Technology ",
              "dsl": ""
            }
          ],
          "personId": 58397
        }
      ]
    },
    {
      "id": 58569,
      "typeId": 11823,
      "title": "Timeline: An Authoring Platform for Parameterized Stories",
      "addons": {
        "broadcastLink": {
          "duringSessionOnly": false,
          "type": "broadcastLink",
          "url": "https://ohyay.co/viewer.html?wsid=ws_W6kSiqvJ#scene_fUb-vM0q"
        },
        "doi": {
          "type": "doiLink",
          "url": "https://doi.org/10.1145/3452918.3465501"
        }
      },
      "trackId": 11245,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58618,
        58629
      ],
      "eventIds": [],
      "abstract": "The Timeline platform aims to afford interactors a novel way of experiencing complex, multi-sequential stories and causal relationships while capitalizing on the affordances of interactive digital narratives. Along with the authoring tool, this paper discusses exploratory techniques and best practices that hope to promote new methods of multi-sequential storytelling, i.e. replay stories centered on multiple instantiations, that emphasize parallelism and orienting milestones.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Georgia",
              "city": "Atlanta",
              "institution": "Georgia Institute of Technology",
              "dsl": ""
            }
          ],
          "personId": 58480
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Georgia",
              "city": "Atlanta",
              "institution": "Georgia Institute of Technology",
              "dsl": "Digital Media"
            }
          ],
          "personId": 58500
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Georgia",
              "city": "Atlanta",
              "institution": "Georgia Institute of Technology",
              "dsl": ""
            }
          ],
          "personId": 58544
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Georgia",
              "city": "Atlanta",
              "institution": "Georgia Institute of Technology",
              "dsl": ""
            }
          ],
          "personId": 58471
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Georgia",
              "city": "Atlanta",
              "institution": "Georgia Institute of Technology",
              "dsl": "Digital Media, School of Literature, Media and Communication"
            }
          ],
          "personId": 58554
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Georgia",
              "city": "Atlanta",
              "institution": "Georgia Institute of Technology",
              "dsl": "Digital Media, School of Literature, Media and Communication"
            }
          ],
          "personId": 58467
        }
      ]
    },
    {
      "id": 58570,
      "typeId": 11823,
      "title": "Augmented Reality-Based Remote Family Visits in Nursing Homes",
      "addons": {
        "broadcastLink": {
          "duringSessionOnly": false,
          "type": "broadcastLink",
          "url": "https://ohyay.co/viewer.html?wsid=ws_W6kSiqvJ#scene_LiYp_hKD"
        },
        "doi": {
          "type": "doiLink",
          "url": "https://doi.org/10.1145/3452918.3465502"
        }
      },
      "trackId": 11245,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58619,
        58627
      ],
      "eventIds": [],
      "abstract": "During the COVID-19 pandemic, many nursing homes had to restrict visitations. This had a major negative impact on the wellbeing of residents and their family members. In response, residents and family members increasingly resorted to mediated communication to maintain social contact. To facilitate high-quality mediated social contact between residents in nursing homes and remote family members, we developed an augmented reality (AR)-based communication tool. In this study, we compared the user experience (UX) of AR-communication with that of video calling, for 10 pairs of residents and family members. We measured enjoyment, spatial presence and social presence, attitudes, behavior and conversation duration. In the AR-communication condition, residents perceived a 3D projection of their remote family member onto a chair placed in front of them. In the video calling condition, the family member was shown using 2D video. In both conditions, the family member perceived the resident in the video calling mode on a 2D screen. While residents reported no differences in their UX between both conditions, family members reported higher spatial presence for the AR-communication condition compared to video-calling. Conversation durations were significantly longer during AR-communication than during video calling. We tentatively suggest that there may be (unconscious) differences in UX during AR-based communication compared to video calling. ",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Netherlands",
              "state": "Not Applicable",
              "city": "Soesterberg",
              "institution": "TNO Human Factors",
              "dsl": "Perception, Cognition, Neuroscience & technology"
            }
          ],
          "personId": 58474
        },
        {
          "affiliations": [
            {
              "country": "Netherlands",
              "state": "",
              "city": "The Hague",
              "institution": "TNO",
              "dsl": ""
            }
          ],
          "personId": 58541
        },
        {
          "affiliations": [
            {
              "country": "Netherlands",
              "state": "",
              "city": "The Hague",
              "institution": "TNO",
              "dsl": ""
            }
          ],
          "personId": 58489
        },
        {
          "affiliations": [
            {
              "country": "Netherlands",
              "state": "",
              "city": "Amsterdam",
              "institution": "University of Amsterdam",
              "dsl": ""
            }
          ],
          "personId": 58548
        },
        {
          "affiliations": [
            {
              "country": "Netherlands",
              "state": "",
              "city": "Heerlen",
              "institution": "MeanderGroep Zuid-Limburg",
              "dsl": ""
            }
          ],
          "personId": 58523
        },
        {
          "affiliations": [
            {
              "country": "Netherlands",
              "state": "",
              "city": "The Hague",
              "institution": "TNO",
              "dsl": ""
            }
          ],
          "personId": 58524
        }
      ]
    },
    {
      "id": 58571,
      "typeId": 11823,
      "title": "Foldables and 2-in-1s: Understanding and Supporting the Needs of Hybrid Device Users",
      "addons": {
        "broadcastLink": {
          "duringSessionOnly": false,
          "type": "broadcastLink",
          "url": "https://ohyay.co/viewer.html?wsid=ws_W6kSiqvJ#scene_WsGXzDk1"
        },
        "doi": {
          "type": "doiLink",
          "url": "https://doi.org/10.1145/3452918.3465503"
        }
      },
      "trackId": 11245,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58617,
        58638
      ],
      "eventIds": [],
      "abstract": "Foldables and 2-in-1 devices provide users with new ways to adapt their device to their mobile context, allowing users to switch device configuration, screen size and shape, and input mechanism in seconds. This has strong implications for the design of interactive media applications that need to adapt to the user’s changing context and device parameters. In this study, we explored how users opportunistically make use of these new device affordances in their everyday lives through interviews with 15 diverse hybrid device owners, identifying use cases and pain points. Users reported regularly moving through multiple configurations or input modes while using a single product, or completing a single task. Based on our learnings, we provide recommendations for practitioners designing for hybrid mobile devices.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "San Bruno",
              "institution": "YouTube",
              "dsl": ""
            }
          ],
          "personId": 58539
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "San Bruno",
              "institution": "YouTube",
              "dsl": ""
            }
          ],
          "personId": 58550
        }
      ]
    },
    {
      "id": 58572,
      "typeId": 11823,
      "title": "PRIM Project: Playing and Recording with Interactivity and Multisensoriality",
      "addons": {
        "broadcastLink": {
          "duringSessionOnly": false,
          "type": "broadcastLink",
          "url": "https://ohyay.co/viewer.html?wsid=ws_W6kSiqvJ#scene_ieWXddwH"
        },
        "doi": {
          "type": "doiLink",
          "url": "https://doi.org/10.1145/3452918.3465487"
        }
      },
      "trackId": 11245,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58616,
        58628
      ],
      "eventIds": [],
      "abstract": "Multisensory Interaction (M.I.) is a promising research field acting on both perception and cognition. Among benefits, including the \"design for all\" approach, it is expected to increase humans’ cognitive performance (such as learning and cognitive stimulation) as well as user's experience. To our knowledge, there is no convincing tool allowing researchers to create easily multisensory scenarios, exercises or experimental interaction situations. This paper introduces the PRIM project which aims at designing a new and original tool for designing multisensory interactive interaction situations.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "France",
              "state": "",
              "city": "Saint-Denis",
              "institution": "Paris 8 University",
              "dsl": ""
            }
          ],
          "personId": 58468
        },
        {
          "affiliations": [
            {
              "country": "France",
              "state": "",
              "city": "Saint-Denis",
              "institution": "Paris 8 University",
              "dsl": ""
            }
          ],
          "personId": 58559
        },
        {
          "affiliations": [
            {
              "country": "France",
              "state": "",
              "city": "Saint-Denis",
              "institution": "Paris 8 University",
              "dsl": ""
            }
          ],
          "personId": 58545
        },
        {
          "affiliations": [
            {
              "country": "France",
              "state": "",
              "city": "Vannes",
              "institution": "South Brittany University",
              "dsl": ""
            }
          ],
          "personId": 58566
        },
        {
          "affiliations": [
            {
              "country": "France",
              "state": "",
              "city": "Saint-Denis",
              "institution": "Paris 8 University",
              "dsl": ""
            }
          ],
          "personId": 58536
        },
        {
          "affiliations": [
            {
              "country": "France",
              "state": "",
              "city": "Saint-Denis",
              "institution": "Paris 8 University",
              "dsl": ""
            }
          ],
          "personId": 58549
        },
        {
          "affiliations": [
            {
              "country": "France",
              "state": "",
              "city": "Paris",
              "institution": "Université Paris Lumière",
              "dsl": "EA 4004 - Cognitions Humaine et Artificielle"
            }
          ],
          "personId": 58527
        },
        {
          "affiliations": [
            {
              "country": "France",
              "state": "",
              "city": "Saint-Denis",
              "institution": "Paris 8 University",
              "dsl": ""
            }
          ],
          "personId": 58475
        },
        {
          "affiliations": [
            {
              "country": "France",
              "state": "",
              "city": "Saint-Denis",
              "institution": "Paris 8 University",
              "dsl": ""
            }
          ],
          "personId": 58517
        }
      ]
    },
    {
      "id": 58573,
      "typeId": 11823,
      "title": "Co-creation Stage: a Web-based Tool for Collaborative and Participatory Co-located Art Performances",
      "addons": {
        "broadcastLink": {
          "duringSessionOnly": false,
          "type": "broadcastLink",
          "url": "https://ohyay.co/viewer.html?wsid=ws_W6kSiqvJ#scene_4GwM2vjo"
        },
        "doi": {
          "type": "doiLink",
          "url": "https://doi.org/10.1145/3452918.3465483"
        }
      },
      "trackId": 11245,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58618,
        58629
      ],
      "eventIds": [],
      "abstract": "In recent years, artists and communities have expressed the desire to work with tools that facilitate co-creation and allow distributed community performances. These performances can be spread over several physical stages, connecting them on real-time towards a single experience with the audience distributed along them. This enables a wider remote audience consuming the performance through their own devices, and even grants the participation of remote users in the show. In this paper we introduce the Co-creation Stage, a web-based tool that allows managing heterogeneous content sources, with a particular focus on live and on-demand media, across several distributed devices. The Co-creation Stage is part of the toolset developed in the Traction H2020 project which enables community performing art shows, where professional artists and non-professional participants perform together from different stages and locations. Here we present the design process, the architecture and the main functionalities of the tool as well as the results of the first user evaluation with Opera houses and artists.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Spain",
              "state": "",
              "city": "San Sebastián",
              "institution": "Vicomtech",
              "dsl": ""
            }
          ],
          "personId": 58553
        },
        {
          "affiliations": [
            {
              "country": "Spain",
              "state": "",
              "city": "San Sebastian",
              "institution": "Vicomtech",
              "dsl": ""
            }
          ],
          "personId": 58540
        },
        {
          "affiliations": [
            {
              "country": "Spain",
              "state": "",
              "city": "Donostia",
              "institution": "Vicomtech",
              "dsl": ""
            },
            {
              "country": "Spain",
              "state": "",
              "city": "San Sebastian",
              "institution": "University of the Basque Country",
              "dsl": ""
            }
          ],
          "personId": 58538
        },
        {
          "affiliations": [
            {
              "country": "Spain",
              "state": "",
              "city": "Donostia",
              "institution": "Vicomtech",
              "dsl": ""
            }
          ],
          "personId": 58464
        },
        {
          "affiliations": [
            {
              "country": "Spain",
              "state": "Gipuzkoa",
              "city": "Donostia-San Sebastian",
              "institution": "Vicomtech",
              "dsl": "Digital Media"
            }
          ],
          "personId": 58558
        },
        {
          "affiliations": [
            {
              "country": "Portugal",
              "state": "Aveiro",
              "city": "Aveiro",
              "institution": "University of Aveiro",
              "dsl": "Digimedia"
            }
          ],
          "personId": 58565
        },
        {
          "affiliations": [
            {
              "country": "Netherlands",
              "state": "",
              "city": "Amsterdam",
              "institution": "Centrum Wiskunde & Informatica",
              "dsl": ""
            }
          ],
          "personId": 58483
        },
        {
          "affiliations": [
            {
              "country": "Netherlands",
              "state": "Netherlands",
              "city": "Amsterdam",
              "institution": "CWI ",
              "dsl": "DIS "
            }
          ],
          "personId": 58551
        },
        {
          "affiliations": [
            {
              "country": "Netherlands",
              "state": "",
              "city": "Amsterdam",
              "institution": "CWI",
              "dsl": ""
            }
          ],
          "personId": 58535
        }
      ]
    },
    {
      "id": 58574,
      "typeId": 11823,
      "title": "Appropriate Timing and Length of Voice News Notifications",
      "addons": {
        "broadcastLink": {
          "duringSessionOnly": false,
          "type": "broadcastLink",
          "url": "https://ohyay.co/viewer.html?wsid=ws_W6kSiqvJ#scene_B_XV0jqJ"
        },
        "doi": {
          "type": "doiLink",
          "url": "https://doi.org/10.1145/3452918.3465488"
        }
      },
      "trackId": 11245,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58626,
        58639
      ],
      "eventIds": [],
      "abstract": "Voice news notifications pushed without a user's explicit request enable the user to consume the news while they are performing various other activities. Thus, the user can keep up with the news naturally on a daily basis. However, the notifications can be intrusive if the timing of delivery is inappropriate. To estimate the appropriate timing, we prototyped a system that detects breakpoints in users' daily routines at home based on IoT sensor data and then sends voice news notifications through a speaker centrally located in a smart home environment. The system was installed in the residence of four participants for field testing over a duration of nearly two weeks. Subsequently, the participants were interviewed regarding their subjective evaluation of the system. The results suggest that (1) voice news notifications at appropriate timings can increase the number of user opportunities in accessing news updates without unduly distracting the user, and (2) the acceptable voice news notification clip length differs depending on the activities subsequent to the breakpoints. We believe that our voice notification system can be applied to enable users to receive news updates in a low-intrusive manner without distracting them from their daily activities.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Japan",
              "state": "",
              "city": "Tokyo",
              "institution": "NHK (Japan Broadcasting Corporation)",
              "dsl": ""
            }
          ],
          "personId": 58477
        },
        {
          "affiliations": [
            {
              "country": "Japan",
              "state": "",
              "city": "Tokyo",
              "institution": "NHK (Japan Broadcasting Corporation)",
              "dsl": ""
            }
          ],
          "personId": 58476
        },
        {
          "affiliations": [
            {
              "country": "Japan",
              "state": "",
              "city": "Tokyo",
              "institution": "NHK (Japan Broadcasting Corporation)",
              "dsl": ""
            }
          ],
          "personId": 58493
        }
      ]
    },
    {
      "id": 58575,
      "typeId": 11823,
      "title": "Liquid Hands: Evoking Emotional States via Augmented Reality Music Visualizations",
      "addons": {
        "broadcastLink": {
          "duringSessionOnly": false,
          "type": "broadcastLink",
          "url": "https://ohyay.co/viewer.html?wsid=ws_W6kSiqvJ#scene_lvFAfZJ_"
        },
        "doi": {
          "type": "doiLink",
          "url": "https://doi.org/10.1145/3452918.3465496"
        }
      },
      "trackId": 11245,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58620,
        58630
      ],
      "eventIds": [],
      "abstract": "Music performances have transformed in unprecedented ways with the advent of digital music. Plenty of music visualizers enhance live performances in various forms, including LED display boards and holographic illustrations. However, the impracticability of live performances due to the CoVID-19 outbreak has led to event organizers adopting alternatives in virtual environments. In this work, we propose Liquid Hands, an Augmented Reality (AR) music visualizer system, wherein three-dimensional particles react to the flow of music, forming a visually aesthetic escapade. With hand-particle interactions, Liquid Hands aims to enrich the music listening experience in one's personal space and bridge the gap between virtual and physical concerts. We intend to explore the emotions our system induces by conducting a pilot study, in which we measure the user's psychological state through Electroencephalography (EEG). We hypothesize that the proposed system will evoke emotions akin to those exhibited in live music performances.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Australia",
              "state": "South Australia",
              "city": "Adelaide",
              "institution": "Brewed Engagement Extended Reality Labs",
              "dsl": ""
            }
          ],
          "personId": 58462
        },
        {
          "affiliations": [
            {
              "country": "Australia",
              "state": "South Australia",
              "city": "Adelaide",
              "institution": "Brewed Engagement Extended Reality Labs",
              "dsl": ""
            }
          ],
          "personId": 58555
        }
      ]
    },
    {
      "id": 58576,
      "typeId": 11823,
      "title": "Smartphone-based Content Annotation for Ground Truth Collection in Affective Computing",
      "addons": {
        "broadcastLink": {
          "duringSessionOnly": false,
          "type": "broadcastLink",
          "url": "https://ohyay.co/viewer.html?wsid=ws_W6kSiqvJ#scene_1MzNR7vm"
        },
        "doi": {
          "type": "doiLink",
          "url": "https://doi.org/10.1145/3452918.3465505"
        }
      },
      "trackId": 11245,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58626,
        58639
      ],
      "eventIds": [],
      "abstract": "This paper presents a real-time emotion-annotation tool using a personal mobile device. To this end, an application based on the Valence-Arousal model was developed, following two different approaches (\"Two-step Sequential Annotation\" and \"One-step MatrixAnnotation\"). The application was tested through, an experiment where users performed annotations with each version of the app and then filled a feedback questionnaire. This questionnaire contained statements used to assess the usability and mental workload. A total of 16 (9 female) participants aged between 21 and 34 years old engaged in this experiment. Overall the results were quite encouraging in both versions, taking into account that this is still a work in progress. The \"Single-step Matrix Annotation\" was considered the preferred version.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Portugal",
              "state": "",
              "city": "Lisbon",
              "institution": "Instituto de Telecomunicações",
              "dsl": ""
            },
            {
              "country": "Portugal",
              "state": "",
              "city": "Lisbon",
              "institution": "Instituto Superior Técnico",
              "dsl": "Department of Bioengineering"
            }
          ],
          "personId": 58490
        },
        {
          "affiliations": [
            {
              "country": "Portugal",
              "state": "",
              "city": "Lisbon",
              "institution": "Instituto de Telecomunicações",
              "dsl": ""
            },
            {
              "country": "Portugal",
              "state": "",
              "city": "Lisbon",
              "institution": "Instituto Superior Técnico",
              "dsl": "Department of Bioengineering"
            }
          ],
          "personId": 58470
        },
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "",
              "city": "London",
              "institution": "BBC R&D",
              "dsl": ""
            }
          ],
          "personId": 58394
        },
        {
          "affiliations": [
            {
              "country": "Portugal",
              "state": "",
              "city": "Lisbon",
              "institution": "Instituto de Telecomunicações",
              "dsl": ""
            },
            {
              "country": "Portugal",
              "state": "",
              "city": "Lisbon",
              "institution": "Instituto Superior Técnico",
              "dsl": "Department of Bioengineering"
            }
          ],
          "personId": 58522
        },
        {
          "affiliations": [
            {
              "country": "Portugal",
              "state": "",
              "city": "Lisbon",
              "institution": "Instituto de Telecomunicações",
              "dsl": ""
            },
            {
              "country": "Portugal",
              "state": "",
              "city": "Lisbon",
              "institution": "Instituto Superior Técnico",
              "dsl": "Department of Bioengineering"
            }
          ],
          "personId": 58508
        }
      ]
    },
    {
      "id": 58577,
      "typeId": 11823,
      "title": "Designing an Educational Virtual Reality Application to Learn Ergonomics in a Work Place",
      "addons": {
        "broadcastLink": {
          "duringSessionOnly": false,
          "type": "broadcastLink",
          "url": "https://ohyay.co/viewer.html?wsid=ws_W6kSiqvJ#scene_pidXD67U"
        },
        "doi": {
          "type": "doiLink",
          "url": "https://doi.org/10.1145/3452918.3465504"
        }
      },
      "trackId": 11245,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58619,
        58627
      ],
      "eventIds": [],
      "abstract": "In this paper we describe the process of designing an educational Virtual Reality (VR) application for university medical students to learn how to set up a work place ergonomically correct. We focus on commercially available hardware and a commercial game engine. This was a collaboration between medical experts and VR experts to achieve the ideal results. This use case builds on research of 3D user interfaces (UI) to create an UI system that novice VR-users can use intuitively. Next steps include a user study to compare immersive and non-immersive versions, as well as learn effects in VR.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Garching near München",
              "institution": "Leibniz Supercomputing Centre, Bavarian Academy of Sciences and Humanities",
              "dsl": ""
            }
          ],
          "personId": 58525
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Munich",
              "institution": "Institute and Outpatient Clinic for Occupational, Social and Environmental Medicine, LMU University Hospital Munich",
              "dsl": ""
            }
          ],
          "personId": 58520
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Munich",
              "institution": "Institute and Outpatient Clinic for Occupational, Social and Environmental Medicine, LMU University Hospital Munich",
              "dsl": ""
            }
          ],
          "personId": 58562
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Munich",
              "institution": "Institute and Outpatient Clinic for Occupational, Social and Environmental Medicine, LMU Hospital",
              "dsl": ""
            }
          ],
          "personId": 58567
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Munich",
              "institution": "Institute and Outpatient Clinic for Occupational, Social and Environmental Medicine, LMU University Hospital Munich",
              "dsl": ""
            }
          ],
          "personId": 58552
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Garching near Munich",
              "institution": "Bavarian Academy of Sciences and Humanities",
              "dsl": "Leibniz Supercomputing Centre"
            }
          ],
          "personId": 58511
        }
      ]
    },
    {
      "id": 58578,
      "typeId": 11823,
      "title": "Accessibility of Interactive Television and Media Experiences: Users with Disabilities Have Been Little Voiced at IMX and TVX",
      "addons": {
        "broadcastLink": {
          "duringSessionOnly": false,
          "type": "broadcastLink",
          "url": "https://ohyay.co/viewer.html?wsid=ws_W6kSiqvJ#scene_4vEaE_fr"
        },
        "doi": {
          "type": "doiLink",
          "url": "https://doi.org/10.1145/3452918.3465485"
        }
      },
      "trackId": 11245,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58616,
        58628
      ],
      "eventIds": [],
      "abstract": "We conduct an overview of the landscape of scientific research falling at the intersection of television, immersive media, and accessible interactive technology. To this end, we consider for our analysis a number of 449 papers published at IMX, TVX, and EuroITV between 2003 and 2020, of which we report a total of 19 papers (4.23%) addressing users with disabilities and only 9 (2.00%) actually involving people with disabilities as participants in user studies. We analyze the topics and research contributions of these papers, and draw conclusions about the extent to which accessibility research has been present in the IMX/TVX community.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Romania",
              "state": "",
              "city": "Suceava",
              "institution": "Ștefan cel Mare University of Suceava",
              "dsl": "MintViz Lab, MANSiD Research Center"
            }
          ],
          "personId": 58429
        }
      ]
    },
    {
      "id": 58579,
      "typeId": 11823,
      "title": "Hybrid Workflow Process for Home Based Movement Capture",
      "addons": {
        "broadcastLink": {
          "duringSessionOnly": false,
          "type": "broadcastLink",
          "url": "https://ohyay.co/viewer.html?wsid=ws_W6kSiqvJ#scene_fu6eclUo"
        },
        "doi": {
          "type": "doiLink",
          "url": "https://doi.org/10.1145/3452918.3465499"
        }
      },
      "trackId": 11245,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58617,
        58638
      ],
      "eventIds": [],
      "abstract": "Telehealth rehabilitation systems aimed at providing physical and occupational therapy in the home face considerable challenges in terms of clinician and therapist buy-in, system and training costs, and patient and caregiver acceptance. Understanding the optimal workflow process to support practitioners in delivering quality care in partnership with assistive technologies is significant. We describe the iterative co-development of our hybrid physical/digital workflow process for assisting therapists with the setup and calibration of a computer vision based system for remote rehabilitation. Through an interdisciplinary collaboration, we present promising preliminary concepts for streamlining the translation of research outcomes into everyday healthcare experiences. ",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Virginia",
              "city": "Blacksburg",
              "institution": "Virginia Tech",
              "dsl": ""
            }
          ],
          "personId": 58504
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Virginia",
              "city": "Blacksburg",
              "institution": "Virginia Tech",
              "dsl": ""
            }
          ],
          "personId": 58518
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Virginia",
              "city": "Blacksburg",
              "institution": "Virginia Polytechnic Institute & State University (Virginia Tech) (SSO)",
              "dsl": ""
            }
          ],
          "personId": 58484
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Virginia",
              "city": "Blacksburg",
              "institution": "Virginia Tech",
              "dsl": "Department of Computer Science"
            }
          ],
          "personId": 58479
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Virginia",
              "city": "Blacksburg",
              "institution": "Virginia Tech",
              "dsl": ""
            }
          ],
          "personId": 58458
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Virginia",
              "city": "Radford",
              "institution": "Radford University",
              "dsl": ""
            }
          ],
          "personId": 58543
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Virginia",
              "city": "Roanoke",
              "institution": "Carillion Clinic",
              "dsl": ""
            }
          ],
          "personId": 58497
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Virginia",
              "city": "Blacksburg",
              "institution": "Virginia Tech",
              "dsl": ""
            }
          ],
          "personId": 58463
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Virginia",
              "city": "Blacksburg",
              "institution": "Virginia Tech",
              "dsl": ""
            }
          ],
          "personId": 58533
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Virginia",
              "city": "Blacksburg",
              "institution": "Virginia Tech",
              "dsl": ""
            }
          ],
          "personId": 58469
        }
      ]
    },
    {
      "id": 58580,
      "typeId": 11823,
      "title": "Taking That Perfect Aerial Photo: A Synopsis of Interactions for Drone-based Aerial Photography and Video",
      "addons": {
        "broadcastLink": {
          "duringSessionOnly": false,
          "type": "broadcastLink",
          "url": "https://ohyay.co/viewer.html?wsid=ws_W6kSiqvJ#scene_-A0WGuIY"
        },
        "doi": {
          "type": "doiLink",
          "url": "https://doi.org/10.1145/3452918.3465484"
        }
      },
      "trackId": 11245,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58618,
        58629
      ],
      "eventIds": [],
      "abstract": "Personal drones are more and more present in our lives and acting as \"flying cameras\" is one of their most prominent applications. In this work, we conduct a synopsis of the scientific literature on human-drone interaction to identify system functions and corresponding commands for controlling drone-based aerial photography and video, from which we compile a dictionary of interactions. We also discuss opportunities for more research at the intersection of drone computing, augmented vision, and personal photography.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Romania",
              "state": "",
              "city": "Suceava",
              "institution": "Ștefan cel Mare University of Suceava",
              "dsl": "MintViz Lab, MANSiD Center"
            }
          ],
          "personId": 58499
        },
        {
          "affiliations": [
            {
              "country": "Romania",
              "state": "",
              "city": "Suceava",
              "institution": "Ștefan cel Mare University of Suceava",
              "dsl": "MintViz Lab, MANSiD Center"
            }
          ],
          "personId": 58429
        },
        {
          "affiliations": [
            {
              "country": "Belgium",
              "state": "",
              "city": "Louvain-la-Neuve",
              "institution": "Université catholique de Louvain",
              "dsl": "Louvain School of Management/LiLab"
            }
          ],
          "personId": 58492
        }
      ]
    },
    {
      "id": 58581,
      "typeId": 11823,
      "title": "Personal Viewing History Collection Method for Video Streaming Services in User-Centric Model",
      "addons": {
        "broadcastLink": {
          "duringSessionOnly": false,
          "type": "broadcastLink",
          "url": "https://ohyay.co/viewer.html?wsid=ws_W6kSiqvJ#scene__WENWmPQ"
        },
        "doi": {
          "type": "doiLink",
          "url": "https://doi.org/10.1145/3452918.3465492"
        }
      },
      "trackId": 11245,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58618,
        58629
      ],
      "eventIds": [],
      "abstract": "The personal viewing history of broadcast and internet content can be used to improve the quality of online services for the user; consequently, enhancing a person’s experience in their daily life. This study proposes a collection method of the personal viewing history of online video streaming services in a user-centric model, where the user owns and controls their data. By obtaining event data from a video element of HTML5 in a video streaming player on a web browser, users can store their viewing history separately from the service provider’s system. Because this method employs standardized web technologies, it can be applied to multiple viewing devices and player implementations. Additionally, a prototype of a video streaming player extension is developed. Implementation of the proposed method and verification tests are conducted on the prototype. The results obtained suggest that the proposed method is applicable to existing HTML5 compliant web browsers.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Japan",
              "state": "",
              "city": "Tokyo",
              "institution": "NHK (Japan Broadcasting Corporation)",
              "dsl": ""
            }
          ],
          "personId": 58557
        },
        {
          "affiliations": [
            {
              "country": "Japan",
              "state": "",
              "city": "Tokyo",
              "institution": "NHK (Japan Broadcasting Corporation)",
              "dsl": ""
            }
          ],
          "personId": 58476
        },
        {
          "affiliations": [
            {
              "country": "Japan",
              "state": "",
              "city": "Tokyo",
              "institution": "NHK (Japan Broadcasting Corporation)",
              "dsl": ""
            }
          ],
          "personId": 58493
        }
      ]
    },
    {
      "id": 58582,
      "typeId": 11821,
      "title": "Building A ‘Sicko’ AI ",
      "addons": {
        "broadcastLink": {
          "duringSessionOnly": false,
          "type": "broadcastLink",
          "url": "https://ohyay.co/viewer.html?wsid=ws_W6kSiqvJ#scene_7BnViVml"
        },
        "doi": {
          "type": "doiLink",
          "url": "https://doi.org/10.1145/3452918.3467814"
        },
        "Presentation Video": {
          "duration": 1,
          "title": "Building A ‘Sicko’ AI",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=gtZeRVz8uVI"
        }
      },
      "trackId": 11242,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58626,
        58639
      ],
      "eventIds": [],
      "abstract": "Using the GPT-2 algorithm developed by OpenAI in February 2019, a skewered or ‘sicko’ AI character was created as a live time entity running in the Google cloud. The algorithm allows imitations of human dialogue that produce fake and often realistic interactions emanating from computer cloud-based agents. The character was created as one of two characters in the emotionally intelligent artificial intelligence brainwave opera AIBO (Artificial Intelligent Brainwave Opera). The spoken word opera rhetorically inquired “Can an AI be fascist?” and “Can an AI have epigenetic or inherited traumatic memory?” through the interplay of human and non-human characters. This paper discusses certain aspects involved in creating the GPT-2 cloud-based character AIBO. ",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Latvia",
              "state": "",
              "city": "Riga",
              "institution": "RISEBA University",
              "dsl": "Creative Media"
            },
            {
              "country": "United States",
              "state": "Massachusetts",
              "city": "Cambridge",
              "institution": "MIT",
              "dsl": "Open Documentary Lab"
            }
          ],
          "personId": 58473
        }
      ]
    },
    {
      "id": 58583,
      "typeId": 11821,
      "title": "Content Wizard: demo of a trans-vector digital video publication tool",
      "addons": {
        "broadcastLink": {
          "duringSessionOnly": false,
          "type": "broadcastLink",
          "url": "https://ohyay.co/viewer.html?wsid=ws_W6kSiqvJ#scene_Pi-I3sD8"
        },
        "doi": {
          "type": "doiLink",
          "url": "https://doi.org/10.1145/3452918.3468083"
        },
        "Presentation Video": {
          "duration": 1,
          "title": "Content Wizard: demo of a trans-vector digital video publication tool",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=jDoKA3VNR28"
        }
      },
      "trackId": 11242,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58618,
        58629
      ],
      "eventIds": [],
      "abstract": "In order to optimise the distribution of video assets online, media organizations need tailor their offerings for specific digital channels and better understand the interests of their audiences at particular points in time, which are often influenced by contemporary new stories and trends on social media. For this purpose, the research project ReTV has developed a Web-based tool termed 'Content Wizard' which demonstrates an end-to-end, semi-automated workflow for video content creation, adaptation and distribution across digital channels. Digital assets can be selected based on predicted future trending topics, re-purposed according to the different digital channels they will be published upon and scheduled for the optimal future publication date. The result is an innovative video publication workflow that meets the marketing needs of media organisations in this age of transient online media spread across multiple channels. ",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Austria",
              "state": "",
              "city": "Vienna",
              "institution": "MODUL Technology GmbH",
              "dsl": ""
            }
          ],
          "personId": 58486
        },
        {
          "affiliations": [
            {
              "country": "Greece",
              "state": "",
              "city": "Thessaloniki",
              "institution": "CERTH-ITI",
              "dsl": ""
            }
          ],
          "personId": 58460
        },
        {
          "affiliations": [
            {
              "country": "Greece",
              "state": "",
              "city": "Thessaloniki ",
              "institution": "CERTH-ITI",
              "dsl": ""
            }
          ],
          "personId": 58485
        },
        {
          "affiliations": [
            {
              "country": "Greece",
              "state": "",
              "city": "Thessaloniki",
              "institution": "CERTH-ITI",
              "dsl": ""
            }
          ],
          "personId": 58531
        },
        {
          "affiliations": [
            {
              "country": "Greece",
              "state": "",
              "city": "Thessaloniki",
              "institution": "Centre for Research and Technology Hellas (CERTH)",
              "dsl": "Information Technologies Institute (ITI)"
            }
          ],
          "personId": 58509
        },
        {
          "affiliations": [
            {
              "country": "Switzerland",
              "state": "",
              "city": "Zürich",
              "institution": "Genistat AG",
              "dsl": ""
            }
          ],
          "personId": 58534
        },
        {
          "affiliations": [
            {
              "country": "Netherlands",
              "state": "",
              "city": "Hilversum",
              "institution": "Netherlands Institute for Sound and Vision",
              "dsl": ""
            }
          ],
          "personId": 58506
        }
      ]
    },
    {
      "id": 58584,
      "typeId": 11821,
      "title": "Towards XR Communication for Visiting Elderly at Nursing Homes",
      "addons": {
        "broadcastLink": {
          "duringSessionOnly": false,
          "type": "broadcastLink",
          "url": "https://ohyay.co/viewer.html?wsid=ws_W6kSiqvJ#scene_LkrioQCn"
        },
        "doi": {
          "type": "doiLink",
          "url": "https://doi.org/10.1145/3452918.3467815"
        },
        "Presentation Video": {
          "duration": 1,
          "title": "Towards XR Communication for Visiting Elderly at Nursing Homes",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=pZoaP2PDYy4"
        }
      },
      "trackId": 11242,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58620,
        58630
      ],
      "eventIds": [],
      "abstract": "Due to the current pandemic, the elderly in care homes are greatly affected by the lack of contact with their families, resulting in various mental conditions (e.g., depression, feelings of loneliness) and deterioration of mental health for dementia patients. In response, residents and family members increasingly resorted to mediated communication to maintain social contact. To facilitate high-quality mediated social contact between residents in nursing homes and remote family members, we developed an Augmented Reality (AR)-based communication tool. The proposed demonstrator improved this situation by providing a working communication tool that enables the elderly to feel being together with their family by means of AR techniques. A complete end-to-end-chain architecture is defined, where the aspects of capture, transmission, and rendering are thoroughly investigated to fit the purpose of the use case. Based on an extensive user study comprising user experience (UX) and quality of service (QoS) measurements, each module is presented with the improvements made and the resulting higher quality AR communication platform.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Netherlands",
              "state": "",
              "city": "The Hague",
              "institution": "TNO",
              "dsl": ""
            }
          ],
          "personId": 58542
        },
        {
          "affiliations": [
            {
              "country": "Netherlands",
              "state": "",
              "city": "The Hague",
              "institution": "TNO",
              "dsl": ""
            }
          ],
          "personId": 58489
        },
        {
          "affiliations": [
            {
              "country": "Netherlands",
              "state": "",
              "city": "The Hague",
              "institution": "TNO",
              "dsl": ""
            }
          ],
          "personId": 58530
        },
        {
          "affiliations": [
            {
              "country": "Netherlands",
              "state": "",
              "city": "The Hague",
              "institution": "TNO",
              "dsl": ""
            }
          ],
          "personId": 58524
        }
      ]
    },
    {
      "id": 58585,
      "typeId": 11823,
      "title": "Graphic Novel Subtitles: Requirement Elicitation and System Implementation",
      "addons": {
        "broadcastLink": {
          "duringSessionOnly": false,
          "type": "broadcastLink",
          "url": "https://ohyay.co/viewer.html?wsid=ws_W6kSiqvJ#scene_A9z7Sdng"
        },
        "doi": {
          "type": "doiLink",
          "url": "https://doi.org/10.1145/3452918.3465489"
        }
      },
      "trackId": 11245,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58616,
        58628
      ],
      "eventIds": [],
      "abstract": "Consuming subtitled video content relies on a viewers ability to match up and understand a number of visual inputs simultaneously. This can create challenges in immersion due to the overall readability of subtitles and the speed at which they are presented. In this paper we introduce Graphic Novel Subtitles as an alternative media consumption method that is based on combining video keyframes with subtitle text to create a comic-type experience. We carry out a requirement elicitation survey with 34 participants in order to explore this concept in more detail and identify key features that we present as system requirements.We then introduce a system that can automatically generate a graphic novel from video and subtitle files, and discuss our future evaluation plans.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "",
              "city": "Dundee",
              "institution": "University of Dundee",
              "dsl": ""
            }
          ],
          "personId": 58491
        },
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "",
              "city": "Dundee",
              "institution": "University of Dundee",
              "dsl": ""
            }
          ],
          "personId": 58512
        }
      ]
    },
    {
      "id": 58586,
      "typeId": 11823,
      "title": "Understanding Rules in Live Streaming Micro Communities on Twitch",
      "addons": {
        "broadcastLink": {
          "duringSessionOnly": false,
          "type": "broadcastLink",
          "url": "https://ohyay.co/viewer.html?wsid=ws_W6kSiqvJ#scene_2Cpst3sN"
        },
        "doi": {
          "type": "doiLink",
          "url": "https://doi.org/10.1145/3452918.3465491"
        }
      },
      "trackId": 11245,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58618,
        58629
      ],
      "eventIds": [],
      "abstract": "Rules and norms are critical to community governance. Live streaming communities like Twitch consist of thousands of micro-communities called channels. We conducted two studies to understand the micro-community rules. Study one suggests that Twitch users perceive that both rules transparency and communication frequency matter to channel vibe and frequency of harassment.  Study two finds that the most popular channels have no channel or chat rules; among these having rules, rules encouraged by streamers are prominent. We explain why this may happen and how this contributes to community moderation and future research.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New Jersey",
              "city": "Newark",
              "institution": "New Jersey Institute of Technology",
              "dsl": ""
            }
          ],
          "personId": 58393
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New Jersey",
              "city": "Newark",
              "institution": "New Jersey Institute of Technology",
              "dsl": ""
            }
          ],
          "personId": 58482
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New Jersey",
              "city": "Newark ",
              "institution": "New Jersey Institute of Technology",
              "dsl": ""
            }
          ],
          "personId": 58391
        }
      ]
    },
    {
      "id": 58587,
      "typeId": 11821,
      "title": "Exploring Affect Recognition in a Virtual Reality Environment",
      "addons": {
        "broadcastLink": {
          "duringSessionOnly": false,
          "type": "broadcastLink",
          "url": "https://ohyay.co/viewer.html?wsid=ws_W6kSiqvJ#scene_sivNGn4O"
        },
        "doi": {
          "type": "doiLink",
          "url": "https://doi.org/10.1145/3452918.3467671"
        },
        "Presentation Video": {
          "duration": 1,
          "title": "Exploring Affect Recognition in a Virtual Reality Environment",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=PUsvHyMz1-s"
        }
      },
      "trackId": 11242,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58620,
        58630
      ],
      "eventIds": [],
      "abstract": "The current global pandemic has resulted in increased social isolation for many. To combat worsening mental states including increased stress and boredom resulting from loneliness, we present a virtual environment designed to simulate social interaction and improve mood. The virtual environment takes the form of a restaurant in which users hold a conversation with a virtual patron. Built in the Unity3D engine and experienced in an Oculus Quest virtual reality headset, our program communicates with an off-the-shelf electroencephalogram (EEG) headset to gather user affective states. Affective states trigger changes in lighting, sound, and conversation topics in real-time based on the user’s emotions. The changes made to the environment reflect relevant psychology research to potentially improve the user’s mood.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Arizona",
              "city": "Tempe",
              "institution": "Arizona State University",
              "dsl": ""
            }
          ],
          "personId": 58465
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Arizona",
              "city": "Tempe",
              "institution": "Arizona State University",
              "dsl": ""
            }
          ],
          "personId": 58494
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Arizona",
              "city": "Chandler",
              "institution": "Arizona State University",
              "dsl": ""
            }
          ],
          "personId": 58521
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Arizona",
              "city": "Phoenix ",
              "institution": "Arizona State University",
              "dsl": ""
            }
          ],
          "personId": 58461
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Arizona",
              "city": "Tempe",
              "institution": "Arizona State University",
              "dsl": "School of Computing, Informatics, and Decision Systems Engineering"
            }
          ],
          "personId": 58516
        }
      ]
    },
    {
      "id": 58588,
      "typeId": 11823,
      "title": "Interactive Characters for Virtual Reality Stories",
      "addons": {
        "broadcastLink": {
          "duringSessionOnly": false,
          "type": "broadcastLink",
          "url": "https://ohyay.co/viewer.html?wsid=ws_W6kSiqvJ#scene_ySgMMDcA"
        },
        "doi": {
          "type": "doiLink",
          "url": "https://doi.org/10.1145/3452918.3465494"
        }
      },
      "trackId": 11245,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58620,
        58630
      ],
      "eventIds": [],
      "abstract": " Virtual Reality (VR) content production is now a flourishing industry. The specifics of VR, as opposed to videogames or movies, allow for a content format where users experience, at the same time, the narrative richness characteristic of movies and theatre plays with interactive engagement. To create such a content format some technical challenges still need to be solved, the main being the need for a new generation of animation engines that can deliver interactive characters appropriate for narrative-focused VR interactive content. We review the main assumptions of this approach and recent progress in interactive character animation techniques that seems  promising to realise this goal.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Switzerland",
              "state": "",
              "city": "Geneva",
              "institution": "Artanim Foundation",
              "dsl": ""
            }
          ],
          "personId": 58488
        },
        {
          "affiliations": [
            {
              "country": "Switzerland",
              "state": "",
              "city": "Geneva",
              "institution": "Artanim Foundation",
              "dsl": ""
            }
          ],
          "personId": 58564
        }
      ]
    },
    {
      "id": 58589,
      "typeId": 11821,
      "title": "Using Video Games to Help Visualize and Teach Microbiological Concepts",
      "addons": {
        "broadcastLink": {
          "duringSessionOnly": false,
          "type": "broadcastLink",
          "url": "https://ohyay.co/viewer.html?wsid=ws_W6kSiqvJ#scene_2YS_F2PV"
        },
        "doi": {
          "type": "doiLink",
          "url": "https://doi.org/10.1145/3452918.3468027"
        },
        "Presentation Video": {
          "duration": 1,
          "title": "Using Video Games to Help Visualize and Teach Microbiological Concepts",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=2AiCEQ0kpkM"
        }
      },
      "trackId": 11242,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58619,
        58627
      ],
      "eventIds": [],
      "abstract": "Microbiology is the study of the invisible world that is ever present in and around us. Oftentimes, it can be difficult to communicate and visualize microbiological concepts to students due to many limitations. Static images in textbooks and simple representations of microscopic organisms and processes attempt to combat this, but it can be restricting. To address this, we seek to understand if interactive learning biology video games can lead to better concept retention and comprehension than traditional assignments, such as a reading article with static images. To analyze this, we use Infection Defense, a free, appealing, easily accessible video game about the immune system, a highly relevant and important microbiological concept. Concurrently, we also seek to analyze participant interest before and after playing the game, compared to standard methods. It is reasonable that the use of a video game to learn can lead to enhanced comprehension and engagement in scientific concepts.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Michigan",
              "city": "East Lansing",
              "institution": "Michigan State University",
              "dsl": "Department of Microbiology & Molecular Genetics"
            }
          ],
          "personId": 58532
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Michigan",
              "city": "East Lansing",
              "institution": "Michigan State University",
              "dsl": "Department of Media & Information"
            }
          ],
          "personId": 58507
        }
      ]
    },
    {
      "id": 58590,
      "typeId": 11821,
      "title": "Augmented Reality Anatomy Visualization for Surgery Assistance with HoloLens",
      "addons": {
        "broadcastLink": {
          "duringSessionOnly": false,
          "type": "broadcastLink",
          "url": "https://ohyay.co/viewer.html?wsid=ws_W6kSiqvJ#scene_cbKf_cqH"
        },
        "doi": {
          "type": "doiLink",
          "url": "https://doi.org/10.1145/3452918.3468005"
        },
        "Presentation Video": {
          "duration": 1,
          "title": "Augmented Reality Anatomy Visualization for Surgery Assistance with HoloLens",
          "type": "video",
          "url": "https://www.youtube.com/watch?v=50wFZ1Htibc"
        }
      },
      "trackId": 11242,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58620,
        58630
      ],
      "eventIds": [],
      "abstract": "Immediate care for trauma wounded patients in austere or remote settings makes medical knowledge, skills, and efficiency of the on-duty medical professional paramount. For wounds that extend deep into internal anatomy, proper visualization of internal anatomy can enable more efficient and effective evaluation when presented to medical providers positioned close to the point of injury (POI). In this paper, a conceptual Augmented Reality (AR) surgical tool is presented to provide visualization of internal human anatomy, superimposed on the view of a patient, to assist medical providers for immediate casualty care. This AR surgical tool can play a role in 3D surgery or treatment planning as a navigational aid in preparing medical interventions and enhancing surgery or treatment procedures by displaying otherwise obscured anatomy and nearby vessels. Critical software and hardware components are integrated to construct a prototype AR system for the portable AR surgical visualization tool. The system uses a Microsoft HoloLens 1 and an Azure Kinect camera for simultaneous body-tracking and anatomy overlay to demonstrate the overall concept. Future extension of this work will aim to create a more accurate and compact prototype system that utilizes HoloLens 2 with an embedded Kinect camera for laboratory and field tests of its use in surgery assistance. Such an AR tool can also serve as a training tool for medical caregivers, applied with a human subject or a medical manikin.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New Jersey",
              "city": "Newark",
              "institution": "NJIT",
              "dsl": "Informatics"
            }
          ],
          "personId": 58459
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New Jersey",
              "city": "Newark",
              "institution": "NJIT",
              "dsl": "Informatics"
            }
          ],
          "personId": 58528
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New Jersey",
              "city": "Newwark",
              "institution": "NJIT",
              "dsl": "Biomedical Engineering"
            }
          ],
          "personId": 58529
        }
      ]
    },
    {
      "id": 58591,
      "typeId": 11823,
      "title": "Conversational User Interfaces As Assistive interlocutors For Young Children's Bilingual Language Acquisition",
      "addons": {
        "broadcastLink": {
          "duringSessionOnly": false,
          "type": "broadcastLink",
          "url": "https://ohyay.co/viewer.html?wsid=ws_W6kSiqvJ#scene_ZxE3BcZP"
        },
        "doi": {
          "type": "doiLink",
          "url": "https://doi.org/10.1145/3452918.3465498"
        }
      },
      "trackId": 11245,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58616,
        58628
      ],
      "eventIds": [],
      "abstract": "Children in international and cross-cultural families in and outside of the US often learn and speak more than one language. Challenges can arise for these children in terms of communicating with other children and being able to fully participate in school and society using the primary country language, in developing relationships with distant relatives in other languages, and with the lack of opportunities for practising additional languages within a small community of speakers. Recent research shows that some parents use screen media content to acquaint their children with their parent's native language, and to also help them become proficient in the language of communication in the country that they reside in. We leverage the qualities of screen media in aiding children with language learning, and try to translate those qualities into the design of a CUI for children to explore the potential of designing conversational user interfaces which can double as assistive language aids. By reviewing the relevant literature about the role of screen media content in young children’s language learning, and interviewing a subset of parents raising multilingual children, we present a preliminary list of objectives to guide the design of conversational user interfaces for young children's bilingual language acquisition.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Virginia",
              "city": "Blacksburg",
              "institution": "Virginia Tech",
              "dsl": "Department of Computer Science"
            }
          ],
          "personId": 58568
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Virginia",
              "city": "Blacksburg",
              "institution": "Virginia Tech",
              "dsl": "Computer Science"
            }
          ],
          "personId": 58505
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Virginia",
              "city": "Blacksburg",
              "institution": "Virginia Tech",
              "dsl": "Computer Science"
            }
          ],
          "personId": 58519
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Virginia",
              "city": "Blacksburg",
              "institution": "Virginia Tech",
              "dsl": "Department of Computer Science"
            }
          ],
          "personId": 58479
        }
      ]
    },
    {
      "id": 58592,
      "typeId": 11823,
      "title": "Going Beyond Second Screens: Applications for the Multi-display Intelligent Living Room",
      "addons": {
        "broadcastLink": {
          "duringSessionOnly": false,
          "type": "broadcastLink",
          "url": "https://ohyay.co/viewer.html?wsid=ws_W6kSiqvJ#scene_geXaxJja"
        },
        "doi": {
          "type": "doiLink",
          "url": "https://doi.org/10.1145/3452918.3465486"
        }
      },
      "trackId": 11245,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58626,
        58639
      ],
      "eventIds": [],
      "abstract": "This work aims to investigate how the amenities offered by Intelligent Environments can be used to shape new types of useful, exciting and fulfilling experiences while watching sports or movies. Towards this direction, two ambient media players were developed aspiring to offer live access to secondary information via the available displays of an Intelligent Living Room, and to appropriately exploit the technological equipment so as to support natural interaction. Expert-based evaluation experiments revealed some factors that can influence the overall experience significantly, without hindering the viewers’ immersion to the main media.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Greece",
              "state": "",
              "city": "Heraklion, Crete",
              "institution": "Institute of Computer Science, Foundation for Research and Technology - Hellas (FORTH)",
              "dsl": ""
            }
          ],
          "personId": 58487
        },
        {
          "affiliations": [
            {
              "country": "Greece",
              "state": "",
              "city": "Heraklion, Crete",
              "institution": "Institute of Computer Science, Foundation for Research and Technology – Hellas (FORTH)",
              "dsl": ""
            }
          ],
          "personId": 58502
        },
        {
          "affiliations": [
            {
              "country": "Greece",
              "state": "",
              "city": "Heraklion, Crete",
              "institution": "Institute of Computer Science, Foundation for Research and Technology - Hellas (FORTH)",
              "dsl": ""
            }
          ],
          "personId": 58514
        },
        {
          "affiliations": [
            {
              "country": "Greece",
              "state": "",
              "city": "Heraklion, Crete",
              "institution": "Institute of Computer Science, Foundation for Research and Technology - Hellas (FORTH)",
              "dsl": ""
            }
          ],
          "personId": 58472
        },
        {
          "affiliations": [
            {
              "country": "Greece",
              "state": "",
              "city": "Heraklion, Crete",
              "institution": "Institute of Computer Science, Foundation for Research and Technology - Hellas (FORTH)",
              "dsl": ""
            }
          ],
          "personId": 58495
        },
        {
          "affiliations": [
            {
              "country": "Greece",
              "state": "",
              "city": "Heraklion, Crete",
              "institution": "Institute of Computer Science, Foundation for Research and Technology - Hellas (FORTH)",
              "dsl": ""
            },
            {
              "country": "Greece",
              "state": "",
              "city": "Heraklion, Crete",
              "institution": "University of Crete",
              "dsl": "Computer Science Departement"
            }
          ],
          "personId": 58556
        }
      ]
    },
    {
      "id": 58593,
      "typeId": 11823,
      "title": "MixMyVisit – Enhancing the Visitor Experience Through Automatic Generated Videos",
      "addons": {
        "broadcastLink": {
          "duringSessionOnly": false,
          "type": "broadcastLink",
          "url": "https://ohyay.co/viewer.html?wsid=ws_W6kSiqvJ#scene_6NkQFzDZ"
        },
        "doi": {
          "type": "doiLink",
          "url": "https://doi.org/10.1145/3452918.3465500"
        }
      },
      "trackId": 11245,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58617,
        58638
      ],
      "eventIds": [],
      "abstract": "Cultural places like museums have been looking for means to enrich the visitor experience during and after the visit. This paper reports on a proposal to contribute to this field presenting a system that automatically creates personalized memory videos of the visit, by identifying the paths of visitors in cultural spaces. The MixMyVisit project combines low-cost devices with NFC technology, allowing a simple way for identifying visitors’ paths, a bot for interaction with the visitor through a textual chat implemented in a social network, the ability for the visitor to share its own captured contents (photos or videos), a server-side video engine supported by ffmpeg components and an online responsive video editor. The features and main technical developments are presented on the paper. The results of an evaluation carried by two experts provide positive insights towards such a system and the team expects to get a final validation in a field trial to be carried out. ",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Portugal",
              "state": "Aveiro",
              "city": "Aveiro",
              "institution": "University of Aveiro",
              "dsl": "Digimedia"
            }
          ],
          "personId": 58565
        },
        {
          "affiliations": [
            {
              "country": "Portugal",
              "state": "",
              "city": "Aveiro",
              "institution": "University of Aveiro",
              "dsl": "Digimedia"
            }
          ],
          "personId": 58526
        },
        {
          "affiliations": [
            {
              "country": "Portugal",
              "state": "",
              "city": "Aveiro",
              "institution": "University of Aveiro",
              "dsl": "Digimedia"
            }
          ],
          "personId": 58510
        },
        {
          "affiliations": [
            {
              "country": "Portugal",
              "state": "",
              "city": "Aveiro",
              "institution": "University of Aveiro",
              "dsl": "Digimedia"
            }
          ],
          "personId": 58496
        }
      ]
    },
    {
      "id": 58594,
      "typeId": 11823,
      "title": "Towards User Generated AR Experiences",
      "addons": {
        "broadcastLink": {
          "duringSessionOnly": false,
          "type": "broadcastLink",
          "url": "https://ohyay.co/viewer.html?wsid=ws_W6kSiqvJ#scene_qqWoE0Jf"
        },
        "doi": {
          "type": "doiLink",
          "url": "https://doi.org/10.1145/3452918.3465495"
        }
      },
      "trackId": 11245,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58620,
        58630
      ],
      "eventIds": [],
      "abstract": "Communication with a customer or future user during the planning and design phase is crucial in applications such as interior design and furniture retailing. Augmented Reality (AR) has the potential to make these communication processes highly effective and provide a better experience for the customer. Current AR authoring solutions are quite complex and require manually creating scenes or rely on objects prepared with even more complex applications such as CAD tools. However, both design experts and their customers often lack the IT skills to use these tools. In addition, many practical cases involve changing reality rather than just adding to it, thus requiring the use of Diminished Reality (DR) technologies. This paper presents a comprehensive analysis of the requirements of both professionals and consumers (gathered using user surveys and individual interviews) for a lightweight and automated authoring process of AR and DR experiences, deriving a set of requirements that can be aligned with state of the art technologies and identifying a number of challenges for AR research.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Sweden",
              "state": "",
              "city": "Stockholm",
              "institution": "Usability Partners",
              "dsl": ""
            }
          ],
          "personId": 58537
        },
        {
          "affiliations": [
            {
              "country": "Greece",
              "state": "",
              "city": "Thessaloniki",
              "institution": "Centre for Research and Innovation Hellas",
              "dsl": "Information Technologies Institute"
            }
          ],
          "personId": 58547
        },
        {
          "affiliations": [
            {
              "country": "Greece",
              "state": "",
              "city": "Thessaloniki",
              "institution": "Centre for Research and Technology Hellas",
              "dsl": "Information Technologies Institute"
            }
          ],
          "personId": 58563
        },
        {
          "affiliations": [
            {
              "country": "Greece",
              "state": "",
              "city": "Thessaloniki",
              "institution": "Information Technologies Institute / Centre of Research & Technology - Hellas",
              "dsl": ""
            }
          ],
          "personId": 58513
        },
        {
          "affiliations": [
            {
              "country": "Greece",
              "state": "",
              "city": "Thessaloniki",
              "institution": "Centre for Research and Technology Hellas",
              "dsl": "Information Technologies Institute "
            }
          ],
          "personId": 58503
        },
        {
          "affiliations": [
            {
              "country": "Austria",
              "state": "",
              "city": "Graz",
              "institution": "JOANNEUM RESEARCH",
              "dsl": ""
            }
          ],
          "personId": 58546
        }
      ]
    },
    {
      "id": 58595,
      "typeId": 11823,
      "title": "Towards Immersive and Social Audience Experience in Remote VR Opera",
      "addons": {
        "broadcastLink": {
          "duringSessionOnly": false,
          "type": "broadcastLink",
          "url": "https://ohyay.co/viewer.html?wsid=ws_W6kSiqvJ#scene_oY2KkuXJ"
        },
        "doi": {
          "type": "doiLink",
          "url": "https://doi.org/10.1145/3452918.3465490"
        }
      },
      "trackId": 11245,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58620,
        58630
      ],
      "eventIds": [],
      "abstract": "Opera is a historic art that struggles to be approachable to modern audiences. In partnership with the Irish National Opera (INO), this work considers how VR may be used to develop a new form of immersive opera. To this end, we ran three open-ended focus groups to consider how creative, sensory, and social VR technologies may be employed in digital opera. Our findings assert the importance of creating an immersive experience by safely giving audiences agency to interact, to democratize personal and social experiences, and to consider different ways of representing their bodies, their social rituals, and the virtual social space. Using these findings, we envision a new form of VR opera that couples physical traditions with digital affordances.\r\n",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Netherlands",
              "state": "Netherlands",
              "city": "Amsterdam",
              "institution": "CWI ",
              "dsl": "DIS "
            }
          ],
          "personId": 58551
        },
        {
          "affiliations": [
            {
              "country": "Ireland",
              "state": "",
              "city": "Dublin",
              "institution": "Irish National Opera",
              "dsl": ""
            }
          ],
          "personId": 58561
        },
        {
          "affiliations": [
            {
              "country": "Netherlands",
              "state": "",
              "city": "Amsterdam",
              "institution": "Centrum Wiskunde & Informatica",
              "dsl": ""
            }
          ],
          "personId": 58560
        },
        {
          "affiliations": [
            {
              "country": "Netherlands",
              "state": "",
              "city": "Amsterdam",
              "institution": "CWI",
              "dsl": ""
            }
          ],
          "personId": 58535
        }
      ]
    },
    {
      "id": 58596,
      "typeId": 11823,
      "title": "Measuring the User Satisfaction in a Recommendation Interface with Multiple Carousels",
      "addons": {
        "broadcastLink": {
          "duringSessionOnly": false,
          "type": "broadcastLink",
          "url": "https://ohyay.co/viewer.html?wsid=ws_W6kSiqvJ#scene_aVD_33jI"
        },
        "doi": {
          "type": "doiLink",
          "url": "https://doi.org/10.1145/3452918.3465493"
        }
      },
      "trackId": 11245,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58616,
        58628
      ],
      "eventIds": [],
      "abstract": "It is common for video-on-demand and music streaming services to adopt a user interface composed of several recommendation lists, i.e. widgets or swipeable carousels, each generated according to a specific criterion or algorithm (e.g. most recent, top popular, recommended for you, editors' choice, etc.). \r\nSelecting the appropriate combination of carousel has significant impact on user satisfaction.\r\nA crucial aspect of this user interface is that to measure the relevance a new carousel for the user it is not sufficient to account solely for its individual quality. Instead, it should be considered that other carousels will already be present in the interface.\r\nThis is not considered by traditional evaluation protocols for recommenders systems, in which each carousel is evaluated in isolation, regardless of (i) which other carousels are displayed to the user and (ii) the relative position of the carousel with respect to other carousels. \r\nHence, we propose a two-dimensional evaluation protocol for a carousel setting that will measure the quality of a recommendation carousel based on how much it improves upon the quality of an already available set of carousels.\r\nOur evaluation protocol takes into account also the position bias, i.e. users do not explore the carousels sequentially, but rather concentrate on the top-left corner of the screen.\r\nWe report experiments on the movie domain and notice that under a carousel setting the definition of which criteria has to be preferred to generate a list of recommended items changes with respect to what is commonly understood. ",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Italy",
              "state": "",
              "city": "Milano",
              "institution": "Politecnico di Milano",
              "dsl": ""
            }
          ],
          "personId": 58515
        },
        {
          "affiliations": [
            {
              "country": "Italy",
              "state": "",
              "city": "Milano",
              "institution": "Politecnico di Milano",
              "dsl": ""
            }
          ],
          "personId": 58466
        },
        {
          "affiliations": [
            {
              "country": "Italy",
              "state": "",
              "city": "Milano",
              "institution": "Politecnico di Milano",
              "dsl": ""
            }
          ],
          "personId": 58481
        }
      ]
    },
    {
      "id": 58597,
      "typeId": 11823,
      "title": "Exploring Perceptions of Bystander Intervention Training using Virtual Reality",
      "addons": {
        "broadcastLink": {
          "duringSessionOnly": false,
          "type": "broadcastLink",
          "url": "https://ohyay.co/viewer.html?wsid=ws_W6kSiqvJ#scene_uodyhWis"
        },
        "doi": {
          "type": "doiLink",
          "url": "https://doi.org/10.1145/3452918.3465497"
        }
      },
      "trackId": 11245,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58619,
        58627
      ],
      "eventIds": [],
      "abstract": "This paper presents a virtual reality (VR) application that allows users to view a series of 360 degree videos, depicting bystander intervention scenarios, from a bystander perspective. Bystander intervention is a commonly used training on how to prevent and de-escalate potentially harmful or violent scenarios. This application enables users to witness, from a first-hand perspective, a successful bystander intervention strategy being used by another person. This paper discusses motivations for creating such an application by giving an overview of the state of the art in bystander intervention training methods. It also discusses the application flow and design of the created system. Additionally, a preliminary user study was conducted to gain initial feedback and user perspectives on the system.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Florida",
              "city": "Tampa",
              "institution": "University of South Florida",
              "dsl": ""
            },
            {
              "country": "United States",
              "state": "Florida",
              "city": "Tampa",
              "institution": "University of South Florida",
              "dsl": ""
            }
          ],
          "personId": 58501
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Florida",
              "city": "Tampa",
              "institution": "University of South Florida",
              "dsl": ""
            }
          ],
          "personId": 58478
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Florida",
              "city": "Tampa",
              "institution": "University of South Florida",
              "dsl": "Computer Science & Engineering Department/College of Engineering"
            },
            {
              "country": "United States",
              "state": "Florida",
              "city": "Tampa",
              "institution": "University of South Florida",
              "dsl": "Computer Science & Engineering Department/College of Engineering"
            }
          ],
          "personId": 58498
        }
      ]
    },
    {
      "id": 58607,
      "typeId": 11822,
      "title": "Real-time Anxiety Prediction in Virtual Reality Exposure Therapy",
      "addons": {
        "broadcastLink": {
          "duringSessionOnly": false,
          "type": "broadcastLink",
          "url": "https://ohyay.co/viewer.html?wsid=ws_W6kSiqvJ#scene_JZ5SXUw8"
        }
      },
      "trackId": 11243,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58619,
        58627
      ],
      "eventIds": [],
      "abstract": "Detection of anxiety patterns in real-time within a virtual reality environment has many uses for medicinal, psychological or entertainment purposes. Virtual reality exposure therapy (VRET) is a therapy method that is quickly rising in popularity, and a built-in way to monitor anxiety levels within VRET applications can contribute to the therapy by providing physiological feedback from the user. This feedback can be used to make meaningful adjustments to context such as increasing exposure levels as user anxiety decreases. For the measurement of physiological signals within Virtual Reality applications, on-body biosensors are generally preferred due to mobility concerns. These biosensors can, however, be susceptible to noise due to movement and it is hard to extract information from a single type of signal. As a countermeasure, this study uses multimodal data and machine learning. The goal of the study is to integrate these signals into a virtual reality experience and accurately assess anxiety levels in real-time by examining patterns across different types of measurements and using a neural network to process information and reduce the effect of noise.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Ireland",
              "state": "",
              "city": "Cork",
              "institution": "University College Cork",
              "dsl": ""
            }
          ],
          "personId": 58436
        }
      ]
    },
    {
      "id": 58608,
      "typeId": 11824,
      "title": "Challenges & Opportunities with Remote UX Research on TV and ‘Connected’ Devices",
      "trackId": 11246,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58456
      ],
      "eventIds": [],
      "abstract": "When YouTube’s offices closed in 2020, we were presented with the challenge of preserving the physicality of user experience research in a remote research environment. To test our products on TVs and connected devices, we leveraged other devices participants would have access to at home, and repurposed existing research and prototyping tools for mobile, web, and tablet to approximate physical experiences on TVs and connected devices. We plan to continue leveraging these remote approaches when we return to physical lab settings, as they’ve helped us get a more representative sample more easily and cost effectively. We also hope to keep evolving and innovating and think about how we can expand these solutions to test at scale.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "San Bruno",
              "institution": "YouTube/Google",
              "dsl": ""
            }
          ],
          "personId": 58601
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "San Bruno",
              "institution": "YouTube/Google",
              "dsl": ""
            }
          ],
          "personId": 60897
        }
      ]
    },
    {
      "id": 58609,
      "typeId": 11822,
      "title": "A Quality of Experience Evaluation of Instruction Formats for Procedure Training in Augmented Reality",
      "addons": {
        "broadcastLink": {
          "duringSessionOnly": false,
          "type": "broadcastLink",
          "url": "https://ohyay.co/viewer.html?wsid=ws_W6kSiqvJ#scene_2MW0yQSk"
        }
      },
      "trackId": 11243,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58620,
        58630
      ],
      "eventIds": [],
      "abstract": "Augmented reality (AR) is widely regarded as a promising training platform. AR integrates real and virtual information into a single scene. This reduces attention changes between workpiece and instruction. Error correction in the form of instruction verification feedback using computer vision can ensure correct learning during training. AR based training can be personalized to suit the trainee requirements from novice to expert. Multimedia instruction formats reduce extraneous cognitive load on the trainee compared to single medium instruction formats such as text only. This leaves the user with more cognitive resources for understanding and learning. However, multimedia instruction formats tend to consume more digital resources than static text only instruction formats. This is a concern in mobile AR devices where digital resources are limited.\r\n\tThis work will evaluate the influence of instruction format resource efficiency on learning in an AR procedure training application. This will be achieved in a between groups study design where animated 3D instructions are compared against static 2D text-based instructions. Learning will be objectively evaluated in a post training recall phase. The extrinsic cognitive load resulting from the different instruction formats is the independent variable that will influence learning as measured from each individual participant’s baseline. The participants cognitive load will be measured implicitly by means of eye-tracking using the in-built Hololens 2 mixed reality headset eye tracking sensors, and by micro facial expressions (MFEs). An application profiler will record digital resource consumption influenced by the graphical and computation requirements of the different instruction formats. An AR Rubik’s Cube solving application will be used for this evaluation. This work will focus on the influence of cognitive load on AR user quality of experience (QoE). The user’s QoE will be measured implicitly via emotion by means of the participant’s micro-facial expressions and physiological signals. The participant’s QoE and cognitive load will be subjectively reported in post experience questionnaires. This work will also evaluate the utility of AR instruction verification feedback, self-paced training, and the influence of these on user QoE.\r\n",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Ireland",
              "state": "Co. Westmeath",
              "city": "Athlone",
              "institution": "Athlone Institute of Technology",
              "dsl": "Computer and Software Engineering"
            }
          ],
          "personId": 58598
        },
        {
          "affiliations": [
            {
              "country": "Ireland",
              "state": "",
              "city": "Athlone",
              "institution": "Athlone Institute of Technology",
              "dsl": ""
            }
          ],
          "personId": 58599
        },
        {
          "affiliations": [
            {
              "country": "Ireland",
              "state": "Westmeath",
              "city": "Athlone",
              "institution": "Athlone Institute of Technology",
              "dsl": "Electronics & Informatics"
            }
          ],
          "personId": 58604
        }
      ]
    },
    {
      "id": 58610,
      "typeId": 11822,
      "title": "Redesigning Digital Peer-to-Peer Payments for Social Connections: A Sociotechnical Approach",
      "addons": {
        "broadcastLink": {
          "duringSessionOnly": false,
          "type": "broadcastLink",
          "url": "https://ohyay.co/viewer.html?wsid=ws_W6kSiqvJ#scene_BVKB3j8w"
        }
      },
      "trackId": 11243,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58617,
        58638
      ],
      "eventIds": [],
      "abstract": "My proposed dissertation research investigates the social and interactive aspects of digital peer-to-peer (P2P)  payments and seeks to redesign such technology for supporting both secure transactions and nuanced social interactions/connections through a sociotechnical approach. Specifically, my goal is to i) reveal and elaborate the multidimensional influences of digital P2P payments on both financial experiences/processes and everyday social interactions, ii) design and develop prototypes that highlight the importance of the interplay of financial and social engagement when designing digital P2P payments platforms. My research will not only contribute to better understanding new and more complicated social phenomena and dynamics emerging in today's digital economy but also benefit the HCI community by informing future research on computer-mediated communication through financial technologies.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "South Carolina",
              "city": "Clemson",
              "institution": "Clemson University",
              "dsl": "School of Computing"
            }
          ],
          "personId": 58605
        }
      ]
    },
    {
      "id": 58611,
      "typeId": 11822,
      "title": "Understanding the Voluntary Moderation Practices in Live Streaming Communities",
      "addons": {
        "broadcastLink": {
          "duringSessionOnly": false,
          "type": "broadcastLink",
          "url": "https://ohyay.co/viewer.html?wsid=ws_W6kSiqvJ#scene_jSbWZ3zs"
        }
      },
      "trackId": 11243,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58618,
        58629
      ],
      "eventIds": [],
      "abstract": "The moderation task in the live streaming community is challenging due to the interactivity and ephemerality of live text-based communication in the chat. Moderators had to make decisions with time constraints and less instruction, experiencing information overload and emotional toll. I aim to understand their decision-making process, identify the challenges during the process, explore the relationship with other stakeholders in the community. I applied mixed methods (interview, survey, observation) to explore these issues. My dissertation focused on content moderation in interactive media, and the results can potentially provide guidance to content moderation in interactive media platforms with high interactivity and synchronicity.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New Jersey",
              "city": "Newark",
              "institution": "New Jersey Institute of Technology",
              "dsl": ""
            }
          ],
          "personId": 58393
        }
      ]
    },
    {
      "id": 58612,
      "typeId": 11822,
      "title": "Understanding Immersion Experience When Using Virtual Reality for Foreign Language Learning",
      "addons": {
        "broadcastLink": {
          "duringSessionOnly": false,
          "type": "broadcastLink",
          "url": "https://ohyay.co/viewer.html?wsid=ws_W6kSiqvJ#scene_fHebIjCP"
        }
      },
      "trackId": 11243,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58619,
        58627
      ],
      "eventIds": [],
      "abstract": "One of the most effective ways to learn a foreign language is by immersion in its native cultures. However, in practice, few students have access to these kinds of experiences. Virtual Reality (VR) technology has the potential to expand access allowing more students to have similar immersion experiences. These experiences are more engaging than conventional methods such as passively watching videos or interacting with two-dimensional user interfaces. However, are they more conducive to learning? My dissertation project is to examine students’ immersion experience in different VR conditions for their foreign language learning through three studies: guided naturalistic VR condition, unguided and guided naturalistic VR conditions, and naturalistic and artificial VR. ",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Maryland",
              "city": "Baltimore",
              "institution": "University of Maryland, Baltimore County",
              "dsl": "Department of Information Systems"
            }
          ],
          "personId": 58606
        }
      ]
    },
    {
      "id": 58613,
      "typeId": 11822,
      "title": "Virtual Reality And Collaborative Learning In Higher Education A Research Thesis Proposal",
      "addons": {
        "broadcastLink": {
          "duringSessionOnly": false,
          "type": "broadcastLink",
          "url": "https://ohyay.co/viewer.html?wsid=ws_W6kSiqvJ#scene_rj809rN7"
        }
      },
      "trackId": 11243,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58619,
        58627
      ],
      "eventIds": [],
      "abstract": "For the past forty years, research has revealed many ways in which Computer-Supported Collaborative Learning (CSCL) can be utilized to support and enhance education. Similarly, Virtual Reality (VR) technology has proven promising for different educational purposes. These affordances, however, tend to change when the technology behind them advances; as such, research should continue to examine the effects how these advances affect the pedagogy. With VR technology continuously expanding, its potential for Collaborative Learning (CL) requires further studying. This research project aims to better understand how different aspects of VR can be used to support key dimensions of successful CL. In doing so, the research project hopes to provide guidelines as to how these VR aspects can be implemented to facilitate and enhance collaboration between group members in an educational setting.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Netherlands",
              "state": "Zuid Holland",
              "city": "Delft",
              "institution": "Centre for Education and Learning",
              "dsl": "Delft Technical University"
            }
          ],
          "personId": 58603
        }
      ]
    },
    {
      "id": 58614,
      "typeId": 11822,
      "title": "Non-Visual Web Design: Enhancing User Experience (UX) Through Aesthetic Semantics",
      "addons": {
        "broadcastLink": {
          "duringSessionOnly": false,
          "type": "broadcastLink",
          "url": "https://ohyay.co/viewer.html?wsid=ws_W6kSiqvJ#scene_7ZmVKUBC"
        }
      },
      "trackId": 11243,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58617,
        58638
      ],
      "eventIds": [],
      "abstract": "This project will improve the ability of people to experience non-visual web content by developing an understanding of the relationship between web based visual aesthetic semantics and their auditory counterparts. Current non-visual methods of presenting web applications focus on text-based information transfer and do not take into consideration the aesthetic design or intended emotive journey that users should feel. As a result, users experience high cognitive load, information overload and a reduced ability to fully engage with aesthetic-rich websites in non-visual interfaces. A potentially innovative way to retain the informative data of visual web components for use in non-visual systems, is to correlate the semantic meaning of visual aesthetics to non-visual aesthetics of semantic equivalence.\r\n\r\nThis research has three specific aims:\r\n\r\n1. Discover which visual and non-visual aesthetics have the strongest impact on affective semantics;\r\n2. Establish if analogous affects exist between visual and non-visual web aesthetics;\r\n3. Develop a framework which delivers analogous informative value in both visual and non-visual web pages using affective aesthetic semantics.\r\n\r\nThe objectives of this research are as follows:\r\n\r\n1. Carry out an online quantitative survey to determine affective responses to atomic web aesthetics;\r\n2. Develop a JS library of atomic affect ratings, which quantifies singular and compounded aesthetic web elements, and can be used to correlate said atomic ratings to audio with analogous ratings;\r\n3. Produce a scalable and extendable JavaScript framework which utilises the core concept of aesthetic semantics and atomic affect rating to enhance UX design in non-visual interfaces.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "Scotland",
              "city": "Dundee",
              "institution": "University of Dundee",
              "dsl": ""
            }
          ],
          "personId": 58600
        }
      ]
    },
    {
      "id": 58615,
      "typeId": 11822,
      "title": "Toward an Understanding of Flow Cost in Entertainment Media Use",
      "addons": {
        "broadcastLink": {
          "duringSessionOnly": false,
          "type": "broadcastLink",
          "url": "https://ohyay.co/viewer.html?wsid=ws_W6kSiqvJ#scene___EphwHJ"
        }
      },
      "trackId": 11243,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58617,
        58638
      ],
      "eventIds": [],
      "abstract": "Flow is a highly desirable experience in entertainment media use because it can facilitate escapism and enjoyment. This paper proposes a research program that challenges the view that the outcomes of flow are not always positive, rather, they are dependent on the context in which flow occurs. When occurring under the pursuit of multiple goals in a resource-limited context, the full absorption of cognitive and attentional resources due to flow can potentially divert the user’s resources (attention, cognitive effort, time) away from goals outside of the media activity, imposing resource costs to the performance of such goals. Employing lab experiments, this research will examine people’s attention, task performance, and affect when engaging in the flow-inducing media use and subsequent activities. Findings from this research will inform the design of intelligent systems such as management tools or virtual assistants that can reduce the cost of negative flow for users.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Illinois",
              "city": "Urbana",
              "institution": "Institute of Communications Research",
              "dsl": "University of Illinois at Urbana-Champaign"
            }
          ],
          "personId": 58602
        }
      ]
    },
    {
      "id": 58641,
      "typeId": 11835,
      "title": "Human-media Interaction in the Global South: Designing Immersive Technologies for the Next Billion ‘US’ers (Closing Keynote)",
      "trackId": 11284,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        58642
      ],
      "eventIds": [],
      "abstract": "Suleman is a HCI researcher and a design practitioner. His work in academia and the industry focuses on the intersection of design, technology and inclusion in the context of the Global South. He uses HCI research methods to inform his design practice and experiments with technologies and design methods to improve their effectiveness in the local context whilst catalysing an industry-academia knowledge exchange. In this talk, Suleman will discuss his latest university-based research and applied work on designing immersive and interactive technologies for people on the margins. He will discuss his approach of combining elements of playfulness, serious storytelling, gamification and social interaction for designing digital interventions and systems for diverse user groups in Pakistan.\n \nHe will explore the way cultural background, religion, literacy level, socioeconomic status and previous exposure to technology shape how different users, mainly at the margins, interact with ,and accept or reject immersive technologies. He will also analyse the pros and cons of using the “quick and dirty approach” for technology development and discuss how people on margins associate short- and long-term expectations with the half-cooked interventions and digital solutions. \n \nHis talk will include four different case studies involving diverse groups of participants and domains to explain the methodological and technological challenges researchers and practitioners face in their studies with marginalized people and how to address some of these challenges while researching in the global south. He will focus on lessons learned on engaging children with autism in the design process while designing a multimedia educational application for them. He will also touch upon the methodological and practical complexities of developing a serious game for teenagers with mental health conditions. Through another case study, he will highlight the challenges and the associated excitement that comes with designing and evaluating immersive games for adults with visual impairment. The final case study will examine the multilayered design process of developing a virtual reality-based intervention for the elderly with dementia.\n \nAnd lastly, based on his experience in the field in both Pakistan and Europe, he will raise a few elementary questions about the process of working with people on the margins. He will also expand on the importance of decolonizing human-media interaction research in the global south while keeping in mind the relative nature of the term “marginality”.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "Lahore University of Management Sciences (LUMS); LUMS Learning Institute"
            }
          ],
          "personId": 58640
        }
      ]
    },
    {
      "id": 58660,
      "typeId": 11815,
      "title": "SensoryX – Multisensory Experiences",
      "addons": {
        "broadcastLink": {
          "duringSessionOnly": false,
          "type": "broadcastLink",
          "url": "https://ohyay.co/viewer.html?wsid=ws_W6kSiqvJ#scene_avIKDudb"
        }
      },
      "trackId": 11285,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        59454
      ],
      "eventIds": [],
      "abstract": "Multimedia applications have primarily engaged two of the human senses – aural and visual. With recent advances in computational technology, however it is possible to develop multisensory applications across all senses. Important findings from psychological and neuroscience research, as well as technological advances responsible for increased diversity of devices with higher computational power and communication capabilities, augmented by various sensor and display technologies have enabled targeting other human senses. Moreover, the state of the art for multisensory systems has been pushed forward with the evolution of Mixed Reality-related technologies that allowed several senses to be stimulated at the same time, presenting users with ‘real experiences’ designed in virtual worlds. The Multisensory Experiences workshop will focus on enhancing the multisensory scope of both designers and developers of multimedia and Mixed Reality experiences who could thus harness the whole spectrum of sensory experiences. For this, the workshop will challenge current practices in designing experiences, will explore meaningful design spaces and will identify future research directions for creating experiences at the intersection of various sensory dimensions.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "University of Kent"
            }
          ],
          "personId": 58652
        },
        {
          "affiliations": [
            {
              "institution": "Federal Institute of Espírito Santo"
            }
          ],
          "personId": 58653
        },
        {
          "affiliations": [
            {
              "institution": "Brunel University"
            }
          ],
          "personId": 58654
        }
      ]
    },
    {
      "id": 58661,
      "typeId": 11815,
      "title": "LIQUE 2021 – Life Improvement in Quality by Ubiquitous Experiences Workshop",
      "addons": {
        "broadcastLink": {
          "duringSessionOnly": false,
          "type": "broadcastLink",
          "url": "https://ohyay.co/viewer.html?wsid=ws_W6kSiqvJ#scene_uf8kCvlK"
        }
      },
      "trackId": 11285,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        59455
      ],
      "eventIds": [],
      "abstract": "LIQUE 2021 – Life Improvement in Quality by Ubiquitous Experiences Workshop aims to contribute to immersive experiences to improve the quality of life. We intend to highlight the development of initiatives that go beyond entertainment in the global search for new uses of interactive media in a diverse environment. As Interactive Media Experiences (IMX) become more and more present everywhere, in a pervasive, universal and predominant way (or in a unique word: ubiquitous) there is a growing interest in IMX systems designed for life quality improvements in all possible aspects. This is especially relevant nowadays that we all are facing the challenge to keep the comfort related to technological development and at same time respect the earth equilibrium and ecosystems’ maintenance in all aspects and levels.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "Federal University of Maranhao"
            }
          ],
          "personId": 58655
        },
        {
          "affiliations": [
            {
              "institution": "Universidade Federal Fluminense"
            }
          ],
          "personId": 58656
        },
        {
          "affiliations": [
            {
              "institution": "Universidade Federal Fluminense"
            }
          ],
          "personId": 58657
        },
        {
          "affiliations": [
            {
              "institution": "University of Sao Paulo"
            }
          ],
          "personId": 58658
        },
        {
          "affiliations": [
            {
              "institution": "Federal University of Maranhao"
            }
          ],
          "personId": 58659
        }
      ]
    },
    {
      "id": 58662,
      "typeId": 11815,
      "title": "XR in Games – How to make a better game experience",
      "addons": {
        "broadcastLink": {
          "duringSessionOnly": false,
          "type": "broadcastLink",
          "url": "https://ohyay.co/viewer.html?wsid=ws_W6kSiqvJ#scene_LdET7mDN"
        }
      },
      "trackId": 11285,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        59453
      ],
      "eventIds": [],
      "abstract": "Extended Reality is becoming an important and relevant field in digital entertainment, thanks to the high immersion possibilities achieved through it. These experiences combine visible, acoustic and haptic senses in such a way that users can truly be moved to an alternative reality. However, there are many challenges and limitations coming from both technological and game design aspects. Cybersickness, space orientation, interaction design, graphical response, tracking, streaming data and collaboration issues are some of the relevant topics that must be investigated and developed in the next few years, in order to increase and popularize the field. The XR in Games workshop aims to bring researchers and practitioners together to discuss and present these challenges, presenting ongoing solutions, possibilities and strategies to improve the player experience. We intend to discuss innovative implementation techniques that might affect player experiences in XR environments.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "Universidade Federal Fluminense"
            }
          ],
          "personId": 58643
        },
        {
          "affiliations": [
            {
              "institution": "Universidade Federal Fluminense"
            }
          ],
          "personId": 58644
        },
        {
          "affiliations": [
            {
              "institution": "Université Côte d’Azur"
            }
          ],
          "personId": 58645
        }
      ]
    },
    {
      "id": 58663,
      "typeId": 11815,
      "title": "DataTV-2021 – 2nd International Workshop on Data-driven Personalisation of Television",
      "addons": {
        "broadcastLink": {
          "duringSessionOnly": false,
          "type": "broadcastLink",
          "url": "https://ohyay.co/viewer.html?wsid=ws_W6kSiqvJ#scene_qpp_DXS-"
        }
      },
      "trackId": 11285,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        59456
      ],
      "eventIds": [],
      "abstract": "The DataTV-2021 workshop will continue from the successful DataTV-2019 workshop at ACM IMX where a range of topics were presented, as reported in the workshop proceedings at http://datatv2019.iti.gr/, as well as the DataTV-2020 Webinar organized on September 14th, 2020 as a free event with expert speakers and lightning talks (https://retv-project.eu/datatv2020/). The aim of the DataTV-2021 workshop will be to extend the remit of the previous workshop to address the increasing importance and relevance of richly granular and semantically expressive data about TV and immersive audiovisual content in the media value chain. Such data needs extraction, modelling and management before it can be meaningfully reused in new, innovative services for TV or other immersive audiovisual settings (360° video in AR or MR).",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "Birmingham City University"
            }
          ],
          "personId": 58646
        },
        {
          "affiliations": [
            {
              "institution": "MODUL Technology GmbH"
            }
          ],
          "personId": 58647
        },
        {
          "affiliations": [
            {
              "institution": "CERTH-ITI"
            }
          ],
          "personId": 58648
        }
      ]
    },
    {
      "id": 58664,
      "typeId": 11836,
      "title": "Doctoral Consortium - Mentorship Program",
      "trackId": 11286,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        59457
      ],
      "eventIds": [],
      "abstract": "The Doctoral Consortium track in IMX 2021 is made up of a mentorship program and a poster presentation session. This segment of the conference will match students with mentors to discuss the students' research topic.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "Research Institutes of Sweden"
            }
          ],
          "personId": 58649
        },
        {
          "affiliations": [
            {
              "institution": "Google"
            }
          ],
          "personId": 58650
        }
      ]
    },
    {
      "id": 59447,
      "typeId": 11812,
      "title": "Inclusive Design",
      "trackId": 11287,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        59458
      ],
      "eventIds": [],
      "abstract": "Inclusive Design is an approach used in many sectors to try and allow everyone to experience our services and products in an equitable way. One of the ways we could do this is by celebrating diversity in how we design and take into account the different barriers faced by different communities across the globe. This panel brings together experts from Namibia, India and Brazil to discuss what inclusive design looks like for them, the charms of the communities they work with, the challenges they face in designing with and for them and how other communities can learn from the methods they have used in order to build a more inclusive world that benefits all of us.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "Riot Games"
            }
          ],
          "personId": 59441
        },
        {
          "affiliations": [
            {
              "institution": "Namibia University of Science and Technology"
            }
          ],
          "personId": 59444
        },
        {
          "affiliations": [
            {
              "institution": "Microsoft"
            }
          ],
          "personId": 59446
        },
        {
          "affiliations": [
            {
              "institution": "Federal University of Technology – Paraná"
            }
          ],
          "personId": 59431
        }
      ]
    },
    {
      "id": 59448,
      "typeId": 11835,
      "title": "Where does “AI” end and “we” begin?",
      "trackId": 11284,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        59452
      ],
      "eventIds": [],
      "abstract": "In this talk, Sougwen Chung explores the evolution of human and computer interaction towards models of human and non-human relation. Through a de-centering of the human subject, this talk illuminates sensory constellations between humans, machines and nature, stewarding a newfound “planetary sensing” in responsible co-creation with AI.\n\nRejecting the notion that machines will replace humans, Sougwen’s work addresses the role of art, science, design, and engineering in stewarding destinations beyond the limitations of our current cultural imagination.",
      "authors": [
        {
          "affiliations": [],
          "personId": 58651
        }
      ]
    },
    {
      "id": 59449,
      "typeId": 11812,
      "title": "State of Art on Gaming",
      "trackId": 11287,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        59459
      ],
      "eventIds": [],
      "abstract": "Increasingly we find that the technologies used and audiences served by the media sector and the gaming sector are heading towards a confluence with interaction and personalisation playing important roles in the experiences people want. Who are games designed for and how do we incorporate inclusive design in our processes? How is advertising conducted in modern games? What is the role of machine learning in the future of game production?",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "Twitch"
            }
          ],
          "personId": 59433
        },
        {
          "affiliations": [
            {
              "institution": "Youtube"
            }
          ],
          "personId": 59435
        },
        {
          "affiliations": [
            {
              "institution": "Microsoft"
            }
          ],
          "personId": 59436
        },
        {
          "affiliations": [
            {
              "institution": "Activision"
            }
          ],
          "personId": 59437
        }
      ]
    },
    {
      "id": 59450,
      "typeId": 11812,
      "title": "Future of Media",
      "trackId": 11287,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        59461
      ],
      "eventIds": [],
      "abstract": "The media industry is continually changing and expanding; never standing still and increasingly addressing a global market simultaneously. Audience demands are evolving and so are the types of experiences, devices and platforms on which content can be consumed. In this competitive ecosystem, what are the technical and editorial challenges involved in producing and distributing content at scale robustly? What are the measures of success and how do we innovate?",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "Tencent"
            }
          ],
          "personId": 59443
        },
        {
          "affiliations": [
            {
              "institution": "Intel"
            }
          ],
          "personId": 59445
        },
        {
          "affiliations": [
            {
              "institution": "Fox"
            }
          ],
          "personId": 59432
        },
        {
          "affiliations": [
            {
              "institution": "Twitch"
            }
          ],
          "personId": 59434
        }
      ]
    },
    {
      "id": 59451,
      "typeId": 11812,
      "title": "(Live) Entertainment on Immersive",
      "trackId": 11287,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        59460
      ],
      "eventIds": [],
      "abstract": "Virtual Reality (VR) has come a long way from a science-fiction concept to a privileged science-based field studied by a few researchers in laboratories to a ‘medium’ experimented on by creatives the worldover. It’s no longer necessary to have multiple slides to tell us what we mean when someone wants to talk of VR, maybe just one. Now there are many applications for VR but one of the more compelling ones is the idea of experiencing (live) events together while apart. What are the challenges involved in bringing (live) entertainment to audiences on an immersive platform?",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "Goldsmiths University"
            }
          ],
          "personId": 59438
        },
        {
          "affiliations": [
            {
              "institution": "Universitat de Barcelona"
            }
          ],
          "personId": 59439
        },
        {
          "affiliations": [
            {
              "institution": "Lost Horizon"
            }
          ],
          "personId": 59440
        },
        {
          "affiliations": [
            {
              "institution": "Consultant"
            }
          ],
          "personId": 59442
        }
      ]
    }
  ],
  "people": [
    {
      "id": 58389,
      "firstName": "Jeongmi",
      "lastName": "Lee",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58390,
      "firstName": "Rhianne",
      "lastName": "Jones",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58391,
      "firstName": "Donghee Yvette",
      "lastName": "Wohn",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58392,
      "firstName": "Pu",
      "lastName": "Feng",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58393,
      "firstName": "Jie",
      "lastName": "Cai",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58394,
      "firstName": "Vinoba",
      "lastName": "Vinayagamoorthy",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58395,
      "firstName": "Irina",
      "lastName": "Popovici",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58396,
      "firstName": "Sylvia",
      "lastName": "Rothe",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58397,
      "firstName": "Mashael",
      "lastName": "Almoqbel",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58398,
      "firstName": "Alejandro",
      "lastName": "Sztrajman",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58399,
      "firstName": "Jirassaya",
      "lastName": "Uttarapong",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58400,
      "firstName": "Zhiqun",
      "lastName": "Zhao",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58401,
      "firstName": "Melanie",
      "lastName": "Duckert",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58402,
      "firstName": "Tony",
      "lastName": "Stockman",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58403,
      "firstName": "Mea",
      "lastName": "Wang",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58404,
      "firstName": "Zhihai",
      "lastName": "He",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58405,
      "firstName": "Heinrich",
      "lastName": "Hussmann",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58406,
      "firstName": "Stuart",
      "lastName": "James",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58407,
      "firstName": "Sabin",
      "lastName": "Tabirca",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58408,
      "firstName": "Marija",
      "lastName": "Slavkovik",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58409,
      "firstName": "Wim",
      "lastName": "Lamotte",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58410,
      "firstName": "Daniele",
      "lastName": "Giunchi",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58411,
      "firstName": "Eugene",
      "lastName": "Hwang",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58412,
      "firstName": "Than Htut",
      "lastName": "Soe",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58413,
      "firstName": "Juan Carlos",
      "lastName": "Martinez",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58414,
      "firstName": "Neelima",
      "lastName": "Sailaja",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58415,
      "firstName": "Anthony",
      "lastName": "Steed",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58416,
      "firstName": "Pia",
      "lastName": "Probst",
      "middleInitial": "Carola",
      "affiliations": []
    },
    {
      "id": 58417,
      "firstName": "Maarten",
      "lastName": "Wijnants",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58418,
      "firstName": "Peter",
      "lastName": "Quax",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58419,
      "firstName": "Youngmin",
      "lastName": "Park",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58420,
      "firstName": "Eva",
      "lastName": "Geurts",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58421,
      "firstName": "Frode",
      "lastName": "Guribye",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58422,
      "firstName": "Wenjun",
      "lastName": "Wu",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58423,
      "firstName": "Louise",
      "lastName": "Barkhuus",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58424,
      "firstName": "Luca",
      "lastName": "Turchet",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58425,
      "firstName": "David",
      "lastName": "Murphy",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58426,
      "firstName": "Derek",
      "lastName": "McAuley",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58427,
      "firstName": "David",
      "lastName": "Baker",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58428,
      "firstName": "Ovidiu-Ciprian",
      "lastName": "Ungurean",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58429,
      "firstName": "Radu-Daniel",
      "lastName": "Vatavu",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58430,
      "firstName": "Hendrik",
      "lastName": "Lievens",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58431,
      "firstName": "Hosub",
      "lastName": "Lee",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58432,
      "firstName": "Dane",
      "lastName": "Acena",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58433,
      "firstName": "Haohong",
      "lastName": "Wang",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58434,
      "firstName": "Kyle",
      "lastName": "Jorgensen",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58435,
      "firstName": "Guo",
      "lastName": "Freeman",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58436,
      "firstName": "Deniz",
      "lastName": "Mevlevioğlu",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58458,
      "firstName": "Sai Krishna",
      "lastName": "Yeshala",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58459,
      "firstName": "Enrique",
      "lastName": "Castelan",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58460,
      "firstName": "Konstantinos",
      "lastName": "Apostolidis",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58461,
      "firstName": "Kimberly",
      "lastName": "Wiseman",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58462,
      "firstName": "G S Rajshekar",
      "lastName": "Reddy",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58463,
      "firstName": "Olivia",
      "lastName": "Menezes",
      "middleInitial": "C.",
      "affiliations": []
    },
    {
      "id": 58464,
      "firstName": "Iñigo",
      "lastName": "Tamayo",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58465,
      "firstName": "Brandon",
      "lastName": "Hang",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58466,
      "firstName": "Maurizio",
      "lastName": "Ferrari Dacrema",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58467,
      "firstName": "Janet",
      "lastName": "Murray",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58468,
      "firstName": "Celine",
      "lastName": "Jost",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58469,
      "firstName": "Thanassis",
      "lastName": "Rikakis",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58470,
      "firstName": "Patrícia",
      "lastName": "Bota",
      "middleInitial": "J.",
      "affiliations": []
    },
    {
      "id": 58471,
      "firstName": "Michelle",
      "lastName": "Ramirez",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58472,
      "firstName": "Emmanouil",
      "lastName": "Adamakis",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58473,
      "firstName": "Ellen",
      "lastName": "Pearlman",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58474,
      "firstName": "Alexander",
      "lastName": "Toet",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58475,
      "firstName": "Isis",
      "lastName": "Truck",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58476,
      "firstName": "Kinji",
      "lastName": "Matsumura",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58477,
      "firstName": "Hiromu",
      "lastName": "Ogawa",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58478,
      "firstName": "Soumya",
      "lastName": "Abraham",
      "middleInitial": "Joseph",
      "affiliations": []
    },
    {
      "id": 58479,
      "firstName": "Aisling",
      "lastName": "Kelliher",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58480,
      "firstName": "Pedro",
      "lastName": "Silva",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58481,
      "firstName": "Paolo",
      "lastName": "Cremonesi",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58482,
      "firstName": "Cameron",
      "lastName": "Guanlao",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58483,
      "firstName": "Jie",
      "lastName": "Li",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58484,
      "firstName": "Tamim",
      "lastName": "Ahmed",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58485,
      "firstName": "Evlampios",
      "lastName": "Apostolidis",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58486,
      "firstName": "Lyndon",
      "lastName": "Nixon",
      "middleInitial": "J B",
      "affiliations": []
    },
    {
      "id": 58487,
      "firstName": "Asterios",
      "lastName": "Leonidis",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58488,
      "firstName": "Joan",
      "lastName": "Llobera",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58489,
      "firstName": "Tessa",
      "lastName": "Klunder",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58490,
      "firstName": "Gonçalo",
      "lastName": "Salvador",
      "middleInitial": "Filipe Duarte",
      "affiliations": []
    },
    {
      "id": 58491,
      "firstName": "Amy",
      "lastName": "Gourlay",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58492,
      "firstName": "Jean",
      "lastName": "Vanderdonckt",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58493,
      "firstName": "Arisa",
      "lastName": "Fujii",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58494,
      "firstName": "Sara",
      "lastName": "Loucks",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58495,
      "firstName": "Dimitrios",
      "lastName": "Milathianakis",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58496,
      "firstName": "Bárbara",
      "lastName": "Soares",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58497,
      "firstName": "Cathleen",
      "lastName": "Garcia",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58498,
      "firstName": "Marvin",
      "lastName": "Andujar",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58499,
      "firstName": "Alexandru-Ionut",
      "lastName": "Siean",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58500,
      "firstName": "Shuyu",
      "lastName": "Gao",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58501,
      "firstName": "Sarah",
      "lastName": "Garcia",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58502,
      "firstName": "Maria",
      "lastName": "Korozi",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58503,
      "firstName": "Petros",
      "lastName": "Daras",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58504,
      "firstName": "Juliet",
      "lastName": "Clark",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58505,
      "firstName": "Timothy",
      "lastName": "Stelter",
      "middleInitial": "L.",
      "affiliations": []
    },
    {
      "id": 58506,
      "firstName": "Rasa",
      "lastName": "Bocyte",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58507,
      "firstName": "Rabindra",
      "lastName": "Ratan",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58508,
      "firstName": "Ana",
      "lastName": "Fred",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58509,
      "firstName": "Vasileios",
      "lastName": "Mezaris",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58510,
      "firstName": "José",
      "lastName": "Soares",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58511,
      "firstName": "Dieter",
      "lastName": "Kranzlmüller",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58512,
      "firstName": "Michael",
      "lastName": "Crabb",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58513,
      "firstName": "Dimitrios",
      "lastName": "Zarpalas",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58514,
      "firstName": "Vasilios",
      "lastName": "Kouroumalis",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58515,
      "firstName": "Nicolò",
      "lastName": "Felicioni",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58516,
      "firstName": "Javier",
      "lastName": "Gonzalez-Sanchez",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58517,
      "firstName": "Gérard",
      "lastName": "Uzan",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58518,
      "firstName": "Setor",
      "lastName": "Zilevu",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58519,
      "firstName": "Scott",
      "lastName": "McCrickard",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58520,
      "firstName": "Klara",
      "lastName": "Kriszun",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58521,
      "firstName": "Pooja",
      "lastName": "Patel",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58522,
      "firstName": "Hugo",
      "lastName": "Plácido da Silva",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58523,
      "firstName": "Bram",
      "lastName": "Smeets",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58524,
      "firstName": "Omar",
      "lastName": "Niamut",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58525,
      "firstName": "Elisabeth",
      "lastName": "Mayer",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58526,
      "firstName": "Pedro",
      "lastName": "Beça",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58527,
      "firstName": "Charles",
      "lastName": "Tijus",
      "middleInitial": "Albert",
      "affiliations": []
    },
    {
      "id": 58528,
      "firstName": "Margarita",
      "lastName": "Vinnikov",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58529,
      "firstName": "Xianlian",
      "lastName": "Zhou",
      "middleInitial": "Alex",
      "affiliations": []
    },
    {
      "id": 58530,
      "firstName": "Aschwin",
      "lastName": "Brandt",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58531,
      "firstName": "Damianos",
      "lastName": "Galanopoulos",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58532,
      "firstName": "Angelos",
      "lastName": "Gogonis",
      "middleInitial": "R.",
      "affiliations": []
    },
    {
      "id": 58533,
      "firstName": "Minakshi",
      "lastName": "Seth",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58534,
      "firstName": "Basil",
      "lastName": "Philipp",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58535,
      "firstName": "Pablo",
      "lastName": "Cesar",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58536,
      "firstName": "Jack",
      "lastName": "Sagot",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58537,
      "firstName": "Richard",
      "lastName": "Whitehand",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58538,
      "firstName": "Stefano",
      "lastName": "Masneri",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58539,
      "firstName": "Steven",
      "lastName": "Schirra",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58540,
      "firstName": "Ana",
      "lastName": "Dominguez",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58541,
      "firstName": "Hans",
      "lastName": "Stokking",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58542,
      "firstName": "Sylvie",
      "lastName": "Dijkstra-Soudarissanane",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58543,
      "firstName": "Sarah",
      "lastName": "Garrison",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58544,
      "firstName": "Sanjeev",
      "lastName": "Nayak",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58545,
      "firstName": "Dominique",
      "lastName": "Archambault",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58546,
      "firstName": "Werner",
      "lastName": "Bailer",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58547,
      "firstName": "Georgios",
      "lastName": "Albanis",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58548,
      "firstName": "Zeph",
      "lastName": "van Berlo",
      "middleInitial": "M.C.",
      "affiliations": []
    },
    {
      "id": 58549,
      "firstName": "Rémy",
      "lastName": "Sohier",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58550,
      "firstName": "Caitlin",
      "lastName": "Barta",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58551,
      "firstName": "Alina",
      "lastName": "Striner",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58552,
      "firstName": "Katja",
      "lastName": "Radon",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58553,
      "firstName": "Héctor",
      "lastName": "Rivas Pagador",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58554,
      "firstName": "Colin",
      "lastName": "Stricklin",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58555,
      "firstName": "Damien",
      "lastName": "Rompapas",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58556,
      "firstName": "Constantine",
      "lastName": "Stephanidis",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58557,
      "firstName": "Daisuke",
      "lastName": "Sekine",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58558,
      "firstName": "Mikel",
      "lastName": "Zorrilla",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58559,
      "firstName": "Justin",
      "lastName": "Debloos",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58560,
      "firstName": "Thomas",
      "lastName": "Röggla",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58561,
      "firstName": "Sarah",
      "lastName": "Halpin",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58562,
      "firstName": "Luisa",
      "lastName": "Merz",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58563,
      "firstName": "Nikolaos",
      "lastName": "Zioulis",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58564,
      "firstName": "Caecilia",
      "lastName": "Charbonnier",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58565,
      "firstName": "Pedro",
      "lastName": "Almeida",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58566,
      "firstName": "Brigitte",
      "lastName": "Le Pévédic",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58567,
      "firstName": "Marie Astrid",
      "lastName": "Garrido",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58568,
      "firstName": "Neelma",
      "lastName": "Bhatti",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58598,
      "firstName": "Eoghan",
      "lastName": "Hynes",
      "middleInitial": "Paul",
      "affiliations": []
    },
    {
      "id": 58599,
      "firstName": "Ronan",
      "lastName": "Flynn",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58600,
      "firstName": "Labake",
      "lastName": "Odushegun",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58601,
      "firstName": "Chelsea",
      "lastName": "Miller",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58602,
      "firstName": "Giang",
      "lastName": "Pham",
      "middleInitial": "V",
      "affiliations": []
    },
    {
      "id": 58603,
      "firstName": "Nesse",
      "lastName": "van der Meer",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58604,
      "firstName": "Niall",
      "lastName": "Murray",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58605,
      "firstName": "Lingyuan",
      "lastName": "Li",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58606,
      "firstName": "Hye-Kyung",
      "lastName": "Bae",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58631,
      "firstName": "Q. Vera",
      "lastName": "Liao",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58632,
      "firstName": "Nitesh",
      "lastName": "Goyal",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58633,
      "firstName": "Asreen",
      "lastName": "Rostami",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58634,
      "firstName": "Hyejin Hannah",
      "lastName": "Kum-Biocca",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58635,
      "firstName": "Timothy",
      "lastName": "Neate",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58636,
      "firstName": "Seonghoon",
      "lastName": "Ban",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58637,
      "firstName": "Jie",
      "lastName": "Li",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 58640,
      "firstName": "Suleman",
      "lastName": "Shahid",
      "affiliations": []
    },
    {
      "id": 58643,
      "firstName": "Esteban",
      "lastName": "Clua",
      "affiliations": []
    },
    {
      "id": 58644,
      "firstName": "Daniela",
      "lastName": "Trevisan",
      "affiliations": []
    },
    {
      "id": 58645,
      "firstName": "Lucile",
      "lastName": "Sassatelli",
      "affiliations": []
    },
    {
      "id": 58646,
      "firstName": "Jeremy",
      "lastName": "Foss",
      "affiliations": []
    },
    {
      "id": 58647,
      "firstName": "Lyndon",
      "lastName": "Nixon",
      "affiliations": []
    },
    {
      "id": 58648,
      "firstName": "Vasileios",
      "lastName": "Mezaris",
      "affiliations": []
    },
    {
      "id": 58649,
      "firstName": "Asreen",
      "lastName": "Rostami",
      "affiliations": []
    },
    {
      "id": 58650,
      "firstName": "Nitesh",
      "lastName": "Goyal",
      "affiliations": []
    },
    {
      "id": 58651,
      "firstName": "Sougwen",
      "lastName": "Chung",
      "affiliations": []
    },
    {
      "id": 58652,
      "firstName": "Alexandra",
      "lastName": "Covaci",
      "affiliations": []
    },
    {
      "id": 58653,
      "firstName": "Estêvão",
      "lastName": "Saleme",
      "middleInitial": "Bissoli",
      "affiliations": []
    },
    {
      "id": 58654,
      "firstName": "Gheorghita",
      "lastName": "Ghinea",
      "affiliations": []
    },
    {
      "id": 58655,
      "firstName": "Anselmo",
      "lastName": "Paiva",
      "middleInitial": "C.",
      "affiliations": []
    },
    {
      "id": 58656,
      "firstName": "Aura",
      "lastName": "Conci",
      "affiliations": []
    },
    {
      "id": 58657,
      "firstName": "Débora",
      "lastName": "Muchaluat-Saade",
      "middleInitial": "C.",
      "affiliations": []
    },
    {
      "id": 58658,
      "firstName": "Fátima",
      "lastName": "Marques",
      "middleInitial": "L. S. Nunes",
      "affiliations": []
    },
    {
      "id": 58659,
      "firstName": "Tiago",
      "lastName": "Borchartt",
      "middleInitial": "Bonini",
      "affiliations": []
    },
    {
      "id": 59431,
      "firstName": "Frederick",
      "lastName": "van Amstel",
      "affiliations": []
    },
    {
      "id": 59432,
      "firstName": "Mayur",
      "lastName": "Srinivasan",
      "affiliations": []
    },
    {
      "id": 59433,
      "firstName": "Sanjay",
      "lastName": "Kairam",
      "affiliations": []
    },
    {
      "id": 59434,
      "firstName": "Stephanie",
      "lastName": "Neill",
      "middleInitial": "J.",
      "affiliations": []
    },
    {
      "id": 59435,
      "firstName": "Danae",
      "lastName": "Holmes",
      "affiliations": []
    },
    {
      "id": 59436,
      "firstName": "Haiyan",
      "lastName": "Zhang",
      "affiliations": []
    },
    {
      "id": 59437,
      "firstName": "Jenny",
      "lastName": "Taran",
      "affiliations": []
    },
    {
      "id": 59438,
      "firstName": "Tara",
      "lastName": "Collingwoode-Williams",
      "affiliations": []
    },
    {
      "id": 59439,
      "firstName": "Alejandro",
      "lastName": "Beacco",
      "affiliations": []
    },
    {
      "id": 59440,
      "firstName": "Robin",
      "lastName": "Collings",
      "affiliations": []
    },
    {
      "id": 59441,
      "firstName": "Kate",
      "lastName": "Grandprey-Shores",
      "affiliations": []
    },
    {
      "id": 59442,
      "firstName": "Zillah",
      "lastName": "Watson",
      "affiliations": []
    },
    {
      "id": 59443,
      "firstName": "Shan",
      "lastName": "Liu",
      "affiliations": []
    },
    {
      "id": 59444,
      "firstName": "Heike",
      "lastName": "Winschiers-Theophilus",
      "affiliations": []
    },
    {
      "id": 59445,
      "firstName": "Jill",
      "lastName": "Boyce",
      "affiliations": []
    },
    {
      "id": 59446,
      "firstName": "Kalika",
      "lastName": "Bali",
      "affiliations": []
    },
    {
      "id": 60897,
      "firstName": "Sophie",
      "lastName": "Amberkar",
      "middleInitial": "",
      "affiliations": []
    }
  ],
  "recognitions": [],
  "publicationInfo": {
    "hideLinksBeforeConference": false,
    "version": 57,
    "publicationStatus": "PUBLISHED",
    "isProgramEnabled": true,
    "isDraft": false,
    "isRegistrationEnabled": false,
    "publicationDate": "2021-06-22 11:57:08+00"
  }
}