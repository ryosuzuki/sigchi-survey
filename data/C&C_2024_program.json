{
  "schemeVersion": 7,
  "cc_licence": "Content of this file is licensed under a CC BY-NC-SA 4.0 license. For details see https://creativecommons.org/licenses/by-nc-sa/4.0/",
  "conference": {
    "id": 10112,
    "shortName": "C&C",
    "displayShortName": "",
    "year": 2024,
    "startDate": 1719100800000,
    "endDate": 1719360000000,
    "fullName": "16th ACM Conference on Creativity & Cognition",
    "url": "https://cc.acm.org/2024/",
    "location": "Chicago, IL",
    "timeZoneOffset": -300,
    "timeZoneName": "America/Chicago",
    "logoUrl": "https://files.sigchi.org/conference/logo/10112/b38c3dd8-fc0b-a137-5520-99f4041548bd.png",
    "name": "C&C 2024"
  },
  "publicationInfo": {
    "hideLinksBeforeConference": true,
    "version": 30,
    "publicationStatus": "PUBLISHED",
    "isProgramEnabled": true,
    "isDraft": false,
    "isRegistrationEnabled": false,
    "publicationDate": "2024-06-18 02:34:51+00"
  },
  "sponsors": [
    {
      "id": 10595,
      "name": "Adobe",
      "logoUrl": "https://files.sigchi.org/conference/sponsor/10112/logo/001f73c3-0ccd-93e7-e1c2-86aaf82a1875.png",
      "levelId": 10341,
      "url": "https://research.adobe.com/",
      "description": "<p><span style=\"background-color: oklab(0.798803 0.0268804 0.148792 / 0.08);\">With a team of world-class research scientists, engineers, artists, and designers, Adobe Research combines cutting-edge academic discovery with industry impact. Our researchers shape early-stage ideas into innovative technologies. Many of Adobe Research’s breakthroughs are incorporated into Adobe’s products, building the company’s reputation as a leader in fostering new forms of creativity and in advancing document and content intelligence. Our team collaborates with interns and faculty from universities across the globe.</span></p>",
      "order": 0,
      "extraPadding": 8
    },
    {
      "id": 10596,
      "name": "Google",
      "logoUrl": "https://files.sigchi.org/conference/sponsor/10112/logo/e065bd47-c6fa-382a-a413-d7c5660781a5.png",
      "levelId": 10342,
      "url": "http://www.google.com",
      "order": 0,
      "extraPadding": 8
    }
  ],
  "sponsorLevels": [
    {
      "id": 10317,
      "name": "Sponsors",
      "rank": 3,
      "isDefault": true
    },
    {
      "id": 10341,
      "name": "Gold",
      "rank": 1,
      "isDefault": false
    },
    {
      "id": 10342,
      "name": "Silver",
      "rank": 2,
      "isDefault": false
    }
  ],
  "floors": [],
  "rooms": [
    {
      "id": 11561,
      "name": "SCE 301",
      "setup": "THEATRE",
      "typeId": 13473,
      "note": ""
    },
    {
      "id": 11562,
      "name": "SCE 605",
      "setup": "THEATRE",
      "typeId": 13473,
      "note": ""
    },
    {
      "id": 11568,
      "name": "SCE 613",
      "setup": "CLASSROOM",
      "typeId": 13476,
      "note": ""
    },
    {
      "id": 11570,
      "name": "Workshop Offsite",
      "setup": "NO_ROOM",
      "typeId": 13473
    },
    {
      "id": 11582,
      "name": "Bridgeport",
      "setup": "NO_ROOM",
      "typeId": 13525
    },
    {
      "id": 11625,
      "name": "Chicago Architecture Center",
      "setup": "NO_ROOM",
      "typeId": 13471
    },
    {
      "id": 11673,
      "name": "SCE 713",
      "setup": "CLASSROOM",
      "typeId": 13476,
      "note": ""
    },
    {
      "id": 11681,
      "name": "SCE 6th Floor Hall",
      "setup": "NO_ROOM",
      "typeId": 13471
    }
  ],
  "tracks": [
    {
      "id": 12825,
      "name": "Creativity & Cognition 2024 Pictorials",
      "typeId": 13524
    },
    {
      "id": 12826,
      "name": "Creativity & Cognition 2024 Artworks",
      "typeId": 13525
    },
    {
      "id": 12827,
      "name": "Creativity & Cognition 2024 Tutorials",
      "typeId": 13468
    },
    {
      "id": 12828,
      "name": "Creativity & Cognition 2024 Posters",
      "typeId": 13474
    },
    {
      "id": 12829,
      "name": "Creativity & Cognition 2024 Graduate Student Symposium",
      "typeId": 13470
    },
    {
      "id": 12830,
      "name": "Creativity & Cognition 2024 Technical Demonstrations",
      "typeId": 13469
    },
    {
      "id": 12831,
      "name": "Creativity & Cognition 2024 Workshops",
      "typeId": 13476
    },
    {
      "id": 12832,
      "name": "Creativity & Cognition 2024 Undergraduate Research",
      "typeId": 13626
    },
    {
      "id": 12833,
      "name": "Creativity & Cognition 2024 Papers",
      "typeId": 13473
    },
    {
      "id": 12932,
      "typeId": 13527
    },
    {
      "id": 12933,
      "typeId": 13625
    }
  ],
  "contentTypes": [
    {
      "id": 13468,
      "name": "Course",
      "displayName": "Courses",
      "color": "#66c2a4",
      "duration": 360
    },
    {
      "id": 13469,
      "name": "Demo",
      "displayName": "Demos",
      "color": "#006d2c",
      "duration": 120
    },
    {
      "id": 13470,
      "name": "Doctoral Consortium",
      "color": "#6baed6",
      "duration": 5
    },
    {
      "id": 13471,
      "name": "Event",
      "displayName": "Events",
      "color": "#ffc034",
      "duration": 0
    },
    {
      "id": 13473,
      "name": "Paper",
      "displayName": "Papers",
      "color": "#0d42cc",
      "duration": 20
    },
    {
      "id": 13474,
      "name": "Poster",
      "displayName": "Posters",
      "color": "#ff7a00",
      "duration": 120
    },
    {
      "id": 13476,
      "name": "Workshop",
      "displayName": "Workshops",
      "color": "#f60000",
      "duration": 420
    },
    {
      "id": 13477,
      "name": "Break",
      "color": "#7f6aff",
      "duration": 5
    },
    {
      "id": 13524,
      "name": "Pictorials",
      "color": "#006d2c",
      "duration": 20
    },
    {
      "id": 13525,
      "name": "Artwork",
      "color": "#8e008b",
      "duration": 150
    },
    {
      "id": 13526,
      "name": "Art Panel Presentation",
      "color": "#006d2c",
      "duration": 10
    },
    {
      "id": 13527,
      "name": "Invited Art Talk",
      "color": "#26e5f1",
      "duration": 30
    },
    {
      "id": 13625,
      "name": "Keynotes",
      "color": "#32d923",
      "duration": 75
    },
    {
      "id": 13626,
      "name": "UG Symposium Presentation",
      "color": "#8e008b",
      "duration": 0
    },
    {
      "id": 13627,
      "name": "UG Symposium Poster",
      "color": "#ff99ca",
      "duration": 120
    },
    {
      "id": 13628,
      "name": "UG Symposium Demo",
      "color": "#969696",
      "duration": 120
    }
  ],
  "timeSlots": [
    {
      "id": 13917,
      "type": "BREAK",
      "startDate": 1719131400000,
      "endDate": 1719133200000
    },
    {
      "id": 13918,
      "type": "SESSION",
      "startDate": 1719133200000,
      "endDate": 1719162000000
    },
    {
      "id": 13925,
      "type": "BREAK",
      "startDate": 1719216000000,
      "endDate": 1719219600000
    },
    {
      "id": 13926,
      "type": "SESSION",
      "startDate": 1719219600000,
      "endDate": 1719221400000
    },
    {
      "id": 13927,
      "type": "SESSION",
      "startDate": 1719221400000,
      "endDate": 1719225900000
    },
    {
      "id": 13928,
      "type": "BREAK",
      "startDate": 1719225900000,
      "endDate": 1719226800000
    },
    {
      "id": 13929,
      "type": "SESSION",
      "startDate": 1719226800000,
      "endDate": 1719230400000
    },
    {
      "id": 13930,
      "type": "LUNCH",
      "startDate": 1719230400000,
      "endDate": 1719237600000
    },
    {
      "id": 13931,
      "type": "SESSION",
      "startDate": 1719237600000,
      "endDate": 1719241200000
    },
    {
      "id": 13932,
      "type": "BREAK",
      "startDate": 1719241200000,
      "endDate": 1719242100000
    },
    {
      "id": 13933,
      "type": "SESSION",
      "startDate": 1719242100000,
      "endDate": 1719245700000
    },
    {
      "id": 13934,
      "type": "BREAK",
      "startDate": 1719252000000,
      "endDate": 1719261000000
    },
    {
      "id": 13935,
      "type": "BREAK",
      "startDate": 1719302400000,
      "endDate": 1719306900000
    },
    {
      "id": 13936,
      "type": "SESSION",
      "startDate": 1719306900000,
      "endDate": 1719307800000
    },
    {
      "id": 13937,
      "type": "SESSION",
      "startDate": 1719307800000,
      "endDate": 1719311400000
    },
    {
      "id": 13938,
      "type": "BREAK",
      "startDate": 1719311400000,
      "endDate": 1719312300000
    },
    {
      "id": 13939,
      "type": "SESSION",
      "startDate": 1719312300000,
      "endDate": 1719317700000
    },
    {
      "id": 13940,
      "type": "LUNCH",
      "startDate": 1719317700000,
      "endDate": 1719324000000
    },
    {
      "id": 13941,
      "type": "SESSION",
      "startDate": 1719324000000,
      "endDate": 1719327600000
    },
    {
      "id": 13942,
      "type": "SESSION",
      "startDate": 1719327600000,
      "endDate": 1719334800000
    },
    {
      "id": 13943,
      "type": "SESSION",
      "startDate": 1719338400000,
      "endDate": 1719347400000
    },
    {
      "id": 13944,
      "type": "BREAK",
      "startDate": 1719388800000,
      "endDate": 1719392400000
    },
    {
      "id": 13945,
      "type": "SESSION",
      "startDate": 1719392400000,
      "endDate": 1719393300000
    },
    {
      "id": 13946,
      "type": "SESSION",
      "startDate": 1719393300000,
      "endDate": 1719396000000
    },
    {
      "id": 13947,
      "type": "BREAK",
      "startDate": 1719398700000,
      "endDate": 1719399600000
    },
    {
      "id": 13948,
      "type": "SESSION",
      "startDate": 1719399600000,
      "endDate": 1719404100000
    },
    {
      "id": 13949,
      "type": "LUNCH",
      "startDate": 1719404100000,
      "endDate": 1719412200000
    },
    {
      "id": 13950,
      "type": "SESSION",
      "startDate": 1719412200000,
      "endDate": 1719415800000
    },
    {
      "id": 13951,
      "type": "BREAK",
      "startDate": 1719415800000,
      "endDate": 1719416700000
    },
    {
      "id": 13952,
      "type": "SESSION",
      "startDate": 1719416700000,
      "endDate": 1719419400000
    },
    {
      "id": 13953,
      "type": "SESSION",
      "startDate": 1719419400000,
      "endDate": 1719421200000
    },
    {
      "id": 13963,
      "type": "SESSION",
      "startDate": 1719334800000,
      "endDate": 1719338400000
    },
    {
      "id": 13984,
      "type": "SESSION",
      "startDate": 1719248400000,
      "endDate": 1719252000000
    },
    {
      "id": 14092,
      "type": "SESSION",
      "startDate": 1719396000000,
      "endDate": 1719398700000
    }
  ],
  "sessions": [
    {
      "id": 157531,
      "name": "Dance, Code, and Visual Strategies",
      "isParallelPresentation": false,
      "importedId": "14113",
      "typeId": 13473,
      "roomId": 11562,
      "chairIds": [
        157978
      ],
      "contentIds": [
        157781,
        157834,
        158020
      ],
      "source": "SYS",
      "timeSlotId": 13931
    },
    {
      "id": 157864,
      "name": "Award Session 2",
      "isParallelPresentation": false,
      "importedId": "14114",
      "typeId": 13473,
      "roomId": 11562,
      "chairIds": [
        157594
      ],
      "contentIds": [
        157856,
        157802,
        158024,
        157822
      ],
      "source": "SYS",
      "timeSlotId": 13939
    },
    {
      "id": 157865,
      "name": "Generative AI and Data",
      "isParallelPresentation": false,
      "importedId": "14115",
      "typeId": 13473,
      "roomId": 11561,
      "chairIds": [
        157631
      ],
      "contentIds": [
        157823,
        157859,
        158025
      ],
      "source": "SYS",
      "timeSlotId": 13931
    },
    {
      "id": 157866,
      "name": "Creativity and Working with AI",
      "isParallelPresentation": false,
      "importedId": "14116",
      "typeId": 13473,
      "roomId": 11562,
      "chairIds": [
        157692
      ],
      "contentIds": [
        157788,
        157782,
        157790
      ],
      "source": "SYS",
      "timeSlotId": 13929
    },
    {
      "id": 157867,
      "name": "Co-Creation",
      "isParallelPresentation": false,
      "importedId": "14117",
      "typeId": 13473,
      "roomId": 11561,
      "chairIds": [
        157699
      ],
      "contentIds": [
        157803,
        157838
      ],
      "source": "SYS",
      "timeSlotId": 13929
    },
    {
      "id": 157868,
      "name": "Cross-modal Creativity",
      "isParallelPresentation": false,
      "importedId": "14118",
      "typeId": 13473,
      "roomId": 11561,
      "chairIds": [
        165027
      ],
      "contentIds": [
        157800,
        157854,
        158011
      ],
      "source": "SYS",
      "timeSlotId": 13950
    },
    {
      "id": 157869,
      "name": "Communities of Creativity",
      "isParallelPresentation": false,
      "importedId": "14119",
      "typeId": 13473,
      "roomId": 11562,
      "chairIds": [
        164832
      ],
      "contentIds": [
        157808,
        157846,
        157793
      ],
      "source": "SYS",
      "timeSlotId": 13950
    },
    {
      "id": 157870,
      "name": "Poster and Demo Session",
      "isParallelPresentation": true,
      "importedId": "14120",
      "typeId": 13474,
      "roomId": 11561,
      "chairIds": [
        164826,
        164827
      ],
      "contentIds": [
        157933,
        157929,
        157934,
        157925,
        157918,
        157920,
        157921,
        157931,
        157919,
        157930,
        157928,
        157927,
        157922,
        157923,
        157932,
        157924,
        157935,
        157926,
        158037,
        166912,
        166913,
        166910,
        166909,
        166908,
        166907,
        166906,
        166911
      ],
      "source": "SYS",
      "timeSlotId": 13942
    },
    {
      "id": 158128,
      "name": "Undergraduate Student Symposium",
      "isParallelPresentation": false,
      "importedId": "14123",
      "typeId": 13474,
      "roomId": 11568,
      "chairIds": [
        157610,
        164828
      ],
      "contentIds": [
        158028,
        158029,
        158009,
        158010,
        158015,
        158014,
        158023,
        158012
      ],
      "source": "SYS",
      "timeSlotId": 13918
    },
    {
      "id": 158129,
      "name": "Art Exhibition and Reception",
      "isParallelPresentation": true,
      "importedId": "14124",
      "typeId": 13469,
      "roomId": 11582,
      "chairIds": [
        164831,
        165028
      ],
      "contentIds": [
        158030,
        158019,
        158033,
        158016,
        158031,
        158018,
        158035,
        158034,
        158032,
        158013,
        158017,
        166540
      ],
      "source": "SYS",
      "timeSlotId": 13943
    },
    {
      "id": 158132,
      "name": "Workshop 3 Full Day",
      "isParallelPresentation": false,
      "importedId": "14127",
      "typeId": 13476,
      "roomId": 11570,
      "chairIds": [],
      "contentIds": [
        158022
      ],
      "source": "SYS",
      "timeSlotId": 13918
    },
    {
      "id": 158149,
      "name": "Keynote: Carol Strohecker",
      "isParallelPresentation": false,
      "importedId": "14144",
      "typeId": 13625,
      "roomId": 11562,
      "chairIds": [
        165026
      ],
      "contentIds": [
        166902
      ],
      "source": "SYS",
      "timeSlotId": 13927
    },
    {
      "id": 158150,
      "name": "Keynote: Rubaiat Habib Kazi",
      "isParallelPresentation": false,
      "importedId": "14145",
      "typeId": 13625,
      "roomId": 11562,
      "chairIds": [
        165026
      ],
      "contentIds": [
        166901
      ],
      "source": "SYS",
      "timeSlotId": 13948
    },
    {
      "id": 158152,
      "name": "Graduate Student Symposium",
      "isParallelPresentation": false,
      "importedId": "14147",
      "typeId": 13470,
      "roomId": 11562,
      "chairIds": [
        164829,
        164830
      ],
      "contentIds": [
        157943,
        157944,
        157945,
        157942,
        157946,
        157947,
        157941
      ],
      "source": "SYS",
      "timeSlotId": 13918
    },
    {
      "id": 158153,
      "name": "Video and Moving Image",
      "isParallelPresentation": false,
      "importedId": "14148",
      "typeId": 13473,
      "roomId": 11562,
      "chairIds": [
        166895
      ],
      "contentIds": [
        157840,
        157863,
        157836
      ],
      "source": "SYS",
      "timeSlotId": 13933
    },
    {
      "id": 158177,
      "name": "Award Session 1",
      "isParallelPresentation": false,
      "importedId": "14172",
      "typeId": 13473,
      "roomId": 11562,
      "chairIds": [
        157615
      ],
      "contentIds": [
        157858,
        157842,
        157817
      ],
      "source": "SYS",
      "timeSlotId": 13937
    },
    {
      "id": 158200,
      "name": "Workshop 1 Full Day",
      "isParallelPresentation": false,
      "importedId": "14195",
      "typeId": 13476,
      "roomId": 11673,
      "chairIds": [],
      "contentIds": [
        158027
      ],
      "source": "SYS",
      "timeSlotId": 13918
    },
    {
      "id": 159835,
      "name": "Creativity, Feedback, and Ideas",
      "isParallelPresentation": false,
      "importedId": "14197",
      "typeId": 13473,
      "roomId": 11561,
      "chairIds": [
        157594
      ],
      "contentIds": [
        158203,
        157857,
        157815
      ],
      "source": "SYS",
      "timeSlotId": 13933
    },
    {
      "id": 159836,
      "name": "Invited Art Talk",
      "isParallelPresentation": false,
      "importedId": "14198",
      "typeId": 13527,
      "roomId": 11562,
      "chairIds": [
        164831
      ],
      "contentIds": [
        166897
      ],
      "source": "SYS",
      "timeSlotId": 13946
    },
    {
      "id": 166541,
      "name": "Art Panel",
      "isParallelPresentation": false,
      "importedId": "14378",
      "typeId": 13526,
      "roomId": 11562,
      "chairIds": [
        158007
      ],
      "contentIds": [
        166542,
        166543,
        166544,
        166545
      ],
      "source": "SYS",
      "timeSlotId": 14092
    }
  ],
  "events": [
    {
      "id": 158130,
      "name": "Conference Reception",
      "isParallelPresentation": false,
      "importedId": "14125",
      "typeId": 13471,
      "roomId": 11625,
      "chairIds": [],
      "contentIds": [],
      "startDate": 1719252000000,
      "endDate": 1719261000000,
      "presenterIds": [],
      "source": "SYS"
    },
    {
      "id": 158180,
      "name": "Opening Remarks",
      "isParallelPresentation": false,
      "importedId": "14175",
      "typeId": 13471,
      "roomId": 11562,
      "chairIds": [],
      "contentIds": [],
      "startDate": 1719219600000,
      "endDate": 1719221400000,
      "presenterIds": [],
      "source": "SYS"
    },
    {
      "id": 158181,
      "name": "Coffee Break",
      "isParallelPresentation": false,
      "importedId": "14176",
      "typeId": 13471,
      "roomId": 11562,
      "chairIds": [],
      "contentIds": [],
      "startDate": 1719225900000,
      "endDate": 1719226800000,
      "presenterIds": [],
      "source": "SYS"
    },
    {
      "id": 158182,
      "name": "Town Hall",
      "isParallelPresentation": false,
      "importedId": "14177",
      "typeId": 13471,
      "roomId": 11562,
      "chairIds": [],
      "contentIds": [],
      "startDate": 1719416700000,
      "endDate": 1719419400000,
      "presenterIds": [],
      "source": "SYS"
    },
    {
      "id": 158183,
      "name": "Coffee Break",
      "isParallelPresentation": false,
      "importedId": "14178",
      "typeId": 13471,
      "roomId": 11562,
      "chairIds": [],
      "contentIds": [],
      "startDate": 1719311400000,
      "endDate": 1719312300000,
      "presenterIds": [],
      "source": "SYS"
    },
    {
      "id": 158184,
      "name": "Coffee Break",
      "isParallelPresentation": false,
      "importedId": "14179",
      "typeId": 13471,
      "roomId": 11562,
      "chairIds": [],
      "contentIds": [],
      "startDate": 1719241200000,
      "endDate": 1719242100000,
      "presenterIds": [],
      "source": "SYS"
    },
    {
      "id": 158185,
      "name": "Lunch",
      "isParallelPresentation": false,
      "importedId": "14180",
      "typeId": 13471,
      "roomId": 11562,
      "chairIds": [],
      "contentIds": [],
      "startDate": 1719230400000,
      "endDate": 1719237600000,
      "presenterIds": [],
      "source": "SYS"
    },
    {
      "id": 158186,
      "name": "Lunch",
      "isParallelPresentation": false,
      "importedId": "14181",
      "typeId": 13471,
      "roomId": 11562,
      "chairIds": [],
      "contentIds": [],
      "startDate": 1719404100000,
      "endDate": 1719412200000,
      "presenterIds": [],
      "source": "SYS"
    },
    {
      "id": 158187,
      "name": "Lunch",
      "isParallelPresentation": false,
      "importedId": "14182",
      "typeId": 13471,
      "roomId": 11562,
      "chairIds": [],
      "contentIds": [],
      "startDate": 1719317700000,
      "endDate": 1719324000000,
      "presenterIds": [],
      "source": "SYS"
    },
    {
      "id": 158188,
      "name": "Opening Remarks",
      "isParallelPresentation": false,
      "importedId": "14183",
      "typeId": 13471,
      "roomId": 11562,
      "chairIds": [],
      "contentIds": [],
      "startDate": 1719306900000,
      "endDate": 1719307800000,
      "presenterIds": [],
      "source": "SYS"
    },
    {
      "id": 158189,
      "name": "Opening Remarks",
      "isParallelPresentation": false,
      "importedId": "14184",
      "typeId": 13471,
      "roomId": 11562,
      "chairIds": [],
      "contentIds": [],
      "startDate": 1719392400000,
      "endDate": 1719393300000,
      "presenterIds": [],
      "source": "SYS"
    },
    {
      "id": 158190,
      "name": "Diversity, Equity and Inclusion at Creativity & Cognition",
      "isParallelPresentation": false,
      "importedId": "14185",
      "typeId": 13471,
      "roomId": 11562,
      "chairIds": [
        158007
      ],
      "contentIds": [],
      "startDate": 1719324000000,
      "endDate": 1719327600000,
      "description": "This panel will discuss the power and importance of diversity and interdisciplinarity from a variety of perspectives, and how the conference series might progress towards accomplishing these goals.",
      "presenterIds": [
        158006,
        157699,
        157725,
        157730
      ],
      "source": "SYS"
    },
    {
      "id": 158191,
      "name": "Closing Remarks",
      "isParallelPresentation": false,
      "importedId": "14186",
      "typeId": 13471,
      "roomId": 11562,
      "chairIds": [],
      "contentIds": [],
      "startDate": 1719419400000,
      "endDate": 1719421200000,
      "presenterIds": [],
      "source": "SYS"
    },
    {
      "id": 158192,
      "name": "Coffee Break",
      "isParallelPresentation": false,
      "importedId": "14187",
      "typeId": 13471,
      "roomId": 11562,
      "chairIds": [],
      "contentIds": [],
      "startDate": 1719398700000,
      "endDate": 1719399600000,
      "presenterIds": [],
      "source": "SYS"
    },
    {
      "id": 158193,
      "name": "Coffee Break",
      "isParallelPresentation": false,
      "importedId": "14188",
      "typeId": 13471,
      "roomId": 11562,
      "chairIds": [],
      "contentIds": [],
      "startDate": 1719415800000,
      "endDate": 1719416700000,
      "presenterIds": [],
      "source": "SYS"
    },
    {
      "id": 158194,
      "name": "Registration",
      "isParallelPresentation": false,
      "importedId": "14189",
      "typeId": 13471,
      "roomId": 11681,
      "chairIds": [],
      "contentIds": [],
      "startDate": 1719131400000,
      "endDate": 1719133200000,
      "presenterIds": [],
      "source": "SYS"
    },
    {
      "id": 158195,
      "name": "Registration",
      "isParallelPresentation": false,
      "importedId": "14190",
      "typeId": 13471,
      "roomId": 11681,
      "chairIds": [],
      "contentIds": [],
      "startDate": 1719216000000,
      "endDate": 1719219600000,
      "presenterIds": [],
      "source": "SYS"
    },
    {
      "id": 158196,
      "name": "Registration",
      "isParallelPresentation": false,
      "importedId": "14191",
      "typeId": 13471,
      "roomId": 11681,
      "chairIds": [],
      "contentIds": [],
      "startDate": 1719388800000,
      "endDate": 1719392400000,
      "presenterIds": [],
      "source": "SYS"
    },
    {
      "id": 158197,
      "name": "Registration",
      "isParallelPresentation": false,
      "importedId": "14192",
      "typeId": 13471,
      "roomId": 11681,
      "chairIds": [],
      "contentIds": [],
      "startDate": 1719302400000,
      "endDate": 1719306900000,
      "presenterIds": [],
      "source": "SYS"
    },
    {
      "id": 159837,
      "name": "Buses to Art Venue",
      "isParallelPresentation": false,
      "importedId": "14199",
      "typeId": 13471,
      "chairIds": [],
      "contentIds": [],
      "startDate": 1719334800000,
      "endDate": 1719338400000,
      "location": "Street near student center",
      "presenterIds": [],
      "source": "SYS"
    },
    {
      "id": 163118,
      "name": "Buses to Reception",
      "isParallelPresentation": false,
      "importedId": "14200",
      "typeId": 13471,
      "chairIds": [],
      "contentIds": [],
      "startDate": 1719248400000,
      "endDate": 1719252000000,
      "location": "Street near student center",
      "presenterIds": [],
      "source": "SYS"
    }
  ],
  "contents": [
    {
      "id": 157781,
      "typeId": 13473,
      "title": "Centering Bodies in Space and Place through Virtual Reality Dance Performance: A Practice-Based Research Perspective",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24a-3567",
      "source": "PCS",
      "trackId": 12833,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        157531
      ],
      "eventIds": [],
      "abstract": "Our most cutting-edge virtual reality remains focused on visual perception over embodiment.  This article presents a dance performance project that stems from a foundation in somatics, creative dance, and HCI to embrace the challenge of centring bodies and embodiment within virtual reality dance performance. Our team of choreographers, dancers, and technologists recount the two-year development of the 360 video through ideation, movement tracking workshops, prototyping, process share-outs, to a final performance, to reflect on how our goal to centre bodies guided our artistic and technology choices throughout the entire process of making. Space became a key theme as we refined the choreography and design to use the full potentialities of the immersive environment. Place became a key theme as we prioritised configurations that enabled the performance to be showcased in the Pacific, Eastern Europe and Latin America. We discuss challenges and opportunities for supporting embodiment in virtual reality dance performance.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "New Zealand",
              "state": "Auckland",
              "city": "Auckland",
              "institution": "University of Auckland",
              "dsl": "Computer Science"
            }
          ],
          "personId": 157572
        },
        {
          "affiliations": [
            {
              "country": "New Zealand",
              "state": "N/A",
              "city": "Auckland",
              "institution": "University of Auckland",
              "dsl": ""
            }
          ],
          "personId": 157574
        },
        {
          "affiliations": [
            {
              "country": "New Zealand",
              "state": "",
              "city": "Auckland",
              "institution": "The University of Auckland",
              "dsl": ""
            }
          ],
          "personId": 157745
        },
        {
          "affiliations": [
            {
              "country": "New Zealand",
              "state": "Aucklnad",
              "city": "Auckland",
              "institution": "University of Auckland",
              "dsl": "Civil and Environmental Engineering"
            }
          ],
          "personId": 157622
        }
      ]
    },
    {
      "id": 157782,
      "typeId": 13473,
      "title": "MIMOSA: Human-AI Co-Creation of Computational Spatial Audio Effects on Videos",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24a-2358",
      "source": "PCS",
      "trackId": 12833,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        157866
      ],
      "eventIds": [],
      "abstract": "Spatial audio offers more immersive video consumption experiences to viewers; however, creating and editing spatial audio often expensive and requires specialized equipment and skills, posing a high barrier for amateur video creators. We present MIMOSA, a human-AI co-creation tool that enables amateur users to computationally generate and manipulate spatial audio effects. For a video with only monaural or stereo audio, MIMOSA automatically grounds each sound source to the corresponding sounding object in the visual scene and enables users to further validate and fix the errors in the locations of sounding objects. Users can also augment the spatial audio effect by flexibly manipulating the sounding source positions and creatively customizing the audio effect. The design of MIMOSA exemplifies a human-AI collaboration approach that, instead of utilizing state-of-art end-to-end \"black-box\" ML models, uses a multistep pipeline that aligns its interpretable intermediate results with the user’s workflow. A lab user study with 15 participants demonstrates MIMOSA’s usability, usefulness, expressiveness, and capability in creating immersive spatial audio effects in collaboration with users. ",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Indiana",
              "city": "Notre Dame",
              "institution": "University of Notre Dame",
              "dsl": "Department of Computer Science and Engineering"
            }
          ],
          "personId": 157701
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Indiana",
              "city": "Notre Dame",
              "institution": "University of Notre Dame",
              "dsl": "Department of Computer Science and Engineering"
            }
          ],
          "personId": 157744
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Indiana",
              "city": "Notre Dame",
              "institution": "University of Notre Dame",
              "dsl": "Department of Computer Science and Engineering"
            }
          ],
          "personId": 157681
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "La Jolla",
              "institution": "University of California San Diego",
              "dsl": "Jacobs School of Engineering"
            }
          ],
          "personId": 157696
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Pennsylvania",
              "city": "Pittsburgh",
              "institution": "Carnegie Mellon University",
              "dsl": "Department of electrical and computer engineering"
            }
          ],
          "personId": 157690
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Texas",
              "city": "Richardson",
              "institution": "University of Texas at Dallas",
              "dsl": "Department of Computer Science"
            }
          ],
          "personId": 157539
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Indiana",
              "city": "Notre Dame",
              "institution": "University of Notre Dame",
              "dsl": "Department of Computer Science and Engineering"
            }
          ],
          "personId": 157563
        }
      ]
    },
    {
      "id": 157788,
      "typeId": 13473,
      "title": "Creativity Support in the Age of Large Language Models: An Empirical Study Involving Professional Writers",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24a-7049",
      "source": "PCS",
      "trackId": 12833,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        157866
      ],
      "eventIds": [],
      "abstract": "The development of large language models (LLMs) capable of following instructions and engaging in conversational interactions has led to increased interest in their use across various support tools. We investigate the effectiveness of contemporary LLMs in assisting professional writers via an empirical user study (n=30). The design of our collaborative writing interface is grounded in the cognitive process model of writing. This allows writers to obtain model help in each of the three non-linear cognitive activities in the writing process: planning, translating and reviewing. Participants write short fiction/non-fiction with model help and are subsequently asked to submit a post-completion survey to provide qualitative feedback on the potential and pitfalls of LLMs as writing collaborators. Upon analyzing the writer-LLM interactions, we find that while seeking help across all three types of cognitive activities, writers find LLMs more helpful in translation and reviewing. Our findings from analyzing both the interactions and the survey responses highlight future research directions in creative writing assistance using LLMs.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New York",
              "city": "New York",
              "institution": "Columbia University",
              "dsl": "Computer Science"
            }
          ],
          "personId": 157642
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New York",
              "city": "New York",
              "institution": "New York University",
              "dsl": "Center for Data Science"
            }
          ],
          "personId": 157655
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Washington",
              "city": "Seattle",
              "institution": "ALLEN ALLEN INSTiTUTE FOR ARTiFiCiAL INTELLiGENCE (AI2) & UNiVERSiTY OF WASHiNGTON",
              "dsl": ""
            }
          ],
          "personId": 157549
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New York",
              "city": "New York",
              "institution": "Columbia University",
              "dsl": "Computer Science"
            }
          ],
          "personId": 157625
        }
      ]
    },
    {
      "id": 157790,
      "typeId": 13473,
      "title": "Evolving Roles and Workflows of Creative Practitioners in the Age of Generative AI",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24a-4973",
      "source": "PCS",
      "trackId": 12833,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        157866
      ],
      "eventIds": [],
      "abstract": "Creative practitioners (like designers, software developers, and architects) have started to employ Generative AI models (GenAI) to produce text, images, and assets comparable to those made by people. While HCI research explores specific GenAI models and creativity support tools, little is known about practitioners' evolving roles and workflows with GenAI models across a project's stages. This knowledge is key to guide the development of the new generation of Creativity Support Tools. We contribute to this knowledge by employing a triangulated method to capture interviews, videos, and survey responses of creative practitioners reflecting on projects they completed with GenAI. Our observations let us derive a set of factors that capture practitioners' perceived roles, challenges, benefits, and interaction patterns when creating with GenAI. \r\nFrom these factors, we offer insights and propose design opportunities and priorities that serve to encourage reflection from the wider community of Creativity Support Tools and GenAI stakeholders such as systems creators, researchers, and educators on how to develop systems that meet the needs of creatives in human-centered ways. ",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "San Diego",
              "institution": "University of California",
              "dsl": "Design Lab"
            }
          ],
          "personId": 157769
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Washington",
              "city": "Kirkland",
              "institution": "Microsoft Research",
              "dsl": ""
            }
          ],
          "personId": 157591
        }
      ]
    },
    {
      "id": 157793,
      "typeId": 13473,
      "title": "“The Gallery is Ephemeral”: Exploring the Intersection of Archival Practice and Technology in Artist-Run Initiatives. ",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24a-3444",
      "source": "PCS",
      "trackId": 12833,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        157869
      ],
      "eventIds": [],
      "abstract": "Artist-Run Initiatives (ARIs) are grassroots art galleries and project spaces that support artists by providing space for creative expression, experimentation, and exposure. While culturally important, these non-institutional collectives exist in precarious circumstances, with limited access to funding, heavy dependence on volunteers, and uncertainty in securing permanent space. We are particularly interested in how these issues intersect with ARIs’ uses of technology in archival practice. Through interviews with ARI committee members, our findings show intriguing perceptions of technological influence on archival practice, with concerns over reliance on cloud storage services, difficulties of digitising archival content, and how to present archived material on various digital platforms. We conclude with discussion on how future research might help support these communities to develop archival practices that are better suited to their practice.\r\n",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "",
              "city": "Newcastle upon Tyne",
              "institution": "Newcastle University",
              "dsl": "Open Lab"
            }
          ],
          "personId": 157751
        },
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "",
              "city": "Newcastle upon Tyne",
              "institution": "Newcastle University",
              "dsl": "Open Lab"
            }
          ],
          "personId": 157537
        }
      ]
    },
    {
      "id": 157800,
      "typeId": 13473,
      "title": "ThermalPen: Investigating the Influence of Thermal Haptic Feedback for Creativity in 3D Sketching",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24a-5265",
      "source": "PCS",
      "trackId": 12833,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        157868
      ],
      "eventIds": [],
      "abstract": "This paper presents ThermalPen, a novel device for 3D sketching that utilizes thermal feedback to allow users to feel the materiality of their sketches. The pen lets users draw using six colours and three textures mapped to different temperatures. Our goal is to investigate the influence of thermal feedback on user creativity for 3D sketching. In a user study with 24 participants, we asked them to draw with and without thermal feedback. Our results show that thermal feedback improved user creativity for specific tasks. Qualitative results also indicate an effect on the user experience. Our work contributes to understanding how thermal feedback can increase user satisfaction with 3D sketching and provide insights and directions for future work.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Darmstadt",
              "institution": "Technische Universität Darmstadt",
              "dsl": "Telecooperation Lab"
            }
          ],
          "personId": 157656
        },
        {
          "affiliations": [
            {
              "country": "Canada",
              "state": "Nova Scotia",
              "city": "Halifax",
              "institution": "Dalhousie University",
              "dsl": "HCI4Good, Faculty of Computer Science"
            }
          ],
          "personId": 157695
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Darmstadt",
              "institution": "TU Darmstadt",
              "dsl": "Telecooperation Lab"
            }
          ],
          "personId": 157755
        },
        {
          "affiliations": [
            {
              "country": "Canada",
              "state": "Nova Scotia",
              "city": "Halifax",
              "institution": "Dalhousie University",
              "dsl": "Faculty of Computer Science"
            }
          ],
          "personId": 157637
        }
      ]
    },
    {
      "id": 157802,
      "typeId": 13473,
      "title": "SHARP: Exploring Version Control Systems in Live Coding Music",
      "award": "HONORABLE_MENTION",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24a-4011",
      "source": "PCS",
      "trackId": 12833,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        157864
      ],
      "eventIds": [],
      "abstract": "Version control systems, which have proven essential for software engineering, can also provide value to creative and artistic practices. In this paper, we explore version control in the creative domain of live coding music, a generative performance practice where programmers edit and run code live to generate audiovisual artifacts. To that end, we developed SHARP, a lightweight version control system that live coders can use during performances as well as in preparation or practice sessions. We conducted a user study where live coders used SHARP for several weeks, wrote diary entries reflecting on their sessions, recorded a performance using SHARP, and participated in exit interviews. We found that SHARP enabled participants to engage with musical form on the fly in novel ways. In addition, the study revealed multifaceted perspectives on how and when versioning can be useful in the context of live coding. Our results inform the design of versioning systems for live coding and more generally for performance and generative arts practices.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Virginia",
              "city": "Blacksburg",
              "institution": "Virginia Tech",
              "dsl": ""
            }
          ],
          "personId": 157627
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Virginia",
              "city": "Blacksburg",
              "institution": "Virginia Tech",
              "dsl": ""
            }
          ],
          "personId": 157749
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Virginia",
              "city": "Blacksburg",
              "institution": "Virginia Tech",
              "dsl": ""
            }
          ],
          "personId": 157692
        }
      ]
    },
    {
      "id": 157803,
      "typeId": 13473,
      "title": "Perceptions of Interaction Dynamics in Co-Creative AI: A Comparative Study of Interaction Modalities in Drawcto",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24a-3434",
      "source": "PCS",
      "trackId": 12833,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        157867
      ],
      "eventIds": [],
      "abstract": "This paper explores how different interaction modalities with AI agents affect human perception of the co-creative process. We utilize the Wizard of Oz methodology within Drawcto, a co-creative drawing system, to examine co-creativity across three scenarios: human-human, human-robot, and human-software interactions. Using a mixed-methods approach, we combined insights using the Observable Creative Sensemaking (OCSM) method with data from structured interviews. The study involved 20 participants engaging in a collaborative drawing task under each interaction scenario. Key findings reveal an average OCSM curve indicative of typical human-human interactions, varied themes in human-AI collaboration, and a notable influence of AI embodiment on participant perceptions, with the robot interface resembling human-human collaboration more closely than the software interface. Overall, this research offers valuable insights into how different interaction modalities influence the perceived role of AI in the co-creative process and provides design considerations for enhancing human-AI co-creative interactions.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Georgia",
              "city": "Atlanta",
              "institution": "Georgia Institute of Technology",
              "dsl": "Digital Media"
            }
          ],
          "personId": 157675
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Georgia",
              "city": "Atlanta",
              "institution": "Georgia Institute of Technology",
              "dsl": "Digital Media"
            }
          ],
          "personId": 157547
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Georgia",
              "city": "Atlanta",
              "institution": "Georgia Institute of Technology",
              "dsl": "Digital Media"
            }
          ],
          "personId": 157756
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Georgia",
              "city": "Atlanta",
              "institution": "Georgia Tech",
              "dsl": ""
            }
          ],
          "personId": 157618
        }
      ]
    },
    {
      "id": 157808,
      "typeId": 13473,
      "title": "\"Different and Boundary-Pushing:\" How Blind and Low Vision Youth Live Code Together",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24a-3392",
      "source": "PCS",
      "trackId": 12833,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        157869
      ],
      "eventIds": [],
      "abstract": "Live coding, or real-time algorithmic performance, is a rich medium for engaging novices in informal creative STEM learning. However, despite inclusive and open-source communities, disabled practitioners are underrepresented in live coding, and prior work highlights numerous accessibility barriers. To understand the perspectives of Blind and Low Vision (BLV) live coders, we formed FiLOrk (Fil Laptop Orchestra) with five BLV teens. Across two semesters, FiLOrk performed three original works, each guided by a core concept and improvisational structure for manipulating code and maintaining shared awareness. We interviewed four musicians to understand how they felt about the learning environment and how their creative identities formed individually and in relation to one another. We reflect on FiLOrk's outcomes and propose strategies for future live coding ensembles to meaningfully include novices with and without disabilities.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "North Carolina",
              "city": "Chapel Hill",
              "institution": "University of North Carolina at Chapel Hill",
              "dsl": "Information and Library Science"
            }
          ],
          "personId": 157725
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New York",
              "city": "New York",
              "institution": "New York University",
              "dsl": ""
            }
          ],
          "personId": 157741
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New York",
              "city": "New York",
              "institution": "New York University",
              "dsl": ""
            }
          ],
          "personId": 157609
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New York",
              "city": "New York",
              "institution": "LiveCode.NYC",
              "dsl": ""
            }
          ],
          "personId": 157674
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New York",
              "city": "New York",
              "institution": "Filomen M. D'Agostino Greenberg Music School",
              "dsl": ""
            }
          ],
          "personId": 157648
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New York",
              "city": "New York",
              "institution": "New York University",
              "dsl": "Occupational Therapy / Technology, Culture, Society"
            }
          ],
          "personId": 157691
        }
      ]
    },
    {
      "id": 157815,
      "typeId": 13473,
      "title": "When to Give Feedback: Exploring Tradeoffs in the Timing of Design Feedback",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24a-9775",
      "source": "PCS",
      "trackId": 12833,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        159835
      ],
      "eventIds": [],
      "abstract": "Advances in AI have opened up the potential for creativity tools to computationally generate design feedback. In a future when designers can request feedback anytime on demand, how would the timing of these requests impact novices’ creative learning processes? What are the tradeoffs of providing access to feedback throughout a design task (in-action) versus only providing feedback after (on-action)? We explored these questions through a Wizard-of-Oz study (N=20) using an interactive design probe, where participants could request feedback either throughout the design process or only after they complete a full draft. We found that in-action participants frequently request feedback, resulting in better improvements as indicated by a greater decrease in issues in their final design. However, we saw that in-action feedback can also risk users overly relying on feedback instead of engaging in more holistic self-evaluation. We discuss the implications of our insights on designing tools for creative feedback.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "La Jolla",
              "institution": "University of California San Diego",
              "dsl": ""
            }
          ],
          "personId": 157699
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "San Diego",
              "institution": "UCSD",
              "dsl": "Cognitive Science"
            }
          ],
          "personId": 157565
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "San Diego",
              "institution": "UC San Diego",
              "dsl": ""
            }
          ],
          "personId": 157587
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "San Diego",
              "institution": "University of California San Diego",
              "dsl": ""
            }
          ],
          "personId": 157728
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "San Diego",
              "institution": "UCSD",
              "dsl": ""
            }
          ],
          "personId": 157576
        },
        {
          "affiliations": [
            {
              "country": "Korea, Republic of",
              "state": "",
              "city": "Daejeon",
              "institution": "KAIST",
              "dsl": "School of Computing"
            }
          ],
          "personId": 157601
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "La Jolla",
              "institution": "University of California San Diego",
              "dsl": ""
            }
          ],
          "personId": 157559
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "San Diego",
              "institution": "University of California, San Diego",
              "dsl": "Department of Cognitive Science and Design Lab"
            }
          ],
          "personId": 157716
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "La Jolla",
              "institution": "University of California, San Diego",
              "dsl": "Dept of Cognitive Science"
            }
          ],
          "personId": 157672
        }
      ]
    },
    {
      "id": 157817,
      "typeId": 13473,
      "title": "Reflection Across AI-based Music Composition",
      "award": "HONORABLE_MENTION",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24a-1201",
      "source": "PCS",
      "trackId": 12833,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        158177
      ],
      "eventIds": [],
      "abstract": "Reflection is fundamental to creative practice. However, the plurality of ways in which people reflect when using AI Generated Content (AIGC) is underexplored. This paper takes AI-based music composition as a case study to explore how artist-researcher composers reflected when integrating AIGC into their music composition process. The AI tools explored range from Markov Chains for music generation to Variational Auto-Encoders for modifying timbre. We used a novel method where our composers would pause and reflect back on screenshots of their composing after every hour, using this documentation to write first-person accounts showcasing their subjective viewpoints on their experience. We triangulate the first-person accounts with interviews and questionnaire measures to contribute descriptions on how the composers reflected. For example, we found that many composers reflect on future directions in which to take their music whilst curating AIGC. Our findings contribute to supporting future explorations on reflection in creative HCI contexts.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "",
              "city": "London",
              "institution": "Queen Mary University of London",
              "dsl": ""
            }
          ],
          "personId": 157631
        },
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "",
              "city": "London",
              "institution": "Queen Mary University of London",
              "dsl": ""
            }
          ],
          "personId": 157641
        },
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "",
              "city": "London",
              "institution": "Queen Mary University of London",
              "dsl": ""
            }
          ],
          "personId": 157687
        },
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "",
              "city": "London",
              "institution": "Queen Mary University of London",
              "dsl": ""
            }
          ],
          "personId": 157630
        },
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "",
              "city": "London",
              "institution": "Queen Mary University of London",
              "dsl": ""
            }
          ],
          "personId": 157652
        },
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "",
              "city": "London",
              "institution": "Queen Mary University of London",
              "dsl": ""
            }
          ],
          "personId": 157735
        },
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "",
              "city": "London",
              "institution": "Queen Mary University of London",
              "dsl": ""
            }
          ],
          "personId": 157736
        },
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "",
              "city": "York",
              "institution": "University of York",
              "dsl": ""
            }
          ],
          "personId": 157722
        },
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "",
              "city": "London",
              "institution": "University of the Arts London",
              "dsl": "Creative Computing Institute"
            }
          ],
          "personId": 157532
        }
      ]
    },
    {
      "id": 157822,
      "typeId": 13473,
      "title": "“My ideas come little by little”: how graphic professionals manage ideas",
      "award": "HONORABLE_MENTION",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24a-3107",
      "source": "PCS",
      "trackId": 12833,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        157864
      ],
      "eventIds": [],
      "abstract": "To understand and support creative work, we need to look at its manifestation in everyday professional practice. We do so by focusing on the core activity of capturing and managing material representations of ideas, i.e. idea management. Starting from previous empirical research in other domains, we devise a theoretical framework and extend it in the domain of Graphics. Combining a qualitative survey (n=48) and in-depth interviews (n=15), we look for unexpected themes that emerge only among graphic professionals. We expand the existing knowledge in four main ways: we identify what makes a graphic idea \\textit{good} compared to other domains, we observe that practitioners balance conflicting creative identities with consequences on their idea management needs, that graphic ideas are sculpted out of inspirational material, and that creative control is negotiated with clients and collaborators.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "La Jolla",
              "institution": "University of California San Diego",
              "dsl": "Cognitive Science"
            },
            {
              "country": "Denmark",
              "state": "",
              "city": "Aarhus",
              "institution": "University of Aarhus",
              "dsl": "Centre for Digital Creativity"
            }
          ],
          "personId": 157577
        },
        {
          "affiliations": [
            {
              "country": "Denmark",
              "state": "",
              "city": "Aarhus",
              "institution": "Aarhus University",
              "dsl": "Centre for Digital Creativity"
            }
          ],
          "personId": 157560
        }
      ]
    },
    {
      "id": 157823,
      "typeId": 13473,
      "title": "Using Incongruous Genres to Explore Music Making with AI Generated Content",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24a-6977",
      "source": "PCS",
      "trackId": 12833,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        157865
      ],
      "eventIds": [],
      "abstract": "Deep learning generative AI models trained on huge datasets are capable of producing complex and high quality music. However, there are few studies of how AI Generated Content (AIGC) is actually used or appropriated in creative practice. We present two first-person accounts by musician-researchers of explorations of an interactive generative AI system trained on Irish Folk music. The AI is intentionally used by musicians from incongruous genres of Punk and Glitch to explore questions of how the model is appropriated into creative practice and how it changes creative practice when used outside of its intended genre. Reflections on the first-person accounts highlight issues of control, ambiguity, trust, and filtering AIGC. The accounts also highlight the role of AI as an audience and critic and how the musicians’ practice changed in response to the AIGC. We suggest that our incongruous approach may help to foreground the creative work and frictions in human-AI creative practice.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "",
              "city": "London",
              "institution": "University of the Arts London",
              "dsl": "Creative Computing Institute"
            }
          ],
          "personId": 157532
        },
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "",
              "city": "London",
              "institution": "Queen Mary University of London",
              "dsl": ""
            }
          ],
          "personId": 157641
        },
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "",
              "city": "London",
              "institution": "Queen Mary University of London",
              "dsl": ""
            }
          ],
          "personId": 157631
        }
      ]
    },
    {
      "id": 157834,
      "typeId": 13473,
      "title": "Body and Code: A Distributed Cognition Exploration Into Dance and Computing Learning",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24a-9328",
      "source": "PCS",
      "trackId": 12833,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        157531
      ],
      "eventIds": [],
      "abstract": "Representational forms are central to how we explore, communicate, and learn. Yet they can be challenging to engage with as designers because they vary across disciplines, cultures, and communities. In this paper, we study a dance and computing learning environment through the lens of distributed cognition to examine how representations and processing of information across people and systems impacted the learning process. We analyzed video and audio data from three workshops of dance and STEM instructors learning about, creating with, and co-designing computing activities with danceON—a creative computing platform that supports coding animations over dance videos. We identified the ways that the instructors used their bodies as a shared point of negotiation while co-creating dance artifacts, the participatory role of danceON within the sensemaking process, the ways that the instructors interpreted and translated representations across physical and digital spaces, and the impact of the instructors’ collaborative interactions to their sensemaking.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New York",
              "city": "New York",
              "institution": "New York University",
              "dsl": "Steinhardt School of Culture, Education, and Human Development"
            }
          ],
          "personId": 157730
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New York",
              "city": "New York",
              "institution": "New York University",
              "dsl": ""
            }
          ],
          "personId": 157579
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New York",
              "city": "New York City",
              "institution": "New York University",
              "dsl": "Interactive Telecommunications Program, Tisch School of the Arts"
            }
          ],
          "personId": 157698
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New York",
              "city": "New York",
              "institution": "New York University",
              "dsl": "Steinhardt - Administration, Leadership, and Technology"
            }
          ],
          "personId": 157543
        }
      ]
    },
    {
      "id": 157836,
      "typeId": 13473,
      "title": "How Example-Based Authoring of Motion Graphics Impacts Creative Expression: Differences in Perceptions of Professional and Casual Motion Designers",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24a-5325",
      "source": "PCS",
      "trackId": 12833,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        158153
      ],
      "eventIds": [],
      "abstract": "Motion graphics authoring is a time-intensive endeavor, demanding proficiency in various feature-rich software. Automated, example-based solutions are now being explored to simplify the process of creating motion graphics. To investigate how such streamlined authoring tools impact motion designers' workflows and perceptions of creativity, we deployed an end-to-end motion graphics authoring tool to 14 users, spanning casual to professional design expertise. Our key findings reveal a dichotomy: casual designers embraced the tool's automation, finding empowerment in its simplicity, even at the expense of losing narrative control. Conversely, professionals expressed reservations and raised concerns about the trade-offs between efficiency and creative autonomy. Notably, the level of automation in animation emerged as a point of contention, underscoring differing expectations between the two groups. Our work contributes insights into such nuances, offering implications for designing the next generation of motion graphics authoring tools that cater to a broad spectrum of creative aspirations and abilities.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Canada",
              "state": "British Columbia",
              "city": "Surrey",
              "institution": "Simon Fraser University",
              "dsl": "Interactive Art and Technology"
            }
          ],
          "personId": 157661
        },
        {
          "affiliations": [
            {
              "country": "Canada",
              "state": "British Columbia",
              "city": "Burnaby",
              "institution": "Simon Fraser University",
              "dsl": "Computing Science"
            }
          ],
          "personId": 157595
        }
      ]
    },
    {
      "id": 157838,
      "typeId": 13473,
      "title": "Exploring the Potential for Generative AI-based Conversational Cues for Real-Time Collaborative Ideation",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24a-3587",
      "source": "PCS",
      "trackId": 12833,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        157867
      ],
      "eventIds": [],
      "abstract": "What is the potential value and role for AI to facilitate real-time creative discussions? The paper explores principles for Generative-AI based conversational support by investigating how humans -- playing the role of an AI agent -- generate contextual conversational cues to guide an ideation session. We studied n=42 people (14 triads) brainstorming through a remote meeting design probe that allows a wizard facilitator to oversee the ideation and send text-based cues that appear real-time in the ideator interface. Thematic analysis of conversations, cues and post-hoc reflections by facilitators uncovered focal points, strategies and challenges. Notably, 44\\% of the cues sent out by the facilitators were either dismissed or ignored because they did not notice the cue update. When ideators did notice cues, certain facilitator strategies impacted the conversation more than others. Based on our analysis, we present design opportunities to improve generative AI-based systems to better support real-time creative collaborations.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "San Diego",
              "institution": "University of California, San Diego",
              "dsl": "Department of Cognitive Science and Design Lab"
            },
            {
              "country": "United States",
              "state": "California",
              "city": "San Diego",
              "institution": "University of California, San Diego",
              "dsl": "Department of Cognitive Science and Design Lab"
            }
          ],
          "personId": 157664
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "San Diego",
              "institution": "University of California San Diego",
              "dsl": ""
            },
            {
              "country": "United States",
              "state": "California",
              "city": "San Diego",
              "institution": "University of California San Diego",
              "dsl": ""
            }
          ],
          "personId": 157665
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "San Diego",
              "institution": "UCSD",
              "dsl": "Design Lab"
            },
            {
              "country": "United States",
              "state": "California",
              "city": "San Diego",
              "institution": "UCSD",
              "dsl": "Design Lab"
            }
          ],
          "personId": 157708
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New York",
              "city": "New York City",
              "institution": "New York University",
              "dsl": ""
            },
            {
              "country": "United States",
              "state": "New York",
              "city": "New York City",
              "institution": "New York University",
              "dsl": ""
            }
          ],
          "personId": 157639
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "San Diego",
              "institution": "University of California",
              "dsl": "Design Lab"
            },
            {
              "country": "United States",
              "state": "California",
              "city": "San Diego",
              "institution": "University of California",
              "dsl": "Design Lab"
            }
          ],
          "personId": 157769
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "San Diego",
              "institution": "University of California, San Diego",
              "dsl": "Department of Cognitive Science and Design Lab"
            },
            {
              "country": "United States",
              "state": "California",
              "city": "San Diego",
              "institution": "University of California, San Diego",
              "dsl": "Department of Cognitive Science and Design Lab"
            }
          ],
          "personId": 157716
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "La Jolla",
              "institution": "University of California, San Diego",
              "dsl": "Dept of Cognitive Science"
            },
            {
              "country": "United States",
              "state": "California",
              "city": "La Jolla",
              "institution": "University of California, San Diego",
              "dsl": "Dept of Cognitive Science"
            }
          ],
          "personId": 157672
        }
      ]
    },
    {
      "id": 157840,
      "typeId": 13473,
      "title": "VideoMap: Supporting Video Exploration, Brainstorming, and Prototyping in the Latent Space",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24a-4273",
      "source": "PCS",
      "trackId": 12833,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        158153
      ],
      "eventIds": [],
      "abstract": "Video editing is a creative and complex endeavor and we believe that there is potential for reimagining a new video editing interface to better support the creative and exploratory nature of video editing. We take inspiration from latent space exploration tools that help users find patterns and connections within complex datasets. We present VideoMap, a proof-of-concept video editing interface that operates on video frames projected onto a latent space. We support intuitive navigation through map-inspired navigational elements and facilitate transitioning between different latent spaces through swappable lenses. We built three VideoMap components to support editors in three common video tasks. In a user study with both professionals and non-professionals, editors found that VideoMap helps reduce grunt work, offers a user-friendly experience, provides an inspirational way of editing, and effectively supports the exploratory nature of video editing. We further demonstrate the versatility of VideoMap by implementing three extended applications.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Pennsylvania",
              "city": "Pittsburgh",
              "institution": "Carnegie Mellon University",
              "dsl": "Human-Computer Interaction Institute"
            }
          ],
          "personId": 157614
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "San Jose",
              "institution": "Adobe Research",
              "dsl": ""
            }
          ],
          "personId": 157660
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "San Jose",
              "institution": "Adobe Research",
              "dsl": ""
            }
          ],
          "personId": 157632
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Washington",
              "city": "Seattle",
              "institution": "Adobe Research",
              "dsl": ""
            }
          ],
          "personId": 157763
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Pennsylvania",
              "city": "Pittsburgh",
              "institution": "Carnegie Mellon University",
              "dsl": "Human-Computer Interaction Institute"
            }
          ],
          "personId": 157538
        }
      ]
    },
    {
      "id": 157842,
      "typeId": 13473,
      "title": "Improving Selection of Analogical Inspirations through Chunking and Recombination",
      "award": "HONORABLE_MENTION",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24a-3538",
      "source": "PCS",
      "trackId": 12833,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        158177
      ],
      "eventIds": [],
      "abstract": "Analogies can be a powerful source of new ideas; however, creators often fail to recognize and harness potentially beneficial analogical leads, especially from other problem domains. In this paper, we introduce AnalogiLead, an interactive interface designed to reduce premature dismissal of analogies by facilitating playful exploration of analogical leads. Drawing on cognitive mechanisms of conceptual chunking and recombination, AnalogiLead scaffolds users to engage with meaningful chunks of problems and analogies and recombine them into inspiring brainstorming questions. In a within-subjects experiment, participants (N=23) who used AnalogiLead dismissed analogies 4x less often, with 12x fewer decision changes, compared to a baseline interface with no chunking or recombination. This reduction in premature dismissal was associated with ~64% longer processing time. Through qualitative analysis of video and think-aloud data, we describe how the chunking and recombination mechanisms facilitated playful engagement with analogies. These findings highlight opportunities and challenges for improving analogical innovation through careful theory-driven design of interfaces for selecting analogical leads.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Denmark",
              "state": "",
              "city": "Aarhus",
              "institution": "Aarhus University",
              "dsl": "Department of Computer Science"
            }
          ],
          "personId": 157592
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Maryland",
              "city": "College Park",
              "institution": "University of Maryland",
              "dsl": "College of Information Studies"
            }
          ],
          "personId": 157594
        }
      ]
    },
    {
      "id": 157846,
      "typeId": 13473,
      "title": "Shared, Shaped, and Stolen: Tracing Sites of Knowledge Transfer across Creative Communities of Practice",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24a-4789",
      "source": "PCS",
      "trackId": 12833,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        157869
      ],
      "eventIds": [],
      "abstract": "Within various creative domains, communities of practice (CoPs) are instrumental in fostering knowledge creation and innovation. Although each community disseminates knowledge through resources like online video tutorials, this content is often hidden behind different contexts and semantics that limits practitioners' ability to learn, borrow, and adapt knowledge from each other. To trace how knowledge disseminates across CoPs, we analyzed video transcripts across 25 communities and characterized them using Term Frequency Proportional Document Frequency (TF*PDF) of extracted materials, tools, and techniques concepts. Using a cluster heatmap visualization, we   reveal material and material parallels as boundaries for umbrella CoPs, techniques as strong predictors of kindred CoPs, and outliers as emerging sites of hybrid CoPs. We discuss implications for the design of knowledge discovery support tools to characterize material workflows, track knowledge evolution, and develop semantic vocabularies.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Texas",
              "city": "Arlington",
              "institution": "University of Texas at Arlington",
              "dsl": "Computer Science & Engineering"
            }
          ],
          "personId": 157561
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Texas",
              "city": "Arlington",
              "institution": "University of Texas at Arlington",
              "dsl": "Computer Science & Engineering"
            }
          ],
          "personId": 157750
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Texas",
              "city": "Arlington",
              "institution": "UT Arlington",
              "dsl": ""
            }
          ],
          "personId": 157610
        }
      ]
    },
    {
      "id": 157854,
      "typeId": 13473,
      "title": "A Shared Affinity for Complexity: Exploring Cross-Modal Aesthetic Experiences",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24a-6083",
      "source": "PCS",
      "trackId": 12833,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        157868
      ],
      "eventIds": [],
      "abstract": "Previous studies have suggested human preference for artworks with greater image complexity. Here we aim to further explore the impact of complexity on aesthetic experiences in both visual and auditory domains. Twenty-eight college students were tasked with viewing pairs of abstract paintings by Ely Raman and indicating their preference using a two-alternative forced choice procedure. Following this, they listened to Western tonal music for five seconds and completed a simple choice reaction task. A longer reaction time was taken as an indication of greater immersion in the music and, consequently, a stronger preference. Our findings confirmed a preference for complexity in both visual and auditory modalities. Additionally, a notable correlation was observed between the inclination towards complexity in the visual domain and that in the auditory domain, lending support to the Taste Typicality as an explanation for aesthetic experiences.\r\n",
      "authors": [
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Zhuhai, Guangdong Province",
              "institution": "BNU-HKBU United international College",
              "dsl": "Applied Psychology Programme"
            }
          ],
          "personId": 157551
        },
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Zhuhai",
              "institution": "BNU-HKBU United International College",
              "dsl": "Guangdong Provincial Key Laboratory IRADS"
            },
            {
              "country": "China",
              "state": "",
              "city": "Zhuhai",
              "institution": "BNU-HKBU United International College",
              "dsl": "Applied Psychology Programme"
            }
          ],
          "personId": 157578
        }
      ]
    },
    {
      "id": 157856,
      "typeId": 13473,
      "title": "Homogenization Effects of Large Language Models on Human Creative Ideation",
      "award": "BEST_PAPER",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24a-3058",
      "source": "PCS",
      "trackId": 12833,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        157864
      ],
      "eventIds": [],
      "abstract": "Large language models (LLMs) are now being used in a wide variety of contexts, including as creativity support tools (CSTs) intended to help their users come up with new ideas. But do LLMs actually support user creativity? We hypothesized that the use of an LLM as a CST might make the LLM’s users feel more creative, and even broaden the range of ideas suggested by each individual user, but also homogenize the ideas suggested by different users. We conducted a 36-participant comparative user study and found, in accordance with the homogenization hypothesis, that different users tended to produce less semantically distinct ideas with ChatGPT than with an alternative CST. Additionally, ChatGPT users generated a greater number of more detailed ideas, but also felt less responsible for the ideas they generated. We discuss potential implications of these findings for users, designers, and developers of LLM-based CSTs.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "Santa Cruz",
              "institution": "Independent Researcher",
              "dsl": ""
            }
          ],
          "personId": 157757
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "Santa Clara",
              "institution": "Santa Clara University",
              "dsl": ""
            }
          ],
          "personId": 157638
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "Santa Clara",
              "institution": "Santa Clara University",
              "dsl": ""
            }
          ],
          "personId": 157767
        }
      ]
    },
    {
      "id": 157857,
      "typeId": 13473,
      "title": "Idea-Centric Search: Four Patterns of Information Seeking During Creative Ideation",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24a-1271",
      "source": "PCS",
      "trackId": 12833,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        159835
      ],
      "eventIds": [],
      "abstract": "As search evolves and Generative AI enables users to express more complex information needs and goals, it is an opportune moment to investigate how the search for information influences creativity. Little is known about how creators --- especially novices who lack domain-specific terminology --- use web search when developing an idea, and vice versa, how new information shapes an idea. To investigate how ideas evolve through web search, we conducted an online lab study with 56 design students who engaged in a 3-week product redesign project. Through a mixed-method analysis of web search logs, surveys, and interviews, we report on the different search behaviors, strategies, challenges and four distinct patterns--Orienters, Refiners, Confirmers, and Pivoters--that illustrate how the impact of search depends on the maturity of an idea. We discuss design opportunities to enhance web search systems for ideation and pedagogical interventions to teach creators how to improve idea-centric search. ",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "La Jolla",
              "institution": "University of California, San Diego",
              "dsl": "Dept of Cognitive Science"
            }
          ],
          "personId": 157721
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "San Diego",
              "institution": "University of California",
              "dsl": "Design Lab"
            }
          ],
          "personId": 157769
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "La Jolla",
              "institution": "University of California, San Diego",
              "dsl": "ProtoLab"
            }
          ],
          "personId": 157775
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "La Jolla",
              "institution": "UC San Diego",
              "dsl": "PrototLab"
            }
          ],
          "personId": 157711
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "La Jolla",
              "institution": "University of California, San Diego",
              "dsl": "Dept of Cognitive Science"
            }
          ],
          "personId": 157672
        }
      ]
    },
    {
      "id": 157858,
      "typeId": 13473,
      "title": "Get Your Hands Dirty? A Comparative Study of Tool Usage and Perceptual Engagement in Physical and Digital Sculpting",
      "award": "HONORABLE_MENTION",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24a-1194",
      "source": "PCS",
      "trackId": 12833,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        158177
      ],
      "eventIds": [],
      "abstract": "The creation of 3D content, crucial in various applications, is often challenging and time-intensive. While digital tools are prevalent for 3D content creation, traditional clay sculpting offers an embodied experience that fosters artists' perceptual engagement with physical space, enhancing their interactive and cognitive connection with the creation process. We conducted an eight-day live sculpting session at an art academy, systematically comparing the creative workflows of eight professional artists in both physical and digital mediums. Our qualitative and quantitative analysis include artists' differences in tool usage between physical and digital sculpting, variations in visual and tactile perceptual engagement, and the potential for future integration of the two modalities. Our study provides insights into the benefits of physical and digital sculpting and may inform future design of hybrid interfaces for 3D content creation.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Guangzhou",
              "institution": "The Hong Kong University of Science and Technology (Guangzhou)",
              "dsl": "Computational Media and Arts"
            }
          ],
          "personId": 157754
        },
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Guangzhou",
              "institution": "Hong Kong University of Science and Technology (Guangzhou)",
              "dsl": ""
            }
          ],
          "personId": 157653
        },
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Guangzhou",
              "institution": "South China University of Technology",
              "dsl": ""
            }
          ],
          "personId": 157550
        },
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Hang Zhou",
              "institution": "China Academy of Art",
              "dsl": "Sculpture and Public Art/Interdisciplinary Sculpture Research Institute "
            }
          ],
          "personId": 157542
        },
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Hangzhou",
              "institution": "China Academy of Art",
              "dsl": "Sculpture and Public Art /Interdisciplinary Sculpture Research Institute "
            }
          ],
          "personId": 157626
        },
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Guangzhou",
              "institution": "The Hong Kong University of Science and Technology (Guangzhou)",
              "dsl": "Computational Media and Arts"
            }
          ],
          "personId": 157590
        }
      ]
    },
    {
      "id": 157859,
      "typeId": 13473,
      "title": "Ai.llude: Investigating Rewriting AI-Generated Text to Support Creative Expression",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24a-5830",
      "source": "PCS",
      "trackId": 12833,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        157865
      ],
      "eventIds": [],
      "abstract": "In each step of the creative writing process, writers must grapple with their creative goals and individual perspectives. This process affects the writer’s sense of authenticity and their engagement with the written output. Fluent text generation by AIs risks undermining the reflective loop of rewriting. We hypothesize that deliberately generating imperfect intermediate text can encourage rewriting and prompt higher level decision making. Using logs from 27 writing sessions using a text generation AI, we characterize how writers adapt and rewrite AI suggestions, and show that intermediate suggestions significantly motivate and increase rewriting. We discuss the implications of this finding, and future steps for investigating how to leverage intermediate text in AI writing support tools to support ownership over creative expression. ",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Illinois",
              "city": "Urbana",
              "institution": "University of Illinois Urbana-Champaign",
              "dsl": ""
            }
          ],
          "personId": 157548
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Illinois",
              "city": "Urbana",
              "institution": "University of Illinois, Urbana-Champaign",
              "dsl": ""
            }
          ],
          "personId": 157761
        }
      ]
    },
    {
      "id": 157863,
      "typeId": 13473,
      "title": "Videogenic: Identifying Highlight Moments in Videos with Professional Photographs as a Prior",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24a-2043",
      "source": "PCS",
      "trackId": 12833,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        158153
      ],
      "eventIds": [],
      "abstract": "This paper investigates the challenge of extracting highlight moments from videos. To perform this task, we need to understand what constitutes a highlight for arbitrary video domains while at the same time being able to scale across different domains. Our key insight is that photographs taken by photographers tend to capture the most remarkable or photogenic moments of an activity. Drawing on this insight, we present Videogenic, a technique capable of creating domain-specific highlight videos for a diverse range of domains. In a human evaluation study (N=50), we show that a high-quality photograph collection combined with CLIP-based retrieval (which uses a neural network with semantic knowledge of images) can serve as an excellent prior for finding video highlights. In a within-subjects expert study (N=12), we demonstrate the usefulness of Videogenic in helping video editors create highlight videos with lighter workload, shorter task completion time, and better usability.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Pennsylvania",
              "city": "Pittsburgh",
              "institution": "Carnegie Mellon University",
              "dsl": "Human-Computer Interaction Institute"
            }
          ],
          "personId": 157614
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "San Jose",
              "institution": "Adobe Research",
              "dsl": ""
            }
          ],
          "personId": 157660
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "San Jose",
              "institution": "Adobe Research",
              "dsl": ""
            }
          ],
          "personId": 157632
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Washington",
              "city": "Seattle",
              "institution": "Adobe Research",
              "dsl": ""
            }
          ],
          "personId": 157763
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Pennsylvania",
              "city": "Pittsburgh",
              "institution": "Carnegie Mellon University",
              "dsl": "Human-Computer Interaction Institute"
            }
          ],
          "personId": 157538
        }
      ]
    },
    {
      "id": 157918,
      "typeId": 13474,
      "title": "Creative Insights into Motion: Enhancing Human Activity Understanding with 3D Data Visualization and Annotation ",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24e-1053",
      "source": "PCS",
      "trackId": 12828,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        157870
      ],
      "eventIds": [],
      "abstract": "This paper presents a novel 3D system for human motion analysis - Motion Data Visualization and Annotation (MoViAn). Designed to provide a comprehensive visual representation of 3D human motion data, MoViAn incorporates detailed visualization of gaze direction, hand movements, and object interactions, alongside an interactive interface for efficient data annotation. A user study involving eight participants indicates that MoViAn enables users to thoroughly explore and annotate human motion data, with System Usability Scale (SUS) results demonstrating a satisfactory usability level. The contribution of this paper lies in the development of an interactive and usable data analytics tool aimed at deepening the understanding of human behaviors and intentions in various creative, cognitive, and physical activities that ultimately can facilitate the design and creation of innovative tools that enhance human life in multiple domains.\r\n",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "Orange",
              "institution": "Chapman University",
              "dsl": "Fowler School of Engineering"
            }
          ],
          "personId": 157909
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "Orange",
              "institution": "Chapman University",
              "dsl": ""
            }
          ],
          "personId": 157643
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "Orange",
              "institution": "Chapman University",
              "dsl": "Fowler School of Engineering"
            }
          ],
          "personId": 157605
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "Orange",
              "institution": "Chapman University",
              "dsl": "Fowler School of Engineering"
            }
          ],
          "personId": 157680
        }
      ]
    },
    {
      "id": 157919,
      "typeId": 13474,
      "title": "From Digital Practices to Bond Formation: A Mixed-Method Case Study of BTS Online Fandom Communities",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24e-1041",
      "source": "PCS",
      "trackId": 12828,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        157870
      ],
      "eventIds": [],
      "abstract": "Through this poster submission I present my ongoing investigation into the dynamics of interpersonal relationships within online fandom communities, specifically focusing on the BTS fandom community known as ARMY. Amid the digital era's paradox of increased content creation and consumption alongside declining meaningful social interactions, I hope to identify online fandom communities as unique spaces where interpersonal relationships not only thrive but contribute to the sustainability of these digital communities. Using a case study approach on the ARMY fandom, which expanded during the pandemic, my research aims to dissect the nuances of relationship formation and sustainability. Through a combination of literature review, online diary studies, interviews, and digital ethnography, I explore how fans engage, and support each other, nurturing a sense of community. Initial findings highlight the interplay between personal and collective identity formation, the supportive role of community spaces, the impact of social support on well-being, and a profound sense of belonging among members. This study offers valuable perspectives on designing digital spaces that foster strong social connections.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Indiana",
              "city": "West Lafayette",
              "institution": "Purdue University",
              "dsl": ""
            }
          ],
          "personId": 157875
        }
      ]
    },
    {
      "id": 157920,
      "typeId": 13474,
      "title": "DataBites: An embodied and co-creative museum exhibit to foster children’s understanding of supervised machine learning",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24e-1040",
      "source": "PCS",
      "trackId": 12828,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        157870
      ],
      "eventIds": [],
      "abstract": "It is essential to increase children’s understanding of artificial intelligence\r\nand machine learning as they encounter it through their\r\ndaily activities. We have developed DataBites, a museum exhibit\r\naimed at fostering middle-school-age children’s understanding of\r\nsupervised machine learning. DataBites engages visitors in learning\r\nabout the steps and practices of supervised machine learning, using\r\nthree guiding design principles: embodied interaction, creativity,\r\nand collaboration. Our design allows learners to use tangible pieces\r\nto collaboratively create their own labeled examples of pizzas and\r\nsandwiches to include in a training dataset for an image-based\r\nmachine-learning pizza/sandwich classification algorithm. The algorithm\r\ncan classify sandwiches and pizzas by learning patterns\r\nfrom people’s examples. Learners can view the results and self-evaluate\r\nhow well their dataset did at enabling the algorithm to\r\ndistinguish between the two items. This poster paper contributes a\r\nnovel design and approach to engaging children in learning about\r\nAI in museum settings.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Illinois",
              "city": "Evanston",
              "institution": "Northwestern University",
              "dsl": "Computer Science"
            }
          ],
          "personId": 157897
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Illinois",
              "city": "Evanston",
              "institution": "Northwestern University",
              "dsl": "Computer Science"
            }
          ],
          "personId": 157915
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Illinois",
              "city": "Evanston",
              "institution": "Northwestern University",
              "dsl": "Department of Communication Studies"
            }
          ],
          "personId": 157615
        }
      ]
    },
    {
      "id": 157921,
      "typeId": 13474,
      "title": "Designing AI with Metaphors: Leveraging Ambiguity and Defamiliarization to Support Design Creativity",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24e-1060",
      "source": "PCS",
      "trackId": 12828,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        157870
      ],
      "eventIds": [],
      "abstract": "Existing literature on designing AI technologies has largely focused on personifying the AI system as a human-like \"agent\" with a persona, using metaphors like \"collaborator\" or \"teammate.\"  However, these personifying metaphors may have problematic consequences and do not reflect the full breadth of the design space for human-AI interaction.  We report the design process of, and initial results from, a participatory speculative design workshop that supports participants in designing AI systems using novel, non-human metaphors.  We articulate two current design recommendations for interaction or workshop designers interested in AI and metaphors: Defamiliarization of AI supports creative interpretation of ambiguous metaphors and Explicit metaphorical thinking scaffolds participants’ use of ambiguity as a resource.  We also discuss two potential results suggested by our initial data collection: Ambiguous metaphorical thinking may support groups negotiating values and The term AI may limit attempts at defamiliarization.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Illinois",
              "city": "Urbana",
              "institution": "University of Illinois Urbana-Champaign",
              "dsl": ""
            }
          ],
          "personId": 157904
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Illinois",
              "city": "Urbana",
              "institution": "University of Illinois Urbana-Champaign",
              "dsl": ""
            }
          ],
          "personId": 157880
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Illinois",
              "city": "Urbana",
              "institution": "University of Illinois, Urbana-Champaign",
              "dsl": ""
            }
          ],
          "personId": 157761
        }
      ]
    },
    {
      "id": 157922,
      "typeId": 13474,
      "title": "Reconstructing Identity: An Augmented Reality Exploring Self-Objectification",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24e-1006",
      "source": "PCS",
      "trackId": 12828,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        157870
      ],
      "eventIds": [],
      "abstract": "Reconstructing Identity harnesses Augmented Reality (AR) technology to prompt introspection and dialogue on identity and societal roles in an era of upheaval and unpredictability. It offers a space for contemplation and experimentation. The work invites audiences into a virtual overlay of reality, allowing them to engage with and reflect on the complexities of self-identity and societal expectations. By integrating AR, the artwork creates an immersive environment, enhancing the interaction between the audience and the art. This approach emphasizes the potential of AR in deepening the understanding of our place in a complex world and exploring personal identity. In this artwork, AR enables a deeper connection with the audience, encouraging them to contemplate and experiment with the deconstruction of self-objectification.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New York",
              "city": "Brooklyn",
              "institution": "Pratt Institute",
              "dsl": ""
            }
          ],
          "personId": 157913
        },
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Shenzhen",
              "institution": "Harbin Institute of Technology",
              "dsl": "Shenzhen International School of Design"
            },
            {
              "country": "China",
              "state": "",
              "city": "Taipa",
              "institution": "University of Macau",
              "dsl": "Faculty of Social Science"
            }
          ],
          "personId": 157917
        },
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Hong Kong SAR",
              "institution": "Hong Kong University of Science and Technology",
              "dsl": "Academy of Interdisciplinary Studies"
            },
            {
              "country": "China",
              "state": "",
              "city": "Hong Kong SAR",
              "institution": "Hong Kong Polytechnic University",
              "dsl": "School of Design"
            }
          ],
          "personId": 157879
        }
      ]
    },
    {
      "id": 157923,
      "typeId": 13474,
      "title": "Selection of technologies during design learning activities in an undergraduate course",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24e-1037",
      "source": "PCS",
      "trackId": 12828,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        157870
      ],
      "eventIds": [],
      "abstract": "One of the most frequent problems with using maker technologies, especially for students, is the selection of technology during the prototyping stage. Few studies have focused on the variables that influence students' choice of technology when learning about interactive prototyping. In this study, the variables influencing students' technology choices when they interactive prototypes are examined. We performed a study based on interviews with undergraduate students involved in using technologies to prototype interactivities at a design school. We analyzed the students’ artworks and discussions using the grounded theory framework. The electrical and communication properties of the components, along with the socio-technical environment in which the students are learning, are important considerations when choosing components. Our findings provide educational practitioners with significant information and clarify the necessity of more research and the redesign of boards and components. ",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Italy",
              "state": "",
              "city": "Urbino",
              "institution": "University of Urbino",
              "dsl": ""
            }
          ],
          "personId": 157887
        }
      ]
    },
    {
      "id": 157924,
      "typeId": 13474,
      "title": "Subtle Visual Cues in Mixed Reality: Influencing User Perception and Facilitating Interaction",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24e-1048",
      "source": "PCS",
      "trackId": 12828,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        157870
      ],
      "eventIds": [],
      "abstract": "This paper introduces and investigates the use of subtle visual cues in Mixed Reality (MR) interfaces to blend digital content with the physical world, enhancing user experience. With Extended Reality (XR) technologies becoming more common, creating immersive environments that effectively combine digital and physical elements is crucial. Traditional MR methods often inadequately integrate 2D and 3D digital content into physical settings.\r\n\r\nThis research addresses these issues by incorporating visual cues such as shadows, lighting, textures, blur, and distortions into MR interfaces. These cues are designed to enhance the perception of objects within the physical environment, intuitively convey information, and minimize conventional interface distractions.\r\n\r\nThe paper includes multiple use cases and user tests to evaluate the effectiveness of these cues. The results inform design enhancements, striving to better integrate visual cues in XR to bridge the gap between digital content and the physical world. This study advances MR by demonstrating how subtle visual adjustments can improve user interactions, making digital elements appear as natural components of the user's environment.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Pennsylvania",
              "city": "Pittsburgh",
              "institution": "Carnegie Mellon University",
              "dsl": ""
            }
          ],
          "personId": 157899
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Pennsylvania",
              "city": "pittsburgh",
              "institution": "Carnegie Mellon University",
              "dsl": ""
            }
          ],
          "personId": 157882
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Pennsylvania",
              "city": "PITTSBURGH ",
              "institution": "Carnegie Mellon University",
              "dsl": "School of Design"
            }
          ],
          "personId": 157891
        }
      ]
    },
    {
      "id": 157925,
      "typeId": 13474,
      "title": "Communicating Design Intent Using Drawing and Text",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24e-1036",
      "source": "PCS",
      "trackId": 12828,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        157870
      ],
      "eventIds": [],
      "abstract": "Realizing a designer's intent in software currently requires tedious manipulation of geometric primitives, such as points and curves.\r\nBy contrast, designers routinely communicate more abstract design goals to one another using an efficient combination of natural language and drawings.\r\nWhat would it take to develop artificial systems that understand how humans naturally convey design intent, and thereby enable more seamless interactions between humans and machines throughout the design process?\r\nFirst, it is vital to establish benchmarks that showcase the full range of strategies that humans use to successfully communicate about design intent. \r\nHere we take initial steps towards that goal by conducting an online study in which pairs of human participants -- a ``Designer'' and ``Maker'' -- collaborated over multiple turns to recreate target designs.\r\nIn each turn, Designers sent messages containing language, drawings, or both to the Maker, describing how to modify an existing design toward the target. \r\nWe found a preference for communicating using drawings in early turns and observed several multimodal strategies for conveying design intent. \r\nBy comparing how human Makers and GPT-4V carried out instructions, we identify a gap in human and machine understanding of multimodal instructions and suggest a path for bridging this gap.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "La Jolla",
              "institution": "University of California, San Diego",
              "dsl": "Cognitive Science"
            },
            {
              "country": "United States",
              "state": "California",
              "city": "San Francisco",
              "institution": "Autodesk",
              "dsl": ""
            }
          ],
          "personId": 157884
        },
        {
          "affiliations": [
            {
              "country": "Canada",
              "state": "Ontario",
              "city": "Toronto",
              "institution": "Autodesk Research",
              "dsl": ""
            }
          ],
          "personId": 157898
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "San Francisco",
              "institution": "Autodesk",
              "dsl": ""
            }
          ],
          "personId": 157895
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "Stanford",
              "institution": "Stanford University",
              "dsl": "Psychology"
            }
          ],
          "personId": 157896
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "San Francisco",
              "institution": "Autodesk",
              "dsl": ""
            }
          ],
          "personId": 157905
        }
      ]
    },
    {
      "id": 157926,
      "typeId": 13474,
      "title": "touchBase: A Tangible Programming Language for Physical Computing",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24e-1047",
      "source": "PCS",
      "trackId": 12828,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        157870
      ],
      "eventIds": [],
      "abstract": "Tangible programming languages (TPL) involve physical objects, often interlocking blocks, that represent computer programming elements. Users connect TPL blocks in logical chains to construct code that typically controls the behavior of another device. Designed for young children, they offer a playful and embodied approach to computer science education. While these systems have proven to be effective for teaching beginner programming constructs, the complexity of TPL code is often limited, which also limits the types of problems that learners can engage with. Our work explores how integrating visual design elements into the design of a TPL can support greater complexity in programming concepts, a smoother transition to advanced programming settings, and enhanced learner expression. We present touchBase, a TPL for physical computing that leverages principles of Gestalt psychology to demonstrate the importance of considering the uniquely multimodal cognitive experience when designing tangible tools for computer science education. ",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New York",
              "city": "Brooklyn",
              "institution": "New York University",
              "dsl": ""
            }
          ],
          "personId": 157910
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New York",
              "city": "New York City",
              "institution": "New York University",
              "dsl": "Interactive Telecommunications Program, Tisch School of the Arts"
            }
          ],
          "personId": 157698
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New York",
              "city": "BROOKLYN",
              "institution": "New York University",
              "dsl": "LEARN"
            }
          ],
          "personId": 157903
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New York",
              "city": "Brooklyn",
              "institution": "New York University",
              "dsl": ""
            }
          ],
          "personId": 157916
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New York",
              "city": "New York",
              "institution": "New York University",
              "dsl": "Steinhardt - Administration, Leadership, and Technology"
            }
          ],
          "personId": 157543
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New York",
              "city": "New York",
              "institution": "New York University",
              "dsl": "Steinhardt School of Culture, Education, and Human Development"
            }
          ],
          "personId": 157730
        }
      ]
    },
    {
      "id": 157927,
      "typeId": 13474,
      "title": "MS Slide Designer: A Study on Human-AI Collaboration for Content Creation",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24e-1024",
      "source": "PCS",
      "trackId": 12828,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        157870
      ],
      "eventIds": [],
      "abstract": "Human-AI collaboration can be used to improve people’s competency in the creative content space. Nevertheless, users struggle to partner with AI to create aesthetic and coherent content. Through our study, participants create slide presentations and use the Microsoft Slide Designer AI tool as part of their design process. Thereafter, our team conducts user interviews to understand the users' experience, observe the kind of AI suggestions users accept, and learn about AI teaching good slide design. The study highlights that the tool is good at recognizing context of words, but the user’s control over the presentation process is limited, resulting in an iterative slide creation process. Based on the findings collected, our research suggests strategies through which humans can perform more effective human-AI collaboration in the creative content space. For instance, MS Designer should be more interpretable seen through a new feature suggestion asking for tags with each design recommendation.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Illinois",
              "city": "Urbana",
              "institution": "University of Illinois, Urbana-Champaign",
              "dsl": "Department of Computer Science"
            },
            {
              "country": "United States",
              "state": "California",
              "city": "Sunnyvale",
              "institution": "Juniper Networks Inc.",
              "dsl": ""
            }
          ],
          "personId": 157901
        }
      ]
    },
    {
      "id": 157928,
      "typeId": 13474,
      "title": "Knowledge Net: Fostering Children's Understanding of Knowledge Representations Through Creative Making and Embodied Interaction in a Museum Exhibit",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24e-1046",
      "source": "PCS",
      "trackId": 12828,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        157870
      ],
      "eventIds": [],
      "abstract": "As young people increasingly use AI in their daily lives, it is imperative to foster these learners’ AI literacy. We present Knowledge Net, a collaborative tangible tabletop museum exhibit aimed at teaching users about knowledge representations, which are central to understanding AI and understudied in AI education research. In this exhibit, we center creative making and embodied interaction by allowing learners to craft the appearance, behaviors, and traits of characters in a virtual world by manipulating semantic networks. Our poster features the exhibit design and corresponding rationale, and this paper contributes an exploration of how creative making and embodied interaction can be utilized to teach young learners about knowledge representations--and AI more broadly--in informal learning environments.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Illinois",
              "city": "Evanston",
              "institution": "Northwestern University",
              "dsl": ""
            }
          ],
          "personId": 157876
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Illinois",
              "city": "Evanston",
              "institution": "Northwestern University",
              "dsl": ""
            }
          ],
          "personId": 157888
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Illinois",
              "city": "Evanston",
              "institution": "Northwestern University",
              "dsl": ""
            }
          ],
          "personId": 157902
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Illinois",
              "city": "Evanston",
              "institution": "Northwestern University",
              "dsl": ""
            }
          ],
          "personId": 157908
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Illinois",
              "city": "Evanston",
              "institution": "Northwestern University",
              "dsl": "Department of Communication Studies"
            }
          ],
          "personId": 157615
        }
      ]
    },
    {
      "id": 157929,
      "typeId": 13474,
      "title": "CoCo Matrix: Taxonomy of Cognitive Contributions in Co-writing with Intelligent Agents",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24e-1056",
      "source": "PCS",
      "trackId": 12828,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        157870
      ],
      "eventIds": [],
      "abstract": "In recent years, there has been a growing interest in employing intelligent agents in writing. Previous work emphasizes the evaluation of the end product-a polished coherent written piece. However, the journey to that product remains an invaluable dimension of the creative process. To understand how to recognize human efforts in co-writing with intelligent writing systems, we adapt Flower and Hayes’ cognitive process theory of writing and propose CoCo Matrix, a two-dimensional taxonomy of entropy and information gain, to depict the new human-agent co-writing model. We define four quadrants and situate thirty-four published systems within the taxonomy. Our research found that low entropy and high information gain systems are under-explored, yet offer promising future directions in writing tasks that benefit from the agent’s divergent planning and the human’s focused translation. As the landscape of writing tools embraces AI, CoCo has implications in writing assistant tool design as well as in the domain of writing pedagogy.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Indiana",
              "city": "South Bend",
              "institution": "University of Notre Dame",
              "dsl": "Department of Computer Science and Engineering"
            }
          ],
          "personId": 157893
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Indiana",
              "city": "Notre Dame",
              "institution": "University of Notre Dame",
              "dsl": "Department of Computer Science and Engineering"
            }
          ],
          "personId": 157877
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Indiana",
              "city": "Notre Dame",
              "institution": "University of Notre Dame",
              "dsl": "Department of Computer Science and Engineering"
            }
          ],
          "personId": 157563
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Indiana",
              "city": "South Bend",
              "institution": "University of Notre Dame",
              "dsl": " Department of Computer Science and Engineering"
            }
          ],
          "personId": 157894
        }
      ]
    },
    {
      "id": 157930,
      "typeId": 13474,
      "title": "How do video content creation goals impact which concepts people prioritize for generating B-roll imagery?",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24e-1023",
      "source": "PCS",
      "trackId": 12828,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        157870
      ],
      "eventIds": [],
      "abstract": "B-roll is vital to producing high-quality videos. However, while text-to-image generation models can streamline B-roll production, it remains unclear how these tools support content creators with different goals. Toward closing this gap, we aimed to understand how creator's goals guide which visual concepts they prioritize for B-roll generation. We introduce a benchmark containing judgments from >800 people as to which terms across 12 video transcripts have highest priority for B-roll accompaniment. We verified that participants reliably prioritized different visual concepts depending on whether they prioritized video informativity or entertainment. We next explored how various heuristic algorithms and LLMs could predict human judgments, but found that none fully captured judgments in either goal condition, with state-of-the-art LLMs (i.e., GPT-4) underperforming a baseline that sampled only nouns or nouns and adjectives. Overall, our work identifies opportunities for improvement in future algorithms aimed at streamlining video production workflows.\r\n",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "La Jolla",
              "institution": "University of California, San Diego",
              "dsl": "Psychology"
            }
          ],
          "personId": 157907
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "San Francisco",
              "institution": "Adobe Research",
              "dsl": ""
            }
          ],
          "personId": 157889
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Washington",
              "city": "Seattle",
              "institution": "Adobe Research",
              "dsl": ""
            }
          ],
          "personId": 157912
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "Palo Alto",
              "institution": "Adobe Systems",
              "dsl": "Adobe Research"
            }
          ],
          "personId": 157900
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "Stanford",
              "institution": "Stanford University",
              "dsl": "Psychology"
            }
          ],
          "personId": 157896
        }
      ]
    },
    {
      "id": 157931,
      "typeId": 13474,
      "title": "Fostering AI Literacy with LuminAI through Embodiment and Creativity in Informal Learning Spaces",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24e-1033",
      "source": "PCS",
      "trackId": 12828,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        157870
      ],
      "eventIds": [],
      "abstract": "LuminAI is an interactive art installation that allows participants to collaborate with an AI dance partner by improvising movements. During the interaction, the participant dances with an AI dance partner who learns from the participant's movements in real-time and remixes them into new, unexpected forms of motion. LuminAI blurs the lines between the participant and AI agent, inviting the participant to improvise and engage with AI in a dance of creativity. Recently, we've redesigned LuminAI with the educational purpose of enhancing the public's AI literacy. We separated LuminAI into three panels with AI-related educational goals for each panel and redesigned the user interaction. In this paper, we present the redesign of LuminAI and educational goals centering on enhancing the public's AI literacy.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Georgia",
              "city": "Atlanta",
              "institution": "Georgia Institute of Technology",
              "dsl": "Expressive Machinery Lab"
            }
          ],
          "personId": 157693
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Georgia",
              "city": "Atlanta",
              "institution": "Georgia Institute of Technology",
              "dsl": ""
            }
          ],
          "personId": 157911
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Georgia",
              "city": "Atlanta",
              "institution": "Georgia Institute of Technology",
              "dsl": "Literature, Media, and Communication"
            }
          ],
          "personId": 157886
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Georgia",
              "city": "Atlanta",
              "institution": "Georgia Institute of Technology",
              "dsl": "Express Machinery Lab"
            }
          ],
          "personId": 157890
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Georgia",
              "city": "Atlanta",
              "institution": "Georgia Tech",
              "dsl": ""
            }
          ],
          "personId": 157873
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Georgia",
              "city": "Atlanta",
              "institution": "Georgia Insitute of Technology",
              "dsl": "Expressive Machinery Lab"
            }
          ],
          "personId": 158127
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Georgia",
              "city": "Atlanta",
              "institution": "Georgia Tech",
              "dsl": ""
            }
          ],
          "personId": 157618
        }
      ]
    },
    {
      "id": 157932,
      "typeId": 13474,
      "title": "Story Shaker: A System for Parental Involvement in Relationships Between Siblings with a Large Age Gap",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24e-1044",
      "source": "PCS",
      "trackId": 12828,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        157870
      ],
      "eventIds": [],
      "abstract": "Sibling relationships are the longest-lasting relationships in a family and have significant impacts on both individuals and the family. However, when there is a large age gap, the physical and social distances caused by the age difference can make it difficult to maintain closeness in these relationships. In this paper, we propose the Story Shaker system, consisting of storytelling machine hardware and a story-based interaction strategy, aimed at involving parents to enhance relationships between siblings with a large age gap. Story Shaker provides parents with story models, inspiring them to narrate children's stories to the younger sibling based on the older sibling's life experiences. This paper introduces Story Shaker, a story-based interaction strategy, and usability research. The results show that Story Shaker can enhance the relationships between siblings with a significant age difference, and the introduction of interactive strategies involving parents can provide opportunities for deeper communication between them.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Hangzhou",
              "institution": "Computer Science and Technology",
              "dsl": "Zhejiang University"
            },
            {
              "country": "China",
              "state": "",
              "city": "Jiaxing",
              "institution": "Innovation Center of Yangtze River Delta, Zhejiang University",
              "dsl": "Future Design Laboratory"
            }
          ],
          "personId": 157881
        },
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Hangzhou",
              "institution": "College of Computer Science and Technology",
              "dsl": "Zhejiang University"
            }
          ],
          "personId": 157883
        },
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "MACAU",
              "institution": "MACAU University of Science and Technology",
              "dsl": ""
            }
          ],
          "personId": 157906
        }
      ]
    },
    {
      "id": 157933,
      "typeId": 13474,
      "title": "AI-Yo: Embedding Psychosocial Aspects In the Fashion Stylist Chatbot Design",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24e-1021",
      "source": "PCS",
      "trackId": 12828,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        157870
      ],
      "eventIds": [],
      "abstract": "Fashion serves as a means to not only present an enhanced version of oneself but also to actively become a better individual through its influence. Meanwhile, the rapid development of AI technology has brought more possibilities in the tech-assisted personal fashion domain. We review the literature regarding imitation theory, fashion psychology, and the changes in fashion paradigms. Leveraging these theories, we propose a future personalized fashion solution: a fashion stylist chatbot that is capable of generating inspirational fashion styles on virtual representations of our bodies. Differentiating from previous work, this solution can help us build our wardrobe starting from thinking about our psychosocial aspects.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "China",
              "state": "Guangdong",
              "city": "Shenzhen",
              "institution": "Harbin Institute of Technology",
              "dsl": "Shenzhen International School of Design"
            }
          ],
          "personId": 157885
        },
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Shenzhen",
              "institution": "Harbin Institute of Technology",
              "dsl": "Shenzhen International School of Design"
            }
          ],
          "personId": 157917
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Illinois",
              "city": "Urbana",
              "institution": "University of Illinois at Urbana Champaign",
              "dsl": "Computer Science"
            }
          ],
          "personId": 157874
        },
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Shenzhen",
              "institution": "Harbin Institute of Technology",
              "dsl": "Shenzhen International School of Design"
            }
          ],
          "personId": 157914
        }
      ]
    },
    {
      "id": 157934,
      "typeId": 13474,
      "title": "Cognitive Operations and Patterns in Remote Design Collaboration: A Protocol Study",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24e-1043",
      "source": "PCS",
      "trackId": 12828,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        157870
      ],
      "eventIds": [],
      "abstract": "While remote Computer Supported Cooperative Work (CSCW) offer unprecedented opportunities for collaboration and innovation, it also posts unique challenges in shaping design team cognition (DTC). To address this knowledge gap in understanding DTC during remote teamwork, this research introduces a new coding scheme and conducts protocol analysis on nine online design sessions. The findings of this study focus on examining the dynamics of design operations and patterns during remote teamwork, highlighting the interconnected nature of the three cognitive dimensions – ‘representation’ (R), ‘communication’ (C), and ‘allocation’ (A) – in the R-C-A framework. The study demonstrates that the R-C-A framework offers a valuable approach to examining cognitive operations and patterns in remote design collaboration. Furthermore, the insights gained from this research hold the potential to enrich and optimise design collaboration in remote CSCW, thereby contributing to advancements in design practice and education.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Australia",
              "state": "",
              "city": "Sydney",
              "institution": "The University of New South Wales",
              "dsl": "School of Built Environment"
            }
          ],
          "personId": 157878
        }
      ]
    },
    {
      "id": 157935,
      "typeId": 13474,
      "title": "The Digital Blossoming: Generative Flowers of Ethnic Wisdom",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24e-1009",
      "source": "PCS",
      "trackId": 12828,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        157870
      ],
      "eventIds": [],
      "abstract": "This research explores the computational empowerment of intangible cultural heritage through interactive generative platforms. Prototypes in TouchDesigner software visualize traditional Kam minority patterns by applying particle system effects to highlight symbolic meanings. Users actively transform heritage visuals through real-time interaction, fostering cultural appreciation. Technical realization involves visual programming to construct specialized generative workflows. Phases of diffusion and dissipation of culturally significant motifs are configured procedurally. Preliminary explorations will inform training generative AI models by discerning cultural logic. The goal is an adaptive living database where tradition evolves algorithmically. This pioneering approach synergizes heritage and technology to maintain intangible culture. It provides a model for participatory digital curation where communities actively shape legacies. Limitations around complexity persist. However, the research pioneers cultural resilience through computational creativity.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Hong Kong SAR",
              "institution": "Hong Kong Polytechnic University",
              "dsl": "School of Design"
            }
          ],
          "personId": 157879
        },
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Shenzhen",
              "institution": "Harbin Institute of Technology",
              "dsl": "Shenzhen International School of Design"
            }
          ],
          "personId": 157917
        },
        {
          "affiliations": [
            {
              "country": "China",
              "state": "Guangdong",
              "city": "guangzhou",
              "institution": "Guangzhou Academy of Fine Arts",
              "dsl": "Guangzhou Academy of Fine Arts"
            }
          ],
          "personId": 157871
        },
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Zhuhai",
              "institution": "Beijing Normal University",
              "dsl": ""
            }
          ],
          "personId": 157872
        },
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Chengdu",
              "institution": "Southwest Minzu University",
              "dsl": ""
            }
          ],
          "personId": 157892
        }
      ]
    },
    {
      "id": 157941,
      "typeId": 13470,
      "title": "Overcoming challenges to personal narrative co-writing with AI: A participatory design approach for under-resourced high school students and those that support them",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24f-1014",
      "source": "PCS",
      "trackId": 12829,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        158152
      ],
      "eventIds": [],
      "abstract": "Our proposed research seeks to design co-writing AI systems to preserve the writer’s personal voice and maintain evaluation integrity with under-resourced high school students applying to college.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Illinois",
              "city": "Evanston",
              "institution": "Northwestern University",
              "dsl": "Technology and Social Behavior Program"
            }
          ],
          "personId": 157937
        }
      ]
    },
    {
      "id": 157942,
      "typeId": 13470,
      "title": "Creative Explainable AI Tools to Understand Algorithmic Decision-Making",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24f-1013",
      "source": "PCS",
      "trackId": 12829,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        158152
      ],
      "eventIds": [],
      "abstract": "This doctoral research aims to to design interactive Explainable AI (XAI) tools in response to the challenge of fostering AI literacy among adults without technical expertise. The tools developed thus far focus on edge detection, confidence thresholds, and sensitivity, and were designed based on principles from learning sciences and user-centered design to make AI accessible and ethically reflective. My efforts have resulted in successful design, implementation, and preliminary evaluation. Conducted with 42 adult participants, the study reveals notable improvements in familiarity with and confidence in discussing AI concepts. Qualitative feedback highlights user engagement and enhanced understanding, demonstrating immediate impact and laying a foundation for ongoing work. Looking forward, my work will delve deeper into how non-experts can critically engage with AI's decision-making processes, understand algorithmic trade-offs, and consider how AI can better serve society. This approach broadens AI literacy and leverages cognitive principles for creative and ethical technological interventions.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Illinois",
              "city": "Evanston",
              "institution": "Northwestern University",
              "dsl": ""
            }
          ],
          "personId": 157938
        }
      ]
    },
    {
      "id": 157943,
      "typeId": 13470,
      "title": "Every Body Dance Now: What Dancers with Disabilities Can Teach HCI",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24f-1012",
      "source": "PCS",
      "trackId": 12829,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        158152
      ],
      "eventIds": [],
      "abstract": "This project aims to bring disabled perspectives into discussions about embodied co-creation in human-computer interaction (HCI). Everyone, from children to professional artists, learn and express themselves through creatively collaborating with others. Co-creativity is well supported by Human-Computer Interaction research and education initiatives. This project aims to use dance as a lens for expanding HCI’s understanding of the needs people with disabilities have during embodied co-creative activities. While potential applications include education and skills training, questions at this stage will focus on how dancers who use mobility aids collaborate with others; how HCI as a field can support their artistic expression; and what cognitive theory can learn from embodied collaboration by dancers who use mobility aids.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Illinois",
              "city": "Evanston",
              "institution": "Northwestern University",
              "dsl": "Media, Technology and Society"
            }
          ],
          "personId": 157940
        }
      ]
    },
    {
      "id": 157944,
      "typeId": 13470,
      "title": "Experiential Tutorials: Designing Tutorial Authoring Tools to Facilitate Tacit Knowledge Exchange in Creative Practices",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24f-1018",
      "source": "PCS",
      "trackId": 12829,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        158152
      ],
      "eventIds": [],
      "abstract": "Tutorials serve as a fundamental mechanism for disseminating knowledge within creative practices. Yet, tutorials struggle to convey tacit knowledge, a type of knowledge that practitioners internalize over time and experience. The subconscious nature of tacit knowledge often causes experienced practitioners to inadvertently omit fundamental actions in their instructions, which poses significant challenges for novices attempting to grasp the basics. However, no two novices are alike, making it challenging and burdensome for the tutorial author to align their tutorials with the audiences’ expertise. My doctoral research aims to create a more bespoke learning experience where tutorials are adapted to learners’ experiences without burdening the tutorial author.  My contributions towards this goal include a tutorial concept extraction method that identifies the core vocabulary of a practice to inform authors of their audiences’ language, a typology that aids authors to identify key characteristics of tacit knowledge to enable richer instructions, and a framework that enables authors to use the tutorial medium effectively to maximize tacit knowledge transfer. I am currently working towards a tutorial authoring tool that leverages large language models to extract a learner's unique and relevant experiences to create a personal knowledge inventory. Future work would combine this inventory with previous contributions to augment tutorials to be experiential, or aligned with learners' experiences.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Texas",
              "city": "Arlington",
              "institution": "University of Texas at Arlington",
              "dsl": "Computer Science & Engineering"
            }
          ],
          "personId": 157750
        }
      ]
    },
    {
      "id": 157945,
      "typeId": 13470,
      "title": "Embodied Cognition, Body Coherence, and Immersion in Non-Euclidean Virtual Reality",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24f-1017",
      "source": "PCS",
      "trackId": 12829,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        158152
      ],
      "eventIds": [],
      "abstract": "Embodied Cognition (EC) encompasses the notion that the body shapes cognition. Fundamental to this, are the ideas of image-schemas and conceptualisation. These concepts posit that abstract thought is a sort of metaphor grounded in some phenomenological body-environment interaction. The intuitive environment that we exist in can be described using Euclidean geometry. Recently, Virtual Reality (VR) has been used to successfully simulate non-Euclidean environments. These are geometric spaces that are non-intuitive, and are counter to the Euclidean space that we perceive in our day-to-day life. Hence, building on the idea that Human Computer Interaction (HCI) can be used to experimentally test ideas in philosophy of mind, we look to explore how image-schemas and conceptualisation apply to immersive, non-Euclidean environments, simulated using VR.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "New Zealand",
              "state": "",
              "city": "Auckland",
              "institution": "University of Auckland",
              "dsl": ""
            }
          ],
          "personId": 157939
        }
      ]
    },
    {
      "id": 157946,
      "typeId": 13470,
      "title": "Understanding and Supporting Code Performances",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24f-1015",
      "source": "PCS",
      "trackId": 12829,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        158152
      ],
      "eventIds": [],
      "abstract": "The term \"live coding\" can refer either to a performative musical practice or to a lecture technique in the CS classroom. These two disparate practices are united in that they can be thought of as code performances, where a performer writes, edits, and runs code live in front of an audience. In my research, I aim to better understand code performances and how we can support them. In a recent project, I explored how a version control system could benefit live coding music. I found that backtracking affordances could facilitate incorporating musical form on the fly and that version trees could act as a visual aid for both the performer and the audience. In another ongoing project, I am exploring how to support live coding in the CS classroom, focusing on increasing audience learning and engagement. In the future, I plan to explore how to best represent code performances so performers can iterate on their own ideas more easily, as well as share and collaborate with others.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Virginia",
              "city": "Blacksburg",
              "institution": "Virginia Tech",
              "dsl": ""
            }
          ],
          "personId": 157627
        }
      ]
    },
    {
      "id": 157947,
      "typeId": 13470,
      "title": "Mixed-Initiative Methods for Co-Creation in Scientific Research",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24f-1010",
      "source": "PCS",
      "trackId": 12829,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        158152
      ],
      "eventIds": [],
      "abstract": "The scientific process is inherently creative, requiring the generation and exploration of ideas for scientific inspiration, projects, study design, and communication. As large language models (LLMs) advance rapidly, scientists increasingly take advantage of their abilities. While LLMs show great promise in supporting many steps of the scientific process, researchers still face significant challenges in steering and validating their output. Interactions tailored to scientists and their specific tasks may empower them to harness the full creative potential of LLMs. I present a course of research that will lead to the development and evaluation of mixed-initiative methods for co-creation in scientific research. These methods aim to facilitate verification and control of AI output. I briefly describe my prior and proposed work on mixed-initiative methods for co-creating scientific inspiration, studies, and communication, and I focus on my current project on an LLM-powered tool for co-creating scientific ideas.\r\n",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Washington",
              "city": "Seattle",
              "institution": "University of Washington",
              "dsl": ""
            }
          ],
          "personId": 157936
        }
      ]
    },
    {
      "id": 158009,
      "typeId": 13626,
      "title": "Evaluation of Concept Erasing for Signature Artistic Styles in Diffusion Models",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24k-1013",
      "source": "PCS",
      "trackId": 12832,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        158128
      ],
      "eventIds": [],
      "abstract": "Artists have been raising the alarm about unfair and opaque practices of generative AI models for nearly two years. In a technological attempt to answer these concerns, concept erasing has promised to give artists more agency in determining whether new generative AI models get to clone their signature artistic styles. The idea behind this method is simple: take an already trained AI model, choose an artist's style to remove from the model, and apply minimal changes to suppress that concept. Simple integration into existing pipelines makes it a particularly appealing solution. However, the efficacy of this method has so far been examined for only one artist's style at a time. This paper, thus, examines concept erasing at scale, simulating the hypothetical application of this technology for simultaneously erasing many artists. It finds that the method does not reliably erase the concepts in cases with more than one artist's style, highlighting a gap in the technology and the literature around it.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "Palo Alto",
              "institution": "Stanford University",
              "dsl": ""
            }
          ],
          "personId": 157987
        }
      ]
    },
    {
      "id": 158010,
      "typeId": 13626,
      "title": "Interactive Modules Using Parametric Design",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24k-1010",
      "source": "PCS",
      "trackId": 12832,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        158128
      ],
      "eventIds": [],
      "abstract": "This research proposal examines prefabricated modules as a tool to encourage interaction and creativity within an urban context. The design is contrived from a modifiable kit of parts, which promotes playful assembly and proactive engagement. To assist in these goals, the module is realized in the generative and parametric temporal software known as Grasshopper and Rhino 3D. These softwares act as a multi-faceted tool and design strategy that boosts iterative thinking and user-agency. The process produces individual adaptable panels that are combined and reconfigured to accommodate the user’s specific needs. Overall, this proposal investigates the possibilities of parametric design to produce accessible modules that are modified through user experience to foster creativity and interaction. \r\n",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Texas",
              "city": "College Station",
              "institution": "Texas A&M University",
              "dsl": "Department of Architecture"
            }
          ],
          "personId": 157996
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Texas",
              "city": "College Station",
              "institution": "Texas A&M University ",
              "dsl": ""
            }
          ],
          "personId": 157963
        }
      ]
    },
    {
      "id": 158011,
      "typeId": 13524,
      "title": "TapeStory: Exploring the Storytelling Potential of Interactive Tapestries",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24b-8086",
      "source": "PCS",
      "trackId": 12825,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        157868
      ],
      "eventIds": [],
      "abstract": "Our ancestors communicated stories through tapestries, using them to adorn both public and private spaces. Traditionally, these tapestries were static artworks hanging on walls without any interaction with the audience. Nevertheless, textiles offer a versatile medium as they can be crafted from various materials and colors and manipulated to produce unique and touch-responsive textures. Our vision is to integrate the tactile capabilities of weaving with capacitive sensor technology to create a media-immersed interactive art installation that explores the negative impact of noise pollution on marine life ecosystems. Marine animals, particularly cetaceans, heavily rely on sound for communication, navigation, and hunting, and noise pollution can disrupt these essential functions. By harnessing the storytelling potential of tapestries and the power of capacitive sensors connected to microcontrollers, we developed a storytelling experience with a unique embodied interface that educates the public and decision-makers about pressing issues.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Portugal",
              "state": "",
              "city": "Funchal",
              "institution": "University of Madeira",
              "dsl": ""
            },
            {
              "country": "Portugal",
              "state": "",
              "city": "Lisbon",
              "institution": "University of Lisbon",
              "dsl": "ITI/LARSyS, IST"
            }
          ],
          "personId": 157993
        },
        {
          "affiliations": [
            {
              "country": "Portugal",
              "state": "",
              "city": "Funchal",
              "institution": "University of Madeira ",
              "dsl": ""
            },
            {
              "country": "Portugal",
              "state": "",
              "city": "Lisbon",
              "institution": "IST, University of Lisbon",
              "dsl": "ITI/LARSyS"
            }
          ],
          "personId": 157952
        },
        {
          "affiliations": [
            {
              "country": "Portugal",
              "state": "",
              "city": "Funchal",
              "institution": "University of Madeira",
              "dsl": ""
            },
            {
              "country": "Portugal",
              "state": "",
              "city": "Funchal",
              "institution": "WowSystems",
              "dsl": ""
            }
          ],
          "personId": 157951
        }
      ]
    },
    {
      "id": 158012,
      "typeId": 13626,
      "title": "Trace to Touch: Eliciting Gestures from Capacitive Touch Electrodes",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24k-1017",
      "source": "PCS",
      "trackId": 12832,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        158128
      ],
      "eventIds": [],
      "abstract": "Capacitive touch relies on electrodes to detect and interpret touch gestures. These electrodes are conventionally designed as rigid, grid-like structures, optimized for manufacturing efficiency. However, the advent of diverse conductive materials opens new avenues for enhancing the way electrodes are designed. In this paper, we develop a textile-silicone sensor composite using embedded conductive yarn as a capacitive touch electrode. By deviating from the grid pattern, we explore how alternative patterns can inspire novel, playful, and expressive gestures. We describe our design process for conceptualizing gestures from electrode design principles and iteratively testing gesture detection using an off-the-shelf CNN model. Our approach in developing a textile-silicone sensor with unique electrode designs enables the development of creative, comfortable and customizable haptic interfaces.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Texas",
              "city": "Arlington",
              "institution": "The University of Texas at Arlington",
              "dsl": ""
            }
          ],
          "personId": 157959
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Texas",
              "city": "Arlington",
              "institution": "The University of Texas at Arlington",
              "dsl": "Hybrid Atelier"
            }
          ],
          "personId": 157980
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Texas",
              "city": "Arlington",
              "institution": "UT Arlington",
              "dsl": ""
            }
          ],
          "personId": 157610
        }
      ]
    },
    {
      "id": 158013,
      "typeId": 13525,
      "title": "dAnCing LiNes",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24c-1038",
      "source": "PCS",
      "trackId": 12826,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        158129
      ],
      "eventIds": [],
      "abstract": "dAnCing LiNes explores how dance can generate a choreographic view of drawing through mediated representation. Capturing chorographic scores and task-based instructions, the act of drawing is interpreted as a choreographic activity through data visualisations. Through cross artform partnerships with dancers, choreographers, drone and robotics specialists, new artistic methodologies have been deployed to reinterpret five multi-participant live choreographed performances in public locations. \r\nThe resulting installation which comprises the projections of the five data visualisations, and a robotic CNC Drawing Machine, brings attention to the dancers’ patterns and formations, revealing sightlines and perspectives that cannot be seen simultaneously during the live events. The addition of ambience sound specific to each location facilitates the creation of an immersive environment that echoes the specificity of each location. \r\nBecoming a ‘collaborator’ of the art making process, the CNC Drawing Machine transfers the choreographic patterns and formations back onto a roll of unfolding paper ‘live’ in the gallery space, offering a further iteration of the translation of dance into drawing. ",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "Cornwall",
              "city": "Falmouth",
              "institution": "Falmouth University ",
              "dsl": "The Falmouth School of Art"
            }
          ],
          "personId": 157689
        }
      ]
    },
    {
      "id": 158014,
      "typeId": 13626,
      "title": "Speculative Morphing Matter: Designing a Sustainable Future Via Morphing Materials and Structures",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24k-1018",
      "source": "PCS",
      "trackId": 12832,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        158128
      ],
      "eventIds": [],
      "abstract": "We present Speculative Morphing Matter, a set of speculated morphing materials that can change shapes and properties in response to external stimuli, corresponding to specific design scenarios. Using the speculative design approach, we envision how such materials and systems enabled by them offer different design possibilities for us to restore and protect the currently damaged ecology. The series of speculative designs and extended reflections are based on state-of-art morphing matter technologies introduced in the engineering and science fields. Exploring into various design spaces from land to water and from anthroposphere to biosphere, we present four scenarios with illustrative images and technical assumptions on different speculative working mechanisms of the morphing material in future efforts of environmental protection and sustainable development. We hope to inspire people about how we can actively construct a more sustainable future for human beings to coexist with the ecosystem with sustainable design of a promising technology.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Pennsylvania",
              "city": "Pittsburgh",
              "institution": "Carnegie Mellon University",
              "dsl": ""
            }
          ],
          "personId": 157989
        }
      ]
    },
    {
      "id": 158015,
      "typeId": 13626,
      "title": "Sentura: Understanding the Cognitive Affordances of Silicone Microtextures in Tangible User Interface Design",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24k-1019",
      "source": "PCS",
      "trackId": 12832,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        158128
      ],
      "eventIds": [],
      "abstract": "Silicone has long been an influential material in haptic design due to its durability, flexibility, and versatility. However, its flat and smooth surface restricts potential applications. Using microtextures, we can improve on earlier designs by exploiting microtextured silicone's sensory perception and influence on users' emotions and feelings. In this paper, we explore the applications and benefits of microtextures in haptic design. We conduct a between-subjects psychophysics experiment to characterize the sensory perception of each texture using an adapted form of the Geneva Emotion Wheel. We also report the results of a card sort elicitation task to better understand how textures can improve and influence user actions for tactile user interface applications. Finally, we analyze the results and discuss the unique features of each silicone sample that contributed to users' experiences, as well as potential future implementation in textiles, wearable devices, and robotics.\r\n",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Texas",
              "city": "Arlington",
              "institution": "The University of Texas at Arlington",
              "dsl": "Hybrid Atelier"
            }
          ],
          "personId": 157980
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Texas",
              "city": "Arlington",
              "institution": "The University of Texas at Arlington",
              "dsl": ""
            }
          ],
          "personId": 157959
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New York",
              "city": "Troy",
              "institution": "Rensselaer Polytechnic Institute",
              "dsl": "The School of Humanities, Arts, and Social Sciences "
            }
          ],
          "personId": 157950
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Texas",
              "city": "Arlington",
              "institution": "UT Arlington",
              "dsl": ""
            }
          ],
          "personId": 157610
        }
      ]
    },
    {
      "id": 158016,
      "typeId": 13525,
      "title": "Mosaic Immersion: Through Shared Touch and Stories",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24c-1012",
      "source": "PCS",
      "trackId": 12826,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        158129
      ],
      "eventIds": [],
      "abstract": "\"Mosaic Immersion\" is a mixed-reality installation that interweaves physica and virtual experiences in a shared space. Participants explore interconnected narratives through uniquely created rock objects with their hand images. Mosaic Immersion was inspired by cairn stacking along hiking trails. Cairns, which are created by carefully balancing rocks on top of one another, serve as markers or symbols along the trail, guiding and providing a sense of connection for hikers. It is a practice that carries both cultural and personal significance. These rock formations create a shared experience, inviting others to contribute their own stones or simply admire the collective effort. Within this space, the boundaries between physical and virtual realms blur, inviting profound explorations of resilience and connection in the human experience.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Texas",
              "city": "College Station",
              "institution": "Texas A&M University",
              "dsl": "School of Performance, Visualization & Fine Arts/Soft Interaction Lab"
            }
          ],
          "personId": 157570
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Texas",
              "city": "College Station",
              "institution": "Texas A&M University",
              "dsl": "School of Performance, Visualization & Fine Arts/Soft Interaction Lab"
            }
          ],
          "personId": 157540
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Texas",
              "city": "College Station",
              "institution": "Texas A&M University",
              "dsl": ""
            }
          ],
          "personId": 157960
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Texas",
              "city": "College Station",
              "institution": "Texas A&M",
              "dsl": "VIsualization"
            }
          ],
          "personId": 157969
        }
      ]
    },
    {
      "id": 158017,
      "typeId": 13525,
      "title": "`zones of flow (iv)': horizontal immersion \\& interactions with water indoors",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24c-1014",
      "source": "PCS",
      "trackId": 12826,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        158129
      ],
      "eventIds": [],
      "abstract": "`zones of flow (iv)' is an interactive immersive audiovisual installation designed to be experienced horizontally, while people are sandwiched between flows: a projection featuring water surfaces and reflections (above), a fully functioning waterbed (below), and stereo sounds (around). Visitors are invited to lie down on the waterbed and use their bodies and hand gestures to self-regulate the flows of moving images playing above them, and the surrounding sounds. The media presented in the installation brings snippets of the landscape indoors through field recordings and moving images featuring water and flows. With their bodies, people move the water that gently enwraps them underneath, and with their hands (through pressure and proximity sensing) they control and self-regulate their audiovisual experience (see https://vimeo.com/844939019, 2:54min video documentation).",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "",
              "city": "Canterbury",
              "institution": "University of Kent",
              "dsl": "School of Engineering"
            }
          ],
          "personId": 158007
        }
      ]
    },
    {
      "id": 158018,
      "typeId": 13525,
      "title": "TIME ENOUGH: Generative AI Visions of Climate Change as Cave Paintings of the Future",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24c-1033",
      "source": "PCS",
      "trackId": 12826,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        158129
      ],
      "eventIds": [],
      "abstract": "It is difficult to tangibly feel climate change because it must be imagined into the future. The original cave painting in pre-historic times, too was an attempt to imagine the future in a creative space that we no longer understand. Generative AI (GenAI) serves as a tool for us today much as cave paintings were for pre-historic humans to imagine a climate future by interfacing our tools into drawings of our visions. TIME ENOUGH is a collective voice of today concerning the future narrated using GenAI, showing both how we envision challenges of the climate and how we may adapt to them in the future. These images and videos recreate a modern version of the age-old cave painting in the first truly creative space in human history, showing how our imaginations and anxieties of today are mere echoes of what concerned our ancestors from a seemingly remote time.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Hong Kong",
              "state": "",
              "city": "Hong Kong",
              "institution": "City University of Hong Kong",
              "dsl": "School of Creative Media"
            }
          ],
          "personId": 157581
        },
        {
          "affiliations": [
            {
              "country": "Hong Kong",
              "state": "",
              "city": "HONG KONG",
              "institution": "CITY UNIVERSITY OF HONG KONG",
              "dsl": "School of Creative Media"
            }
          ],
          "personId": 157995
        },
        {
          "affiliations": [
            {
              "country": "Hong Kong",
              "state": "",
              "city": "Hong Kong ",
              "institution": "City University of Hong Kong",
              "dsl": "School of Creative Media, City University of Hong Kong"
            }
          ],
          "personId": 158001
        },
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Hong Kong, SAR",
              "institution": "City University of Hong Kong ",
              "dsl": "School of Creative Media"
            }
          ],
          "personId": 157957
        }
      ]
    },
    {
      "id": 158019,
      "typeId": 13525,
      "title": "A Synergistic Connection: I Tell the Moon My Secret and the Moon Tells Me Yours",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24c-1011",
      "source": "PCS",
      "trackId": 12826,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        158129
      ],
      "eventIds": [],
      "abstract": "I Tell the Moon My Secret and the Moon Tells Me Yours (ITMMSMTMY), created by artist Zoe Li in 2023, is an art piece featuring a robotic arm that repeatedly depicts the waveform of collected secrets, creating light painting photographs with the involvement of Moon. Only when the Moon appears within a certain field of view can the waveform of this sentence be successfully captured by the camera with a long exposure. That is to say, whether the trace of the waveform can be revealed is determined by the natural environment — only when the Moon is bright and clear in the night sky can this secret possibly be conveyed. The project experiments on the synergic dynamics among uncontrollable natural environments, a precise data-driven robot system and humans, fostering new discourse on their relationships through synergistic visual imagery. By portraying the robotic system as an active agent connecting humanity with the cosmic environment, the project also intends to depict the interconnection between these parties, shifting perspective from an anthropocentric view.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Guangzhou",
              "institution": "Computational Media and Arts,The Hong Kong University of Science and Technology (Guangzhou)",
              "dsl": ""
            }
          ],
          "personId": 157968
        },
        {
          "affiliations": [
            {
              "country": "China",
              "state": "Guangdong",
              "city": "Guangzhou",
              "institution": "Hong Kong University of Science and Technology (Guangzhou)",
              "dsl": ""
            }
          ],
          "personId": 157962
        },
        {
          "affiliations": [
            {
              "country": "China",
              "state": "Guangdong",
              "city": "Guangzhou",
              "institution": "Hong Kong University of Science and Technology (Guangzhou)",
              "dsl": "Computational Media and Arts"
            },
            {
              "country": "Hong Kong",
              "state": "",
              "city": "Hong Kong",
              "institution": "Hong Kong University  of Science and Technology",
              "dsl": "Integrative Systems and Design"
            }
          ],
          "personId": 157949
        }
      ]
    },
    {
      "id": 158020,
      "typeId": 13524,
      "title": "A review of visual strategies in pictorials",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24b-6429",
      "source": "PCS",
      "trackId": 12825,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        157531
      ],
      "eventIds": [],
      "abstract": "This pictorial review illustrates an array of visual strategies employed in 271 pictorials published in DIS, C&C, and TEI conferences between 2014 and 2023. Based on a thematic analysis the pictorial review presents the visual strategies under seven analytical themes: 1) composition, 2) typogra¬phy, 3) colour, 4) drawing attention, 5) visual style, 6) active engagement, and 7) visual related work. The review focuses on strategies for communicating research visually, rather than the content and contribution of the reviewed picto¬rials. The review outlines both basic graphical principles, as well as novel use of visual elements. The pictorial is the first attempt at a visual analysis of the pictorial format, offering authors of future pictorials, both an overview of the devel¬opment of the format, as well as inspiration for new ways to complement text with visual content. Lastly, the challenges and future potentials which emerged from the review are discussed.\r\n",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Denmark",
              "state": "",
              "city": "Aarhus",
              "institution": "Aarhus University",
              "dsl": "Department of Digital Design and Information Studies"
            }
          ],
          "personId": 157953
        },
        {
          "affiliations": [
            {
              "country": "Denmark",
              "state": "",
              "city": "Aarhus",
              "institution": "Aarhus University",
              "dsl": "Department of Digital Design and Information Studies"
            }
          ],
          "personId": 157964
        },
        {
          "affiliations": [
            {
              "country": "Denmark",
              "state": "",
              "city": "Aarhus",
              "institution": "Aarhus University",
              "dsl": "Department of Digital Design and Information Studies"
            }
          ],
          "personId": 157985
        }
      ]
    },
    {
      "id": 158022,
      "typeId": 13476,
      "title": "(W)E-waste: Creative Making with Wasted Computing Devices",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24j-1017",
      "source": "PCS",
      "trackId": 12831,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        158132
      ],
      "eventIds": [],
      "abstract": "Computing devices become waste for a variety of reasons. They break down, become obsolete, or are no longer trendy. These events are so common that currently, e-waste has become the largest consumer waste stream in the world. However, taking apart e-waste devices reveals how they often contain many useful parts and components that could be scrapped and creatively integrated into new forms. These include highly expressive materials like sensors, displays, microcontrollers, etc. This workshop will explore processes in creative making with e-waste, examining the unique materiality of e-waste and how its reuse differs and/or converges with other material reuse processes. To do so, our workshop will combine hands-on activities (tear-downs, rapid prototyping, and tutorials) with discussion of the challenges and opportunities in this space. We aim to use these activities to explore how HCI can better support creative making with e-waste across a wide audience.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Illinois",
              "city": "Chicago",
              "institution": "University of Chicago",
              "dsl": ""
            }
          ],
          "personId": 158003
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New York",
              "city": "New York",
              "institution": "Cornell Tech",
              "dsl": "Information Science"
            }
          ],
          "personId": 157970
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New York",
              "city": "New York",
              "institution": "Cornell Tech",
              "dsl": "Information Science"
            }
          ],
          "personId": 157958
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Illinois",
              "city": "Chicago",
              "institution": "University of Chicago",
              "dsl": ""
            }
          ],
          "personId": 157986
        }
      ]
    },
    {
      "id": 158023,
      "typeId": 13626,
      "title": "The Impact of Generative AI on Artists",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24k-1020",
      "source": "PCS",
      "trackId": 12832,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        158128
      ],
      "eventIds": [],
      "abstract": "Generative AI has the potential to augment artists’ creative expression, while simultaneously harming their professions through unethical data collection practices and replacement of human labor. We conducted a thematic analysis of social media posts to\r\nunderstand artists’ perceptions and experiences of the direct and indirect impact of generative AI on their profession. Our findings also highlight growing public distrust toward artists amidst the rise of generative AI, with accusations of using AI tools leading to stress and fear of unemployment. Our study provides valuable insights into the complex interplay between artists, generative AI, and the public. We discuss potential protective measures for artists, including regulatory interventions and opt-in/out data collection, and explore future impacts of generative AI on artists’ creative processes",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Pennsylvania",
              "city": "Swarthmore",
              "institution": "Swarthmore College",
              "dsl": "Department of Computer Science"
            }
          ],
          "personId": 157983
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Pennsylvania",
              "city": "Swarthmore",
              "institution": "Swarthmore College",
              "dsl": "Department of Computer Science"
            }
          ],
          "personId": 157979
        }
      ]
    },
    {
      "id": 158024,
      "typeId": 13524,
      "title": "The Secret Life of Data – Uncovering the Diverse, Lived, and More-Than-Human Nature of Personal Data",
      "award": "HONORABLE_MENTION",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24b-9469",
      "source": "PCS",
      "trackId": 12825,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        157864
      ],
      "eventIds": [],
      "abstract": "As the datafication of our personal lives increases, researchers have started to critique what we consider as data. Where data are often seen from a reductionist perspective –as neutral numbers and graphs– theory suggests that data are messy, subjective, and pertaining to more than the human alone. They are experienced and lived with, something which is often not accounted for in personal data. To explore what people themselves consider data, sixteen interlocutors participated in a cultural probe study where they visually documented what they considered data in their everyday lives. Our analysis indicates that data can be disciplinary, social, and extend beyond ourselves, incorporating more-than-human aspects. Data are often regarded for entertainment, work, and wellbeing purposes. As interlocutors actively engaged and lived with data, we end the pictorial with a working definition of personal data, which acknowledges people’s active roles in their data creation. ",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Weimar",
              "institution": "Human Computer Interaction",
              "dsl": "Bauhaus-Universität Weimar"
            }
          ],
          "personId": 157978
        },
        {
          "affiliations": [
            {
              "country": "Netherlands",
              "state": "",
              "city": "Eindhoven",
              "institution": "Eindhoven University of Technology",
              "dsl": "Industrial Design"
            }
          ],
          "personId": 158005
        },
        {
          "affiliations": [
            {
              "country": "Germany",
              "state": "",
              "city": "Weimar",
              "institution": "Bauhaus-Universität Weimar",
              "dsl": ""
            }
          ],
          "personId": 157954
        }
      ]
    },
    {
      "id": 158025,
      "typeId": 13524,
      "title": "Sampling the Glitch Spectrum: Exploring the Architecture of Digital Media",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24b-6732",
      "source": "PCS",
      "trackId": 12825,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        157865
      ],
      "eventIds": [],
      "abstract": "An empirical record of glitch practice is portrayed in this pictorial. In wandering through the information environments of digital files, researchers can discover unexpected artifacts through experimental interactions. The production of these images span about seven years and range across various digital media, such as photography, video footage, 3D renders, and gaming. This work expands the concept of organic architecture to the realm of the digital medium. Inspired by nature, analogies from physical phenomena and scientific principles are used to inform the research-creation. In doing so, glitch experiments in digital files enable a co-creativity with technology which reveal their underlying structures and thereby produce a spectrum of expression. Often, uncanny resemblance to natural terrains manifest, indicating a connection through possibilities of configuration, or entropy.\r\n",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New York",
              "city": "Sojourning",
              "institution": "Independent",
              "dsl": ""
            }
          ],
          "personId": 157955
        }
      ]
    },
    {
      "id": 158027,
      "typeId": 13476,
      "title": "Explainable AI for the Arts 2 (XAIxArts2)",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24j-1012",
      "source": "PCS",
      "trackId": 12831,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        158200
      ],
      "eventIds": [],
      "abstract": "This second workshop on explainable AI for the Arts (XAIxArts) brings together a community of researchers and creative practitioners in Human-Computer Interaction (HCI), Interaction Design, AI, explainable AI (XAI), and Digital Arts to explore the role of XAI for the Arts. XAI is a core concern of Human-Centred AI and relies heavily on HCI techniques to explore how to make complex and difficult to understand AI models more understandable to people. Our first workshop explored the landscape of XAIxArts and identified emergent themes. To move the discourse on XAIxArts forward and to contribute to Human-Centred AI more broadly this workshop will: i) bring researchers together to expand the XAIxArts community; ii) collect and critically reflect on current and emerging XAIxArts practice; iii) co-develop a manifesto for XAIxArts; iv) co-develop a proposal for an edited book on XAIxArts; v) engage with the wider discourse on Human-Centred AI.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "",
              "city": "London",
              "institution": "University of the Arts London",
              "dsl": ""
            }
          ],
          "personId": 157965
        },
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "",
              "city": "London",
              "institution": "Queen Mary University of London",
              "dsl": ""
            }
          ],
          "personId": 157631
        },
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "",
              "city": "London",
              "institution": "Queen Mary University of London",
              "dsl": ""
            }
          ],
          "personId": 157972
        },
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "",
              "city": "Nottingham",
              "institution": "University of Nottingham",
              "dsl": ""
            }
          ],
          "personId": 157762
        },
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "",
              "city": "Nottingham",
              "institution": "University of Nottingham",
              "dsl": ""
            }
          ],
          "personId": 157726
        },
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "",
              "city": "London",
              "institution": "Kingston University",
              "dsl": ""
            }
          ],
          "personId": 157990
        },
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "",
              "city": "Edinburgh",
              "institution": "University of Edinburgh",
              "dsl": "Edinburgh Futures Institute"
            }
          ],
          "personId": 157982
        },
        {
          "affiliations": [
            {
              "country": "China",
              "state": "Beijing ",
              "city": "Beijing",
              "institution": "Central Conservatory of Music",
              "dsl": ""
            }
          ],
          "personId": 157743
        },
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Beijing",
              "institution": "Tsinghua University",
              "dsl": ""
            }
          ],
          "personId": 157977
        },
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Beijing",
              "institution": "Tsinghua University",
              "dsl": ""
            }
          ],
          "personId": 157999
        },
        {
          "affiliations": [
            {
              "country": "United Arab Emirates",
              "state": "",
              "city": "Abu Dhabi",
              "institution": "MBZUAI",
              "dsl": ""
            }
          ],
          "personId": 157976
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Maryland",
              "city": "Towson",
              "institution": "Towson University",
              "dsl": ""
            }
          ],
          "personId": 157971
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Utah",
              "city": "Salt Lake City",
              "institution": "University of Utah",
              "dsl": ""
            }
          ],
          "personId": 158000
        },
        {
          "affiliations": [
            {
              "country": "Canada",
              "state": "Quebec",
              "city": "Montréal",
              "institution": "Concordia University",
              "dsl": ""
            }
          ],
          "personId": 157992
        }
      ]
    },
    {
      "id": 158028,
      "typeId": 13626,
      "title": "A Toolkit for Crafting Simple Sonic Interfaces in Education",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24k-1006",
      "source": "PCS",
      "trackId": 12832,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        158128
      ],
      "eventIds": [],
      "abstract": "As STEAM education gains attention and popularity, it becomes increasingly important to explore academic projects that reach across disciplines for holistic learning experiences. This paper supports the growing intersection of craft, sound, and technology research and proposes a toolkit to support education, play, and experimentation within this interdisciplinary space. Creating abstractions for Arduino and ChucK technologies, students can focus on learning circuits and crafting DIY instruments, without spending time coding.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "Berkeley",
              "institution": "UC Berkeley",
              "dsl": ""
            }
          ],
          "personId": 157967
        }
      ]
    },
    {
      "id": 158029,
      "typeId": 13626,
      "title": "Cyber Ear / Cypher Ear, a System for Automatically Appreciating Off-the-Top Rap",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24k-1008",
      "source": "PCS",
      "trackId": 12832,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        158128
      ],
      "eventIds": [],
      "abstract": "We describe Cyber Ear / Cypher Ear, CE/CE (pronounced “Ceecee”) for short, a system for automatically evaluating improvisational, responsive rap in real time. By explicitly modeling freestyle rap appreciation, the system allows us to learn more about different aspects of this type of rap, including which ones are hard to formalize and which ones are more easily modeled computationally. Thus, this system allows us to formulate a novel theory of rap appreciation, and explore how it relies on semantic, phonetic, and lexical connections. One of the significant and difficult aspects of this type of rap is semantic connection. We compare different techniques for assessing the semantic aspects of improvisational rap and provide a preliminary assessment of these methods. We find that WordNet appears to work the best in our current implementation.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Massachusetts",
              "city": "Cambridge",
              "institution": "Massachusetts Institute of Technology",
              "dsl": ""
            }
          ],
          "personId": 157961
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Massachusetts",
              "city": "Cambridge",
              "institution": "Massachusetts Institute of Technology",
              "dsl": ""
            }
          ],
          "personId": 157956
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Massachusetts",
              "city": "Cambridge",
              "institution": "Massachusetts Institute of Technology",
              "dsl": "CMSW & Literature"
            }
          ],
          "personId": 157988
        }
      ]
    },
    {
      "id": 158030,
      "typeId": 13525,
      "title": "A Space Resonating with Being",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24c-1007",
      "source": "PCS",
      "trackId": 12826,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        158129
      ],
      "eventIds": [],
      "abstract": "A Space Resonating with Being is a visual-audio interactive artwork where the visual art on a 55-inch display changes in response to external intervention, focusing on experiencing the space as a living organism. The real-time visual effects that appear on the display reflect the local natural environment when there is no viewer interaction, symbolically integrating the natural environment into a space. When the viewer interacts with the artwork, it is transformed by an algorithm based on physiological signals from the viewer. The artwork changes based on their biorhythms, such as their breathing and heart rate, and they enjoy a unique experience where the art space responds to them, providing a dynamic and colorful visual-audio experience. The artwork draws attention to the impact of the viewer on space and how artwork affects the viewer's internal world perception through the experience of the artwork gradually morphing to resonate with them. ",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Japan",
              "state": "",
              "city": "Toyota",
              "institution": "Toyota Motor Corporation",
              "dsl": ""
            },
            {
              "country": "United States",
              "state": "California",
              "city": "Newport Beach",
              "institution": "Toyota Calty Design Research Inc",
              "dsl": ""
            }
          ],
          "personId": 157974
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "Los Altos",
              "institution": "Toyota Research Institute",
              "dsl": ""
            },
            {
              "country": "United States",
              "state": "California",
              "city": "Los Altos",
              "institution": "Toyota Research Institute",
              "dsl": ""
            }
          ],
          "personId": 158006
        }
      ]
    },
    {
      "id": 158031,
      "typeId": 13525,
      "title": "Motion and trails- Creative possibilities for imaginative spaces.",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24c-1023",
      "source": "PCS",
      "trackId": 12826,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        158129
      ],
      "eventIds": [],
      "abstract": "This paper discusses the digital animation artwork Motion and Trails, which builds on previous explorations of procedural techniques to generate unexpected visual results. Originating from animation processes that require quick workflows by embracing procedural methods, Motion and Trails continues this approach for the 2024 Creativity and Cognition Conference art exhibition by using simulated techniques in Maya and After Effects to transform 3D forms. Considering the theme of Creative Organic Spaces, the artwork aims to tap into creative possibilities through an informed but ‘unknown outcome’ approach to art making. As the latest iteration in an evolving organic process, Motion and Trails focuses animation as an innovative medium while demonstrating its immersive and cinematic capabilities. By utilizing procedural animation to embrace the unknown, this work emphasizes digital practice and abstraction to reveal imaginative new ways of creating virtual spaces.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Australia",
              "state": "",
              "city": "Sydney",
              "institution": "UNSW",
              "dsl": "Art Design and Architecture"
            }
          ],
          "personId": 157719
        }
      ]
    },
    {
      "id": 158032,
      "typeId": 13525,
      "title": "Welcome to a Skeuomorphic World",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24c-1004",
      "source": "PCS",
      "trackId": 12826,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        158129
      ],
      "eventIds": [],
      "abstract": "Welcome to a Skeuomorphic World critically explores the economic implications of substituting organic elements in architecture with synthetic materials, focusing on faux wood flooring for its cost-effective and low-maintenance qualities. The project presents a gradual skeuomorphic depiction of a wooden floor plate, translating a live organic wood log image into 880 abstract 12x12 units. These units are slowly showcased on a sizable LED panel in sequence. Using rephotographs and juxtaposition, the work satirically portrays an organic wood surface in an interactive format, prompting a reconsideration of perceptions surrounding synthetic materiality.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "South Carolina",
              "city": "Columbia",
              "institution": "University of South Carolina",
              "dsl": "Media Arts/School of Visual Art & Design"
            }
          ],
          "personId": 157975
        }
      ]
    },
    {
      "id": 158033,
      "typeId": 13525,
      "title": "Landscape Illusions: An AI and AR Powered Journey from Nature to Imagined Futures",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24c-1025",
      "source": "PCS",
      "trackId": 12826,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        158129
      ],
      "eventIds": [],
      "abstract": "“Landscape Illusions” ventures into the realm where human perception intertwines with the natural world, unveiling a series of AR-infused Chinese landscape painting scrolls with animated experience. This collaboration between artists and generative AI crafts a dialogue that traverses time and space, merging the ancient allure of nature with the innovative pulse of digital creativity. The collection, comprising “Metropolis Veins,” “Rising Tides,” “Symbiotic Horizons,” and “Stellar Reflections,” acts as a mirror reflecting various environmental and societal themes. It invites viewers to engage deeply with the artwork, challenging them to rethink their relationship with the environment around them. This series is a reflection on the complex narratives nature weaves, marrying the serene beauty of traditional landscapes with the inventive power of AI and the immersive experience of AR technology. “Landscape Illusions” prompts critical discussions about nature's role in our lives and the impact we have on it, making it a poignant commentary on contemporary environmental issues and inspiring a reimagined vision for our collective future.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "San Diego",
              "institution": "University of California San Diego",
              "dsl": "Visual Arts"
            }
          ],
          "personId": 158002
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "San Diego",
              "institution": "Independent",
              "dsl": ""
            }
          ],
          "personId": 157994
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "San Diego",
              "institution": "University of California San Diego",
              "dsl": "Visual Arts"
            }
          ],
          "personId": 158008
        }
      ]
    },
    {
      "id": 158034,
      "typeId": 13525,
      "title": "The Wisdom Of Losing (Yourself)",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24c-1041",
      "source": "PCS",
      "trackId": 12826,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        158129
      ],
      "eventIds": [],
      "abstract": "The Wisdom of Losing (Yourself) is a proposal for series of brief filmic artworks by multimedia artist Esther Rolinson. The intention in making the new works is to explore how change in our internal emotional landscapes effects change in the physical world. Related works by Esther Rolinson can be found at www.estherrolinson.co.uk",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "",
              "city": "Hastings",
              "institution": "None",
              "dsl": "Rolinson Craig "
            }
          ],
          "personId": 158004
        }
      ]
    },
    {
      "id": 158035,
      "typeId": 13525,
      "title": "The Matrix of Discomfort: Reimagining Critical AI Artwork through a Lens of Organic Creative Spaces",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24c-1021",
      "source": "PCS",
      "trackId": 12826,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        158129
      ],
      "eventIds": [],
      "abstract": "Wright's notion of \"organic creative space\" invites viewers to experience the harmony and discord inherent when operating at the boundary between the natural and designed worlds. In this artwork, we interrogate similar boundaries: between the natural and artificial, and between the creative and the generative. We explore the use of artificial intelligence systems to generate images of natural phenomena--specifically, women's faces--and the discomfort felt by viewers as they are unsettled by the unanticipated. The Matrix of Discomfort is a multimedia art installation that blends quilting and augmented reality (AR) to critically reflect upon AI as a medium that holds promise and distrust, and that exists at boundaries: between the natural and artificial, the creative and the generative, the digital and the physical. It reimagines the quilt, traditionally a feminized symbol of comfort and relaxation, as a canvas for stimulating conversation about the ethical quandaries and potential promises of generative AI.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Massachusetts",
              "city": "Worcester",
              "institution": "Worcester Polytechnic Institute",
              "dsl": "Computational Media"
            }
          ],
          "personId": 157966
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Massachusetts",
              "city": "Worcester",
              "institution": "WPI",
              "dsl": ""
            }
          ],
          "personId": 157973
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Massachusetts",
              "city": "Worcester",
              "institution": "Worcester Polytechnic Institute",
              "dsl": "Humanities and Arts / Interactive Media and Game Development"
            }
          ],
          "personId": 157984
        }
      ]
    },
    {
      "id": 158037,
      "typeId": 13469,
      "title": "A Technical Demonstration on Streamlining 3D Motion Production Workflows with a Markerless Motion Capture System",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24i-1005",
      "source": "PCS",
      "trackId": 12830,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        157870
      ],
      "eventIds": [],
      "abstract": "This paper presents an innovative markerless motion capture system to streamline 3D animation workflows using spatial computing and deep learning. We employ off-the-shelf cameras and neural networks to reconstruct 3D joint positions from video automatically. Our lightweight solution retargets motions onto character rigs without manual intervention. With accurate real-time tracking of up to 30 fps, our system has faster processing than the previous method. Our system contributes an easy-to-use, cost-effective motion capture solution by replacing specialized equipment with learned spatial reasoning. This work democratizes immersive content creation by streamlining motion capture based on computer vision and deep learning, helping make high-fidelity capture broadly accessible.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Shenzhen",
              "institution": "Harbin Institute of Technology",
              "dsl": "Shenzhen International School of Design"
            },
            {
              "country": "China",
              "state": "",
              "city": "Taipa",
              "institution": "University of Macau",
              "dsl": "Faculty of Social Science"
            }
          ],
          "personId": 157917
        },
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Guangzhou",
              "institution": "Guangzhou Cyanpuppets Information Technology Co.",
              "dsl": ""
            },
            {
              "country": "China",
              "state": "",
              "city": "Guangzhou",
              "institution": "Beijing Normal University",
              "dsl": ""
            }
          ],
          "personId": 158036
        },
        {
          "affiliations": [
            {
              "country": "China",
              "state": "",
              "city": "Hong Kong SAR",
              "institution": "Hong Kong Polytechnic University",
              "dsl": "School of Design"
            },
            {
              "country": "China",
              "state": "",
              "city": "Hong Kong SAR",
              "institution": "Hong Kong University of Science and Technology",
              "dsl": "Academy of Interdisciplinary Studies"
            }
          ],
          "personId": 157879
        }
      ]
    },
    {
      "id": 158203,
      "typeId": 13473,
      "title": "Creativity and Ethnography An Expansive Proposal for ’in the Wild’ Research of Ideas in Practice in Design Studios",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24a-1681",
      "source": "PCS",
      "trackId": 12833,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        159835
      ],
      "eventIds": [],
      "abstract": " A growing number of scholars are exploring ideas ‘in the wild’ and across different timescales through qualitative research, and especially ethnography. Previous controlled and lab-based studies have formalized techniques to encourage idea development and outlined measurements to rate the success of produced ideas based on quantity, quality, novelty, and variety. Qualitative 'in the wild' research aims to fill the knowledge gap regarding the evolution of ideas, how prior ideas shape new ones, and what other factors impact ideas and their development within a professional setting. However, these studies have been hindered due to difficulty around knowing how to 'do' ethnography and to interpret findings through a theoretical lens via ethnographic analysis and writing in creativity studies, HCI, and Design. This paper provides an in-depth discussion of an ethnographic analysis and writing process from a year-long fieldstudy with designers at a large Danish library. In doing so, it also contributes a better understanding of how to do ethnography on ideas to promote a betterment of the scholarship on ideas, designing, and creativity in the field of creativity studies, HCI, and design.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Denmark",
              "state": "",
              "city": "Aarhus",
              "institution": "Aarhus University",
              "dsl": "Centre for Digital Creativity"
            }
          ],
          "personId": 158202
        }
      ]
    },
    {
      "id": 166540,
      "typeId": 13525,
      "title": "Threading Space: Kinetic Sculpture Exploring Spatial Interaction Using Threads In Motion",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "cc24c-1002",
      "source": "PCS",
      "trackId": 12826,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        158129
      ],
      "eventIds": [],
      "abstract": "Threading Space is a kinetic sculpture that explores how human’s spatial perception can be manipulated by dynamically and geometrically reconfiguring physical lines of thread using a swarm of mobile robots on the floor and ceiling. As the threads interact and intertwine with each other, they become a hypnotic medium for tangible patterns in three-dimensional space. Through a physical installation and an interactive GUI, Threading Space invites the audience to explore the potential of using swarm robots and line elements to create, morph, and interact with space.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Illinois",
              "city": "Chicago",
              "institution": "University of Chicago",
              "dsl": ""
            }
          ],
          "personId": 166539
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Illinois",
              "city": "Chicago",
              "institution": "University of Chicago ",
              "dsl": "Department of Computer Science"
            }
          ],
          "personId": 166536
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Illinois",
              "city": "Chicago",
              "institution": "University of Chicago",
              "dsl": "Department of Computer Science"
            }
          ],
          "personId": 166537
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Illinois",
              "city": "Chicago",
              "institution": "University of Chicago",
              "dsl": "Department of Computer Science"
            }
          ],
          "personId": 166534
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "Los Angeles",
              "institution": "University of Southern California",
              "dsl": ""
            }
          ],
          "personId": 166538
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Illinois",
              "city": "Chicago",
              "institution": "University of Chicago",
              "dsl": ""
            }
          ],
          "personId": 166535
        }
      ]
    },
    {
      "id": 166542,
      "typeId": 13526,
      "title": "The Wisdom Of Losing (Yourself)",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "14379",
      "source": "PCS",
      "trackId": 12826,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        166541
      ],
      "eventIds": [],
      "abstract": "The Wisdom of Losing (Yourself) is a proposal for series of brief filmic artworks by multimedia artist Esther Rolinson. The intention in making the new works is to explore how change in our internal emotional landscapes effects change in the physical world. Related works by Esther Rolinson can be found at www.estherrolinson.co.uk",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "state": "",
              "city": "Hastings",
              "institution": "None",
              "dsl": "Rolinson Craig "
            }
          ],
          "personId": 158004
        }
      ]
    },
    {
      "id": 166543,
      "typeId": 13526,
      "title": "Motion and trails- Creative possibilities for imaginative spaces.",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "14380",
      "source": "PCS",
      "trackId": 12826,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        166541
      ],
      "eventIds": [],
      "abstract": "This paper discusses the digital animation artwork Motion and Trails, which builds on previous explorations of procedural techniques to generate unexpected visual results. Originating from animation processes that require quick workflows by embracing procedural methods, Motion and Trails continues this approach for the 2024 Creativity and Cognition Conference art exhibition by using simulated techniques in Maya and After Effects to transform 3D forms. Considering the theme of Creative Organic Spaces, the artwork aims to tap into creative possibilities through an informed but ‘unknown outcome’ approach to art making. As the latest iteration in an evolving organic process, Motion and Trails focuses animation as an innovative medium while demonstrating its immersive and cinematic capabilities. By utilizing procedural animation to embrace the unknown, this work emphasizes digital practice and abstraction to reveal imaginative new ways of creating virtual spaces.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Australia",
              "state": "",
              "city": "Sydney",
              "institution": "UNSW",
              "dsl": "Art Design and Architecture"
            }
          ],
          "personId": 157719
        }
      ]
    },
    {
      "id": 166544,
      "typeId": 13526,
      "title": "Landscape Illusions: An AI and AR Powered Journey from Nature to Imagined Futures",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "14381",
      "source": "PCS",
      "trackId": 12826,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        166541
      ],
      "eventIds": [],
      "abstract": "“Landscape Illusions” ventures into the realm where human perception intertwines with the natural world, unveiling a series of AR-infused Chinese landscape painting scrolls with animated experience. This collaboration between artists and generative AI crafts a dialogue that traverses time and space, merging the ancient allure of nature with the innovative pulse of digital creativity. The collection, comprising “Metropolis Veins,” “Rising Tides,” “Symbiotic Horizons,” and “Stellar Reflections,” acts as a mirror reflecting various environmental and societal themes. It invites viewers to engage deeply with the artwork, challenging them to rethink their relationship with the environment around them. This series is a reflection on the complex narratives nature weaves, marrying the serene beauty of traditional landscapes with the inventive power of AI and the immersive experience of AR technology. “Landscape Illusions” prompts critical discussions about nature's role in our lives and the impact we have on it, making it a poignant commentary on contemporary environmental issues and inspiring a reimagined vision for our collective future.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "San Diego",
              "institution": "University of California San Diego",
              "dsl": "Visual Arts"
            }
          ],
          "personId": 158002
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "San Diego",
              "institution": "Independent",
              "dsl": ""
            }
          ],
          "personId": 157994
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "San Diego",
              "institution": "University of California San Diego",
              "dsl": "Visual Arts"
            }
          ],
          "personId": 158008
        }
      ]
    },
    {
      "id": 166545,
      "typeId": 13526,
      "title": "A Space Resonating with Being",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "14382",
      "source": "PCS",
      "trackId": 12826,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        166541
      ],
      "eventIds": [],
      "abstract": "A Space Resonating with Being is a visual-audio interactive artwork where the visual art on a 55-inch display changes in response to external intervention, focusing on experiencing the space as a living organism. The real-time visual effects that appear on the display reflect the local natural environment when there is no viewer interaction, symbolically integrating the natural environment into a space. When the viewer interacts with the artwork, it is transformed by an algorithm based on physiological signals from the viewer. The artwork changes based on their biorhythms, such as their breathing and heart rate, and they enjoy a unique experience where the art space responds to them, providing a dynamic and colorful visual-audio experience. The artwork draws attention to the impact of the viewer on space and how artwork affects the viewer's internal world perception through the experience of the artwork gradually morphing to resonate with them. ",
      "authors": [
        {
          "affiliations": [
            {
              "country": "Japan",
              "state": "",
              "city": "Toyota",
              "institution": "Toyota Motor Corporation",
              "dsl": ""
            },
            {
              "country": "United States",
              "state": "California",
              "city": "Newport Beach",
              "institution": "Toyota Calty Design Research Inc",
              "dsl": ""
            }
          ],
          "personId": 157974
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "Los Altos",
              "institution": "Toyota Research Institute",
              "dsl": ""
            },
            {
              "country": "United States",
              "state": "California",
              "city": "Los Altos",
              "institution": "Toyota Research Institute",
              "dsl": ""
            }
          ],
          "personId": 158006
        }
      ]
    },
    {
      "id": 166897,
      "typeId": 13527,
      "title": "Interactive art and computer human interaction: a personal story",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "1",
      "source": "CSV",
      "trackId": 12932,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        159836
      ],
      "eventIds": [],
      "authors": [
        {
          "affiliations": [
            {
              "country": "United Kingdom",
              "city": "Leicester",
              "institution": "De Montfort University"
            }
          ],
          "personId": 166898
        }
      ]
    },
    {
      "id": 166901,
      "typeId": 13625,
      "title": "Feynman's Stylus",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "2",
      "source": "CSV",
      "trackId": 12933,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        158150
      ],
      "eventIds": [],
      "abstract": "In this design fiction talk, a renowned theoretical phycisist collaborates with an AI system to remake his scientific diagrams in digital media, which transformed the field of theoretical physics in 20th century. What role will AI play into the invention of new representations (diagrams, abstractions, notations)? How would those representations look like?",
      "authors": [
        {
          "affiliations": [
            {
              "country": "USA",
              "city": "San Francisco",
              "institution": "Adobe Research"
            }
          ],
          "personId": 166899
        }
      ]
    },
    {
      "id": 166902,
      "typeId": 13625,
      "title": "In Dialogue",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "3",
      "source": "CSV",
      "trackId": 12933,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        158149
      ],
      "eventIds": [],
      "abstract": "This keynote extends the theme of organic creative spaces from architecture to learning environments more generally, moving from Frank Lloyd Wright to Jane Jacobs and Janine Benyus--tipping hats along the way to Galileo, Wittgenstein, David Bohm, Peter Senge, and the father/daughter Batesons, Gregory and Mary Catherine. These references shape a framework in which dialogue becomes a method for design and for developing design communities. An exemplar, the Kusske Design Initiative (KDI), is advancing dialogue across disciplines to strengthen a growing community of creative problem-solvers engaged in interdisciplinary collaboration and focused on stewardship of natural environments, ecologies of humans and other living beings and systems, circular economies, and experimentation with \"biomaterials.\" Spanning every scale of human experience-from apparel to cities-these materials are sourced, manufactured, used, and disposed of in ways that \"do no harm\" and ideally give back to their environment, promoting its health and sustainability. KDI collaborators seek inspiration from nature and from each other.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "USA",
              "city": "Twin Cities",
              "institution": "University of Minnesota"
            }
          ],
          "personId": 166900
        }
      ]
    },
    {
      "id": 166906,
      "typeId": 13628,
      "title": "A Toolkit for Crafting Simple Sonic Interfaces in Education",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "14418",
      "source": "PCS",
      "trackId": 12832,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        157870
      ],
      "eventIds": [],
      "abstract": "As STEAM education gains attention and popularity, it becomes increasingly important to explore academic projects that reach across disciplines for holistic learning experiences. This paper supports the growing intersection of craft, sound, and technology research and proposes a toolkit to support education, play, and experimentation within this interdisciplinary space. Creating abstractions for Arduino and ChucK technologies, students can focus on learning circuits and crafting DIY instruments, without spending time coding.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "Berkeley",
              "institution": "UC Berkeley",
              "dsl": ""
            }
          ],
          "personId": 157967
        }
      ]
    },
    {
      "id": 166907,
      "typeId": 13627,
      "title": "Cyber Ear / Cypher Ear, a System for Automatically Appreciating Off-the-Top Rap",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "14419",
      "source": "PCS",
      "trackId": 12832,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        157870
      ],
      "eventIds": [],
      "abstract": "We describe Cyber Ear / Cypher Ear, CE/CE (pronounced “Ceecee”) for short, a system for automatically evaluating improvisational, responsive rap in real time. By explicitly modeling freestyle rap appreciation, the system allows us to learn more about different aspects of this type of rap, including which ones are hard to formalize and which ones are more easily modeled computationally. Thus, this system allows us to formulate a novel theory of rap appreciation, and explore how it relies on semantic, phonetic, and lexical connections. One of the significant and difficult aspects of this type of rap is semantic connection. We compare different techniques for assessing the semantic aspects of improvisational rap and provide a preliminary assessment of these methods. We find that WordNet appears to work the best in our current implementation.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Massachusetts",
              "city": "Cambridge",
              "institution": "Massachusetts Institute of Technology",
              "dsl": ""
            }
          ],
          "personId": 157961
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Massachusetts",
              "city": "Cambridge",
              "institution": "Massachusetts Institute of Technology",
              "dsl": ""
            }
          ],
          "personId": 157956
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Massachusetts",
              "city": "Cambridge",
              "institution": "Massachusetts Institute of Technology",
              "dsl": "CMSW & Literature"
            }
          ],
          "personId": 157988
        }
      ]
    },
    {
      "id": 166908,
      "typeId": 13627,
      "title": "Evaluation of Concept Erasing for Signature Artistic Styles in Diffusion Models",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "14420",
      "source": "PCS",
      "trackId": 12832,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        157870
      ],
      "eventIds": [],
      "abstract": "Artists have been raising the alarm about unfair and opaque practices of generative AI models for nearly two years. In a technological attempt to answer these concerns, concept erasing has promised to give artists more agency in determining whether new generative AI models get to clone their signature artistic styles. The idea behind this method is simple: take an already trained AI model, choose an artist's style to remove from the model, and apply minimal changes to suppress that concept. Simple integration into existing pipelines makes it a particularly appealing solution. However, the efficacy of this method has so far been examined for only one artist's style at a time. This paper, thus, examines concept erasing at scale, simulating the hypothetical application of this technology for simultaneously erasing many artists. It finds that the method does not reliably erase the concepts in cases with more than one artist's style, highlighting a gap in the technology and the literature around it.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "California",
              "city": "Palo Alto",
              "institution": "Stanford University",
              "dsl": ""
            }
          ],
          "personId": 157987
        }
      ]
    },
    {
      "id": 166909,
      "typeId": 13627,
      "title": "Interactive Modules Using Parametric Design",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "14421",
      "source": "PCS",
      "trackId": 12832,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        157870
      ],
      "eventIds": [],
      "abstract": "This research proposal examines prefabricated modules as a tool to encourage interaction and creativity within an urban context. The design is contrived from a modifiable kit of parts, which promotes playful assembly and proactive engagement. To assist in these goals, the module is realized in the generative and parametric temporal software known as Grasshopper and Rhino 3D. These softwares act as a multi-faceted tool and design strategy that boosts iterative thinking and user-agency. The process produces individual adaptable panels that are combined and reconfigured to accommodate the user’s specific needs. Overall, this proposal investigates the possibilities of parametric design to produce accessible modules that are modified through user experience to foster creativity and interaction. \r\n",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Texas",
              "city": "College Station",
              "institution": "Texas A&M University",
              "dsl": "Department of Architecture"
            }
          ],
          "personId": 157996
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Texas",
              "city": "College Station",
              "institution": "Texas A&M University ",
              "dsl": ""
            }
          ],
          "personId": 157963
        }
      ]
    },
    {
      "id": 166910,
      "typeId": 13627,
      "title": "Sentura: Understanding the Cognitive Affordances of Silicone Microtextures in Tangible User Interface Design",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "14422",
      "source": "PCS",
      "trackId": 12832,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        157870
      ],
      "eventIds": [],
      "abstract": "Silicone has long been an influential material in haptic design due to its durability, flexibility, and versatility. However, its flat and smooth surface restricts potential applications. Using microtextures, we can improve on earlier designs by exploiting microtextured silicone's sensory perception and influence on users' emotions and feelings. In this paper, we explore the applications and benefits of microtextures in haptic design. We conduct a between-subjects psychophysics experiment to characterize the sensory perception of each texture using an adapted form of the Geneva Emotion Wheel. We also report the results of a card sort elicitation task to better understand how textures can improve and influence user actions for tactile user interface applications. Finally, we analyze the results and discuss the unique features of each silicone sample that contributed to users' experiences, as well as potential future implementation in textiles, wearable devices, and robotics.\r\n",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Texas",
              "city": "Arlington",
              "institution": "The University of Texas at Arlington",
              "dsl": "Hybrid Atelier"
            }
          ],
          "personId": 157980
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Texas",
              "city": "Arlington",
              "institution": "The University of Texas at Arlington",
              "dsl": ""
            }
          ],
          "personId": 157959
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "New York",
              "city": "Troy",
              "institution": "Rensselaer Polytechnic Institute",
              "dsl": "The School of Humanities, Arts, and Social Sciences "
            }
          ],
          "personId": 157950
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Texas",
              "city": "Arlington",
              "institution": "UT Arlington",
              "dsl": ""
            }
          ],
          "personId": 157610
        }
      ]
    },
    {
      "id": 166911,
      "typeId": 13627,
      "title": "Speculative Morphing Matter: Designing a Sustainable Future Via Morphing Materials and Structures",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "14423",
      "source": "PCS",
      "trackId": 12832,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        157870
      ],
      "eventIds": [],
      "abstract": "We present Speculative Morphing Matter, a set of speculated morphing materials that can change shapes and properties in response to external stimuli, corresponding to specific design scenarios. Using the speculative design approach, we envision how such materials and systems enabled by them offer different design possibilities for us to restore and protect the currently damaged ecology. The series of speculative designs and extended reflections are based on state-of-art morphing matter technologies introduced in the engineering and science fields. Exploring into various design spaces from land to water and from anthroposphere to biosphere, we present four scenarios with illustrative images and technical assumptions on different speculative working mechanisms of the morphing material in future efforts of environmental protection and sustainable development. We hope to inspire people about how we can actively construct a more sustainable future for human beings to coexist with the ecosystem with sustainable design of a promising technology.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Pennsylvania",
              "city": "Pittsburgh",
              "institution": "Carnegie Mellon University",
              "dsl": ""
            }
          ],
          "personId": 157989
        }
      ]
    },
    {
      "id": 166912,
      "typeId": 13627,
      "title": "The Impact of Generative AI on Artists",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "14424",
      "source": "PCS",
      "trackId": 12832,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        157870
      ],
      "eventIds": [],
      "abstract": "Generative AI has the potential to augment artists’ creative expression, while simultaneously harming their professions through unethical data collection practices and replacement of human labor. We conducted a thematic analysis of social media posts to\r\nunderstand artists’ perceptions and experiences of the direct and indirect impact of generative AI on their profession. Our findings also highlight growing public distrust toward artists amidst the rise of generative AI, with accusations of using AI tools leading to stress and fear of unemployment. Our study provides valuable insights into the complex interplay between artists, generative AI, and the public. We discuss potential protective measures for artists, including regulatory interventions and opt-in/out data collection, and explore future impacts of generative AI on artists’ creative processes",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Pennsylvania",
              "city": "Swarthmore",
              "institution": "Swarthmore College",
              "dsl": "Department of Computer Science"
            }
          ],
          "personId": 157983
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Pennsylvania",
              "city": "Swarthmore",
              "institution": "Swarthmore College",
              "dsl": "Department of Computer Science"
            }
          ],
          "personId": 157979
        }
      ]
    },
    {
      "id": 166913,
      "typeId": 13627,
      "title": "Trace to Touch: Eliciting Gestures from Capacitive Touch Electrodes",
      "recognitionIds": [],
      "isBreak": false,
      "importedId": "14425",
      "source": "PCS",
      "trackId": 12832,
      "tags": [],
      "keywords": [],
      "sessionIds": [
        157870
      ],
      "eventIds": [],
      "abstract": "Capacitive touch relies on electrodes to detect and interpret touch gestures. These electrodes are conventionally designed as rigid, grid-like structures, optimized for manufacturing efficiency. However, the advent of diverse conductive materials opens new avenues for enhancing the way electrodes are designed. In this paper, we develop a textile-silicone sensor composite using embedded conductive yarn as a capacitive touch electrode. By deviating from the grid pattern, we explore how alternative patterns can inspire novel, playful, and expressive gestures. We describe our design process for conceptualizing gestures from electrode design principles and iteratively testing gesture detection using an off-the-shelf CNN model. Our approach in developing a textile-silicone sensor with unique electrode designs enables the development of creative, comfortable and customizable haptic interfaces.",
      "authors": [
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Texas",
              "city": "Arlington",
              "institution": "The University of Texas at Arlington",
              "dsl": ""
            }
          ],
          "personId": 157959
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Texas",
              "city": "Arlington",
              "institution": "The University of Texas at Arlington",
              "dsl": "Hybrid Atelier"
            }
          ],
          "personId": 157980
        },
        {
          "affiliations": [
            {
              "country": "United States",
              "state": "Texas",
              "city": "Arlington",
              "institution": "UT Arlington",
              "dsl": ""
            }
          ],
          "personId": 157610
        }
      ]
    }
  ],
  "people": [
    {
      "id": 157532,
      "firstName": "Nick",
      "lastName": "Bryan-Kinns",
      "middleInitial": "",
      "importedId": "KjibcsM9E4XYW_exQe0Lrg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157537,
      "firstName": "Nick",
      "lastName": "Taylor",
      "middleInitial": "",
      "importedId": "Pz9E_MHlRRvPCFbDvgge9A",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157538,
      "firstName": "Nikolas",
      "lastName": "Martelaro",
      "middleInitial": "",
      "importedId": "9NGSZTdtf2HFcb1UzsbraQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157539,
      "firstName": "Yapeng",
      "lastName": "Tian",
      "middleInitial": "",
      "importedId": "B2UOMdZkw1tzkmNfohfXaQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157540,
      "firstName": "John",
      "lastName": "Alberse",
      "middleInitial": "",
      "importedId": "DUgZqhuxDDRPkLqbKeQkVw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157542,
      "firstName": "Zhihao",
      "lastName": "Cao",
      "middleInitial": "",
      "importedId": "dBUeGnSP2HwxHS5WHx2HHw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157543,
      "firstName": "Kayla",
      "lastName": "DesPortes",
      "middleInitial": "",
      "importedId": "eJLkVUxSVBlbfzVZP7DXVA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157547,
      "firstName": "Jisu",
      "lastName": "Park",
      "middleInitial": "",
      "importedId": "E7DrGxmjgNwiWcK646m85Q",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157548,
      "firstName": "David",
      "lastName": "Zhou",
      "middleInitial": "",
      "importedId": "6FcxyvzSHydCmV5vNSgjPQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157549,
      "firstName": "Faeze",
      "lastName": "Brahman",
      "middleInitial": "",
      "importedId": "qhI_HMBJsjY9UcpqNDTRBA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157550,
      "firstName": "Hengyu",
      "lastName": "Meng",
      "middleInitial": "",
      "importedId": "EN0MPByx-jOZv6UAzC_uXQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157551,
      "firstName": "Zhi",
      "lastName": "Cao",
      "middleInitial": "",
      "importedId": "YVs1vgj4IDqf2CSsYw3umQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157559,
      "firstName": "Mengyi",
      "lastName": "Chen",
      "middleInitial": "",
      "importedId": "de0qn3LJBxIdjlQ00RS-FA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157560,
      "firstName": "Peter",
      "lastName": "Dalsgaard",
      "middleInitial": "",
      "importedId": "yA4liGj46NGXCUVLmPwEBg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157561,
      "firstName": "Adam",
      "lastName": "Emerson",
      "middleInitial": "",
      "importedId": "KWwn0GnYiMBSorUuZdWuSA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157563,
      "firstName": "Toby",
      "lastName": "Li",
      "middleInitial": "Jia-Jun",
      "importedId": "il6-1O1vU0p_l7aSJcoJ4g",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157565,
      "firstName": "Grace Yu-Chun",
      "lastName": "Yen",
      "middleInitial": "",
      "importedId": "tC7joetuNnrMs-khrKmwBg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157570,
      "firstName": "Jinsil Hwaryoung",
      "lastName": "Seo",
      "middleInitial": "",
      "importedId": "vP5v7KjE1A0RdlqjrRBytA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157572,
      "firstName": "Danielle",
      "lastName": "Lottridge",
      "middleInitial": "",
      "importedId": "I7iaVtRQy9Xkd-_PcOFQTQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157574,
      "firstName": "Becca",
      "lastName": "Weber",
      "middleInitial": "",
      "importedId": "0p_2mdzgmb3UMPEat3Vh_Q",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157576,
      "firstName": "Mingyi",
      "lastName": "Li",
      "middleInitial": "",
      "importedId": "9EpK8XGHt335EnbXOgxPiQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157577,
      "firstName": "Emilia",
      "lastName": "Rosselli Del Turco",
      "middleInitial": "",
      "importedId": "1Xd_iGMb1ntU0CwKKjRkfw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157578,
      "firstName": "Rongrong",
      "lastName": "Chen",
      "middleInitial": "",
      "importedId": "ikFqnjJu8IKSKYKThVJ8-Q",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157579,
      "firstName": "Shuang",
      "lastName": "Cai",
      "middleInitial": "",
      "importedId": "4xAwLhxfejsl0nxKcHwSTw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157581,
      "firstName": "RAY",
      "lastName": "LC",
      "middleInitial": "",
      "importedId": "bZTPx-Xcqg_ZozQDila34g",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157587,
      "firstName": "Isabelle",
      "lastName": "Pan",
      "middleInitial": "Yan",
      "importedId": "2ewZI7oDB6WdLbtXRSOp3Q",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157590,
      "firstName": "Zeyu",
      "lastName": "Wang",
      "middleInitial": "",
      "importedId": "YsTO8sPaYRW7y1rUJI6Jgg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157591,
      "firstName": "Gonzalo",
      "lastName": "Ramos",
      "middleInitial": "",
      "importedId": "dM5AVn1cAwNEtbvJQDhZIw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157592,
      "firstName": "Arvind",
      "lastName": "Srinivasan",
      "middleInitial": "",
      "importedId": "92kt_lDS_ajeNhH-bbsEug",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157594,
      "firstName": "Joel",
      "lastName": "Chan",
      "middleInitial": "",
      "importedId": "Ez78ia8tP-i2bDyxkR9rQQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157595,
      "firstName": "Parmit",
      "lastName": "Chilana",
      "middleInitial": "K",
      "importedId": "tN_Q0RA96u9zr4DWfu3Lvw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157601,
      "firstName": "Hyoungwook",
      "lastName": "Jin",
      "middleInitial": "",
      "importedId": "rpUQfwShSAC4QuRyv0jqqA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157605,
      "firstName": "Franceli",
      "lastName": "Cibrian",
      "middleInitial": "L.",
      "importedId": "YIjHcbgWU8OIrO-6oJMmLg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157609,
      "firstName": "Izabella",
      "lastName": "Rodrigues",
      "middleInitial": "",
      "importedId": "SKcXti-hNlG0v0mz-fEYxA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157610,
      "firstName": "Cesar",
      "lastName": "Torres",
      "middleInitial": "",
      "importedId": "RSFWkaMza2UT8xiAKLEbZQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157614,
      "firstName": "David Chuan-En",
      "lastName": "Lin",
      "middleInitial": "",
      "importedId": "R4BeOlIwrD06tJ5OqLO0pA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157615,
      "firstName": "Duri",
      "lastName": "Long",
      "middleInitial": "",
      "importedId": "TbS-b0Zqd9_Fx8Ipm9UwSA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157618,
      "firstName": "Brian",
      "lastName": "Magerko",
      "middleInitial": "",
      "importedId": "55-Igj55heYiLduZpcMjzA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157622,
      "firstName": "Roy",
      "lastName": "Davies",
      "middleInitial": "Colin",
      "importedId": "wwJapsiJJ1mCQKU3sNr0SA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157625,
      "firstName": "Smaranda",
      "lastName": "Muresan",
      "middleInitial": "",
      "importedId": "9qMF0eKp9p5uTuOXw6x0RQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157626,
      "firstName": "Yanan",
      "lastName": "Jin",
      "middleInitial": "",
      "importedId": "btxPy00g2vxH1soc22H_ug",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157627,
      "firstName": "Daniel",
      "lastName": "Manesh",
      "middleInitial": "",
      "importedId": "LnmKKmSFDsqTXa7KQ6tblg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157630,
      "firstName": "Jackson",
      "lastName": "Loth",
      "middleInitial": "",
      "importedId": "g_zrOioHrYSCMsm0AqzFcQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157631,
      "firstName": "Corey",
      "lastName": "Ford",
      "middleInitial": "",
      "importedId": "fquFKedONaELQ_j830SibQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157632,
      "firstName": "Joon-Young",
      "lastName": "Lee",
      "middleInitial": "",
      "importedId": "gYEzLsCjLfAxtGG_HZ4k8w",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157637,
      "firstName": "Mayra",
      "lastName": "Barrera Machuca",
      "middleInitial": "Donaji",
      "importedId": "kelrth_S2MBODQVWUWbO2g",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157638,
      "firstName": "Jash Hemant",
      "lastName": "Shah",
      "middleInitial": "",
      "importedId": "xfbyS1q_DG5qOMJCKPPFZQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157639,
      "firstName": "Yuewen",
      "lastName": "Yang",
      "middleInitial": "",
      "importedId": "9Xyupa-hra_nR714l3o6tw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157641,
      "firstName": "Ashley",
      "lastName": "Noel-Hirst",
      "middleInitial": "",
      "importedId": "esvk_hBc9vUIEvAODPfb_w",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157642,
      "firstName": "Tuhin",
      "lastName": "Chakrabarty",
      "middleInitial": "",
      "importedId": "2oAOMlxq1a65FgkWEuo8mg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157643,
      "firstName": "Hector",
      "lastName": "Camarillo-Abad",
      "middleInitial": "M",
      "importedId": "PpzpJDPZKFe_XeuM6TlpGA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157648,
      "firstName": "Madeline",
      "lastName": "Mau",
      "middleInitial": "",
      "importedId": "fcDasiuEZXXkdcWsbv_AAg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157652,
      "firstName": "Pedro",
      "lastName": "Sarmento",
      "middleInitial": "",
      "importedId": "ZwL6XzULLzrgd8DkM8F5hg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157653,
      "firstName": "Zhe",
      "lastName": "Yan",
      "middleInitial": "",
      "importedId": "QpXg34dLvl2jDaD-P42KTg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157655,
      "firstName": "Vishakh",
      "lastName": "Padmakumar",
      "middleInitial": "",
      "importedId": "G7zqhhKVrYABV8JI7b4aZw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157656,
      "firstName": "Philipp",
      "lastName": "Hoffmann",
      "middleInitial": "Pascal",
      "importedId": "PnG_rkv7NyQM-kk5R_bu3A",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157660,
      "firstName": "Fabian Caba",
      "lastName": "Heilbron",
      "middleInitial": "",
      "importedId": "abX55DOM0_kx7CYCK3Jlpg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157661,
      "firstName": "Amir",
      "lastName": "Jahanlou",
      "middleInitial": "",
      "importedId": "Zg1DLImA9t-I39E85ax0TQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157664,
      "firstName": "Jude",
      "lastName": "Rayan",
      "middleInitial": "",
      "importedId": "i8wKdZpH8Vf8t8hzaXkuhg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157665,
      "firstName": "Dhruv",
      "lastName": "Kanetkar",
      "middleInitial": "",
      "importedId": "RRbwqrurJSzRWNjr_vs_rg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157672,
      "firstName": "Steven",
      "lastName": "Dow",
      "middleInitial": "P.",
      "importedId": "8QHJbjDXFqKcG-dlzKVHwg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157674,
      "firstName": "Matthew",
      "lastName": "Kaney",
      "middleInitial": "",
      "importedId": "KB1BMkuducJ73H6v-ZhJBA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157675,
      "firstName": "Manoj",
      "lastName": "Deshpande",
      "middleInitial": "",
      "importedId": "t6wgOUWY0pbIJHEdBCcvCg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157680,
      "firstName": "Trudi",
      "lastName": "Qi",
      "middleInitial": "Di",
      "importedId": "288HEbgdMEujdNVodVJOig",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157681,
      "firstName": "Jerrick",
      "lastName": "Ban",
      "middleInitial": "",
      "importedId": "qJIKKqIXQwia1PXrgqMBaA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157687,
      "firstName": "Sara",
      "lastName": "Cardinale",
      "middleInitial": "",
      "importedId": "MD55scK2DY4LThBFEHWZgA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157689,
      "firstName": "Ella",
      "lastName": "Emanuele",
      "middleInitial": "",
      "importedId": "o6UQHyQusZFkDyWi6GpjPg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157690,
      "firstName": "Ruohong",
      "lastName": "Gan",
      "middleInitial": "",
      "importedId": "mDfmOeyoe3ojsjUvsLgyiQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157691,
      "firstName": "Amy",
      "lastName": "Hurst",
      "middleInitial": "",
      "importedId": "Bne_VZ94m_IW1zHdwk0-5Q",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157692,
      "firstName": "Sang Won",
      "lastName": "Lee",
      "middleInitial": "",
      "importedId": "6iT8RQIiG7T69Z5mNDGzNA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157693,
      "firstName": "Chengzhi",
      "lastName": "Zhang",
      "middleInitial": "",
      "importedId": "L6_FnaOY42NrC3xpsmPXng",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157695,
      "firstName": "Rina",
      "lastName": "Wehbe",
      "middleInitial": "R.",
      "importedId": "jsKmTGp27WbxsEYkNv__LQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157696,
      "firstName": "Kaiwen",
      "lastName": "Jiang",
      "middleInitial": "",
      "importedId": "vRg3Q1TjHYdZFd0QW-HH4g",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157698,
      "firstName": "Vera",
      "lastName": "Zhong",
      "middleInitial": "",
      "importedId": "Pxw7dbW0A0bJ22lNdMTC6g",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157699,
      "firstName": "Jane",
      "lastName": "E",
      "middleInitial": "L",
      "importedId": "pexOf3_TPLCTA3pprxU4tA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157701,
      "firstName": "Zheng",
      "lastName": "Ning",
      "middleInitial": "",
      "importedId": "_BBAh_8tX7FS79E8oGRENQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157708,
      "firstName": "Yifan",
      "lastName": "Gong",
      "middleInitial": "",
      "importedId": "DK0-EuBHzEtHijcun0OS-w",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157711,
      "firstName": "Tiffany",
      "lastName": "Lee",
      "middleInitial": "",
      "importedId": "TJGGdClEWkdQy6Nw4Z6mSA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157716,
      "firstName": "Haijun",
      "lastName": "Xia",
      "middleInitial": "",
      "importedId": "qR18CZssIG8qNcFRCGcljg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157719,
      "firstName": "Anna",
      "lastName": "Tow",
      "middleInitial": "",
      "importedId": "lN1c85PQ3ercHB9KEpkLHA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157721,
      "firstName": "Xiaotong",
      "lastName": "Xu",
      "middleInitial": "(Tone)",
      "importedId": "zBafE1xBRiVhfozJXWfWsQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157722,
      "firstName": "Kyle",
      "lastName": "Worrall",
      "middleInitial": "James",
      "importedId": "ddAlBTBzbfRoKdv8gKGYew",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157725,
      "firstName": "William",
      "lastName": "Payne",
      "middleInitial": "Christopher",
      "importedId": "-qKDf2NaevN2CswyrUPFUQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157726,
      "firstName": "Alan",
      "lastName": "Chamberlain",
      "middleInitial": "",
      "importedId": "Hw9zVvFP4L1tKJpHsOErFQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157728,
      "firstName": "Grace",
      "lastName": "Lin",
      "middleInitial": "",
      "importedId": "NtrlWtNakNYX2dFShalBxQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157730,
      "firstName": "Francisco Enrique Vicente",
      "lastName": "Castro",
      "middleInitial": "",
      "importedId": "3EnLSFTCc2XiTELTs7qoyA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157735,
      "firstName": "Elizabeth",
      "lastName": "Wilson",
      "middleInitial": "",
      "importedId": "hDeKsoJoDlINfYGjENWuNg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157736,
      "firstName": "Lewis",
      "lastName": "Wolstanholme",
      "middleInitial": "",
      "importedId": "mr98ZTbPGqgfxRudGM6QaQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157741,
      "firstName": "Eric",
      "lastName": "Xu",
      "middleInitial": "",
      "importedId": "EvRdeMtDlWSlcykjC-yqhA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157743,
      "firstName": "Zijin",
      "lastName": "Li",
      "middleInitial": "",
      "importedId": "TX7hjNAEloJPyz9Yv0_q9w",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157744,
      "firstName": "Zheng",
      "lastName": "Zhang",
      "middleInitial": "",
      "importedId": "bSbqVIDZ5T8bdWIRHGPy4Q",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157745,
      "firstName": "Joanna",
      "lastName": "Cook",
      "middleInitial": "",
      "importedId": "hn9EOZkhrSPcPSqaiKPmJg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157749,
      "firstName": "Douglas",
      "lastName": "Bowman Jr.",
      "middleInitial": "",
      "importedId": "o8Ci8jRKlCV608REHayCDA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157750,
      "firstName": "Shreyosi",
      "lastName": "Endow",
      "middleInitial": "",
      "importedId": "ifQ7lW_ebiVodCkuP8ebAA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157751,
      "firstName": "Gareth",
      "lastName": "McMurchy",
      "middleInitial": "",
      "importedId": "nFmcRtsqlo-OCoNlet2bjw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157754,
      "firstName": "Xinyu",
      "lastName": "Ma",
      "middleInitial": "",
      "importedId": "rd2wAW7EUrtiRUtVwPg58A",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157755,
      "firstName": "Max",
      "lastName": "Mühlhäuser",
      "middleInitial": "",
      "importedId": "IxtRKZB2rjeAvVGqICIm1w",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157756,
      "firstName": "Supratim",
      "lastName": "Pait",
      "middleInitial": "",
      "importedId": "1rIXSC9RYJs40kwiS_FMGQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157757,
      "firstName": "Barrett",
      "lastName": "Anderson",
      "middleInitial": "R",
      "importedId": "MrEr7FdQC_N8bLa9kQ14SA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157761,
      "firstName": "Sarah",
      "lastName": "Sterman",
      "middleInitial": "",
      "importedId": "4F6Hyz_nePb1Z5ZjY9oN0Q",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157762,
      "firstName": "Helen",
      "lastName": "Kennedy",
      "middleInitial": "",
      "importedId": "R9cLnT-G08PDkcsfruNPuQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157763,
      "firstName": "Oliver",
      "lastName": "Wang",
      "middleInitial": "",
      "importedId": "3_C0lwfT25pP7DCQn4jZhw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157767,
      "firstName": "Max",
      "lastName": "Kreminski",
      "middleInitial": "",
      "importedId": "GaRE7kP9lRv2HLmcdI-Wwg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157769,
      "firstName": "Srishti",
      "lastName": "Palani",
      "middleInitial": "",
      "importedId": "l2VZObNbp4VGFOy2ibMNrA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157775,
      "firstName": "Azzaya",
      "lastName": "Munkhbat",
      "middleInitial": "",
      "importedId": "fnT1ytZZH5wkQm69zq_HPQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157871,
      "firstName": "yutong",
      "lastName": "chen",
      "middleInitial": "",
      "importedId": "V13Brh6J0aD1_YSQmLdVDg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157872,
      "firstName": "Dongliang",
      "lastName": "Xu",
      "middleInitial": "",
      "importedId": "_iAtypc4vng3FFrXkrsVxA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157873,
      "firstName": "William",
      "lastName": "Tate",
      "middleInitial": "",
      "importedId": "ohs7HWjojdcGjex4V3V4JQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157874,
      "firstName": "Jinda",
      "lastName": "Han",
      "middleInitial": "",
      "importedId": "EtHt-IAVS4ElJw_0uwGZkQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157875,
      "firstName": "Suchismita",
      "lastName": "Naik",
      "middleInitial": "",
      "importedId": "iZCben9Uhi2DtDioFCgKgg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157876,
      "firstName": "Sophie",
      "lastName": "Rollins",
      "middleInitial": "",
      "importedId": "WiWCzoxbj7GSIXCdcprh3A",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157877,
      "firstName": "Simret",
      "lastName": "Gebreegziabher",
      "middleInitial": "Araya",
      "importedId": "C-0eru4VplPOG7fK7CagIw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157878,
      "firstName": "Ju Hyun",
      "lastName": "Lee",
      "middleInitial": "",
      "importedId": "IANTToMeq9tubsAZobAR0w",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157879,
      "firstName": "Ze",
      "lastName": "Gao",
      "middleInitial": "",
      "importedId": "URqtoe-37bS946Nm-qD-UQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157880,
      "firstName": "James",
      "lastName": "Eschrich",
      "middleInitial": "",
      "importedId": "PfumcCXUEU2wn-gH6DJN9w",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157881,
      "firstName": "Wenjie",
      "lastName": "Xu",
      "middleInitial": "",
      "importedId": "vGtR2HyykElOZ3idMO16rA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157882,
      "firstName": "Xiaoyu",
      "lastName": "Huang",
      "middleInitial": "",
      "importedId": "z1DnKocPPtzagPEDKxGJWA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157883,
      "firstName": "Zhoutong",
      "lastName": "Yu",
      "middleInitial": "",
      "importedId": "LCjxBFX7sKcXF2xy-ekvbg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157884,
      "firstName": "William",
      "lastName": "McCarthy",
      "middleInitial": "P",
      "importedId": "T068pf1PqbRaiDX8EC5xMA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157885,
      "firstName": "Zaiqiao",
      "lastName": "Ye",
      "middleInitial": "",
      "importedId": "ZxNTt8tBJLzAfTFIbFP6qg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157886,
      "firstName": "Chelsi",
      "lastName": "Cocking",
      "middleInitial": "Alise",
      "importedId": "GiSzZb2Brr8epJ6DVGCsPQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157887,
      "firstName": "Andrea",
      "lastName": "Alessandrini",
      "middleInitial": "",
      "importedId": "BQxFUn5SCnqsL7x66oibpg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157888,
      "firstName": "Katherine",
      "lastName": "Hancock",
      "middleInitial": "",
      "importedId": "RkXqw9KOmoLobXyAmPkGAg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157889,
      "firstName": "Mackenzie",
      "lastName": "Leake",
      "middleInitial": "",
      "importedId": "iUeS_U98Vg4xQUr78-q7Kg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157890,
      "firstName": "Zoe",
      "lastName": "Mock",
      "middleInitial": "Lacy",
      "importedId": "qJVWvFdFaZshpyNxxHsxjQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157891,
      "firstName": "Dina",
      "lastName": "EL-Zanfaly",
      "middleInitial": "",
      "importedId": "fJFGg40AS9R9iMj21KpVQQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157892,
      "firstName": "Zhiwei",
      "lastName": "Wang",
      "middleInitial": "",
      "importedId": "fhDH2Zg-lNeprswuWc-N5A",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157893,
      "firstName": "Ruyuan",
      "lastName": "Wan",
      "middleInitial": "",
      "importedId": "U339oWJ-PxrZuoD4oz7kNw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157894,
      "firstName": "Karla",
      "lastName": "Badillo-Urquiola",
      "middleInitial": "",
      "importedId": "VRhrdLFwz7qhDeyrqPxj1g",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157895,
      "firstName": "Karl",
      "lastName": "Willis",
      "middleInitial": "",
      "importedId": "Cl5lRHH8XDSE0Sb6-VabXw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157896,
      "firstName": "Judith",
      "lastName": "Fan",
      "middleInitial": "E.",
      "importedId": "6EZBXzv7W8PUmf8n_9y_GA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157897,
      "firstName": "Hasti",
      "lastName": "Darabipourshiraz",
      "middleInitial": "",
      "importedId": "TPqauKU0o2LlaicrXfK6Gg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157898,
      "firstName": "Justin",
      "lastName": "Matejka",
      "middleInitial": "",
      "importedId": "b9vzHy9bxgzx71r9rtm0wQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157899,
      "firstName": "Yuehui",
      "lastName": "Du",
      "middleInitial": "",
      "importedId": "i0W7Pqv2LhKJevKA0StA4A",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157900,
      "firstName": "Matthew",
      "lastName": "Fisher",
      "middleInitial": "David",
      "importedId": "pD4-WDED8ahBQT9jncm98Q",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157901,
      "firstName": "Ojasvi",
      "lastName": "Agarwal",
      "middleInitial": "",
      "importedId": "RKT9vogdc3korULXw6KApA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157902,
      "firstName": "Jasmin",
      "lastName": "Ali-Diaz",
      "middleInitial": "",
      "importedId": "ha_tmBFdFPvHkctuRJE8dg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157903,
      "firstName": "Sakshi",
      "lastName": "Kulkarni",
      "middleInitial": "",
      "importedId": "QlMOFmill7YVBMSDmZB56w",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157904,
      "firstName": "Mingyan",
      "lastName": "Tian",
      "middleInitial": "Claire",
      "importedId": "8hjORU01wB3EgzMr0W1Hiw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157905,
      "firstName": "Yewen",
      "lastName": "Pu",
      "middleInitial": "",
      "importedId": "fl1lO1LsGr4r21uH6o5Thg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157906,
      "firstName": "Fangtian",
      "lastName": "Ying",
      "middleInitial": "",
      "importedId": "_7JtR9nQDVdc83olDpP8Dw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157907,
      "firstName": "Holly",
      "lastName": "Huey",
      "middleInitial": "",
      "importedId": "NduH6M3sNNPYUY3GxWLtuw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157908,
      "firstName": "Nyssa",
      "lastName": "Shahdadpuri",
      "middleInitial": "",
      "importedId": "LyGWWkqq4uBBBsOry1pNfw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157909,
      "firstName": "Isaac",
      "lastName": "Browen",
      "middleInitial": "",
      "importedId": "3G5ylyb7MuRrMcwM0dqE3A",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157910,
      "firstName": "Cass",
      "lastName": "Scheirer",
      "middleInitial": "",
      "importedId": "2K78zjF5OONoqbPr5rylaw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157911,
      "firstName": "Milka",
      "lastName": "Trajkova",
      "middleInitial": "",
      "importedId": "zY7xxh75-0YRMWc4BR2KLA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157912,
      "firstName": "Deepali",
      "lastName": "Aneja",
      "middleInitial": "",
      "importedId": "uMi8FlnspOHZRFQJr2BYuQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157913,
      "firstName": "Xingzhi",
      "lastName": "Shi",
      "middleInitial": "",
      "importedId": "b0T8mHorNEuP6FTDxj8Cxg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157914,
      "firstName": "Jianan",
      "lastName": "Ma",
      "middleInitial": "",
      "importedId": "CN5nLGVhLeah-i1o7wGRMA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157915,
      "firstName": "Dev",
      "lastName": "Ambani",
      "middleInitial": "",
      "importedId": "7siaJHKiWEmNvfYHo7CdMw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157916,
      "firstName": "Mashiyat",
      "lastName": "Zaman",
      "middleInitial": "",
      "importedId": "-BF4uF6qSDBca_fscZpxfg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157917,
      "firstName": "Mengyao",
      "lastName": "Guo",
      "middleInitial": "",
      "importedId": "35XbyuSBTkUIa3R6dYdIpA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157936,
      "firstName": "Marissa",
      "lastName": "Radensky",
      "middleInitial": "",
      "importedId": "gRwJHbDfHqoqBNYuMbWbrQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157937,
      "firstName": "Aidan",
      "lastName": "Fitzsimons",
      "middleInitial": "Z",
      "importedId": "gJRlE-iydL-mMNM-gHHhEg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157938,
      "firstName": "Maalvika",
      "lastName": "Bhat",
      "middleInitial": "",
      "importedId": "Vh6GNRpCykUVmwLYDawNJQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157939,
      "firstName": "Maya",
      "lastName": "Gibson",
      "middleInitial": "",
      "importedId": "cJ3Z12tpvdwmz1C7ACQWmw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157940,
      "firstName": "Molly",
      "lastName": "de Blanc",
      "middleInitial": "",
      "importedId": "0CB1eBvYqkLXhUY2b-IeUg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157949,
      "firstName": "Varvara",
      "lastName": "Guljajeva",
      "middleInitial": "",
      "importedId": "pQxd_XKZIhHncaGcFaYwtw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157950,
      "firstName": "Marisa",
      "lastName": "Fernandez",
      "middleInitial": "N.",
      "importedId": "d6A7km3PqByCs0sSea5z4A",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157951,
      "firstName": "Pedro",
      "lastName": "Campos",
      "middleInitial": "",
      "importedId": "v_LrVxPRIEeUHo4ynjXrnA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157952,
      "firstName": "Mara",
      "lastName": "Dionisio",
      "middleInitial": "",
      "importedId": "sYRxhQUiXwdWWab4IZ7BVQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157953,
      "firstName": "Majken",
      "lastName": "Rasmussen",
      "middleInitial": "Kirkegaard",
      "importedId": "n1QQQ1Kkdr0KZO6PQ5aRYA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157954,
      "firstName": "Eva",
      "lastName": "Hornecker",
      "middleInitial": "",
      "importedId": "f1FCmv1ffkE8IC4qXcwyuA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157955,
      "firstName": "Aaron",
      "lastName": "Juarez",
      "middleInitial": "J",
      "importedId": "qhpgIGBxfsopXXYasuXoxw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157956,
      "firstName": "Nick",
      "lastName": "Montfort",
      "middleInitial": "",
      "importedId": "qilrEWsNC7R7j7Mt3S2rlQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157957,
      "firstName": "Kexue",
      "lastName": "Fu",
      "middleInitial": "",
      "importedId": "hLCglFcJ-WwQpVRhuefg2g",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157958,
      "firstName": "Wendy",
      "lastName": "Ju",
      "middleInitial": "",
      "importedId": "p5BP52mcA_s2AjtD8cejnw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157959,
      "firstName": "Aarti",
      "lastName": "Darji",
      "middleInitial": "",
      "importedId": "V1-b6mR63r9CO069B5FHBw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157960,
      "firstName": "Wesley",
      "lastName": "Taylor",
      "middleInitial": "",
      "importedId": "GSMVNKZ5m63eOmE_30lYBw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157961,
      "firstName": "Daniel",
      "lastName": "Villagran",
      "middleInitial": "",
      "importedId": "EucakAj7lMaSGk-DmUz4kA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157962,
      "firstName": "YuFan",
      "lastName": "Li",
      "middleInitial": "",
      "importedId": "kHDjXTRlpf5atVII_-d_EQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157963,
      "firstName": "Riley",
      "lastName": "Wemhoener",
      "middleInitial": "E",
      "importedId": "QRwsA-ItrQEQ46itdsZ4UA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157964,
      "firstName": "Minna",
      "lastName": "Pakanen",
      "middleInitial": "",
      "importedId": "bJkC-SQv3eh_rvdJUvzh9A",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157965,
      "firstName": "Nick",
      "lastName": "Bryan-Kinns",
      "middleInitial": "",
      "importedId": "xANVd9xpFeu_-4Y9yAhIMQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157966,
      "firstName": "Karen",
      "lastName": "Royer",
      "middleInitial": "",
      "importedId": "yeXAk4g43SS7IRVMtNm12g",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157967,
      "firstName": "Christopher",
      "lastName": "Bannon",
      "middleInitial": "",
      "importedId": "yokkI6z2HESOYN9siCLl6A",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157968,
      "firstName": "Zoe Qi-Jing",
      "lastName": "Li",
      "middleInitial": "",
      "importedId": "1F5dC1XMs-6j_cDby9xf7A",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157969,
      "firstName": "Claire",
      "lastName": "Thessen",
      "middleInitial": "J",
      "importedId": "ua6ikkGSdFgbop8be1Z2DQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157970,
      "firstName": "Ilan",
      "lastName": "Mandel",
      "middleInitial": "",
      "importedId": "B-BBteJrKyec7hvMYjdw_g",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157971,
      "firstName": "Jeba",
      "lastName": "Rezwana",
      "middleInitial": "",
      "importedId": "h60JE55P2_446vPsrPN_Sg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157972,
      "firstName": "Shuoyang",
      "lastName": "Zheng",
      "middleInitial": "",
      "importedId": "D-a7Q-1fxFgutXb47uEjxQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157973,
      "firstName": "Gillian",
      "lastName": "Smith",
      "middleInitial": "",
      "importedId": "QK7Oi_kCCQI2RQeyIGAhSw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157974,
      "firstName": "HyeJin",
      "lastName": "Yeom",
      "middleInitial": "",
      "importedId": "OfPDBAkMYf4GSA_eCw7MdQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157975,
      "firstName": "Byeongwon",
      "lastName": "Ha",
      "middleInitial": "",
      "importedId": "JOcJfjgDaYkrmyc_A2R--A",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157976,
      "firstName": "Gus",
      "lastName": "Xia",
      "middleInitial": "",
      "importedId": "x_rrtolQx_9evjjKUK8RNg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157977,
      "firstName": "Qiong",
      "lastName": "Wu",
      "middleInitial": "",
      "importedId": "GCTJXIgveCu1Dsg-cYxpSA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157978,
      "firstName": "Rosa",
      "lastName": "van Koningsbruggen",
      "middleInitial": "",
      "importedId": "UsrAxS9S3x0umSQGaiE54g",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157979,
      "firstName": "Sukrit",
      "lastName": "Venkatagiri",
      "middleInitial": "",
      "importedId": "iWZS5-2XL2aNNyGJrzD5vA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157980,
      "firstName": "Gunnika",
      "lastName": "Kapoor",
      "middleInitial": "",
      "importedId": "FQa0h7tclDSr5YeVoa3t0Q",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157982,
      "firstName": "Drew",
      "lastName": "Hemment",
      "middleInitial": "",
      "importedId": "2RtrH6YTKIwt2G-NC4d4mQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157983,
      "firstName": "Reishiro",
      "lastName": "Kawakami",
      "middleInitial": "",
      "importedId": "q2QDbYBlwv78fxeQm9R10g",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157984,
      "firstName": "Yunus",
      "lastName": "Telliel",
      "middleInitial": "Doğan",
      "importedId": "RqLg3RuG3uWRcVcITwwK1Q",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157985,
      "firstName": "Kasper",
      "lastName": "Heiselberg",
      "middleInitial": "",
      "importedId": "Dbik6Irl-bBWWYPlSiH_zQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157986,
      "firstName": "Pedro",
      "lastName": "Lopes",
      "middleInitial": "",
      "importedId": "vu7xKEsb0s2o9WvEByjw7w",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157987,
      "firstName": "Matyas",
      "lastName": "Bohacek",
      "middleInitial": "",
      "importedId": "8q00ECCisqXQlq44rKS2mw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157988,
      "firstName": "Wasalu",
      "lastName": "Jaco",
      "middleInitial": "",
      "importedId": "ed3SvgyWE5cN_17p5Ax4KQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157989,
      "firstName": "Qimo",
      "lastName": "Wan",
      "middleInitial": "",
      "importedId": "-yfhQu503WAC-Bnl-TFUlA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157990,
      "firstName": "Makayla",
      "lastName": "Lewis",
      "middleInitial": "",
      "importedId": "1MqaDxB3s1M4_6DEYU3_KA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157992,
      "firstName": "Gabriel",
      "lastName": "Vigliensoni",
      "middleInitial": "",
      "importedId": "GDCBtBcolsXDah9ghtpe5w",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157993,
      "firstName": "Laura",
      "lastName": "Santos",
      "middleInitial": "",
      "importedId": "FPIGEGLKDSMSCM1HrtfJig",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157994,
      "firstName": "Zetao",
      "lastName": "Yu",
      "middleInitial": "",
      "importedId": "H3LjMLLemca1XYVfws6A2Q",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157995,
      "firstName": "Sijia",
      "lastName": "Liu",
      "middleInitial": "",
      "importedId": "HH6aggsKfANsxPb1Z6Blfw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157996,
      "firstName": "Jayne",
      "lastName": "Goodman",
      "middleInitial": "",
      "importedId": "D55xb2dTNPsf9MQeyCP0AA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 157999,
      "firstName": "Lanxi",
      "lastName": "Xiao",
      "middleInitial": "",
      "importedId": "zFHDc1iFIgc_OA4cpejogw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 158000,
      "firstName": "Michael",
      "lastName": "Clemens",
      "middleInitial": "",
      "importedId": "X4MZ-EMQ-wi93ca9gge99w",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 158001,
      "firstName": "Latisha Besariani",
      "lastName": "Hendra",
      "middleInitial": "",
      "importedId": "Uxe7AamWXT-OQE-AhKlyAA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 158002,
      "firstName": "Mingyong",
      "lastName": "Cheng",
      "middleInitial": "",
      "importedId": "NrZpLo-lGu2VdvGo307gkg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 158003,
      "firstName": "Jasmine",
      "lastName": "Lu",
      "middleInitial": "",
      "importedId": "7zOfpMLFbNPM2fpIVwBnYA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 158004,
      "firstName": "Esther",
      "lastName": "Rolinson",
      "middleInitial": "",
      "importedId": "pM02amMznexdN45fYEiIMg",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 158005,
      "firstName": "Bart",
      "lastName": "Hengeveld",
      "middleInitial": "",
      "importedId": "aufWnTJcg5VHL8LAbpnQeA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 158006,
      "firstName": "Everlyne",
      "lastName": "Kimani",
      "middleInitial": "",
      "importedId": "oPUwZS73QT9eOgd1LpvdRQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 158007,
      "firstName": "Rocio",
      "lastName": "von Jungenfeld",
      "middleInitial": "",
      "importedId": "iquW-dH14sYQkm4-DUqUDQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 158008,
      "firstName": "Xuexi",
      "lastName": "Dang",
      "middleInitial": "",
      "importedId": "jp2Z1VOeTz1WGx628rP3tA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 158036,
      "firstName": "Yu",
      "lastName": "Nie",
      "middleInitial": "",
      "importedId": "zm5qalDY-Q4ykEavtbmQ4g",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 158127,
      "firstName": "Cassandra",
      "lastName": "Monden",
      "middleInitial": "Naomi",
      "importedId": "7EazbkAC3F2FqZPK-VQMcw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 158202,
      "firstName": "Minke",
      "lastName": "Nouwens",
      "middleInitial": "",
      "importedId": "QqJBEdk_luC0ekx_qRfNMA",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 164826,
      "firstName": "Amna",
      "lastName": "Liaqat",
      "importedId": "14202",
      "source": "SYS",
      "affiliations": [
        {
          "country": "USA",
          "state": "New Jersey",
          "city": "Princeton",
          "institution": "Princeton University"
        }
      ]
    },
    {
      "id": 164827,
      "firstName": "Viveka",
      "lastName": "Weiley",
      "importedId": "14203",
      "source": "SYS",
      "affiliations": [
        {
          "country": "Australia",
          "state": "NSW",
          "city": "Sydney",
          "institution": "CSIRO"
        }
      ]
    },
    {
      "id": 164828,
      "firstName": "Layne",
      "lastName": "Jackson Hubbard",
      "importedId": "14204",
      "source": "SYS",
      "affiliations": [
        {
          "country": "USA",
          "state": "California",
          "city": "Irvine",
          "institution": "University of California at Irvine"
        }
      ]
    },
    {
      "id": 164829,
      "firstName": "Eric",
      "lastName": "Paulos",
      "importedId": "14205",
      "source": "SYS",
      "affiliations": [
        {
          "country": "USA",
          "state": "California",
          "city": "Berkeley",
          "institution": "University of California at Berkeley"
        }
      ]
    },
    {
      "id": 164830,
      "firstName": "Lydia",
      "lastName": "Chilton",
      "importedId": "14206",
      "source": "SYS",
      "affiliations": [
        {
          "country": "USA",
          "state": "New York",
          "city": "New York",
          "institution": "Columbia University"
        }
      ]
    },
    {
      "id": 164831,
      "firstName": "Deborah",
      "lastName": "Tillman",
      "middleInitial": "Turnbull",
      "importedId": "14207",
      "source": "SYS",
      "affiliations": [
        {
          "country": "Australia",
          "state": "NSW",
          "city": "Sydney",
          "institution": "University of New South Wales"
        }
      ]
    },
    {
      "id": 164832,
      "firstName": "Joy",
      "lastName": "Kim",
      "importedId": "14208",
      "source": "SYS",
      "affiliations": [
        {
          "country": "USA",
          "state": "California",
          "city": "Sunnyvale",
          "institution": "Adobe Research"
        }
      ]
    },
    {
      "id": 165026,
      "firstName": "Ellen Yi-Luen",
      "lastName": "Do",
      "importedId": "14312",
      "source": "SYS",
      "affiliations": [
        {
          "country": "USA",
          "state": "Colorado",
          "city": "Boulder",
          "institution": "University of Colorado Boulder"
        }
      ]
    },
    {
      "id": 165027,
      "firstName": "Andrew",
      "lastName": "Webb",
      "importedId": "14313",
      "source": "SYS",
      "affiliations": [
        {
          "country": "USA",
          "state": "Louisiana",
          "city": "Baton Rouge",
          "institution": "Louisiana State University"
        }
      ]
    },
    {
      "id": 165028,
      "firstName": "Hallie",
      "lastName": "Sanclemente Morrison",
      "importedId": "14314",
      "source": "SYS",
      "affiliations": [
        {
          "country": "USA",
          "state": "Illinois",
          "city": "Chicago",
          "institution": "Independent Art Director"
        }
      ]
    },
    {
      "id": 166534,
      "firstName": "Harrison",
      "lastName": "Dong",
      "middleInitial": "",
      "importedId": "DRuR0zJzrgHTaVS8jh5d1Q",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 166535,
      "firstName": "Ken",
      "lastName": "Nakagaki",
      "middleInitial": "",
      "importedId": "lsYt2lERJ_k5SfHL9Sztcw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 166536,
      "firstName": "You",
      "lastName": "Li",
      "middleInitial": "",
      "importedId": "sJ73jvH-r3jvomm_070EOQ",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 166537,
      "firstName": "Emilie",
      "lastName": "Faracci",
      "middleInitial": "",
      "importedId": "7jdI2lmn2HQlcs_maFafow",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 166538,
      "firstName": "Yi",
      "lastName": "Zheng",
      "middleInitial": "",
      "importedId": "jUOnMzj1SbZOoO6F6gJeHw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 166539,
      "firstName": "Ramarko",
      "lastName": "Bhattacharya",
      "middleInitial": "",
      "importedId": "oZQoJsDEjmVpy21Z6RNndw",
      "source": "PCS",
      "affiliations": []
    },
    {
      "id": 166895,
      "firstName": "Zijian (Jason)",
      "lastName": "Ding",
      "importedId": "14414",
      "source": "SYS",
      "affiliations": [
        {
          "country": "USA",
          "state": "Maryland",
          "institution": "University of Maryland"
        }
      ]
    },
    {
      "id": 166898,
      "firstName": "Ernest",
      "lastName": "Edmonds",
      "importedId": "1",
      "source": "CSV",
      "affiliations": []
    },
    {
      "id": 166899,
      "firstName": "Rubaiat Habib",
      "lastName": "Kazi",
      "importedId": "2",
      "source": "CSV",
      "affiliations": []
    },
    {
      "id": 166900,
      "firstName": "Carol",
      "lastName": "Strohecker",
      "importedId": "3",
      "source": "CSV",
      "affiliations": []
    }
  ],
  "recognitions": []
}