{
  "schemeVersion": 7,
  "cc_licence": "Content of this file is licensed under a CC BY-NC-SA 4.0 license. For details see https://creativecommons.org/licenses/by-nc-sa/4.0/",
  "conference": {
    "id": 10011,
    "startDate": 1537660800000,
    "endDate": 1537833600000,
    "shortName": "Auto-UI",
    "name": "Auto-UI 2018",
    "year": 2018,
    "fullName": "10th International ACM Conference on Automotive User Interfaces",
    "url": "https://www.auto-ui.org/18/",
    "location": "Toronto, Canada ",
    "timeZoneOffset": -240,
    "logoUrl": "https://files.sigchi.org/conference/logo/06242290-f949-5f62-8876-08b1472641c0.png",
    "timeZoneName": "America/Toronto"
  },
  "sponsors": [],
  "sponsorLevels": [
    {
      "id": 10019,
      "name": "Sponsors",
      "rank": 1,
      "isDefault": true
    }
  ],
  "floors": [
    {
      "id": 10024,
      "name": "Sheraton Centre - 2F; 123 Queen Street West",
      "mapImageUrl": "https://files.sigchi.org/conference/floor/e5ae5b95-5655-327a-9a56-1818aaaab766.png",
      "roomIds": [
        10099,
        10089,
        10101,
        10091,
        10100
      ]
    },
    {
      "id": 10025,
      "name": "Steamwhistle Brewery; The Roundhouse, 255 Bremner Blvd ",
      "mapImageUrl": "https://files.sigchi.org/conference/floor/7c529b6b-e377-3290-e0b8-dbf1dde6c8c1.png",
      "roomIds": [
        10097
      ]
    },
    {
      "id": 10023,
      "name": "University of Toronto - Bahen Center 2F; 40 St. George St.",
      "mapImageUrl": "https://files.sigchi.org/conference/floor/d8baeb3e-0b15-be3f-1fc2-47428306f7c2.png",
      "roomIds": [
        10098,
        10092,
        10093,
        10094,
        10095,
        10096,
        10102
      ]
    }
  ],
  "rooms": [
    {
      "id": 10098,
      "name": "Bahen Centre, University of Toronto",
      "typeId": 10168,
      "setup": "Special"
    },
    {
      "id": 10099,
      "name": "Foyer of Civic Ballroom, Level 2, Sheraton Centre Toronto",
      "typeId": 10168,
      "setup": "Special"
    },
    {
      "id": 10092,
      "name": "BA 2155",
      "typeId": 10170,
      "setup": "Special"
    },
    {
      "id": 10093,
      "name": "BA 2165",
      "typeId": 10170,
      "setup": "Special"
    },
    {
      "id": 10094,
      "name": "BA 2175",
      "typeId": 10170,
      "setup": "Special"
    },
    {
      "id": 10095,
      "name": "BA 2185",
      "typeId": 10170,
      "setup": "Special"
    },
    {
      "id": 10096,
      "name": "BA 2195",
      "typeId": 10170,
      "setup": "Special"
    },
    {
      "id": 10089,
      "name": "Civic Ballroom",
      "typeId": 10402,
      "setup": "Special"
    },
    {
      "id": 10156,
      "name": "Simcoe and Dufferin",
      "typeId": 10411,
      "setup": "Special"
    },
    {
      "id": 10101,
      "name": "Foyer of Civic Ballroom",
      "typeId": 10409,
      "setup": "Special"
    },
    {
      "id": 10091,
      "name": "Kent and Huron",
      "typeId": 10426,
      "setup": "Special"
    },
    {
      "id": 10102,
      "name": "Registration Area, Bahen Center, University of Toronto",
      "typeId": 10351,
      "setup": "Special"
    },
    {
      "id": 10100,
      "name": "Sheraton Center",
      "typeId": 10408,
      "setup": "Special"
    },
    {
      "id": 10097,
      "name": "Steam Whistle Brewery",
      "typeId": 10407,
      "setup": "Special"
    }
  ],
  "tracks": [
    {
      "id": 10028,
      "typeId": 10168
    },
    {
      "id": 10029,
      "typeId": 10407
    },
    {
      "id": 10030,
      "typeId": 10979
    },
    {
      "id": 10031,
      "typeId": 10992
    },
    {
      "id": 10032,
      "typeId": 11001
    },
    {
      "id": 10033,
      "typeId": 11019
    },
    {
      "id": 10034,
      "typeId": 11033
    },
    {
      "id": 10035,
      "typeId": 11057
    }
  ],
  "contentTypes": [
    {
      "id": 10161,
      "name": "SIG",
      "color": "#7a0177",
      "duration": 90
    },
    {
      "id": 10162,
      "name": "Case Study",
      "color": "#993404",
      "duration": 20,
      "displayName": "Case Studies"
    },
    {
      "id": 10163,
      "name": "Course",
      "color": "#e6550d",
      "duration": 90,
      "displayName": "Courses"
    },
    {
      "id": 10165,
      "name": "Invited Talk",
      "color": "#66c2a4",
      "duration": 90,
      "displayName": "Invited Talks"
    },
    {
      "id": 10166,
      "name": "Operations",
      "color": "#006d2c",
      "duration": 90
    },
    {
      "id": 10167,
      "name": "Panel",
      "color": "#6baed6",
      "duration": 90,
      "displayName": "Panels"
    },
    {
      "id": 10168,
      "name": "Paper",
      "color": "#08519c",
      "duration": 20,
      "displayName": "Papers"
    },
    {
      "id": 10169,
      "name": "Plenary",
      "color": "#756bb1",
      "duration": 90
    },
    {
      "id": 10164,
      "name": "Event",
      "color": "#fecc5c",
      "duration": 0,
      "displayName": "Events"
    },
    {
      "id": 10409,
      "name": "Breakfast",
      "duration": 0
    },
    {
      "id": 10351,
      "name": "Coffee",
      "duration": 0
    },
    {
      "id": 10405,
      "name": "Demo",
      "duration": 0,
      "displayName": "Demos"
    },
    {
      "id": 10411,
      "name": "Exhibitors",
      "duration": 0
    },
    {
      "id": 10408,
      "name": "Information",
      "duration": 0
    },
    {
      "id": 10407,
      "name": "Keynote",
      "duration": 0
    },
    {
      "id": 10412,
      "name": "Papers",
      "duration": 0
    },
    {
      "id": 10426,
      "name": "Posters",
      "duration": 0
    },
    {
      "id": 10410,
      "name": "Presentation",
      "duration": 0
    },
    {
      "id": 10402,
      "name": "Video",
      "duration": 0
    },
    {
      "id": 11019,
      "name": "AutomotiveUI 2018 Demo",
      "duration": 0
    },
    {
      "id": 11033,
      "name": "AutomotiveUI 2018 Papers",
      "duration": 0
    },
    {
      "id": 10979,
      "name": "AutomotiveUI 2018 Video",
      "duration": 0
    },
    {
      "id": 10992,
      "name": "AutomotiveUI 2018 Workshop and Tutorials",
      "duration": 0
    },
    {
      "id": 11057,
      "name": "AutomotiveUI 2018 Works in Progress",
      "duration": 0
    },
    {
      "id": 11001,
      "name": "Exhibit",
      "duration": 0
    },
    {
      "id": 10170,
      "name": "Workshop",
      "color": "#de2d26",
      "duration": 240,
      "displayName": "Workshops"
    }
  ],
  "timeSlots": [
    {
      "id": 10241,
      "type": "LUNCH",
      "startDate": 1537689600000,
      "endDate": 1537693200000
    },
    {
      "id": 10559,
      "type": "SESSION",
      "startDate": 1537689600000,
      "endDate": 1537718400000
    },
    {
      "id": 10562,
      "type": "SESSION",
      "startDate": 1537693200000,
      "endDate": 1537707600000
    },
    {
      "id": 10565,
      "type": "SESSION",
      "startDate": 1537696800000,
      "endDate": 1537698600000
    },
    {
      "id": 10566,
      "type": "SESSION",
      "startDate": 1537707600000,
      "endDate": 1537711200000
    },
    {
      "id": 10569,
      "type": "SESSION",
      "startDate": 1537711200000,
      "endDate": 1537725600000
    },
    {
      "id": 10572,
      "type": "SESSION",
      "startDate": 1537716600000,
      "endDate": 1537718400000
    },
    {
      "id": 10573,
      "type": "SESSION",
      "startDate": 1537772400000,
      "endDate": 1537812000000
    },
    {
      "id": 10574,
      "type": "LUNCH",
      "startDate": 1537773300000,
      "endDate": 1537777800000
    },
    {
      "id": 10575,
      "type": "SESSION",
      "startDate": 1537774200000,
      "endDate": 1537804800000
    },
    {
      "id": 10576,
      "type": "SESSION",
      "startDate": 1537777800000,
      "endDate": 1537779600000
    },
    {
      "id": 10577,
      "type": "SESSION",
      "startDate": 1537779600000,
      "endDate": 1537783200000
    },
    {
      "id": 10578,
      "type": "SESSION",
      "startDate": 1537779600000,
      "endDate": 1537808400000
    },
    {
      "id": 10579,
      "type": "SESSION",
      "startDate": 1537783200000,
      "endDate": 1537785000000
    },
    {
      "id": 10580,
      "type": "SESSION",
      "startDate": 1537785000000,
      "endDate": 1537785900000
    },
    {
      "id": 10581,
      "type": "SESSION",
      "startDate": 1537785900000,
      "endDate": 1537790400000
    },
    {
      "id": 10582,
      "type": "SESSION",
      "startDate": 1537790400000,
      "endDate": 1537795800000
    },
    {
      "id": 10583,
      "type": "SESSION",
      "startDate": 1537795800000,
      "endDate": 1537799400000
    },
    {
      "id": 10584,
      "type": "SESSION",
      "startDate": 1537799400000,
      "endDate": 1537804800000
    },
    {
      "id": 10585,
      "type": "SESSION",
      "startDate": 1537804800000,
      "endDate": 1537808400000
    },
    {
      "id": 10586,
      "type": "SESSION",
      "startDate": 1537813800000,
      "endDate": 1537817400000
    },
    {
      "id": 10587,
      "type": "SESSION",
      "startDate": 1537817400000,
      "endDate": 1537826400000
    },
    {
      "id": 10588,
      "type": "SESSION",
      "startDate": 1537858800000,
      "endDate": 1537898400000
    },
    {
      "id": 10589,
      "type": "LUNCH",
      "startDate": 1537859700000,
      "endDate": 1537864200000
    },
    {
      "id": 10590,
      "type": "SESSION",
      "startDate": 1537860600000,
      "endDate": 1537891200000
    },
    {
      "id": 10591,
      "type": "SESSION",
      "startDate": 1537864200000,
      "endDate": 1537867800000
    },
    {
      "id": 10592,
      "type": "SESSION",
      "startDate": 1537864200000,
      "endDate": 1537894800000
    },
    {
      "id": 10593,
      "type": "SESSION",
      "startDate": 1537867800000,
      "endDate": 1537873200000
    },
    {
      "id": 10622,
      "type": "SESSION",
      "startDate": 1537873200000,
      "endDate": 1537876800000
    },
    {
      "id": 10623,
      "type": "SESSION",
      "startDate": 1537876800000,
      "endDate": 1537878600000
    },
    {
      "id": 10624,
      "type": "SESSION",
      "startDate": 1537878600000,
      "endDate": 1537882200000
    },
    {
      "id": 10625,
      "type": "SESSION",
      "startDate": 1537882200000,
      "endDate": 1537889400000
    },
    {
      "id": 10626,
      "type": "SESSION",
      "startDate": 1537889400000,
      "endDate": 1537893000000
    },
    {
      "id": 10627,
      "type": "SESSION",
      "startDate": 1537893000000,
      "endDate": 1537894800000
    }
  ],
  "sessions": [
    {
      "id": 2106,
      "name": "Coffee Break",
      "typeId": 10351,
      "roomId": 10102,
      "chairIds": [],
      "contentIds": [],
      "timeSlotId": 10241
    },
    {
      "id": 2325,
      "name": "Registration",
      "roomId": 10098,
      "chairIds": [],
      "contentIds": [],
      "timeSlotId": 10559
    },
    {
      "id": 1167,
      "name": "W1 - Second Workshop on Trust in the Age of Automated Driving",
      "typeId": 10170,
      "roomId": 10092,
      "chairIds": [],
      "contentIds": [
        3785
      ],
      "timeSlotId": 10562
    },
    {
      "id": 2471,
      "name": "W2 - ARV 2018: 2nd Workshop on Augmented Reality for Intelligent Vehicles",
      "typeId": 10170,
      "roomId": 10093,
      "chairIds": [],
      "contentIds": [
        3634
      ],
      "timeSlotId": 10562
    },
    {
      "id": 1444,
      "name": "W3 - Workshop on Designing Highly Automated Driving Systems as Radical Innovation ",
      "typeId": 10170,
      "roomId": 10094,
      "chairIds": [],
      "contentIds": [
        6972
      ],
      "timeSlotId": 10562
    },
    {
      "id": 2465,
      "name": "W4 - Automotive UI for Controllability and Safe Transitions of Control",
      "typeId": 10170,
      "roomId": 10095,
      "chairIds": [],
      "contentIds": [
        6938
      ],
      "timeSlotId": 10562
    },
    {
      "id": 1184,
      "name": "W5 - Workshop on Methodology: Evaluating Interactions between Automated Vehicles and Other Road Users - What Works in Practice?",
      "typeId": 10170,
      "roomId": 10096,
      "chairIds": [],
      "contentIds": [
        6046
      ],
      "timeSlotId": 10562
    },
    {
      "id": 2454,
      "name": "Coffee Break",
      "chairIds": [],
      "contentIds": [],
      "timeSlotId": 10565
    },
    {
      "id": 1731,
      "name": "Lunch",
      "chairIds": [],
      "contentIds": [],
      "timeSlotId": 10566
    },
    {
      "id": 1211,
      "name": "W10 - Workshop on Communication between Automated Vehicles and Vulnerable Road User",
      "typeId": 10170,
      "roomId": 10096,
      "chairIds": [],
      "contentIds": [
        7874
      ],
      "timeSlotId": 10569
    },
    {
      "id": 2282,
      "name": "W6 - 2nd Workshop on Situation Awareness in Automotive Evaluation & Design",
      "typeId": 10170,
      "roomId": 10092,
      "chairIds": [],
      "contentIds": [
        4124
      ],
      "timeSlotId": 10569
    },
    {
      "id": 1372,
      "name": "W7 - The Mobile Office",
      "typeId": 10170,
      "roomId": 10093,
      "chairIds": [],
      "contentIds": [
        3876
      ],
      "timeSlotId": 10569
    },
    {
      "id": 1848,
      "name": "W8 - Emotional GaRage: A Workshop on In-Car Emotion Recognition and Regulation",
      "typeId": 10170,
      "roomId": 10094,
      "chairIds": [],
      "contentIds": [
        5197
      ],
      "timeSlotId": 10569
    },
    {
      "id": 2066,
      "name": "W9 - User Interfaces for Publication Transport Vehicles: Future Opportunities and Challenges",
      "typeId": 10170,
      "roomId": 10095,
      "chairIds": [],
      "contentIds": [
        5629
      ],
      "timeSlotId": 10569
    },
    {
      "id": 1598,
      "name": "Coffee Break",
      "chairIds": [],
      "contentIds": [],
      "timeSlotId": 10572
    },
    {
      "id": 1685,
      "name": "Wifi Information",
      "typeId": 10408,
      "roomId": 10100,
      "chairIds": [],
      "contentIds": [
        7230
      ],
      "timeSlotId": 10573
    },
    {
      "id": 1545,
      "name": "Breakfast",
      "typeId": 10409,
      "roomId": 10101,
      "chairIds": [],
      "contentIds": [],
      "timeSlotId": 10574
    },
    {
      "id": 1114,
      "name": "Registration",
      "roomId": 10099,
      "chairIds": [],
      "contentIds": [],
      "timeSlotId": 10575
    },
    {
      "id": 1442,
      "name": "Welcome Session",
      "roomId": 10089,
      "chairIds": [],
      "contentIds": [],
      "timeSlotId": 10576
    },
    {
      "id": 2350,
      "name": "Keynote: Christopher A. Hart",
      "typeId": 10407,
      "roomId": 10089,
      "chairIds": [],
      "contentIds": [
        4167
      ],
      "timeSlotId": 10577
    },
    {
      "id": 2055,
      "name": "Exhibitors",
      "typeId": 10411,
      "roomId": 10156,
      "chairIds": [],
      "contentIds": [
        2709,
        5090,
        6443,
        2848,
        5520
      ],
      "timeSlotId": 10578
    },
    {
      "id": 1916,
      "name": "Coffee Break",
      "roomId": 10089,
      "chairIds": [],
      "contentIds": [],
      "timeSlotId": 10579
    },
    {
      "id": 2124,
      "name": "Videos",
      "typeId": 10402,
      "roomId": 10089,
      "chairIds": [],
      "contentIds": [
        3017,
        8098,
        5083,
        2907,
        7816
      ],
      "timeSlotId": 10580
    },
    {
      "id": 1039,
      "name": "Session 1: Haptics and Gestures",
      "typeId": 10410,
      "roomId": 10089,
      "chairIds": [
        23349
      ],
      "contentIds": [
        4529,
        6490,
        3510,
        3614,
        3514
      ],
      "timeSlotId": 10581
    },
    {
      "id": 1624,
      "name": "Lunch",
      "roomId": 10089,
      "chairIds": [],
      "contentIds": [],
      "timeSlotId": 10582
    },
    {
      "id": 1271,
      "name": "Session 2: Attentive User Interfaces",
      "typeId": 10410,
      "roomId": 10089,
      "chairIds": [
        24980
      ],
      "contentIds": [
        5662,
        6358,
        5049,
        3693
      ],
      "timeSlotId": 10583
    },
    {
      "id": 1389,
      "name": "Interactive Demos (with 1 minute madness) + Coffee",
      "typeId": 10405,
      "roomId": 10091,
      "chairIds": [
        13262
      ],
      "contentIds": [
        5584,
        6416,
        7652,
        4275,
        8103,
        4281,
        4178
      ],
      "timeSlotId": 10584
    },
    {
      "id": 1209,
      "name": "Session 3: User Experience and Acceptance",
      "typeId": 10410,
      "roomId": 10089,
      "chairIds": [
        22824
      ],
      "contentIds": [
        7195,
        6018,
        4600,
        5095
      ],
      "timeSlotId": 10585
    },
    {
      "id": 1066,
      "name": "Cocktail Reception",
      "roomId": 10097,
      "chairIds": [],
      "contentIds": [],
      "timeSlotId": 10586
    },
    {
      "id": 2172,
      "name": "The University of Toronto, Applied Science and Engineering Dinner Banquet + Keynote: Angela Schoellig",
      "typeId": 10407,
      "roomId": 10097,
      "chairIds": [],
      "contentIds": [
        4995
      ],
      "timeSlotId": 10587
    },
    {
      "id": 2205,
      "name": "Wifi Information",
      "typeId": 10408,
      "roomId": 10100,
      "chairIds": [],
      "contentIds": [
        7230
      ],
      "timeSlotId": 10588
    },
    {
      "id": 1583,
      "name": "Breakfast",
      "typeId": 10409,
      "roomId": 10101,
      "chairIds": [],
      "contentIds": [],
      "timeSlotId": 10589
    },
    {
      "id": 1327,
      "name": "Registration",
      "roomId": 10099,
      "chairIds": [],
      "contentIds": [],
      "timeSlotId": 10590
    },
    {
      "id": 2026,
      "name": "Session 4: Augmented Reality",
      "typeId": 10410,
      "roomId": 10089,
      "chairIds": [
        24986
      ],
      "contentIds": [
        6960,
        7912,
        6156,
        5434
      ],
      "timeSlotId": 10591
    },
    {
      "id": 1252,
      "name": "Exhibitors",
      "typeId": 10411,
      "roomId": 10156,
      "chairIds": [],
      "contentIds": [
        2709,
        5090,
        6443,
        2848,
        5520
      ],
      "timeSlotId": 10592
    },
    {
      "id": 1684,
      "name": "Papers Poster Session (with 1 minute madness): Special Approaches + Coffee Break",
      "typeId": 10412,
      "roomId": 10091,
      "chairIds": [
        25017
      ],
      "contentIds": [
        5903,
        7145,
        5743,
        6921,
        2729,
        4269,
        7487,
        7589,
        6369,
        7037
      ],
      "timeSlotId": 10593
    },
    {
      "id": 2033,
      "name": "Session 5: Coordination with Other Road Users",
      "typeId": 10410,
      "roomId": 10089,
      "chairIds": [
        21932
      ],
      "contentIds": [
        7981,
        3670,
        3333,
        6640
      ],
      "timeSlotId": 10622
    },
    {
      "id": 2354,
      "name": "Lunch",
      "roomId": 10089,
      "chairIds": [],
      "contentIds": [],
      "timeSlotId": 10623
    },
    {
      "id": 2357,
      "name": "Lunchtime Panel: Automotive User Interfaces - What We Know and the Future",
      "typeId": 10167,
      "roomId": 10089,
      "chairIds": [
        15970
      ],
      "contentIds": [
        6125
      ],
      "timeSlotId": 10624
    },
    {
      "id": 1126,
      "name": "WIP Poster Session (with 30 second madness) + Coffee",
      "typeId": 10426,
      "roomId": 10091,
      "chairIds": [
        8942
      ],
      "contentIds": [
        4871,
        5804,
        4019,
        6178,
        6627,
        6376,
        3851,
        3161,
        5654,
        8170,
        5245,
        3208,
        3935,
        3091,
        6001,
        7153,
        6769,
        7091,
        5344,
        6227,
        7358,
        5356,
        7155,
        3803,
        4493,
        5900,
        6150,
        6927
      ],
      "timeSlotId": 10625
    },
    {
      "id": 1320,
      "name": "Session 6: Driving in Context",
      "typeId": 10410,
      "roomId": 10089,
      "chairIds": [
        24999
      ],
      "contentIds": [
        3718,
        7485,
        4917,
        5783
      ],
      "timeSlotId": 10626
    },
    {
      "id": 1154,
      "name": "Closing Remarks",
      "roomId": 10089,
      "chairIds": [],
      "contentIds": [],
      "timeSlotId": 10627
    }
  ],
  "events": [],
  "contents": [
    {
      "id": 6018,
      "typeId": 11033,
      "title": "How to Design Valid Simulator Studies for Investigating User Experience in Automated Driving - Review and Hands-On Considerations",
      "trackId": 10034,
      "tags": [],
      "keywords": [],
      "abstract": "Simulator studies have been conducted in the automotive domain since the 1960s. Recently, automated driving studies have become more popular as real-world automated cars start to emerge but at this time not all levels of automation can be realized. But as a simulation does not entail all details of real driving, creating a realistic simulation experience - both on a psychological and physical level - proposes recurring challenges. These are among others: sample acquisition, simulator sickness, simulator training, interface design, take-over requests and secondary tasks in automated driving simulator studies. In this paper, we review existing literature and summarize important lessons from simulations in the domain of driving automation to provide considerations for studies investigating driver behavior in the age of highly automated driving.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "Ulm University"
            }
          ],
          "personId": 24954
        },
        {
          "affiliations": [
            {
              "institution": "Ulm University"
            }
          ],
          "personId": 25002
        },
        {
          "affiliations": [
            {
              "institution": "Ulm University"
            }
          ],
          "personId": 25009
        },
        {
          "affiliations": [
            {
              "institution": "Ulm University"
            }
          ],
          "personId": 24937
        },
        {
          "affiliations": [
            {
              "institution": "Ulm University"
            }
          ],
          "personId": 24961
        },
        {
          "affiliations": [
            {
              "institution": "Ulm University"
            }
          ],
          "personId": 24952
        }
      ],
      "sessionIds": [
        1209
      ],
      "eventIds": []
    },
    {
      "id": 4995,
      "typeId": 10407,
      "title": "Self-Driving Technology Today: What We Can and Cannot (Yet) Do",
      "trackId": 10029,
      "tags": [],
      "keywords": [],
      "abstract": "Over the past decade, our research has focused on algorithms that enable increased vehicle autonomy including vision, control and learning algorithms. We demonstrated these algorithms on different vehicle types ranging from drones and off-road driving vehicles to mobile manipulators. More recently, our team was selected as one of eight teams to compete in the North-American SAE AutoDrive Challenge, a three-year self-driving competition sponsored by General Motors among others. For this competition, we built a self-driving car in six months, took it to the Year 1 competition in Arizona in April 2018, and won!  The automation of vehicle behavior is particularly challenging when the vehicle operates in increasingly unpredictable and changing environments. Traditional robot algorithms largely rely on a-priori knowledge of the system and the environment, which is insufficient when requiring vehicles to deal with unseen situations. This is also reflected in self-driving car algorithms and explains why highway driving is much easier than city driving. This talk aims to highlight current advances and limitations of self-driving technology with the goal of bridging the gap between user interface design and the current capabilities of self-driving technology. As self-driving technology is evolving rapidly, I would also expect automotive interfaces to be required to evolve quickly.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "University of Toronto"
            }
          ],
          "personId": 12739
        }
      ],
      "sessionIds": [
        2172
      ],
      "eventIds": []
    },
    {
      "id": 3333,
      "typeId": 11033,
      "title": "A Field Study Of Pedestrians And Autonomous Vehicles",
      "trackId": 10034,
      "tags": [],
      "keywords": [],
      "abstract": "Autonomous vehicles have been in development for nearly thirty years and recently have begun to operate in real-world, uncontrolled settings. With such advances, more widespread research and evaluation of human interaction with autonomous vehicles (AV) is necessary. Here, we present an interview study of 32 pedestrians who have interacted with Uber AVs. Our findings are focused on understanding and trust of AVs, perceptions of AVs and artificial intelligence, and how the perception of a brand affects these constructs. We found an inherent relationship between favorable perceptions of technology and feelings of trust toward AVs. Trust in AVs was also influenced by a favorable\r\ninterpretation of the company’s brand and facilitated by knowledge about what AV technology is and how it might fit into everyday life. To our knowledge, this paper is the first to surface AV-related interview data from pedestrians in a natural, real-world setting.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "Carnegie Mellon University"
            }
          ],
          "personId": 22734
        },
        {
          "affiliations": [
            {
              "institution": "Carnegie Mellon University"
            }
          ],
          "personId": 23769
        },
        {
          "affiliations": [
            {
              "institution": "Carnegie Mellon University"
            }
          ],
          "personId": 18759
        },
        {
          "affiliations": [
            {
              "institution": "Carnegie Mellon University"
            }
          ],
          "personId": 16675
        },
        {
          "affiliations": [
            {
              "institution": "Carnegie Mellon University"
            }
          ],
          "personId": 19316
        },
        {
          "affiliations": [
            {
              "institution": "Carnegie Mellon University"
            }
          ],
          "personId": 15238
        }
      ],
      "sessionIds": [
        2033
      ],
      "eventIds": []
    },
    {
      "id": 6150,
      "typeId": 11057,
      "title": "Just Look:The Benefits of Gaze-Activated Voice Input in the Car",
      "trackId": 10035,
      "tags": [],
      "keywords": [],
      "abstract": "Voice interaction provides a natural and efficient form of communication with our cars. Current vehicles require the driver to push a button or to utter an artificial keyword before they can use speech input. This limits the potential naturalness and efficiency of voice input. In human communication, we usually use eye contact to express our intention to communicate with others. We conducted a user study with 25 participants that investigated gaze as a means to activate speech input while being occupied with a primary task. Our results indicated a strong dependency on the task. For tasks that refer to information on the screen, gaze activation was superior to push-to-talk and keyword, but it was less valuable if the task had no relation to screen content. We conclude that gaze cannot replace other modes for activation, but it can boost efficiency and user experience for display related tasks.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "University of Bamberg"
            },
            {
              "institution": "BMW Group Research, New Technologies, Innovations"
            }
          ],
          "personId": 16303
        },
        {
          "affiliations": [
            {
              "institution": "BMW Group Research, New Technologies, Innovations"
            }
          ],
          "personId": 13486
        },
        {
          "affiliations": [
            {
              "institution": "University of Bamberg"
            }
          ],
          "personId": 14027
        }
      ],
      "sessionIds": [
        1126
      ],
      "eventIds": []
    },
    {
      "id": 3718,
      "typeId": 11033,
      "title": "Where to Look: Exploring Peripheral Cues for Shifting Attention to Spatially Distributed Out-of-View Objects",
      "trackId": 10034,
      "tags": [],
      "keywords": [],
      "abstract": "Knowing the locations of spatially distributed objects is important in many different scenarios (e.g., driving a car and being aware of other road users). In particular, it is critical for preventing accidents with objects that come too close (e.g., cyclists or pedestrians). In this paper, we explore how peripheral cues can shift a user's attention towards spatially distributed out-of-view objects. We identify a suitable technique for visualization of these out-of-view objects and explore different cue designs to advance this technique to shift the user's attention. In a controlled lab study, we investigate non-animated peripheral cues with audio stimuli and animated peripheral cues without audio stimuli. Further, we looked into how user's identify out-of-view objects. Our results show that shifting the user's attention only takes about 0.86 seconds on average when animated stimuli are used, while shifting the attention with non-animated stimuli takes an average of 1.10 seconds.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "University of Oldenburg"
            }
          ],
          "personId": 24984
        },
        {
          "affiliations": [
            {
              "institution": "Technische Hochschule Ingolstadt"
            }
          ],
          "personId": 24935
        },
        {
          "affiliations": [
            {
              "institution": "University of Oldenburg"
            }
          ],
          "personId": 11670
        },
        {
          "affiliations": [
            {
              "institution": "University of Oldenburg"
            }
          ],
          "personId": 24964
        },
        {
          "affiliations": [
            {
              "institution": "OFFIS - Institute for Information Technology"
            }
          ],
          "personId": 22004
        }
      ],
      "sessionIds": [
        1320
      ],
      "eventIds": []
    },
    {
      "id": 4871,
      "typeId": 11057,
      "title": "Defining Ritualistic Driver and Passenger Behaviour to Inform  In-Vehicle Experiences ",
      "trackId": 10035,
      "tags": [],
      "keywords": [],
      "abstract": "By discovering unconscious ritualistic actions in everyday driving such as preparing for the morning commute, we seek design opportunities to help people achieve critical emotional transitions such as moving from an anxious state to relief. We have gathered and analysed data from workshops and phone interviews from a variety of vehicle and public transport users to capture these key ritualistic scenarios and map their emotional transitions. Design ideation is used to generate concepts for improving the in-vehicle user experience through redesign of vehicle layout, environment and analogue and digital interfaces. We report a set of human-centred design approaches that allow us to study the details of action, objects, people, emotions and meaning for typical car users which are indispensable for designing driving experiences and are often overlooked by the car design process.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "Royal College of Art"
            }
          ],
          "personId": 13192
        },
        {
          "affiliations": [
            {
              "institution": "Royal College of Art"
            }
          ],
          "personId": 11420
        },
        {
          "affiliations": [
            {
              "institution": "Royal College of Art"
            }
          ],
          "personId": 18801
        },
        {
          "affiliations": [
            {
              "institution": "Royal College of Art"
            }
          ],
          "personId": 10680
        },
        {
          "affiliations": [
            {
              "institution": "Royal College of Art"
            }
          ],
          "personId": 10955
        },
        {
          "affiliations": [
            {
              "institution": "Royal College of Art"
            }
          ],
          "personId": 19904
        }
      ],
      "sessionIds": [
        1126
      ],
      "eventIds": []
    },
    {
      "id": 7816,
      "typeId": 10979,
      "title": "Man vs. Machine: A Documentary About Automated Driving In 2018 Somewhere In Bavaria",
      "trackId": 10030,
      "tags": [],
      "keywords": [],
      "abstract": "The shift from manual to automated driving has been one of the most focused research topics in the AutomotiveUI community in recent years. User acceptance and experience was extensively discussed in surveys and simulator studies, however, naturalistic driving studies are still rare. Now, in 2018, we had the chance to test the first authorized automated vehicle (shuttle bus service) in Germany driving in regular traffic. Our video aims to be suggestive of our study setup, in which we compared users' acceptance and experience as a passenger in an automated driving versus a manual driven vehicle. In this video paper, we provide first insights into our results.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "Technische Hochschule Ingolstadt (THI)"
            },
            {
              "institution": "Johannes Kepler University"
            }
          ],
          "personId": 24967
        },
        {
          "affiliations": [
            {
              "institution": "Technische Hochschule Ingolstadt"
            },
            {
              "institution": "Johannes Kepler University"
            }
          ],
          "personId": 24988
        },
        {
          "affiliations": [
            {
              "institution": "Technische Hochschule Ingolstadt"
            }
          ],
          "personId": 24996
        },
        {
          "affiliations": [
            {
              "institution": "Technische Hochschule Ingolstadt"
            },
            {
              "institution": "Johannes Kepler University"
            }
          ],
          "personId": 24958
        }
      ],
      "sessionIds": [
        2124
      ],
      "eventIds": []
    },
    {
      "id": 3208,
      "typeId": 11057,
      "title": "DriverSense: a hyper-realistic testbed for the design and evaluation of novel user interfaces in self-driving vehicles",
      "trackId": 10035,
      "tags": [],
      "keywords": [],
      "abstract": "This paper presents a novel experimental platform for designing and validating onboard user interfaces for self-driving and remotely controlled vehicles.\r\nMost of currently existing academic and industrial testbeds and vehicular simulators are designed to reproduce with high fidelity the ergonomic aspects associated with the driving experience. However, they have very low degrees of realism for what concerns the digital components of the various traffic scenarios. These includes the visuals of the driving simulator and the behaviours of both other vehicles on the road and pedestrians.   \r\nHowever, with increasing deployment of self-driving and remote controlled vehicular modalities, it is expected that the digital components of the driving experience will become more and more relevant, because users will be less engaged in the actual driving tasks and more involved with oversight activities. In this respect, high visual testbed fidelity becomes an important pre-requisite for supporting the design and evaluation of future onboard interfaces.\r\nDriverSense, an innovative experimental testbed based on the hyper-realistic video game GTA V, has been developed to satisfy this need. To showcase its experimental flexibility, a set of selected user studies, presenting novel self-driving interfaces and associated user experience results, are described. These explore the capabilities of inducing trust in self-driving vehicles and explore Heads-Up Diplays (HUDs), Augmented Reality (ARs) and directional audio solutions. \r\n",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "The Royal Institute of Technology (KTH)"
            }
          ],
          "personId": 19628
        },
        {
          "affiliations": [
            {
              "institution": "The Royal Institute of Technology - KTH"
            }
          ],
          "personId": 16484
        },
        {
          "affiliations": [
            {
              "institution": "The Royal Institute of Technology (KTH)"
            }
          ],
          "personId": 15317
        },
        {
          "affiliations": [
            {
              "institution": "KTH Royal Institute of Technology"
            }
          ],
          "personId": 14303
        },
        {
          "affiliations": [
            {
              "institution": "Royal Institute of Technology (KTH)"
            }
          ],
          "personId": 22087
        }
      ],
      "sessionIds": [
        1126
      ],
      "eventIds": []
    },
    {
      "id": 6921,
      "typeId": 11033,
      "title": "P4 - Where Autonomous Buses Might and Might Not Bridge the Gaps in the 4 A’s of Public Transport Passenger Needs – a Review",
      "trackId": 10034,
      "tags": [],
      "keywords": [],
      "abstract": "In the domain of public transport, automation provides several advantages which can lead to better services for the customers. For tapping the full potential of future automated public transport services, passenger requirements have to be thoroughly considered in order to avoid shortcomings discouraging future users to remain or become customers and to support the role of public transit as sustainable backbone of transport. This paper assesses the potential of autonomous bus services with respect to four categories of passenger requirements described as the “4 A’s of Public Transport Passenger Needs”: availability, affordability, accessibility, and acceptability. Based on a review of currently discussed scenarios of automation, benefits and risks regarding the specific needs of different passenger groups are explored for these four categories. Finally, open issues which require special attention or further research are identified.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "AIT Austrian Institute of Technology"
            }
          ],
          "personId": 13854
        },
        {
          "affiliations": [
            {
              "institution": "AIT Austrian Institute of Technology"
            }
          ],
          "personId": 25011
        }
      ],
      "sessionIds": [
        1684
      ],
      "eventIds": []
    },
    {
      "id": 3851,
      "typeId": 11057,
      "title": "A Video-based Study Comparing Communication Modalities between an Autonomous Car and a Pedestrian ",
      "trackId": 10035,
      "tags": [],
      "keywords": [],
      "abstract": "There are increasing needs in communication between an autonomous car and a pedestrian. Some conceptual solutions have been proposed to solve this issue, such as using various communication modalities (eyes, smile, text, light and projector) on a car to communicate with pedestrians. However, there is no detailed study in comparing these communication modalities. In this study, we compare five modalities in a pedestrian street-crossing situation via a video experiment. The results show that a text is better than other modalities to express car’s intention to pedestrians. In addition, we compare the modalities in different scenarios and environments as well as pedestrian’s perception of the modalities.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "National Chiao Tung University"
            },
            {
              "institution": "The University of Tokyo"
            }
          ],
          "personId": 8370
        },
        {
          "affiliations": [
            {
              "institution": "The University of Tokyo"
            }
          ],
          "personId": 19908
        },
        {
          "affiliations": [
            {
              "institution": "The University of Tokyo"
            }
          ],
          "personId": 24979
        },
        {
          "affiliations": [
            {
              "institution": "Toyota Motor Corporation"
            }
          ],
          "personId": 23505
        },
        {
          "affiliations": [
            {
              "institution": "Toyota Motor Corporation"
            }
          ],
          "personId": 23397
        }
      ],
      "sessionIds": [
        1126
      ],
      "eventIds": []
    },
    {
      "id": 5900,
      "typeId": 11057,
      "title": "How can Automotive User Interfaces Represent Kinetic Energy as a Resource? An Interview Study with Hybrid Electric Vehicle Eco-Drivers",
      "trackId": 10035,
      "tags": [],
      "keywords": [],
      "abstract": "One potential contributor to mitigating the CO2 emissions caused by road transport is eco-driving. Eco-driving encompasses all driver behaviors performed to reduce the vehicle’s energy consumption. Drivers’ optimal on-road interaction with the kinetic energy resources is particularly relevant for eco-driving success. Hence, the question is what information do drivers require to optimally interact with the kinetic energy resources? We conducted ten interviews with hybrid electric vehicle (HEV) eco-drivers who actively interact with kinetic energy resources on a daily basis. From these interviews, a set of information requirements was derived. Further steps will comprise the development and testing of an interface prototype based on these information requirements.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "RWTH Aachen University"
            }
          ],
          "personId": 24991
        },
        {
          "affiliations": [
            {
              "institution": "Universität zu Lübeck"
            }
          ],
          "personId": 24931
        }
      ],
      "sessionIds": [
        1126
      ],
      "eventIds": []
    },
    {
      "id": 6156,
      "typeId": 11033,
      "title": "Effect of Volumetric Displays on Depth Perception in Augmented Reality",
      "trackId": 10034,
      "tags": [],
      "keywords": [],
      "abstract": "Augmented reality (AR) head-up displays (HUD) have previously been explored as a potential information delivery system for drivers.  In driving scenarios, correct perception of virtual object distance assists with effective use of AR HUDs in safety-critical applications (e.g., collision warnings).   AR volumetric displays purportedly offer increased accuracy of distance perception through consistent presentation of oculomotor cues such as vergence and accommodation over traditional displays.  For this paper, we investigated volumetric AR displays as a mean of enhancing perception of virtual objects registered to the real world, specifically in terms of distance perception as a result of binocular cues.  We designed and ran an experiment where participants controlled and placed virtual objects next to real-world counterparts at ranges between 7-12 meters.  We found that the volumetric AR display outperformed a traditional fixed focal plane AR HUD when considering distances 5 meters greater than the traditional display's focal depth.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "Virginia Tech"
            }
          ],
          "personId": 19752
        },
        {
          "affiliations": [
            {
              "institution": "Virginia Tech"
            }
          ],
          "personId": 20931
        },
        {
          "affiliations": [
            {
              "institution": "Virginia Tech"
            }
          ],
          "personId": 19883
        },
        {
          "affiliations": [
            {
              "institution": "Virginia Tech"
            }
          ],
          "personId": 24936
        },
        {
          "affiliations": [
            {
              "institution": "Virginia Tech"
            }
          ],
          "personId": 25007
        }
      ],
      "sessionIds": [
        2026
      ],
      "eventIds": []
    },
    {
      "id": 4493,
      "typeId": 11057,
      "title": "I Drive My Car and My States Drive Me: Visualizing Driver's Emotional and Physical States",
      "trackId": 10035,
      "tags": [],
      "keywords": [],
      "abstract": "Drivers' emotional and physical states have a big impact on their driving performance. New technological sensing methods are currently investigated and will soon allow to automatically detect the driver's state. Yet, how to communicate the detected state to the driver is less well understood. In an iterative design process, we developed two concepts to increase the driver's awareness of this issue: (1) a dashboard which provides a continuous overview of four potentially safety-critical states, namely drowsiness, aggressiveness, high workload, and hypoglycaemia, and (2) on-time warnings which alert the driver to an immediate safety risk. We then let 70 drivers experience both concepts in a driving simulation and collected their qualitative feedback in post-study interviews. We found that participants preferred to receive only safety-critical notifications of the driver's state but appreciated a progressive status indicator for easier interpretation. Based on our findings, we suggest first recommendations for visualizing driver's states.  ",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "LMU Munich"
            }
          ],
          "personId": 24983
        },
        {
          "affiliations": [
            {
              "institution": "Hamm-Lippstadt University of Applied Science"
            }
          ],
          "personId": 24088
        },
        {
          "affiliations": [
            {
              "institution": "LMU Munich"
            }
          ],
          "personId": 15934
        },
        {
          "affiliations": [
            {
              "institution": "LMU Munich"
            }
          ],
          "personId": 22310
        },
        {
          "affiliations": [
            {
              "institution": "LMU Munich"
            }
          ],
          "personId": 13412
        },
        {
          "affiliations": [
            {
              "institution": "LMU Munich"
            }
          ],
          "personId": 21488
        },
        {
          "affiliations": [
            {
              "institution": "LMU Munich"
            }
          ],
          "personId": 24972
        }
      ],
      "sessionIds": [
        1126
      ],
      "eventIds": []
    },
    {
      "id": 5903,
      "typeId": 11033,
      "title": "P1 - Design Guidelines for Reliability Communication in Autonomous Vehicles",
      "trackId": 10034,
      "tags": [],
      "keywords": [],
      "abstract": "Currently offered autonomous vehicles still require the human intervention. For instance, when the system fails to perform as expected or adapts to unanticipated situations. Given that reliability of autonomous systems can fluctuate across conditions, this work is a first step towards understanding how this information ought to be communicated to users. We conducted a user study to investigate the effect of communicating the system's reliability through a feedback bar. Subjective feedback was solicited from participants with questionnaires and semi-structured interviews. Based on the qualitative results, we derived guidelines that serve as a foundation for the design of how autonomous systems could provide continuous feedback on their reliability.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "Uni Duisburg-Essen"
            }
          ],
          "personId": 12299
        },
        {
          "affiliations": [
            {
              "institution": "Ulm University"
            }
          ],
          "personId": 24952
        },
        {
          "affiliations": [
            {
              "institution": "Universität Duisburg-Essen"
            }
          ],
          "personId": 19737
        },
        {
          "affiliations": [
            {
              "institution": "LMU Munich"
            },
            {
              "institution": "Max Planck Institute"
            }
          ],
          "personId": 19344
        }
      ],
      "sessionIds": [
        1684
      ],
      "eventIds": []
    },
    {
      "id": 6927,
      "typeId": 11057,
      "title": "Man vs. Machine: Comparing a Fully Automated Bus Shuttle with a Manually Driven Group Taxi in a Field Study",
      "trackId": 10035,
      "tags": [],
      "keywords": [],
      "abstract": "Automated driving functions are traditionally tested in on-road studies, however, mainly focusing on technological aspects (sensor accuracy, etc.). Field studies addressing users' individual needs and expectations are still rare. As a consequence, it is still unclear whether or not automated driving systems will reach a comprehensive market penetration.\r\nTo address this issue, we set-up a user study and compared users' acceptance (utilizing TAM) as a passenger (N=12) of a traditional group taxi vs. an automated bus shuttle both driving in regular traffic.\r\nResults show that participants questioned the usefulness of the automated bus shuttle, mainly due to the reduced speed, but, on the other hand, rated their perceived ease of use and their attitude towards using the ADS more positive than expected. Thus, we conclude that with further development of the technology and by including a user-centered design approach, high user acceptance of ADSs can finally be achieved.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "Technische Hochschule Ingolstadt"
            },
            {
              "institution": "Johannes Kepler University"
            }
          ],
          "personId": 24988
        },
        {
          "affiliations": [
            {
              "institution": "Technische Hochschule Ingolstadt (THI)"
            },
            {
              "institution": "Johannes Kepler University"
            }
          ],
          "personId": 24967
        },
        {
          "affiliations": [
            {
              "institution": "Technische Hochschule Ingolstadt"
            }
          ],
          "personId": 24996
        }
      ],
      "sessionIds": [
        1126
      ],
      "eventIds": []
    },
    {
      "id": 5520,
      "typeId": 11001,
      "title": "Ultrahaptics",
      "trackId": 10032,
      "tags": [],
      "keywords": [],
      "abstract": "https://www.ultrahaptics.com/",
      "authors": [],
      "sessionIds": [
        2055,
        1252
      ],
      "eventIds": []
    },
    {
      "id": 6416,
      "typeId": 11019,
      "title": "D2 - Raux: A Supportive System for Remote Automotive Ux R&D",
      "trackId": 10033,
      "tags": [],
      "keywords": [],
      "abstract": "Natural science research methods are appropriate for the study of existing and emerging phenomena; However, they are insufficient for the study of “wicked problems”. We use design science research methodology to answer research questions relevant to human problems via the creation of innovative artifacts (RAUX), thereby contributing new knowledge to the body of scientific evidence. RAUX demonstrates the front-end interaction of a supportive Remote UX design system in Automotive. It does not only mitigate the automotive domain deficiencies that previous research highlights but also supports in remote UX research and design activities. The users can navigate through and be supported in various activities including contextualization, communication, and presentation.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "Brunel University London"
            }
          ],
          "personId": 15011
        },
        {
          "affiliations": [
            {
              "institution": "Brunel University London"
            }
          ],
          "personId": 15027
        }
      ],
      "sessionIds": [
        1389
      ],
      "eventIds": []
    },
    {
      "id": 3091,
      "typeId": 11057,
      "title": "An Augmented Reality Display for Conditionally Automated Driving",
      "trackId": 10035,
      "tags": [],
      "keywords": [],
      "abstract": "This paper investigates whether an Augmented Reality Head-up Display (AR-HUD) supports usability and reduces visual demand during conditionally automated driving. In a driving simulator study, 24 drivers experienced several driving scenarios while driving with conditional automation. The drivers completed one drive with a fully developed HMI designed for automated driving (AD-HMI) that presented visual information in the cluster display and included auditory and tactile output. In another drive, the same drivers were additionally supported by dynamic and static visual feedback via an AR-HUD concept. The latter was preferred by more than 80% of the sample due to the higher information content and the possibility to leave the eyes on the road. Drivers rated the AR concept to be better understandable and more useful. Eye-tracking revealed lower percentage of gazes to the instrument cluster during AR-HUD drives.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "Wuerzburg Institute for Traffic Sciences"
            }
          ],
          "personId": 13166
        },
        {
          "affiliations": [
            {
              "institution": "Wuerzburg Institute for Traffic Sciences"
            }
          ],
          "personId": 10570
        },
        {
          "affiliations": [
            {
              "institution": "Wuerzburg Institute for Traffic Sciences"
            }
          ],
          "personId": 19385
        },
        {
          "affiliations": [
            {
              "institution": "Wuerzburg Institute for Traffic Sciences"
            }
          ],
          "personId": 19853
        },
        {
          "affiliations": [
            {
              "institution": "Continental Automotive GmbH"
            }
          ],
          "personId": 16196
        },
        {
          "affiliations": [
            {
              "institution": "Continental Automotive GmbH"
            }
          ],
          "personId": 18665
        }
      ],
      "sessionIds": [
        1126
      ],
      "eventIds": []
    },
    {
      "id": 2709,
      "typeId": 11001,
      "title": "Ergoneers",
      "trackId": 10032,
      "tags": [],
      "keywords": [],
      "abstract": "https://www.ergoneers.com/",
      "authors": [],
      "sessionIds": [
        2055,
        1252
      ],
      "eventIds": []
    },
    {
      "id": 5654,
      "typeId": 11057,
      "title": "personalDash: First Steps Towards User-controlled Personalization of 3D Dashboards with Mobile Devices",
      "trackId": 10035,
      "tags": [],
      "keywords": [],
      "abstract": "In the sharing-economy, users do not necessarily own a car but use commercial services to rent a car according to their needs, requirements, and liking.\r\nTo provide the best driving experience and safety, it is necessary that they understand the car and its functionality. \t\r\nAssuming that future vehicles will facilitate mostly screens for information presentation, a possible way to foster this understanding is by remote user-controlled dashboard personalization. \r\nBy that, users can design a layout according to their individual preferences prior to the drive and by that, use a familiar looking dashboard.\r\nMain contributions of this work are (1) first design guidelines for mobile applications allowing personalization of dashboards and (2) information on users views regarding dashboard personalization.\r\nResults of a design workshop with usability experts and a follow-up usability study show that user-controlled personalization has potential and our design guidelines provide a valid foundation for future research.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "Ilmenau University of Technology"
            }
          ],
          "personId": 14206
        },
        {
          "affiliations": [
            {
              "institution": "Ilmenau University of Technology"
            }
          ],
          "personId": 24973
        },
        {
          "affiliations": [
            {
              "institution": "Ilmenau University of Technology"
            }
          ],
          "personId": 24974
        }
      ],
      "sessionIds": [
        1126
      ],
      "eventIds": []
    },
    {
      "id": 5783,
      "typeId": 11033,
      "title": "Why Disable the Autopilot?",
      "trackId": 10034,
      "tags": [],
      "keywords": [],
      "abstract": "The number of systems in commercially available vehicles that assist or automate driving tasks is rapidly increasing. At least for the next decade, using such systems remains up to the discretion of the user. In this paper, different reasons why drivers may disengage the autopilot are investigated. This was done through a simulator study in which the system could drive fully automated, but where participants could also disengage the system. Qualitative data were collected about why participants disengaged the autopilot. The analysis of the data revealed six themes covering the reasons why participants disabled the autopilot: The speed maintained by the autopilot, the behavior of the autopilot in relation to overtaking other vehicles, onset of boredom, onset of sleepiness, lack of trust in the autopilot, and enjoyment of manual driving. On the basis of the results, design opportunities are proposed to counteract the tendency to not use automated driving systems.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "Eindhoven University of Technology"
            }
          ],
          "personId": 14510
        },
        {
          "affiliations": [
            {
              "institution": "Eindhoven University of Technology"
            }
          ],
          "personId": 25014
        },
        {
          "affiliations": [
            {
              "institution": "Eindhoven University of Technology"
            }
          ],
          "personId": 19006
        }
      ],
      "sessionIds": [
        1320
      ],
      "eventIds": []
    },
    {
      "id": 6938,
      "typeId": 10992,
      "title": "Automotive UI for Controllability and Safe Transitions of Control",
      "trackId": 10031,
      "tags": [],
      "keywords": [],
      "abstract": "Highly automated vehicles require users to take over control when they reach the limits of the automation. These control transitions can lead to hazardous accidents if the human and automation do not have a consistent mental model of the abilities, authorities, and responsibilities of each other. In this workshop, we aim to apply existing knowledge to identify issues in control transitions in co-operative human-machine systems and propose solutions for them.\r\nConcrete focus points concern controllability, driving mode awareness, interaction design problems such as conveying the state of driver, automation, and vehicle, and evaluation methods.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "OFFIS Institute for Information Technology"
            }
          ],
          "personId": 25005
        },
        {
          "affiliations": [
            {
              "institution": "RWTH University"
            }
          ],
          "personId": 24933
        },
        {
          "affiliations": [
            {
              "institution": "Fraunhofer Institute"
            }
          ],
          "personId": 24987
        },
        {
          "affiliations": [
            {
              "institution": "University of Oldenburg"
            }
          ],
          "personId": 24964
        }
      ],
      "sessionIds": [
        2465
      ],
      "eventIds": []
    },
    {
      "id": 7195,
      "typeId": 11033,
      "title": "Who is Generation A? Investigating the Experience of Automated Driving for Different Age Groups",
      "trackId": 10034,
      "tags": [],
      "keywords": [],
      "abstract": "The prevalence of Automated Driving Systems (ADS) is expected to open up many possibilities for different user groups with individual needs and challenges. Former secondary/tertiary tasks can become primary tasks, and driving with all its interactions and responsibilities steps back or disappears at all.  At higher levels of AD it is expected that the elderly could maintain or regain individual mobility, thus, play a major role for future markets. \r\nTo understand individual mindsets concerning technology acceptance and user needs we conducted an explorative interview study (N=27). In a simulated automated driving environment, driving experience over time was compared across three age groups (elderly people >65, younger adults <30, younger adults <30 with age simulation suite), utilizing the STAM model for content analysis. Results of the age-comparison indicate no major differences in the general technology acceptance, however, fine-grained analysis revealed interesting differences in participants' perceptions concerning UX design requirements.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "Technische Hochschule Ingolstadt"
            },
            {
              "institution": "Johannes Kepler University"
            }
          ],
          "personId": 24967
        },
        {
          "affiliations": [
            {
              "institution": "Technische Hochschule Ingolstadt"
            }
          ],
          "personId": 10635
        },
        {
          "affiliations": [
            {
              "institution": "Technische Hochschule Ingolstadt"
            },
            {
              "institution": "Johannes Kepler University"
            }
          ],
          "personId": 24988
        },
        {
          "affiliations": [
            {
              "institution": "Technische Hochschule Ingolstadt"
            }
          ],
          "personId": 24996
        }
      ],
      "sessionIds": [
        1209
      ],
      "eventIds": []
    },
    {
      "id": 4124,
      "typeId": 10992,
      "title": "2nd Workshop on Situation Awareness in Automotive Evaluation & Design ",
      "trackId": 10031,
      "tags": [],
      "keywords": [],
      "abstract": "As a promising cognitive construct, situation awareness (SA) helps to assess operators’ dynamic knowledge of the driving task in different contexts as well as to inspire driving assistance system design. This workshop will discuss SA in an automotive context, emphasizing the increasing challenges that are related to vehicle automation. We will begin with an understanding of SA and SA information needs. Next, we will explore how to apply SA concepts to the design of Advanced Driver Assistance Systems (ADAS) and Automated Driving (AD) user interfaces. Finally, we will discuss several useful SA measures, using exercises to demonstrate the value of some example measures. ",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "DENSO International America, Inc"
            }
          ],
          "personId": 10923
        },
        {
          "affiliations": [
            {
              "institution": "Touchstone Evaluations, Inc."
            }
          ],
          "personId": 15684
        },
        {
          "affiliations": [
            {
              "institution": "DENSO International America, Inc."
            }
          ],
          "personId": 10014
        },
        {
          "affiliations": [
            {
              "institution": "Touchstone Evaluations, Inc."
            }
          ],
          "personId": 16961
        },
        {
          "affiliations": [
            {
              "institution": "University of Michigan Transportation Institute"
            }
          ],
          "personId": 24968
        }
      ],
      "sessionIds": [
        2282
      ],
      "eventIds": []
    },
    {
      "id": 3614,
      "typeId": 11033,
      "title": "Reducing the Attentional Demands of In-Vehicle Touchscreens with Stencil Overlays",
      "trackId": 10034,
      "tags": [],
      "keywords": [],
      "abstract": "Vehicle manufacturers are increasingly using touchscreens to support driver access to controls. However, input mechanisms displayed on touchscreens lack the tactile sensations of physical controls, creating risks of greater demand for visual attention. These risks can potentially be mitigated by restoring some degree of tactile feedback to touchscreen interaction. This paper describes a study that examines whether touchscreen target selection during simulated driving is improved by overlaying the touchscreen with a see-through 3D printed stencil that allows underlying touchscreen controls to be located or guided by feel. Results showed that touchscreen targets were selected more quickly and with shorter periods of visual attention towards the touchscreen when the stencil was present than when it was absent. Subjective preferences also favoured the stencil condition. The work demonstrates the value of adding tactile feedback to touchscreen interaction, and shows that stencils are a simple and effective way to reduce attentional demands.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "University of Canterbury"
            }
          ],
          "personId": 22507
        },
        {
          "affiliations": [
            {
              "institution": "University of Canterbury"
            }
          ],
          "personId": 22272
        },
        {
          "affiliations": [
            {
              "institution": "University of Canterbury"
            }
          ],
          "personId": 23302
        },
        {
          "affiliations": [
            {
              "institution": "University of Canterbury"
            }
          ],
          "personId": 20647
        },
        {
          "affiliations": [
            {
              "institution": "University of Canterbury"
            }
          ],
          "personId": 24998
        },
        {
          "affiliations": [
            {
              "institution": "University of Saskatchewan"
            }
          ],
          "personId": 8517
        }
      ],
      "sessionIds": [
        1039
      ],
      "eventIds": []
    },
    {
      "id": 6046,
      "typeId": 10992,
      "title": "Workshop on Methodology: Evaluating Interactions between Automated Vehicles and Other Road Users – What Works in Practice? ",
      "trackId": 10031,
      "tags": [],
      "keywords": [],
      "abstract": "Methods and metrics for studying interactions between automated vehicles and other road users in their vicinity, such as pedestrians, cyclists and non-automated vehicles, are not established yet. This workshop focuses on identifying the strengths and weaknesses of various methodologies that could potentially be used to study such interactions. The objective lies in determining the proper experimental design, sensitivity of metrics for measuring user behavior, ecological validity, generalizability of findings, extraction of insights regarding how findings can be translated into actionable requirements, and the alternatives for conducting longitudinal field studies. It will be of an interactive nature and involve hands-on activities. The workshop will consolidate existing knowledge, identify recurring issues, and explore the path towards resolving these issues. The outcome will be compiled into a paper to share this valuable knowledge with a broader research community.\r\n",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "Eindhoven University of Technology"
            }
          ],
          "personId": 24975
        },
        {
          "affiliations": [
            {
              "institution": "Research Institutes of Sweden (RISE)"
            }
          ],
          "personId": 24956
        },
        {
          "affiliations": [
            {
              "institution": "Research Institutes of Sweden (RISE)"
            }
          ],
          "personId": 20289
        },
        {
          "affiliations": [
            {
              "institution": "Research Institutes of Sweden (RISE)"
            }
          ],
          "personId": 24939
        },
        {
          "affiliations": [
            {
              "institution": "Research Institutes of Sweden (RISE)"
            }
          ],
          "personId": 24978
        },
        {
          "affiliations": [
            {
              "institution": "DLR"
            }
          ],
          "personId": 9888
        },
        {
          "affiliations": [
            {
              "institution": "DLR"
            }
          ],
          "personId": 16118
        },
        {
          "affiliations": [
            {
              "institution": "Institute for Transport Studies"
            }
          ],
          "personId": 24981
        }
      ],
      "sessionIds": [
        1184
      ],
      "eventIds": []
    },
    {
      "id": 5662,
      "typeId": 11033,
      "title": "Let Me Finish before I Take Over: Towards Attention Aware Device Integration in Highly Automated Vehicles",
      "trackId": 10034,
      "tags": [],
      "keywords": [],
      "abstract": "A major promise of automated vehicles is to render it possible for drivers to engage in non-driving related tasks, a setting where the execution pattern will switch from concurrent to sequential multitasking. To allow drivers to safely and efficiently switch between multiple activities (including vehicle control in case of Take-Over situations), we postulate that future vehicles should incorporate capabilities of attentive user interfaces, that precisely plan the timing of interruptions based on driver availability. We propose an attention aware system that issues Take-Over Requests (1) at emerging task boundaries and (2) directly on consumer devices such as smartphones or tablets.\r\nResults of a driving simulator study (N=18), where we evaluated objective, physiological, and subjective measurements, confirm our assumption: attention aware Take-Over Requests have the potential to reduce stress, increase Take-Over performance, and can further raise user acceptance/trust. Consequently, we emphasize to implement attentive user interfaces in future vehicles.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "Technische Hochschule Ingolstadt"
            },
            {
              "institution": "Johannes Kepler University"
            }
          ],
          "personId": 24988
        },
        {
          "affiliations": [
            {
              "institution": "Technische Hochschule Ingolstadt"
            }
          ],
          "personId": 24996
        },
        {
          "affiliations": [
            {
              "institution": "Technische Hochschule Ingolstadt"
            }
          ],
          "personId": 24958
        },
        {
          "affiliations": [
            {
              "institution": "Technische Hochschule Ingolstadt (THI)"
            }
          ],
          "personId": 24967
        },
        {
          "affiliations": [
            {
              "institution": "Catholic University of Eichstätt-Ingolstadt"
            },
            {
              "institution": "Technische Hochschule Ingolstadt"
            }
          ],
          "personId": 24994
        }
      ],
      "sessionIds": [
        1271
      ],
      "eventIds": []
    },
    {
      "id": 2848,
      "typeId": 11001,
      "title": "Smart Eye",
      "trackId": 10032,
      "tags": [],
      "keywords": [],
      "abstract": "http://smarteye.se/",
      "authors": [],
      "sessionIds": [
        2055,
        1252
      ],
      "eventIds": []
    },
    {
      "id": 6178,
      "typeId": 11057,
      "title": "Gaze Tracking Accuracy Maintenance using Traffic Sign Detection",
      "trackId": 10035,
      "tags": [],
      "keywords": [],
      "abstract": "Eye tracking technology is becoming an important component of Advanced Driver Assistance Systems. Unfortunately, eye tracking systems require calibration to correctly associate pupil positions with gaze directions, and periodic calibration would be necessary because the accuracy will deteriorate over time. This routine reduces the usability and practicability of in-vehicle eye tracking technology. \r\nWe propose an approach to automatically perform real-time eye tracking calibration. We apply an object detection algorithm to continually detect objects that would likely attract the drivers' attention, such as traffic signs and lights. Those are, in turn, used as moving stimuli for the gaze accuracy maintenance procedure. The error vectors between recorded fixations and moving targets are calculated immediately and the weighted average of them is used to compensate for the offset of fixations in real-time. We evaluated our method both on laboratory data and real driving data. The results show that we can effectively reduce the gaze tracking errors.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "University of Massachusetts Boston"
            }
          ],
          "personId": 9504
        },
        {
          "affiliations": [
            {
              "institution": "University of Massachusetts Boston"
            }
          ],
          "personId": 16517
        },
        {
          "affiliations": [
            {
              "institution": "University of Massachusetts Boston"
            }
          ],
          "personId": 9119
        }
      ],
      "sessionIds": [
        1126
      ],
      "eventIds": []
    },
    {
      "id": 8098,
      "typeId": 10979,
      "title": "Theo, take a right … uh … left? Conversational Route Negotiations with Autonomous Driving Assistants",
      "trackId": 10030,
      "tags": [],
      "keywords": [],
      "abstract": "We foresee conversational driver assistants playing a crucial role in automated driving interactions. In this video we present a study of user interactions with an in-vehicle agent, “Theo”, under SAE Level 4 automated driving. We use a remote Wizard-of-Oz setup where participants, sitting in a driving simulator, experience real-life video footage transmitted from a vehicle in the neighborhood and interact with Theo to instruct the vehicle where to go. We configured Theo to present 3 levels of conversational abilities (terse, verbose and helpful). We show the results of 9 participants tasked to negotiate destinations and route changes. Voice interaction was reported as preferred means of communication with Theo. There was a clear preference for talkative assistants which were perceived more responsive and intelligent. We highlight challenging interactions for users such as vehicle maneuvers in parking areas and specifying drop off points and interesting associations between the agent performance and the automated vehicle abilities.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "Intel Corporation"
            }
          ],
          "personId": 23131
        },
        {
          "affiliations": [
            {
              "institution": "Intel Labs"
            }
          ],
          "personId": 24946
        },
        {
          "affiliations": [
            {
              "institution": "Amplified by Design"
            }
          ],
          "personId": 8489
        },
        {
          "affiliations": [
            {
              "institution": "Intel Corporation"
            }
          ],
          "personId": 23985
        }
      ],
      "sessionIds": [
        2124
      ],
      "eventIds": []
    },
    {
      "id": 3876,
      "typeId": 10992,
      "title": "The Mobile Office",
      "trackId": 10031,
      "tags": [],
      "keywords": [],
      "abstract": "This workshop discusses the balance between safety and productivity as automated vehicles turn into 'mobile offices': spaces where non-driving activities are performed during one’s daily commute. Technological developments reduce the active role of the human driver that might, nonetheless, require occasional intervention. To what extent are drivers allowed to dedicate resources to non-driving work-related activities? To address this critical question, the workshop brings together a diverse community of researchers and practitioners that are interested in questions as follows: what non-driving activities are likely to be performed on one’s way to work and back; what is a useful taxonomy of these tasks; how can various tasks be studied in experimental settings; and, what are the criteria to assess human performance in automated vehicles. To foster further dialogue, the outcome of the workshop will be an online blog where attendees can contribute their own thoughts: https://medium.com/the-mobile-office.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "Ludwig-Maximilian-Universität"
            },
            {
              "institution": "Max Planck Institute for Biological Cybernetics"
            }
          ],
          "personId": 24953
        },
        {
          "affiliations": [
            {
              "institution": "Utrecht University"
            }
          ],
          "personId": 24932
        },
        {
          "affiliations": [
            {
              "institution": "University of New Hampshire"
            }
          ],
          "personId": 24970
        },
        {
          "affiliations": [
            {
              "institution": "Utrecht University"
            }
          ],
          "personId": 24980
        }
      ],
      "sessionIds": [
        1372
      ],
      "eventIds": []
    },
    {
      "id": 7589,
      "typeId": 11033,
      "title": "P8 - An Investigation into Glace-free Operation of a Touchscreen With and Without Haptic Support in the Driving Simulator",
      "trackId": 10034,
      "tags": [],
      "keywords": [],
      "abstract": "In an empirical study conducted with 25 participants, touch interaction with and without haptic feedback on an 8-inch touchscreen with glance-free operation have been compared with each other. For this purpose, a main menu consisting of four control elements, each with a size of 86 mm x 51 mm, was selected from the touchscreen's existing menu structure. The comparison of with and without haptic support shows that the error rate without haptic feedback is significantly higher than with haptic feedback. This effect is shown in the driving task performed in the driving simulator. Three causes for the significantly higher error rate in conventional operation have been discovered. Furthermore, it was also discovered that the subjective operational stress with haptic support is significantly lower than without haptic support. There were no significant difference in driving lane deviation and efficiency.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "Continental Automotive GmbH"
            }
          ],
          "personId": 17506
        },
        {
          "affiliations": [
            {
              "institution": "Continental Automotive GmbH"
            }
          ],
          "personId": 22197
        },
        {
          "affiliations": [
            {
              "institution": "Continental Automotive GmbH"
            }
          ],
          "personId": 17788
        }
      ],
      "sessionIds": [
        1684
      ],
      "eventIds": []
    },
    {
      "id": 8103,
      "typeId": 11019,
      "title": "D5 - Multi-Display Prototyping Using Any Browser Based UX Tools",
      "trackId": 10033,
      "tags": [],
      "keywords": [],
      "abstract": "With advancements in display technology and increased user demands, automotive manufactures are targeting multiple displays, in various sizes and orientations. They are also adding features and interactions that span across multiple displays in an attempt to engage more users in the car. Today developers and designers use ‘rapid prototyping’ tools like UXPin and Framer, to quickly validate and test their ideas. But these tools do not support Multi-Screens and Multi-Displays prototyping environments. Also, other prototyping tools like EB Guide and Qt, which support such environments, require extensive software learning and development time that denies the purpose of ‘rapid prototyping’. Hence, we propose a solution that would help any automotive designer and/or developers to quickly prototype and test their multi-media solutions for multi-screen vehicle system using any browser based UX tool.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "DENSO TEN AMERICA Limited"
            }
          ],
          "personId": 14642
        },
        {
          "affiliations": [
            {
              "institution": "DENSO TEN AMERICA Limited"
            }
          ],
          "personId": 21800
        }
      ],
      "sessionIds": [
        1389
      ],
      "eventIds": []
    },
    {
      "id": 2729,
      "typeId": 11033,
      "title": "P5 - Eliciting Driver Stress Using Naturalistic Driving Scenarios On Real Roads",
      "trackId": 10034,
      "tags": [],
      "keywords": [],
      "abstract": "We propose a novel method for reliably inducing stress in drivers for the purpose of generating real-world participant data for machine learning, using both scripted in-vehicle stressor events as well as unscripted on-road stressors such as pedestrians and construction zones. On-road drives took place in a vehicle outfitted with an experimental display that lead drivers to believe they had prematurely ran out of charge on an isolated road. We describe the elicitation method, course design, instrumentation, data collection procedure and the post-hoc labeling of unplanned road events to illustrate how rich data about a variety of stress-related events can be elicited from study participants on-road. We validate this method with data including psychophysiological measurements, video, voice, and GPS data from (\\textit{N}=20) participants. Results from algorithmic psychophysiological stress analysis were validated using participant self-reports. Results of stress elicitation analysis show that our method elicited a stress-state in 89\\% of participants.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "Stanford University"
            }
          ],
          "personId": 11104
        },
        {
          "affiliations": [
            {
              "institution": "Scrapworks Inc."
            }
          ],
          "personId": 23257
        },
        {
          "affiliations": [
            {
              "institution": "Cornell Tech"
            }
          ],
          "personId": 24986
        }
      ],
      "sessionIds": [
        1684
      ],
      "eventIds": []
    },
    {
      "id": 6443,
      "typeId": 11001,
      "title": "Nervtech",
      "trackId": 10032,
      "tags": [],
      "keywords": [],
      "abstract": "https://www.nervtech.com/",
      "authors": [],
      "sessionIds": [
        2055,
        1252
      ],
      "eventIds": []
    },
    {
      "id": 5804,
      "typeId": 11057,
      "title": "A Comparison of Emotion Elicitation Methods for Affective Driving Studies",
      "trackId": 10035,
      "tags": [],
      "keywords": [],
      "abstract": "Advances in sensing technology enable the emotional state of car drivers to be captured and interfaces to be built that respond to these emotions. To evaluate such emotionaware interfaces, researchers need to evoke certain emotional states within participants. Emotion elicitation in driving studies poses a challenge as the driving task can interfere with the elicitation task. Induced emotions also lose intensity with time and through secondary tasks. This is why we have analyzed different emotion elicitation techniques for their suitability in automotive research and compared the most promising approaches in a user study. We recommend using autobiographical recollection to induce emotions in driving studies, and suggest a way to prolong emotional states with music playback. We discuss experiences from a a driving simulator study, including solutions for addressing potential privacy issues.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "LMU Munich"
            },
            {
              "institution": "BMW Group Research, New Technologies, Innovations"
            }
          ],
          "personId": 24969
        },
        {
          "affiliations": [
            {
              "institution": "LMU Munich"
            }
          ],
          "personId": 9350
        },
        {
          "affiliations": [
            {
              "institution": "LMU Munich"
            }
          ],
          "personId": 25018
        },
        {
          "affiliations": [
            {
              "institution": "Bundeswehr University"
            },
            {
              "institution": "LMU Munich"
            }
          ],
          "personId": 24993
        }
      ],
      "sessionIds": [
        1126
      ],
      "eventIds": []
    },
    {
      "id": 4269,
      "typeId": 11033,
      "title": "P6 - Looming Auditory Collision Warnings for Semi-Automated Driving: An EEG/ERP Study",
      "trackId": 10034,
      "tags": [],
      "keywords": [],
      "abstract": "Looming sounds can be an ideal warning notification for emergency braking. This agrees with studies that have consistently demonstrated preferential brain processing for looming stimuli. This study investigates and demonstrates that looming sounds can similarly benefit emergency braking in managing a vehicle with adaptive cruise control (ACC). Specifically, looming auditory notifications induced the faster emergency braking times relative to a static auditory notification. Next, we compare the event-related potential (ERP) evoked by a looming notification, relative to its static equivalent. Looming notifications evoke a smaller fronto-central N2 amplitude than their static equivalents. Thus, we infer that looming sounds are consistent with the visual experience of an approaching collision and, hence, induced a corresponding performance benefit. Subjective ratings indicate no significant differences in the perceived workload across the notification conditions. Overall, this work suggests that auditory warnings should have congruent physical properties with the visual events that they warn for.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "University of Tuebingen"
            },
            {
              "institution": "Max Planck Institute for Biological Cybernetics"
            }
          ],
          "personId": 20687
        },
        {
          "affiliations": [
            {
              "institution": "Max Planck Institute for Biological Cybernetics"
            }
          ],
          "personId": 22064
        },
        {
          "affiliations": [
            {
              "institution": "University of Tuebingen"
            }
          ],
          "personId": 19188
        },
        {
          "affiliations": [
            {
              "institution": "Max Planck Institute for Biological Cybernetics"
            },
            {
              "institution": "Ludwig Maximilian University"
            }
          ],
          "personId": 24953
        }
      ],
      "sessionIds": [
        1684
      ],
      "eventIds": []
    },
    {
      "id": 7981,
      "typeId": 11033,
      "title": "Follow Me: Exploring Strategies and Challenges for Collaborative Driving",
      "trackId": 10034,
      "tags": [],
      "keywords": [],
      "abstract": "Current research on Vehicle-to-Vehicle (V2V) communication aims at improving interaction between different vehicles by communication technologies and is mainly focused on driver-to-driver interaction. But how do drivers and passengers of two vehicles that have the same destination communicate with each other? In such a collaborative driving scenario, several factors such as the environmental context or the behavior of the vehicle occupants may influence the communication. In order to explore how information is exchanged in collaborative driving, we conducted an exploratory in-situ study with seven groups of two driver/co-driver pairs each, located in two separate vehicles. During the ride, the participants had to drive collaboratively on a predefined route solving different subtasks. We found that different social (e.g., driving habits, unpredicted intentions) and contextual factors (e.g., night/rain conditions, size or color of the vehicle) influenced collaboration. Our findings provide a deeper understanding of collaborative driving and inform future V2V communication designs.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "University of Salzburg"
            }
          ],
          "personId": 19281
        },
        {
          "affiliations": [
            {
              "institution": "XRUX"
            }
          ],
          "personId": 15816
        },
        {
          "affiliations": [
            {
              "institution": "University of Salzburg"
            }
          ],
          "personId": 25003
        },
        {
          "affiliations": [
            {
              "institution": "University of Salzburg"
            }
          ],
          "personId": 25006
        },
        {
          "affiliations": [
            {
              "institution": "University of Salzburg"
            }
          ],
          "personId": 24963
        }
      ],
      "sessionIds": [
        2033
      ],
      "eventIds": []
    },
    {
      "id": 6960,
      "typeId": 11033,
      "title": "Establishing the Role of a Virtual Lead Vehicle as a Novel Augmented Reality Navigational Aid",
      "trackId": 10034,
      "tags": [],
      "keywords": [],
      "abstract": "This paper reports on two studies investigating how following a lead vehicle could act as a metaphor for an Augmented Reality (AR) system to support navigation tasks. For the first formative study, 34 participants completed a video-based evaluation of the role of a real lead vehicle when navigating a coherent journey. Verbal protocols indicated that a lead vehicle may be a valuable navigation aid at a range of different junction types, but not where drivers may desire a preview of upcoming steps or their overall orientation. A subsequent driving simulator study with 22 participants examined whether an AR lead vehicle may support drivers when navigating at complex junctions, specifically large multi-exit roundabouts. The virtual car led to good navigation and driving performance, which was comparable to a more traditional screen-fixed interface. Overall, this work demonstrates that a virtual lead vehicle may be beneficial within AR navigation devices. ",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "University of Nottingham"
            }
          ],
          "personId": 24960
        },
        {
          "affiliations": [
            {
              "institution": "University of Nottingham"
            }
          ],
          "personId": 24940
        },
        {
          "affiliations": [
            {
              "institution": "University of Nottingham"
            }
          ],
          "personId": 24959
        },
        {
          "affiliations": [
            {
              "institution": "Jaguar Land Rover"
            }
          ],
          "personId": 24982
        },
        {
          "affiliations": [
            {
              "institution": "Jaguar Land Rover"
            }
          ],
          "personId": 15201
        }
      ],
      "sessionIds": [
        2026
      ],
      "eventIds": []
    },
    {
      "id": 4529,
      "typeId": 11033,
      "title": "May the Force Be with You: Ultrasound Haptic Feedback for Mid-Air Gesture Interaction in Cars",
      "trackId": 10034,
      "tags": [],
      "keywords": [],
      "abstract": "  The use of ultrasound haptic feedback for mid-air gestures in cars has been proposed to provide a sense of control over the user's intended actions and to add touch to a touchless interaction. However, the impact of ultrasound feedback to the gesturing hand regarding lane deviation, eyes-off-the-road time (EORT) and perceived mental demand has not yet been measured. This paper investigates the impact of uni- and multimodal presentation of ultrasound feedback on the primary driving task and the secondary gesturing task in a simulated driving environment. The multimodal combinations of ultrasound included visual, auditory, and peripheral lights. We found that ultrasound feedback presented uni-modally and bi-modally resulted in significantly less EORT compared to visual feedback. Our results suggest that multimodal ultrasound feedback for mid-air interaction decreases EORT whilst not compromising driving performance nor mental demand and thus can increase safety while driving. \r\n  ",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "University of Glasgow"
            }
          ],
          "personId": 11778
        },
        {
          "affiliations": [
            {
              "institution": "University of Glasgow"
            }
          ],
          "personId": 17709
        },
        {
          "affiliations": [
            {
              "institution": "University of Glasgow"
            }
          ],
          "personId": 24938
        }
      ],
      "sessionIds": [
        1039
      ],
      "eventIds": []
    },
    {
      "id": 3634,
      "typeId": 10992,
      "title": "ARV 2018: 2nd Workshop on Augmented Reality for Intelligent Vehicles ",
      "trackId": 10031,
      "tags": [],
      "keywords": [],
      "abstract": "Augmented reality (AR) has the potential to improve road safety, support more immersive (non-) driving related activities, and finally enhance driving experience. AR may also be the enabling technology to help on the transition towards automated driving. However, augmented reality still faces a number of technical challenges when applied in vehicles, and also several human factors issues need to be solved. In this workshop, we will discuss potential and constraints as well as impact, role, and adequacy of AR in driving applications. The primary goal of this workshop is to define a research agenda for the use of AR in intelligent vehicles within the next 3 to 5 years.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "Technische Hochschule Ingolstadt"
            },
            {
              "institution": "Johannes Kepler University"
            }
          ],
          "personId": 24996
        },
        {
          "affiliations": [
            {
              "institution": "University of New Hampshire"
            }
          ],
          "personId": 24970
        },
        {
          "affiliations": [
            {
              "institution": "Virginia Tech"
            }
          ],
          "personId": 24936
        },
        {
          "affiliations": [
            {
              "institution": "University of Glasgow"
            }
          ],
          "personId": 24938
        },
        {
          "affiliations": [
            {
              "institution": "University of Applied Sciences Upper Austria"
            },
            {
              "institution": "Technische Hochschule Ingolstadt"
            }
          ],
          "personId": 24962
        }
      ],
      "sessionIds": [
        2471
      ],
      "eventIds": []
    },
    {
      "id": 7091,
      "typeId": 11057,
      "title": "Unskilled and Unaware: Subpar Users of Automated Driving Systems Make Spurious Decisions",
      "trackId": 10035,
      "tags": [],
      "keywords": [],
      "abstract": "This work investigated differences between preference and performance in Human Computer Interactions and their dependency to the respective user skill level. A driving simulator study with N=57 participants was conducted to evaluate a Human-Machine Interface for a Level 3 Automated Driving System. Two experimenters rated interaction performance (e.g., input errors, mode confusions, etc.). Additionally, participants reported their preference by means of perceived usability and acceptance. The sample was split into four groups based on the quartiles of performance. Results revealed that the four groups differed significantly in their performance. However, preference ratings did not show this effect. Thus, the present research could find evidence that the dissociation of performance and preference depends on participants’ skills. Finally, future research directions are outlined.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "BMW Group"
            }
          ],
          "personId": 24995
        },
        {
          "affiliations": [
            {
              "institution": "BMW Group"
            }
          ],
          "personId": 24992
        },
        {
          "affiliations": [
            {
              "institution": "BMW"
            }
          ],
          "personId": 19385
        },
        {
          "affiliations": [
            {
              "institution": "Chemnitz University of Technology"
            }
          ],
          "personId": 21926
        }
      ],
      "sessionIds": [
        1126
      ],
      "eventIds": []
    },
    {
      "id": 4275,
      "typeId": 11019,
      "title": "D4 - Demonstration of a Low-Cost Hyper-Realistic Testbed for Designing Future Onboard Experiences",
      "trackId": 10033,
      "tags": [],
      "keywords": [],
      "abstract": "This demo presents DriverSense, a novel experimental platform for designing and validating onboard user interfaces for self-driving and remotely controlled vehicles. Most of currently existing vehicular testbeds and simulators are designed to reproduce with high fidelity the ergonomic aspects associated with the driving experience. However, with increasing deployment of self-driving and remotely controlled or monitored vehicles, it is expected that the digital components of the driving experience will become more relevant. That is because users will be less engaged in the actual driving tasks and more involved with oversight activities. In this respect, high visual testbed fidelity becomes an important pre-requisite for supporting the design and evaluation of future interfaces. DriverSense, which is based on the hyper-realistic video game GTA V, has been developed to satisfy this need. To showcase its experimental flexibility, a set of self-driving interfaces have been implemented, including Heads-Up Display (HUDs), Augmented Reality (ARs) and directional audio.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "The Royal Institute of Technology (KTH)"
            }
          ],
          "personId": 19628
        },
        {
          "affiliations": [
            {
              "institution": "The Royal Institute of Technology - KTH"
            }
          ],
          "personId": 16484
        },
        {
          "affiliations": [
            {
              "institution": "The Royal Institute of Technology (KTH)"
            }
          ],
          "personId": 15317
        },
        {
          "affiliations": [
            {
              "institution": "KTH Royal Institute of Technology"
            }
          ],
          "personId": 14303
        },
        {
          "affiliations": [
            {
              "institution": "Royal Institute of Technology (KTH)"
            }
          ],
          "personId": 22087
        }
      ],
      "sessionIds": [
        1389
      ],
      "eventIds": []
    },
    {
      "id": 4019,
      "typeId": 11057,
      "title": "Interface Concepts for Intent Communication from Autonomous Vehicles to Vulnerable Road Users",
      "trackId": 10035,
      "tags": [],
      "keywords": [],
      "abstract": "This paper presents six interface concepts for Autonomous Vehicles to communicate their intention to Vulnerable Road Users. The concepts were designed to be scalable and versatile, and attempt to address some of the limitations of existing concepts towards an unambiguous communication. The interfaces exist currently as initial concepts generated from brainstorming sessions and are in the process of being validated through prototype development and controlled studies.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "Eindhoven University of Technology"
            }
          ],
          "personId": 24975
        },
        {
          "affiliations": [
            {
              "institution": "University of Twente"
            }
          ],
          "personId": 24945
        },
        {
          "affiliations": [
            {
              "institution": "NIO GmbH"
            }
          ],
          "personId": 24951
        },
        {
          "affiliations": [
            {
              "institution": "Eindhoven University"
            }
          ],
          "personId": 12866
        },
        {
          "affiliations": [
            {
              "institution": "Eindhoven University"
            }
          ],
          "personId": 25014
        }
      ],
      "sessionIds": [
        1126
      ],
      "eventIds": []
    },
    {
      "id": 4917,
      "typeId": 11033,
      "title": "Don't Be Alarmed: Sonifying Autonomous Vehicle Perception to Increase Situation Awareness",
      "trackId": 10034,
      "tags": [],
      "keywords": [],
      "abstract": "Lack of trust can arise when people do not know what autonomous vehicles perceive in the environment. To convey this information without causing alarm or compelling people to act, we designed and evaluated a way to sonify an autonomous vehicle's perception of salient driving events using abstract auditory icons, or \"earcons.\" These are localized in space using an in-car quadraphonic speaker array to correspond with the direction of events. We describe the interaction design for these awareness cues and a validation experiment (\\textit{N}=28) examining the effects of sonified events on drivers' sense of situation awareness, comfort, and trust. Overall, this work suggests that our designed earcons do improve people's awareness of in-simulation events. The effect of the increased situational awareness on trust and comfort is inconclusive. However, post-study design feedback suggests that sounds should have low levels of intensity and dissonance, and a sense of belonging to a common family.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "Stanford University"
            }
          ],
          "personId": 15999
        },
        {
          "affiliations": [
            {
              "institution": "Stanford University"
            }
          ],
          "personId": 12013
        },
        {
          "affiliations": [
            {
              "institution": "CCRMA, Stanford University"
            }
          ],
          "personId": 10961
        },
        {
          "affiliations": [
            {
              "institution": "Stanford University"
            }
          ],
          "personId": 13540
        },
        {
          "affiliations": [
            {
              "institution": "Stanford University"
            }
          ],
          "personId": 18199
        },
        {
          "affiliations": [
            {
              "institution": "Cornell Tech"
            }
          ],
          "personId": 24986
        }
      ],
      "sessionIds": [
        1320
      ],
      "eventIds": []
    },
    {
      "id": 3510,
      "typeId": 11033,
      "title": "Selection Facilitation Schemes for Predictive Touch with Mid-air Pointing Gestures in Automotive Displays",
      "trackId": 10034,
      "tags": [],
      "keywords": [],
      "abstract": "Predictive touch is an HMI technology that relies on inferring, early in the pointing gesture, the interface item a driver or passenger intends to select on an in-vehicle display [1, 2]. It simplifies and expedites the selection task, thereby reducing the associated interaction effort. This paper presents two studies on drivers using predictive touch and focuses on evaluating the best means to facilitate selecting the intended on-display item. This includes immediate mid-air selection with the system autonomously auto-selecting the predicted interface component, hover/dwell and drivers pressing a button on the steering wheel to execute the selection action. These were arrived at in an expert workshop study with twelve participants. The results of the subsequent evaluation study with twenty four participants demonstrate, using quantitative and qualitative measures, that immediate mid-air selection is a promising assistive scheme, where drivers need not touch a physical surface to select interface components, thus touch-free control.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "University of Cambridge"
            }
          ],
          "personId": 21217
        },
        {
          "affiliations": [
            {
              "institution": "Jaguar Land Rover"
            }
          ],
          "personId": 15201
        },
        {
          "affiliations": [
            {
              "institution": "Jaguar landrover"
            }
          ],
          "personId": 25008
        },
        {
          "affiliations": [
            {
              "institution": "Jaguar Land Rover"
            }
          ],
          "personId": 25010
        },
        {
          "affiliations": [
            {
              "institution": "warwick university"
            }
          ],
          "personId": 19689
        },
        {
          "affiliations": [
            {
              "institution": "Jaguar Land Rover"
            }
          ],
          "personId": 24982
        },
        {
          "affiliations": [
            {
              "institution": "University of Cambridge"
            }
          ],
          "personId": 20682
        },
        {
          "affiliations": [
            {
              "institution": "University of Cambridge"
            }
          ],
          "personId": 20853
        }
      ],
      "sessionIds": [
        1039
      ],
      "eventIds": []
    },
    {
      "id": 4281,
      "typeId": 11019,
      "title": "D6 - In-vehicle Affect Detection System: Identification of Emotional Arousal by Monitoring the Driver and Driving Style",
      "trackId": 10033,
      "tags": [],
      "keywords": [],
      "abstract": "There have been clear needs to address the impact of driver emotions such as anger and happiness on aggressive or distracted driving behaviors. To tackle this issue, we have developed an affect detection system for identifying a driver’s emotional arousal, including the driver’s physiological data and vehicle’s kinematic data. Multimodal sensors are wirelessly connected to a smartphone and then, all the driver and driving data are displayed on our Android application in real-time. With the benefits of this multimodal, portable, non-intrusive, and cost-efficient system, subsequent experiments were designed to test and improve the system. After identifying significant features, various machine learning algorithms will be used to model a driver’s emotional states. Our final goal is to develop an optimized classifier of specific emotional states including arousal and valence. We hope that we can spark lively discussions on driver emotions at AutoUI and use the feedback to improve our system.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "Michigan Technological University"
            }
          ],
          "personId": 12113
        },
        {
          "affiliations": [
            {
              "institution": "Virginia Tech"
            }
          ],
          "personId": 24990
        },
        {
          "affiliations": [
            {
              "institution": "Virginia Tech"
            }
          ],
          "personId": 11541
        }
      ],
      "sessionIds": [
        1389
      ],
      "eventIds": []
    },
    {
      "id": 5049,
      "typeId": 11033,
      "title": "Using Smartwatch Inertial Sensors to Recognize and Distinguish Between Car Drivers and Passengers",
      "trackId": 10034,
      "tags": [],
      "keywords": [],
      "abstract": "People increasingly interact with social media or other apps on their smartphones while driving car. This is naturally a major safety concern, and it remains unclear how to avoid or limit such interaction. We investigate this problem through human activity recognition (HAR) where we developed a system called IRIS, which collects smartwatch accelerometer data and analyses the data through machine learning and predicts if the data origins from a driver or a passenger. We report from a field experiment with 24 participants acting as drivers or passengers where we achieved an overall prediction accuracy of 87%. We further found that various road segments had less effect on the accuracy than anticipated, but we also found that passenger tasks had a negative effect on recognition accuracy. We discuss several implications from findings.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "Human-Centered Computing, Aalborg University"
            }
          ],
          "personId": 10598
        },
        {
          "affiliations": [
            {
              "institution": "Aalborg University"
            }
          ],
          "personId": 24215
        },
        {
          "affiliations": [
            {
              "institution": "Aalborg University"
            }
          ],
          "personId": 9036
        },
        {
          "affiliations": [
            {
              "institution": "Aalborg University"
            }
          ],
          "personId": 12357
        },
        {
          "affiliations": [
            {
              "institution": "Aalborg University"
            }
          ],
          "personId": 13521
        }
      ],
      "sessionIds": [
        1271
      ],
      "eventIds": []
    },
    {
      "id": 3514,
      "typeId": 11033,
      "title": "Investigation of Thermal Stimuli for Lane Changes",
      "trackId": 10034,
      "tags": [],
      "keywords": [],
      "abstract": "Haptic feedback has been widely studied for in-car interactions. However, most of this research has used vibrotactile cues. This paper presents two studies that examine novel thermal feedback for navigation during simulated driving for a lane change task. In the first, we compare the distraction and time differences of audio and thermal feedback. The results show that the presentation of thermal stimuli does not increase lane deviation, but the time needed to complete a lane change increased by 1.82 seconds. In the second study, the influence of variable changes of thermal stimuli on the lane change task performance was tested. We found that the same stimulus design for warm and cold temperatures does not always elicit the same results. Furthermore, variable alterations can have different effects on specified tasks. This suggests that the design of thermal stimuli is highly dependent on what task result should be maximized.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "University of Glasgow"
            }
          ],
          "personId": 10653
        },
        {
          "affiliations": [
            {
              "institution": "University of Glasgow"
            }
          ],
          "personId": 24938
        },
        {
          "affiliations": [
            {
              "institution": "University of Glasgow"
            }
          ],
          "personId": 10644
        },
        {
          "affiliations": [
            {
              "institution": "Jaguar Land Rover"
            }
          ],
          "personId": 13496
        },
        {
          "affiliations": [
            {
              "institution": "Jaguar Land Rover"
            }
          ],
          "personId": 24982
        },
        {
          "affiliations": [
            {
              "institution": "Jaguar Land Rover"
            }
          ],
          "personId": 24934
        }
      ],
      "sessionIds": [
        1039
      ],
      "eventIds": []
    },
    {
      "id": 5434,
      "typeId": 11033,
      "title": "Augmented Reality Displays for Communicating Uncertainty Information in Automated Driving",
      "trackId": 10034,
      "tags": [],
      "keywords": [],
      "abstract": "Safe manual driving performance following takeovers in conditionally automated driving systems is impeded by a lack in situation awareness, partly due to an inappropriate trust in the system's capabilities. Previous work has indicated that the communication of system uncertainties can aid the trust calibration process. However, it has yet to be investigated how the information is best conveyed to the human operator. The study outlined in this publication presents an interface layout to visualise function-specific uncertainty information in an augmented reality display and explores the suitability of 11 visual variables. 46 participants completed a sorting task and indicated their preference for each of these variables. The results demonstrate that particularly colour-based and animation-based variables, above all hue, convey a clear order in terms of urgency and are well-received by participants. The presented findings have implications for all augmented reality displays that are intended to show content varying in urgency.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "Loughborough University"
            }
          ],
          "personId": 25001
        },
        {
          "affiliations": [
            {
              "institution": "Loughborough University"
            }
          ],
          "personId": 25016
        },
        {
          "affiliations": [
            {
              "institution": "Loughborough University"
            }
          ],
          "personId": 24948
        },
        {
          "affiliations": [
            {
              "institution": "Loughborough University"
            }
          ],
          "personId": 24965
        }
      ],
      "sessionIds": [
        2026
      ],
      "eventIds": []
    },
    {
      "id": 6972,
      "typeId": 10992,
      "title": "Workshop on Designing Highly Automated Driving Systems as Radical Innovation",
      "trackId": 10031,
      "tags": [],
      "keywords": [],
      "abstract": "Automated driving systems (ADS), especially in higher levels of automation, seem to be the new focus of innovation regarding future mobility.\r\nTechnological achievements of traveling automation open up new challenges for road traffic. Existing automotive research focuses on problem solving and observational approaches including users and their imagination of the future of mobility to analyze acceptance and user experience of \"incremental\" (step-wised improved) innovations. On the other hand, \"radical'' (something new, enabled by technology or meaning change) innovations extensively increase product quality leaping over incremental innovation. This workshop aims to challenge the current research approaches to automated driving against  \"trying to improve sitting in a horse carriage\" and discuss how we can design \"radical\" innovations for ADS beyond the \"horse carriage'\". Within this interactive workshop, we will utilize a design thinking approach to refocus on underlying problems that ADSs originally aim to solve and generate ideas for radical innovations.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "Technische Hochschule Ingolstadt"
            },
            {
              "institution": "Technical Engineering"
            }
          ],
          "personId": 24967
        },
        {
          "affiliations": [
            {
              "institution": "Technische Hochschule Ingolstadt"
            }
          ],
          "personId": 24996
        },
        {
          "affiliations": [
            {
              "institution": "Virginia Tech"
            }
          ],
          "personId": 11541
        },
        {
          "affiliations": [
            {
              "institution": "University of Stuttgart"
            },
            {
              "institution": "LMU Munich"
            }
          ],
          "personId": 25018
        },
        {
          "affiliations": [
            {
              "institution": "INTEL CORPORATION"
            }
          ],
          "personId": 13262
        }
      ],
      "sessionIds": [
        1444
      ],
      "eventIds": []
    },
    {
      "id": 7485,
      "typeId": 11033,
      "title": "Drowsiness Detection and Warning in Manual and Automated Driving: Results from Subjective Evaluation",
      "trackId": 10034,
      "tags": [],
      "keywords": [],
      "abstract": "Drowsiness is a main cause of serious traffic accidents, and problematic within the ongoing automation of the driving task. Several approaches for drowsiness detection have been published and are in operation in production cars for manual driving. To assess differences in the development of drowsiness between manual and automated driving, and to further investigate the potential of subjective ratings, we conducted a driving simulator study (N=30). The self-assessment was based on the Karolinska Sleepiness Scale (KSS), during and after driving. Furthermore, we examined the impact of travel time and driver age (20-25, 65-70 years). Results confirm that driving mode and travel time have a significant effect on the development of drowsiness. In both age groups, self-ratings were higher for automated driving and particularly by younger subjects. All subjects estimated themselves drowsier during driving. The gained knowledge can be helpful for the development of future driver-vehicle interfaces in driver drowsiness detection.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "AUDI AG"
            },
            {
              "institution": "Technische Hochschule Ingolstadt"
            }
          ],
          "personId": 23010
        },
        {
          "affiliations": [
            {
              "institution": "Technische Hochschule Ingolstadt"
            },
            {
              "institution": "Johannes Kepler University"
            }
          ],
          "personId": 24996
        },
        {
          "affiliations": [
            {
              "institution": "AUDI AG"
            }
          ],
          "personId": 12687
        },
        {
          "affiliations": [
            {
              "institution": "Technische Hochschule Ingolstadt"
            }
          ],
          "personId": 24994
        }
      ],
      "sessionIds": [
        1320
      ],
      "eventIds": []
    },
    {
      "id": 7230,
      "title": "Wifi Information",
      "trackId": 10028,
      "tags": [],
      "keywords": [],
      "abstract": "Network Name: Sheraton Meetings  |   Password: acmtoronto",
      "authors": [],
      "sessionIds": [
        1685,
        2205
      ],
      "eventIds": []
    },
    {
      "id": 7358,
      "typeId": 11057,
      "title": "Beyond Transportation: How to Keep Users Attached When They Are Neither Driving nor Owning Automated Cars?",
      "trackId": 10035,
      "tags": [],
      "keywords": [],
      "abstract": "The way drivers relate to cars is likely bound to change with the rise of automated vehicles and new ownership models. However, personal relationships towards products are an important part of buying decisions. Car manufacturers thus need to provide novel bonding experiences for their future customers in order to stay competitive. \r\nWe introduce a vehicle attachment model based on related work from other domains. In interviews with 16 car owners we verify the approach as promising and derive four attachment types by applying the model: interviewees' personal attachments were grounded on either self-empowering reasons, memories with the car, increased status, or a loving friendship towards their car. We propose how to address the needs of these four attachment types as a first step towards emotionally irreplaceable automated and shared vehicles.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "LMU Munich"
            },
            {
              "institution": "BMW Group Research, New Technologies, Innovations"
            }
          ],
          "personId": 24969
        },
        {
          "affiliations": [
            {
              "institution": "Technische Hochschule Ingolstadt (THI)"
            },
            {
              "institution": "Johannes Kepler University"
            }
          ],
          "personId": 24967
        },
        {
          "affiliations": [
            {
              "institution": "LMU Munich"
            }
          ],
          "personId": 24983
        },
        {
          "affiliations": [
            {
              "institution": "Bundeswehr University Munich"
            }
          ],
          "personId": 24993
        },
        {
          "affiliations": [
            {
              "institution": "LMU Munich"
            }
          ],
          "personId": 24972
        },
        {
          "affiliations": [
            {
              "institution": "Technische Hochschule Ingolstadt"
            }
          ],
          "personId": 24996
        }
      ],
      "sessionIds": [
        1126
      ],
      "eventIds": []
    },
    {
      "id": 7487,
      "typeId": 11033,
      "title": "P7 - Evaluating How Interfaces Influence the User Interaction with Fully Autonomous Vehicles",
      "trackId": 10034,
      "tags": [],
      "keywords": [],
      "abstract": "With increasing automation, occupants of fully autonomous vehicles are likely to be completely disengaged from the driving task. However, even with no driving involved, there are still activities that will require interfaces between the vehicle and passengers. This study evaluated different configurations of screens providing operational-related information to occupants for tracking the progress of journeys. Surveys and interviews were used to measure trust, usability, workload and experience after users were driven by an autonomous low speed pod. Results showed that participants want to monitor the state of the vehicle and see details about the ride, including a map of the route and related information. There was a preference for this information to be displayed via an onboard touchscreen device combined with an overhead letterbox display versus a smartphone-based interface. This paper provides recommendations for the design of devices with the potential to improve the user interaction with future autonomous vehicles.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "University of Warwick"
            }
          ],
          "personId": 13693
        },
        {
          "affiliations": [
            {
              "institution": "Jaguar Land Rover"
            }
          ],
          "personId": 12016
        },
        {
          "affiliations": [
            {
              "institution": "Tata Elxsi"
            }
          ],
          "personId": 9816
        },
        {
          "affiliations": [
            {
              "institution": "University of Warwick"
            }
          ],
          "personId": 23016
        },
        {
          "affiliations": [],
          "personId": 24934
        },
        {
          "affiliations": [],
          "personId": 20228
        },
        {
          "affiliations": [
            {
              "institution": "University of Warwick"
            }
          ],
          "personId": 11955
        }
      ],
      "sessionIds": [
        1684
      ],
      "eventIds": []
    },
    {
      "id": 7874,
      "typeId": 10992,
      "title": "Workshop on Communication between Automated Vehicles and Vulnerable Road Users",
      "trackId": 10031,
      "tags": [],
      "keywords": [],
      "abstract": "The aim of this half-day workshop is to explore the topic of interaction between automated vehicles and vulnerable road users (VRUs), such as pedestrians or cyclists, in an interactive setting. The workshop is hands-on with no submission of position papers or slots for participant presentations. It aims at deriving knowledge about communication\r\nneeds across various traffic scenarios resulting in metrics and methodologies for evaluating communication needs by having the participants go through a brief design and evaluation process in a two-step setting. The workshop results will be collected and preserved on a website hosted by the organisers post-workshop.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "University of Salzburg"
            }
          ],
          "personId": 25015
        },
        {
          "affiliations": [
            {
              "institution": "Technische Hochschule Ingolstadt"
            },
            {
              "institution": "Johannes Kepler University"
            }
          ],
          "personId": 24988
        },
        {
          "affiliations": [
            {
              "institution": "Technische Hochschule Ingolstadt"
            }
          ],
          "personId": 24996
        },
        {
          "affiliations": [
            {
              "institution": "University of Oldenburg"
            }
          ],
          "personId": 24964
        },
        {
          "affiliations": [
            {
              "institution": "University of Salzburg"
            }
          ],
          "personId": 25006
        }
      ],
      "sessionIds": [
        1211
      ],
      "eventIds": []
    },
    {
      "id": 4167,
      "typeId": 10407,
      "title": "Autonomous Vehicles - Lessons from Aviation; Future Challenges",
      "trackId": 10029,
      "tags": [],
      "keywords": [],
      "abstract": "Automation presents the potential to save many lives on our streets and highways, but it also presents many challenges. This presentation is about two aspects of those challenges – those that can benefit from decades of automation experience in aviation, and those for which there is little experience because they have not generally been encountered before.  Aviation. More specifically, the presentation describes aviation experience that has demonstrated the importance of “Human-centric” automation, as opposed to automation “because we can.” Aviation has also shown that complete automation, i.e., with no human present, will not be capable of safe operation until automation designers develop “graceful exits” if (a) the automation fails or (b) the automation encounters unanticipated circumstances. Finally, as aviation automation has become more reliable, it has shown that humans are not good monitors of reliable systems.   Other. The presentation also describes several aspects of automation that have not previously been encountered or addressed in aviation. Included among that list are the importance of street testing; the lack of training for drivers; the frequency of software updates; the use of software that learns with experience; the relative ease of cyber attacks; the lack of federal standards; the competition between automakers re safety; and the need to address ethical concerns.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "Hart Solutions LLC"
            }
          ],
          "personId": 11777
        }
      ],
      "sessionIds": [
        2350
      ],
      "eventIds": []
    },
    {
      "id": 3017,
      "typeId": 10979,
      "title": "Listen to Your Drive: An In-vehicle Sonification System based on Driver Affective States and Driving Data",
      "trackId": 10030,
      "tags": [],
      "keywords": [],
      "abstract": "Auditory displays have widely been used in vehicle contexts because they do not require drivers’ visual attention. Examples include collision warning systems, parking assistance systems, and personal navigation devices to name a few. To explore the full potential of  sonification applications in the automotive context, we have developed an in-vehicle sonification system [1]. Our system aims to integrate driving performance data from the vehicle and driver affective state data from physiological sensors in real-time. Those data can be mapped to auditory parameters and generate various sonification pieces. This sonification can be used to provide feedback about how drivers are driving, guidance on how they are supposed to drive, or situation awareness about the traffic environment. As an early prototype, the present work demonstrates driving data sonification using the MiniSim simulator. We hope this sonification work can enhance driver experience as well as road safety in both manual and automated vehicles.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "Michigan Technological University"
            }
          ],
          "personId": 21336
        },
        {
          "affiliations": [
            {
              "institution": "Virginia Tech"
            }
          ],
          "personId": 11541
        }
      ],
      "sessionIds": [
        2124
      ],
      "eventIds": []
    },
    {
      "id": 3785,
      "typeId": 10992,
      "title": "Second Workshop on Trust in the Age of Automated Driving",
      "trackId": 10031,
      "tags": [],
      "keywords": [],
      "abstract": "This workshop addresses key trust-related issues in the context of automated driving and aims at establishing a common ground for future research. Building on the outcome of the previous workshop at AutoUI 2017, three main aspects are targeted within interactive sessions: (1) Formulation of a comprehensive set of definitions for trust in automated systems; (2) Development of interface approaches for mitigating overtrust and undertrust issues; (3) Identification of an appropriate timing of trust-related cues. Thereby, the current research efforts of both workshop organizers and participants are used as a starting point for several breakout sessions, each addressing one of the three main workshop goals. The outcome of this workshop will provide a benchmark for future work in the field and is also intended to inspire joint publications among the participants.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "Technische Hochschule Ingolstadt"
            },
            {
              "institution": "Johannes Kepler University"
            }
          ],
          "personId": 24988
        },
        {
          "affiliations": [
            {
              "institution": "University of Salzburg"
            }
          ],
          "personId": 25015
        },
        {
          "affiliations": [
            {
              "institution": "Georgia Institute of Technology"
            }
          ],
          "personId": 25017
        },
        {
          "affiliations": [
            {
              "institution": "Loughborough University"
            }
          ],
          "personId": 25001
        },
        {
          "affiliations": [
            {
              "institution": "Ulm University"
            }
          ],
          "personId": 25002
        },
        {
          "affiliations": [
            {
              "institution": "Mapbox"
            }
          ],
          "personId": 19292
        },
        {
          "affiliations": [
            {
              "institution": "Luxembourg Institute of Science and Technology (LIST)"
            }
          ],
          "personId": 24976
        },
        {
          "affiliations": [
            {
              "institution": "Georgia Institute of Technology "
            }
          ],
          "personId": 24955
        }
      ],
      "sessionIds": [
        1167
      ],
      "eventIds": []
    },
    {
      "id": 5197,
      "typeId": 10992,
      "title": "Emotional GaRage: A Workshop on In-Car Emotion Recognition and Regulation",
      "trackId": 10031,
      "tags": [],
      "keywords": [],
      "abstract": "In-car emotion detection and regulation have become an emerging and important branch of research within the automotive domain. Different emotional states can greatly influence human driving performance and user experience both in manual and automated driving conditions. The monitoring and regulation of relevant emotional states is therefore important to avoid critical driving scenarios with the human driver being in charge, and to ensure comfort and acceptance in autonomous driving. In this workshop we want to discuss the empathic user interface research to address challenges and opportunities and to reveal new research directions for future work. This workshop provides a forum for exchange and discussion on empathic user interfaces, including methods for emotion recognition and regulation, empathic automotive human-machine interaction design, user evaluation and measurements, and subsequent improvement of autonomous driving experience.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "German Aerospace Centre (DLR)"
            }
          ],
          "personId": 21895
        },
        {
          "affiliations": [
            {
              "institution": "German Aerospace Center (DLR)"
            }
          ],
          "personId": 24947
        },
        {
          "affiliations": [
            {
              "institution": "Virginia Tech"
            }
          ],
          "personId": 11541
        },
        {
          "affiliations": [
            {
              "institution": "INTEL CORPORATION"
            }
          ],
          "personId": 13262
        },
        {
          "affiliations": [
            {
              "institution": "Intel Corporation"
            }
          ],
          "personId": 9297
        },
        {
          "affiliations": [
            {
              "institution": "Cornell Tech"
            }
          ],
          "personId": 24986
        },
        {
          "affiliations": [
            {
              "institution": "IFSTTAR TS2-LESCOT"
            }
          ],
          "personId": 18418
        }
      ],
      "sessionIds": [
        1848
      ],
      "eventIds": []
    },
    {
      "id": 5584,
      "typeId": 11019,
      "title": "D1 - Application of Augmented Reality for Multi-Scale Interactions in Emergency Vehicles",
      "trackId": 10033,
      "tags": [],
      "keywords": [],
      "abstract": "Currently, paramedics are provided information from the 911 operator regarding the emergency faced by the patient/victim in a medical distress. While many distress scenarios for a patient/victim exist, the challenges faced by a victim with a medical problem has to be imagined by the paramedics driving to the emergency situation. Augmenting the emergency scenario on the ambulance instrument panel of the vehicle dashboard with pre-triage scenarios of patients will help to prepare paramedics for an improved patient care protocol on site. Providing the paramedics with patient distress conditions on a real-time basis will help with facilitating the onboarding experience using a syncing of vital statistics, body positioning and level of medical distress.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "Humber College of Technology and Advanced Learning"
            }
          ],
          "personId": 20003
        },
        {
          "affiliations": [
            {
              "institution": "Humber College of Technology and Advanced Learning"
            }
          ],
          "personId": 11774
        },
        {
          "affiliations": [
            {
              "institution": "Humber College of Technology and Advanced Learning"
            }
          ],
          "personId": 11294
        },
        {
          "affiliations": [
            {
              "institution": "Humber College of Technology and Advanced Learning"
            }
          ],
          "personId": 20548
        },
        {
          "affiliations": [
            {
              "institution": "Humber College of Technology and Advanced Learning"
            }
          ],
          "personId": 14601
        }
      ],
      "sessionIds": [
        1389
      ],
      "eventIds": []
    },
    {
      "id": 4178,
      "typeId": 11019,
      "title": "D7 - A Low-Cost VR-Based Automated Driving Simulator for Rapid Automotive UI Prototyping",
      "trackId": 10033,
      "tags": [],
      "keywords": [],
      "abstract": "Conducting User Experience Design (UXD) research in the context of automated driving today is challenging due to the lack of availability of automated cars that are SAE level 3 or above. This Extended Abstract presents a novel methodological tool for rapid prototyping, as well as testing and evaluation of future automotive interface design ideas. The tool combines Virtual Reality (VR) and real-world driving videos in a flexible Unity3D environment to create visually realistic and immersive experiences. Using portable VR headsets, these exploratory experiences can be safely created anywhere anytime with little overhead, as shown through this interactive demo. We provide insights of using this method in the context of exploring two concepts that use novel windscreen technologies and AR applications for level 3 automated cars and above.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "QUT"
            }
          ],
          "personId": 24944
        },
        {
          "affiliations": [
            {
              "institution": "QUT"
            }
          ],
          "personId": 24957
        }
      ],
      "sessionIds": [
        1389
      ],
      "eventIds": []
    },
    {
      "id": 6227,
      "typeId": 11057,
      "title": "Enhanced Traffic Simulation for Improved Realism in Driving Simulators",
      "trackId": 10035,
      "tags": [],
      "keywords": [],
      "abstract": "The ability to monitor and detect potentially dangerous behaviour in surrounding traffic is vital for the development of intelligent vehicles. However, data collection for these kinds of scenarios is difficult in real-life, and a driving simulator therefore becomes an important substitute. In this paper we present an approach to enhance driving simulators. We experiment on an open source development platform, which is used to test real-life use cases within a simulated vehicle environment. We propose replacing pre-programmed traffic dynamics with real driving data recorded from human drivers in the same environment. This enhances the engagement of the host driver in the more realistically simulated traffic scenario. Signal lights and indicator sounds are also integrated to enrich the driver's sensation. Our preliminary quantitative and qualitative evaluation shows that our enhanced traffic simulation result in an improvement to the driver's perception of the realism of the driving simulator.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "University of Cambridge"
            }
          ],
          "personId": 23680
        },
        {
          "affiliations": [
            {
              "institution": "University of Cambridge"
            }
          ],
          "personId": 11336
        },
        {
          "affiliations": [
            {
              "institution": "Stanford University"
            }
          ],
          "personId": 15329
        },
        {
          "affiliations": [
            {
              "institution": "University of Cambridge"
            }
          ],
          "personId": 20828
        },
        {
          "affiliations": [
            {
              "institution": "University of Cambridge"
            }
          ],
          "personId": 18300
        },
        {
          "affiliations": [
            {
              "institution": "University of Cambridge"
            }
          ],
          "personId": 21997
        }
      ],
      "sessionIds": [
        1126
      ],
      "eventIds": []
    },
    {
      "id": 3670,
      "typeId": 11033,
      "title": "To Cross or Not to Cross: Urgency-Based External Warning Displays on Autonomous Vehicles to Improve Pedestrian Crossing Safety",
      "trackId": 10034,
      "tags": [],
      "keywords": [],
      "abstract": "Autonomous vehicles (AV) may be able to show visual displays on their external surface to support pedestrian communication with the AV. Pedestrian crossing at uncontrolled locations is safety-critical and clear communication between the pedestrian and the AV is important in this situation.  However, research to date has not been clear on how the AV should communicate with pedestrians. We designed two sets of warnings on AVs based on the perception of warning urgency. Each set consisted of three warnings that differed in color and flashing pattern and indicated distinct safety-related information. A survey was conducted to investigate how people make decisions, warnings within and outside of the driving context, and perceived warning compliance. Results showed that people were risk averse in crossing and cars with warning displays were perceived as more urgent. This paper contributes uniquely in exploring research-based approaches on designing warnings to improve pedestrian crossing safety.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "University of Waterloo"
            }
          ],
          "personId": 17361
        },
        {
          "affiliations": [
            {
              "institution": "University of Waterloo"
            }
          ],
          "personId": 11186
        },
        {
          "affiliations": [
            {
              "institution": "University of Waterloo"
            }
          ],
          "personId": 14126
        },
        {
          "affiliations": [
            {
              "institution": "Northwestern Polytechnical University"
            }
          ],
          "personId": 17456
        },
        {
          "affiliations": [
            {
              "institution": "University of Waterloo"
            }
          ],
          "personId": 22824
        }
      ],
      "sessionIds": [
        2033
      ],
      "eventIds": []
    },
    {
      "id": 6358,
      "typeId": 11033,
      "title": "Predicting Environmental Demand and Secondary Task Engagement using Vehicle Kinematics from Naturalistic Driving Data",
      "trackId": 10034,
      "tags": [],
      "keywords": [],
      "abstract": "In this paper, we focus on exploiting the vehicle kinematic signals from a naturalistic driving dataset to estimate motor control difficulty associated with the driving environment (i.e., curvature and poor surface condition), and detect whether the driver was engaged in a secondary task or not. Advanced driver assistance systems can exploit such driver behavior models to better support the driving task and improve safety. Hidden Markov models were built from sequential data; lateral (x-axis) and longitudinal (y-axis) acceleration were used to classify motor control difficulty (lower vs. higher), whereas GPS speed and steering wheel position were used to classify secondary task engagement (yes vs. no). The resulting accuracy for lower motor control difficulty classification was 72.03%, whereas 71.27% was achieved for higher motor control difficulty. Cases of engagement in secondary task vs. not were classified with 84.4% and 74.0% accuracy, respectively. ",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "University of Toronto"
            }
          ],
          "personId": 21942
        },
        {
          "affiliations": [
            {
              "institution": "University of Toronto"
            }
          ],
          "personId": 18457
        },
        {
          "affiliations": [
            {
              "institution": "University of Toronto"
            }
          ],
          "personId": 15050
        }
      ],
      "sessionIds": [
        1271
      ],
      "eventIds": []
    },
    {
      "id": 3161,
      "typeId": 11057,
      "title": "Evaluation of Driving Performance and User Experience of Different Speedometer Types",
      "trackId": 10035,
      "tags": [],
      "keywords": [],
      "abstract": "Previously, the classical analog speedometer was the prevalent form of speed indication in cars. With the emergence of new, freely programmable, instrument clusters, its now\r\npossible to use any form of visualization to display driving speed. In a driving simulator study with n=17 subjects, we examined the impact of diverse speedometer variants on driving performance, gaze duration, and subjective ratings of user experience and workload. Initial results confirm diverse effects. The conventional speedometer resulted in the shortest eyes off-road times, but was rated worst with respect to UX (hedonic quality). The digital speedometer variant achieved polarizing results while the zoom speedometer performed very well in general. The bracket and linear versions of a speedometer were rated poor in most of the analyzed criteria compared to the alternatives.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "Technische Hochschule Ingolstadt"
            }
          ],
          "personId": 13969
        },
        {
          "affiliations": [
            {
              "institution": "Technische Hochschule Ingolstadt"
            }
          ],
          "personId": 24996
        }
      ],
      "sessionIds": [
        1126
      ],
      "eventIds": []
    },
    {
      "id": 6490,
      "typeId": 11033,
      "title": "Exploring the Use of Mid-Air Ultrasonic Feedback to Enhance Automotive User Interfaces",
      "trackId": 10034,
      "tags": [],
      "keywords": [],
      "abstract": "Employing a 2x2 within-subjects design, forty-eight experienced drivers (28 male, 20 female) undertook repeated button selection and ‘slider-bar’ manipulation tasks, to compare a traditional touchscreen with a virtual mid-air gesture interface in a driving simulator. Both interfaces were tested with and without haptic feedback generated using ultrasound. Results show that combining gestures with mid-air haptic feedback was particularly promising, reducing the number of long glances and mean off-road glance time associated with the in-vehicle tasks. For slider-bar tasks in particular, gestures-with-haptics was also associated with the shortest interaction times, highest number of correct responses and least ‘overshoots’, and was favoured by participants. In contrast, for button-selection tasks, the touchscreen was most popular, enabling the highest accuracy and quickest responses, particularly when combined with haptic feedback to guide interactions, although this also increased visual demand. The study shows clear potential for gestures with mid-air ultrasonic haptic feedback in the automotive domain.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "University of Nottingham"
            }
          ],
          "personId": 25000
        },
        {
          "affiliations": [
            {
              "institution": "University of Nottingham"
            }
          ],
          "personId": 24966
        },
        {
          "affiliations": [
            {
              "institution": "University of Nottingham"
            }
          ],
          "personId": 24959
        },
        {
          "affiliations": [
            {
              "institution": "Ultrahaptics"
            }
          ],
          "personId": 24985
        }
      ],
      "sessionIds": [
        1039
      ],
      "eventIds": []
    },
    {
      "id": 5083,
      "typeId": 10979,
      "title": "Predictive Touch: A Novel HMI Technology for Intelligent Displays in Automotive",
      "trackId": 10030,
      "tags": [],
      "keywords": [],
      "abstract": "Predictive touch is an emerging HMI technology that can significantly improve the usability and performance of in-vehicle displays [1-4]. It relies on predicting, early in the pointing gesture, the interface item the driver or passenger intends to select on the display and simplifies the selection task. The user need not touch the display as the system can autonomously auto-select the predicted interface component. This video shows a prototype of a predictive touch system operating in real-time, in a laboratory and vehicle environment. It also depicts the prediction results as calculated by the system whilst pointing in a moving car.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "University of Cambridge"
            }
          ],
          "personId": 21217
        },
        {
          "affiliations": [
            {
              "institution": "University of Cambridge"
            }
          ],
          "personId": 20682
        },
        {
          "affiliations": [
            {
              "institution": "University of Cambridge"
            }
          ],
          "personId": 20853
        },
        {
          "affiliations": [
            {
              "institution": "Jaguar Land Rover"
            }
          ],
          "personId": 24982
        }
      ],
      "sessionIds": [
        2124
      ],
      "eventIds": []
    },
    {
      "id": 3803,
      "typeId": 11057,
      "title": "LED Visualizations for Drivers’ Attention: An Exploratory Study on Experience and Associated Information Contents ",
      "trackId": 10035,
      "tags": [],
      "keywords": [],
      "abstract": "When it comes to highly automated driving, several studies indicate that drivers should be “kept in the loop” when driving in automated mode in order to be better prepared when they need to take over. The challenge lies in finding a way that raises the drivers’ situation awareness without annoying the driver, who may be occupied with another task. Ambient light systems using LED visualizations provide a feasible way to draw attention, however, the kind of information that can be communicated is limited. In this paper, we present an exploratory study, where we investigated the semantic quality of different LED patterns (shown on an LED-strip) by capturing experience and associated information contents. Our initial findings show that LED visualizations, which are experienced quite similar at first, can nonetheless be distinctive with regard to the associated information contents.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "University of Salzburg"
            }
          ],
          "personId": 25003
        },
        {
          "affiliations": [
            {
              "institution": "University of Salzburg"
            }
          ],
          "personId": 14884
        },
        {
          "affiliations": [
            {
              "institution": "University of Salzburg"
            }
          ],
          "personId": 25006
        },
        {
          "affiliations": [
            {
              "institution": "University of Salzburg & AIT"
            }
          ],
          "personId": 24963
        }
      ],
      "sessionIds": [
        1126
      ],
      "eventIds": []
    },
    {
      "id": 2907,
      "typeId": 10979,
      "title": "Car Interaction Design for Car-Sharing Systems",
      "trackId": 10030,
      "tags": [],
      "keywords": [],
      "abstract": "The purpose of this project was to understand the difficulties encountered in the proper placement of secondary controls on an automotive instrument panel while driving a rented car on a short-term basis, such as provided through a service such as Zip Car. Suggested interaction design guidelines for designing a sharing-friendly car were the outcome. The results of the project suggest the most common contemporary control locations and interaction types should be used to improve usability. A summary of the guidelines is provided at the end of the video.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "NC State University"
            }
          ],
          "personId": 11990
        },
        {
          "affiliations": [
            {
              "institution": "NC State University"
            }
          ],
          "personId": 17149
        },
        {
          "affiliations": [
            {
              "institution": "North Carolina State University"
            }
          ],
          "personId": 11468
        },
        {
          "affiliations": [
            {
              "institution": "NC State University"
            }
          ],
          "personId": 18192
        }
      ],
      "sessionIds": [
        2124
      ],
      "eventIds": []
    },
    {
      "id": 3935,
      "typeId": 11057,
      "title": "Biometric Interface for Driver's Stress Detection and Awareness",
      "trackId": 10035,
      "tags": [],
      "keywords": [],
      "abstract": "One of the factors for stress reduction among vehicle drivers is to be aware that stress is present. This project presents a biometric interface for stress detection in drivers, built with open source sensors and hardware. In two series of experiments, we induce stress in test subjects by making them drive progressively difficult scenarios in a simulator. Using the C4.5 classification algorithm, we classified the subjects’ biometric data in order to determine whether the subject was stressed or not. In another series of experiments, we tested the efficacy of two driver feedback systems, a haptic one and a visual one. Identifying a stressful situation allows real-time feedback to drivers, so they can be aware of their stressed state, thus being able to take corrective actions on time, and avoid behavior leading to an accident.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "Universidad Icesi"
            }
          ],
          "personId": 14292
        },
        {
          "affiliations": [
            {
              "institution": "Universidad Icesi"
            }
          ],
          "personId": 8890
        },
        {
          "affiliations": [
            {
              "institution": "Universidad Icesi"
            }
          ],
          "personId": 9945
        }
      ],
      "sessionIds": [
        1126
      ],
      "eventIds": []
    },
    {
      "id": 5344,
      "typeId": 11057,
      "title": "Approach for Enhancing the Perception and Prediction of Traffic Dynamics with a Tactile Interface",
      "trackId": 10035,
      "tags": [],
      "keywords": [],
      "abstract": "Participation in road traffic frequently requires fast and accurate understanding of environmental object characteristics. Here we introduce an assistance function and corresponding interface targeted at enhancing a driver's perception and understanding of environment dynamics in order to improve driving safety and performance. The core functionality of this assistance function lies in the tactile communication of spatio-temporal proximity information about one or multiple traffic participants that are on a collision trajectory with the ego-vehicle. We investigate effects of this assistance function on driver perception and performance in a driving simulator study. \r\nPreliminary results show that participants were able to intuitively understand and use the assistance function and that its utility seems to increase with task difficulty. ",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "Honda Research Institute Europe GmbH"
            }
          ],
          "personId": 24941
        },
        {
          "affiliations": [
            {
              "institution": "Honda Research Institute Europe GmbH"
            }
          ],
          "personId": 19771
        },
        {
          "affiliations": [
            {
              "institution": "Honda Research Institute Europe GmbH"
            }
          ],
          "personId": 15510
        }
      ],
      "sessionIds": [
        1126
      ],
      "eventIds": []
    },
    {
      "id": 6369,
      "typeId": 11033,
      "title": "P9 - Designing a Guardian Angel: Giving an Automated Vehicle the Possibility to Override its Driver",
      "trackId": 10034,
      "tags": [],
      "keywords": [],
      "abstract": "A function of an automated driving vehicle that can override a human driver while driving manually could work as a guardian angel in the car. It can take over control if it detects an imminent accident and has a possibility to avoid it. Because of the urgency of the intervention, there is not enough time to warn the driver in advance. In our study, we collected feedback from users how they perceived such an action while driving in a simulator. We collected feedback about the general design and user interface of such a system. From an ethical point of view, we discovered discrepancies in the views of our participants regarding automated driving functions that need to be addressed in future development.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "Robert Bosch GmbH"
            }
          ],
          "personId": 25013
        },
        {
          "affiliations": [
            {
              "institution": "Hochschule der Medien"
            }
          ],
          "personId": 11472
        },
        {
          "affiliations": [
            {
              "institution": "Robert Bosch GmbH"
            }
          ],
          "personId": 11596
        },
        {
          "affiliations": [
            {
              "institution": "Robert Bosch GmbH"
            }
          ],
          "personId": 25012
        },
        {
          "affiliations": [
            {
              "institution": "University of Ulm"
            }
          ],
          "personId": 24961
        },
        {
          "affiliations": [
            {
              "institution": "Hochschule der Medien"
            }
          ],
          "personId": 16640
        }
      ],
      "sessionIds": [
        1684
      ],
      "eventIds": []
    },
    {
      "id": 5090,
      "typeId": 11001,
      "title": "The National Advanced Driving Simulator",
      "trackId": 10032,
      "tags": [],
      "keywords": [],
      "abstract": "https://www.nads-sc.uiowa.edu/",
      "authors": [],
      "sessionIds": [
        2055,
        1252
      ],
      "eventIds": []
    },
    {
      "id": 6627,
      "typeId": 11057,
      "title": "Adaptive Trust Calibration for Supervised Autonomous Vehicles",
      "trackId": 10035,
      "tags": [],
      "keywords": [],
      "abstract": "Poor trust calibration in autonomous vehicles often degrades total system\r\nperformance in safety or efficiency. Existing studies have primarily examined\r\nthe importance of system transparency of autonomous systems to maintain\r\nproper trust calibration, with little emphasis on how to detect over-trust and\r\nunder-trust nor how to recover from them.\r\nWith the goal of addressing these research gaps, we first provide a framework to\r\ndetect a calibration status on the basis of the user's behavior of reliance.\r\nWe then propose a new concept with cognitive cues called trust calibration\r\ncues (TCCs) to trigger the user to quickly restore appropriate trust calibration.\r\nWith our framework and TCCs, a novel method of adaptive trust\r\ncalibration is explored in this study. We will evaluate our framework and\r\nexamine the effectiveness of TCCs with a newly developed online drone simulator.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "SOKENDAI (The Graduate University for Advanced Studies)"
            }
          ],
          "personId": 16875
        },
        {
          "affiliations": [
            {
              "institution": "National Institute of Informatics and SOKENDAI"
            }
          ],
          "personId": 13815
        }
      ],
      "sessionIds": [
        1126
      ],
      "eventIds": []
    },
    {
      "id": 7652,
      "typeId": 11019,
      "title": "D3 - Scribble Your Way Through Traffic",
      "trackId": 10033,
      "tags": [],
      "keywords": [],
      "abstract": "Scribble is a haptic Human Machine Interface (HMI) that utilizes a drawing interaction to steer a semi- autonomous vehicle. The interface uses a display and a haptic pointing device that enables the driver to draw a path which represents the vehicle’s future trajectory. The objective of Scribble is to blur the lines between who is in control and proposes a more ‘muddy’ form of interaction where higher decision making is performed by the human operator, whilst the machine manages more mundane driving tasks such as lane keeping and managing speed. We present a fully interactive desktop-based demo that includes a 3D simulation environment for highway driving. The interface has been tested in an elaborate simulation study in collaboration with the Mercedes-Benz Advanced Digital Design team at Daimler AG, Sindelfingen, Germany. The contents of this document describe: the Scribble concept, system setup, demo setup, and contribution.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "Eindhoven University"
            }
          ],
          "personId": 12866
        },
        {
          "affiliations": [
            {
              "institution": "Dept. for Industrial Design"
            }
          ],
          "personId": 25014
        },
        {
          "affiliations": [
            {
              "institution": "Instigate BV"
            }
          ],
          "personId": 23919
        },
        {
          "affiliations": [
            {
              "institution": "Daimler AG"
            }
          ],
          "personId": 21065
        },
        {
          "affiliations": [
            {
              "institution": "Daimler AG"
            }
          ],
          "personId": 16447
        }
      ],
      "sessionIds": [
        1389
      ],
      "eventIds": []
    },
    {
      "id": 5095,
      "typeId": 11033,
      "title": "Acceptance Factors for Future Workplaces in Highly Automated Trucks",
      "trackId": 10034,
      "tags": [],
      "keywords": [],
      "abstract": "Once highly automated vehicles become available, drivers will be freed to perform activities other than driving when automated driving mode is activated. Such activities could include relaxing, reading, exercising, or working. The work of professional drivers such as truck drivers can be expected to be especially affected by this technology and to change accordingly as highly automated trucks enable the completion of other working related tasks during automated driving. But will such mobile working places be accepted by truck drivers? In this paper, we report on a survey (N=23) assessing technology acceptance towards Future Workplaces in highly Automated Trucks (FWAT). Results show that a majority of drivers is rather skeptical about FWAT, but that acceptance can be expected to strongly vary. Our paper provides some guidance on how to explain this variance and presents relevant acceptance factors for future FWAT usage.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "AIT Austrian Institute of Technology"
            }
          ],
          "personId": 25011
        },
        {
          "affiliations": [
            {
              "institution": "AIT Austrian Institute of Technology"
            }
          ],
          "personId": 20056
        },
        {
          "affiliations": [
            {
              "institution": "University of Salzburg"
            }
          ],
          "personId": 25003
        },
        {
          "affiliations": [
            {
              "institution": "University of Salzburg"
            }
          ],
          "personId": 25006
        },
        {
          "affiliations": [
            {
              "institution": "AIT Austrian Institute of Technology"
            }
          ],
          "personId": 19581
        },
        {
          "affiliations": [
            {
              "institution": "University of Salzburg & AIT"
            }
          ],
          "personId": 24963
        }
      ],
      "sessionIds": [
        1209
      ],
      "eventIds": []
    },
    {
      "id": 7912,
      "typeId": 11033,
      "title": "Camera-View Augmented Reality: Overlaying Navigation Instructions on a Real-Time View of the Road",
      "trackId": 10034,
      "tags": [],
      "keywords": [],
      "abstract": "Augmented reality navigation aids have been investigated in a number of studies, and results are encouraging, especially for large, head-up displays. However, such displays are not commercially available – in fact they are rare in laboratories as well. In this paper we ask: would drivers be well-served with a navigation aid that overlays AR content on a live feed from a camera that shows the forward road? To answer this question we conducted a simulator-based study and compared the use of such a navigation aid to the use of a head-up AR aid, as well as to the use of 2D map shown on a head-down display. Our results confirm prior results that a head-up AR navigation aid can keep drivers’ visual attention on the road, and that drivers like such a navigation aid. Our results also indicate that a camera-view AR navigation aid might not be well-received by drivers.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "University of New Hampshire"
            },
            {
              "institution": "Qualcomm"
            }
          ],
          "personId": 8657
        },
        {
          "affiliations": [
            {
              "institution": "University of New Hampshire"
            }
          ],
          "personId": 24970
        }
      ],
      "sessionIds": [
        2026
      ],
      "eventIds": []
    },
    {
      "id": 6376,
      "typeId": 11057,
      "title": "Identifying the Factors Influencing Older Adults’ Perceptions of Fully Automated Vehicles ",
      "trackId": 10035,
      "tags": [],
      "keywords": [],
      "abstract": "While Fully Automated Vehicles (FAVs) have the potential to significantly expand older adults’ access to mobility, limited research has focused on older adults’ perceptions of such technology. The current driving simulation-based study will investigate factors that may govern older adults’ perceptions of FAVs with respect to trust, acceptability, and safety. Participants (65+) will experience scenarios of manual and fully automated driving in a high-fidelity driving simulator. Their perceptions of the FAV will be measured before and after the driving experiences using questionnaires. Physiological and behavioral data will also be collected throughout the driving sessions to investigate whether positive or negative perceptions of technology are associated with behavioral or physiological responses. In addition, driving performance and driving styles of participants will be captured during manual driving to investigate whether an alignment between an individual’s driving style and the FAV driving style will lead to a more positive perception towards FAVs. ",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "University of Toronto"
            },
            {
              "institution": "Toronto Rehabilitation Institute"
            }
          ],
          "personId": 24950
        },
        {
          "affiliations": [
            {
              "institution": "University of Toronto"
            },
            {
              "institution": "Toronto Rehabilitation Institute"
            }
          ],
          "personId": 24949
        },
        {
          "affiliations": [
            {
              "institution": "University of Toronto"
            },
            {
              "institution": "Toronto Rehabilitation Institute"
            }
          ],
          "personId": 24943
        }
      ],
      "sessionIds": [
        1126
      ],
      "eventIds": []
    },
    {
      "id": 7145,
      "typeId": 11033,
      "title": "P2 - gAR-age: A Feedback-Enabled Blended Ecosystem for Vehicle Health Monitoring",
      "trackId": 10034,
      "tags": [],
      "keywords": [],
      "abstract": "Standard vehicle maintenance activities can be challenging, time-consuming, error-prone, and expensive. While there is a lot of innovative work that has incorporated latest technologies to provide newer forms of interaction between users and vehicles, there has been less inclination towards utilizing these technologies to enhance activities like vehicle maintenance. The ability to draw parallels simultaneously from physical interaction with vehicles and analysis of recorded data is vital to support prompt and effective decision-making. To blur the disparity between these real and virtual worlds, we present \"gAR-age\"- an ecosystem that enables maintenance personnel to interact with both worlds in a common setting. By learning from historical changes in vehicular components, user behavior, and feedback, this blended ecosystem allows multi-channel communication among users, featuring personalized contextual insights, thereby enabling users to make data-driven decision on the fly.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "Conduent Labs India"
            }
          ],
          "personId": 14832
        },
        {
          "affiliations": [
            {
              "institution": "Conduent Labs India"
            }
          ],
          "personId": 15578
        },
        {
          "affiliations": [
            {
              "institution": "Conduent Labs India"
            }
          ],
          "personId": 19882
        },
        {
          "affiliations": [
            {
              "institution": "Conduent Labs India"
            }
          ],
          "personId": 19198
        }
      ],
      "sessionIds": [
        1684
      ],
      "eventIds": []
    },
    {
      "id": 8170,
      "typeId": 11057,
      "title": "Driving Performance Measures Influenced by Functional Deficits Caused by Stroke; Possible Application to a Driver Health Emergency Detection System  ",
      "trackId": 10035,
      "tags": [],
      "keywords": [],
      "abstract": "The purpose of this study was to extract the driving performance measures influenced by functional deficits caused by stroke, aiming to detect the onset signs of stroke while driving. Hemiplegia and visual field defects were set as the symptoms signs to be detected, and steering behaviors during curve driving were selected as the driving performance measures. First, the driving behavior of healthy controls and patients with a history of stroke were acquired using a driving simulator, and feature values related to steering at curved road sections were analyzed. As a result, with regard to patients with hemiplegia, the total amount of steering tended to be larger and the amount of correction steering and standard deviation of steering angular velocity tended to be smaller. With regard to patients with visual field defects, the total of steering, standard deviation of steering angular velocity, and maximum of steering angular velocity tended to be larger.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "The University of Tokyo"
            }
          ],
          "personId": 21637
        },
        {
          "affiliations": [
            {
              "institution": "The University of Tokyo"
            }
          ],
          "personId": 14016
        },
        {
          "affiliations": [
            {
              "institution": "The University of Tokyo"
            }
          ],
          "personId": 15500
        },
        {
          "affiliations": [
            {
              "institution": "University of Tsukuba Hospital"
            }
          ],
          "personId": 18956
        },
        {
          "affiliations": [
            {
              "institution": "University of Tsukuba Hospital"
            }
          ],
          "personId": 21709
        },
        {
          "affiliations": [
            {
              "institution": "National Institute of Advanced Industrial Science and Technology"
            }
          ],
          "personId": 19011
        },
        {
          "affiliations": [
            {
              "institution": "National Institute of Advanced Industrial Science and Technology"
            }
          ],
          "personId": 11124
        },
        {
          "affiliations": [
            {
              "institution": "National Institute of Advanced Industrial Science and Technology"
            }
          ],
          "personId": 20767
        },
        {
          "affiliations": [
            {
              "institution": "National Institute of Advanced Industrial Science and Technology"
            }
          ],
          "personId": 13582
        },
        {
          "affiliations": [
            {
              "institution": "National Institute of Advanced Industrial Science and Technology"
            }
          ],
          "personId": 15271
        },
        {
          "affiliations": [
            {
              "institution": "National Institute of Advanced Industrial Science and Technology"
            }
          ],
          "personId": 8882
        },
        {
          "affiliations": [
            {
              "institution": "National Institute of Advanced Industrial Science and Technology"
            }
          ],
          "personId": 9234
        }
      ],
      "sessionIds": [
        1126
      ],
      "eventIds": []
    },
    {
      "id": 5356,
      "typeId": 11057,
      "title": "Automotive Research in the Public Space -- Towards Deployment-Based Prototypes For Real Users",
      "trackId": 10035,
      "tags": [],
      "keywords": [],
      "abstract": "Many automotive user studies allow users to experience and evaluate interactive concepts. They are however often limited to small and specific groups of participants, such as students or experts. This might limit the generalizability of results for future users. A possible solution is to allow a large group of unbiased users to actively experience an interactive prototype and generate new ideas, but there is little experience about the realization and benefits of such an approach. We placed an interactive prototype in a public space and gathered objective and subjective data from 693 participants over the course of three months. We found a high variance in data quality and identified resulting restrictions for suitable research questions. This results in concrete requirements to hardware, software, and analytics, e.g. the need for assessing data quality, and give examples how this approach lets users explore a system and give first-contact feedback which differentiates highly from common in-depth expert analyses.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "LMU Munich"
            },
            {
              "institution": "BMW Group Research, New Technologies, Innovations"
            }
          ],
          "personId": 24969
        },
        {
          "affiliations": [
            {
              "institution": "University of Bamberg"
            },
            {
              "institution": "BMW Group Research, New Technologies, Innovations"
            }
          ],
          "personId": 16303
        },
        {
          "affiliations": [
            {
              "institution": "LMU Munich"
            }
          ],
          "personId": 24993
        },
        {
          "affiliations": [
            {
              "institution": "University of Bamberg"
            }
          ],
          "personId": 14027
        }
      ],
      "sessionIds": [
        1126
      ],
      "eventIds": []
    },
    {
      "id": 6125,
      "title": "Automotive User Interfaces - What We Know and the Future",
      "trackId": 10028,
      "tags": [],
      "keywords": [],
      "authors": [
        {
          "affiliations": [
            {
              "institution": "Transport Canada"
            }
          ],
          "personId": 15970
        },
        {
          "affiliations": [
            {
              "institution": "Massachusetts Institute of Technology"
            }
          ],
          "personId": 8374
        },
        {
          "affiliations": [
            {
              "institution": "Ford USA"
            }
          ],
          "personId": 13979
        },
        {
          "affiliations": [
            {
              "institution": "University of Nottingham"
            }
          ],
          "personId": 24959
        },
        {
          "affiliations": [
            {
              "institution": "Technische Hochschule Ingolstadt"
            }
          ],
          "personId": 24996
        }
      ],
      "sessionIds": [
        2357
      ],
      "eventIds": []
    },
    {
      "id": 3693,
      "typeId": 11033,
      "title": "The Effect of Road Bumps on Touch Interaction in Cars",
      "trackId": 10034,
      "tags": [],
      "keywords": [],
      "abstract": "Touchscreens are a common fixture in current vehicles. With autonomous driving, we can expect touch interaction with such in-vehicle media systems to exponentially increase. In spite of vehicle suspension systems, road perturbations will continue to exert forces that can render in-vehicle touch interaction challenging. Using a motion simulator, we investigate how different vehicle speeds interact with road features (i.e., speed bumps) to influence touch interaction. We determine their effect on pointing accuracy and task completion time. We show that road bumps have a significant effect on touch input and can decrease accuracy by 19%. In light of this, we developed a Random Forest (RF) model that improves touch accuracy by 32.0% on our test set and by 22.5% on our validation set. As the lightweight model uses only features that can easily be determined through inertial measurement units, this model could be easily deployed in current automobiles.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "University of Stuttgart"
            }
          ],
          "personId": 24942
        },
        {
          "affiliations": [
            {
              "institution": "University of Stuttgart"
            }
          ],
          "personId": 24971
        },
        {
          "affiliations": [
            {
              "institution": "Max Planck Institute for Biological Cybernetics"
            }
          ],
          "personId": 19300
        },
        {
          "affiliations": [
            {
              "institution": "University of Stuttgart"
            },
            {
              "institution": "University of Regensburg"
            }
          ],
          "personId": 22665
        },
        {
          "affiliations": [
            {
              "institution": "Max Planck Institute for Biological Cybernetics"
            }
          ],
          "personId": 15501
        },
        {
          "affiliations": [
            {
              "institution": "LMU Munich"
            },
            {
              "institution": "Max Planck Institute for Biological Cybernetics"
            }
          ],
          "personId": 24953
        }
      ],
      "sessionIds": [
        1271
      ],
      "eventIds": []
    },
    {
      "id": 5743,
      "typeId": 11033,
      "title": "P3 - How Usability Can Save the Day – Methodological Considerations for Making Automated Driving a Success Story",
      "trackId": 10034,
      "tags": [],
      "keywords": [],
      "abstract": "It will not be long until Level 3 Automated Driving Systems (L3 ADS) enter the consumer market. An important role corresponds to methodology development. The present paper gives impetus to the process of developing robust methods for evaluating Human-Machine Interfaces (HMI) for L3 ADS. First, a literature review on automotive interfaces concerning methodology application is outlined showing that studies often lack to provide both self-report and observational data. To derive a comprehensive image of HMI quality, we recommend multi-method approach in user research. Subsequently, we provide an overview of state-of-the-art self-report and observational measures. From the availability of measures and the necessity to include both in user studies, the issue of the performance-preference dissociation arises. It threatens study designs and interpretation of results. Following methodological recommendations from the present work supports researchers and practitioners in the area of automated driving for proper study design and interpretation of study results.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "BMW Group"
            }
          ],
          "personId": 24995
        },
        {
          "affiliations": [
            {
              "institution": "BMW Group"
            }
          ],
          "personId": 24992
        },
        {
          "affiliations": [
            {
              "institution": "BMW"
            }
          ],
          "personId": 19385
        },
        {
          "affiliations": [
            {
              "institution": "Chemnitz University of Technology"
            }
          ],
          "personId": 21926
        }
      ],
      "sessionIds": [
        1684
      ],
      "eventIds": []
    },
    {
      "id": 6640,
      "typeId": 11033,
      "title": "¡Vamos! Observations of Pedestrian Interactions with Driverless Cars in Mexico",
      "trackId": 10034,
      "tags": [],
      "keywords": [],
      "abstract": "How will pedestrians from different regions interact with an ap- proaching autonomous vehicle? Understanding differences in pedestrian culture and response can help to inform autonomous cars how to behave appropriately in different regional contexts. We conducted a field study comparing the behavioral response of pedestrians between metropolitan Mexico City (N=113) and Colima, a smaller coastal city (N=81). We hid a driver in a car seat costume as a Wizard-of-Oz prototype to evoke pedestrian interaction behavior at a crosswalk or street. Pedestrian interactions were coded for crossing decision, crossing pathway, pacing, and observational behavior. Most distinctly, pedestrians in Mexico City kept their pace and more often crossed in front of the vehicle, while those in Colima stopped in front of the car more often.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "Stanford University"
            }
          ],
          "personId": 24989
        },
        {
          "affiliations": [
            {
              "institution": "Stanford University"
            }
          ],
          "personId": 10178
        },
        {
          "affiliations": [
            {
              "institution": "Stanford University"
            }
          ],
          "personId": 14455
        },
        {
          "affiliations": [
            {
              "institution": "ITAM"
            }
          ],
          "personId": 23257
        },
        {
          "affiliations": [
            {
              "institution": "Universidad de Colima"
            }
          ],
          "personId": 15896
        },
        {
          "affiliations": [
            {
              "institution": "ITAM"
            }
          ],
          "personId": 18730
        },
        {
          "affiliations": [
            {
              "institution": "Cornell Tech"
            }
          ],
          "personId": 24986
        }
      ],
      "sessionIds": [
        2033
      ],
      "eventIds": []
    },
    {
      "id": 6769,
      "typeId": 11057,
      "title": "Preliminary Evaluation of Variables for Communicating Uncertainties Using a Haptic Seat",
      "trackId": 10035,
      "tags": [],
      "keywords": [],
      "abstract": "Recent findings have indicated that the communication of uncertainties is a promising approach for overcoming human factors challenges associated with overtrust issues. The existing approaches, however, are limited in that they require operators to monitor the instrument cluster to perceive changes. As a consequence, significant changes may be missed and operators are regularly interrupted in the execution of non-driving related tasks even if the system is performing well. To overcome this, unobtrusive interfaces are required that are only interruptive if needed.\r\nThis paper presents a lab-based study aiming at the preliminary evaluation of haptic variables for communicating automation uncertainties using a haptic vehicle seat. The initial results indicate that particularly increases in amplitude as well as a rhythm consisting of long vibrations separated by short breaks are well suited for communicating the exceedance of specified uncertainty thresholds. The communication of decreases in uncertainty using vibration cannot be recommended.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "Loughborough University"
            }
          ],
          "personId": 25001
        },
        {
          "affiliations": [
            {
              "institution": "Loughborough University"
            }
          ],
          "personId": 25016
        },
        {
          "affiliations": [
            {
              "institution": "Loughborough University"
            }
          ],
          "personId": 24948
        },
        {
          "affiliations": [
            {
              "institution": "Loughborough University"
            }
          ],
          "personId": 24965
        }
      ],
      "sessionIds": [
        1126
      ],
      "eventIds": []
    },
    {
      "id": 7153,
      "typeId": 11057,
      "title": "Evaluation of Variables for the Communication of Uncertainties Using Peripheral Awareness Displays",
      "trackId": 10035,
      "tags": [],
      "keywords": [],
      "abstract": " The communication of system uncertainties may be key for overcoming challenges related to overtrust in automated driving. Existing approaches are limited to conveying uncertainties using visual displays in the instrument cluster. This requires operators to regularly monitor the display in order to perceive changes which impedes the execution of non-driving related tasks and thereby degrades the user experience. This study evaluates variables for the communication of uncertainties using peripheral awareness displays, considering changes in brightness, hue, position, size, pulse frequency, and movement speed. All variables were assessed in terms of how well participants can distinguish different instances, how logical they are, and how interrupting to a secondary task. With the exception of changes in position, all variables were ranked highly in terms of logic while changes in pulse frequency were perceived as most interrupting. The results inform the development of unobtrusive interfaces for uncertainty communication.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "Loughborough University"
            }
          ],
          "personId": 25001
        },
        {
          "affiliations": [
            {
              "institution": "Loughborough University"
            }
          ],
          "personId": 25016
        },
        {
          "affiliations": [
            {
              "institution": "Loughborough University"
            }
          ],
          "personId": 24948
        },
        {
          "affiliations": [
            {
              "institution": "Loughborough University"
            }
          ],
          "personId": 24965
        }
      ],
      "sessionIds": [
        1126
      ],
      "eventIds": []
    },
    {
      "id": 6001,
      "typeId": 11057,
      "title": "Early Take-Over Preparation in Stereoscopic 3D",
      "trackId": 10035,
      "tags": [],
      "keywords": [],
      "abstract": "Situation awareness in highly automated vehicles can help the driver to get back in the loop during a take-over request (TOR). We propose to present the driver a detailed digital representation of situations causing a TOR via a scaled down digital twin of the highway inside the car. The digital twin virtualizes real time traffic information and is displayed before the actual TOR. In the car cockpit an augmented reality headset or a Stereoscopic 3D (S3D) interface can realize the augmentation. As today's hardware has technical limitations, we build an HMD based mock-up.  We conducted a user study (N=20) to assess the driver behavior during a TOR. We found that workload decreases and steering performance raise significantly with the proposed system. We argue that the augmentation of the surrounding world in the car helps to improve performance during TOR due to better awareness of the upcoming situation.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "LMU Munich"
            },
            {
              "institution": "fortiss GmbH"
            }
          ],
          "personId": 24977
        },
        {
          "affiliations": [
            {
              "institution": "LMU Munich"
            }
          ],
          "personId": 25004
        },
        {
          "affiliations": [
            {
              "institution": "fortiss GmbH"
            }
          ],
          "personId": 12531
        },
        {
          "affiliations": [
            {
              "institution": "LMU Munich"
            }
          ],
          "personId": 24972
        }
      ],
      "sessionIds": [
        1126
      ],
      "eventIds": []
    },
    {
      "id": 7155,
      "typeId": 11057,
      "title": "The Impact of Advanced Vehicle Technologies on Older Driver Safety: A Scoping Review of Subjective Outcomes  ",
      "trackId": 10035,
      "tags": [],
      "keywords": [],
      "abstract": "Advanced vehicle technologies (AVTs) have the potential to modify an older driver’s behind-the-wheel performance by compensating for age and/or health-related changes that can negatively impact their ability to operate a motor vehicle. However, the safety implications of these rapidly evolving technologies are not well understood. A scoping review was conducted to understand the current state of research on AVTs with a particular focus on subjective outcome measures specific to older drivers. Sixteen articles met the inclusion criteria for this scoping review. The methods used to address subjective outcomes across studies were summarized. Seven main subjective outcomes were identified: trust, functionality, satisfaction, usability, workload, acceptability, and usefulness. The results highlight inconsistencies in the research with defining these concepts. Consequently, there is an identified need for a more rigorous classification system and consistent application and interpretation of subjective measures with regard to AVTs.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "Toronto Rehabilitation Institute - UHN"
            },
            {
              "institution": "Institute for Work and Health"
            }
          ],
          "personId": 21932
        },
        {
          "affiliations": [
            {
              "institution": "McMaster University"
            }
          ],
          "personId": 18973
        },
        {
          "affiliations": [
            {
              "institution": "University of Manitoba"
            }
          ],
          "personId": 23271
        },
        {
          "affiliations": [
            {
              "institution": "Toronto Rehabilitation Institute - UHN"
            }
          ],
          "personId": 18399
        },
        {
          "affiliations": [
            {
              "institution": "University of Toronto"
            },
            {
              "institution": "Toronto Rehabilitation Institute"
            }
          ],
          "personId": 24949
        },
        {
          "affiliations": [
            {
              "institution": "University of Toronto"
            },
            {
              "institution": "Toronto Rehabilitation Institute"
            }
          ],
          "personId": 24950
        },
        {
          "affiliations": [
            {
              "institution": "McMaster University"
            },
            {
              "institution": "Toronto Rehabilitation Institute - UHN"
            }
          ],
          "personId": 16894
        },
        {
          "affiliations": [
            {
              "institution": "Toronto Rehabilitation Institute - UHN"
            }
          ],
          "personId": 22387
        },
        {
          "affiliations": [
            {
              "institution": "University of Toronto"
            }
          ],
          "personId": 13446
        },
        {
          "affiliations": [
            {
              "institution": "Centre de recherche Charles-Le Moyne – Saguenay–Lac-Saint-Jean sur les innovations en santé"
            },
            {
              "institution": "Université du Québec à Chicoutimi"
            }
          ],
          "personId": 10908
        }
      ],
      "sessionIds": [
        1126
      ],
      "eventIds": []
    },
    {
      "id": 4600,
      "typeId": 11033,
      "title": "Calibration of Trust Expectancies in Conditionally Automated Driving by Brand, Reliability Information and Introductionary Videos: An Online Study",
      "trackId": 10034,
      "tags": [],
      "keywords": [],
      "abstract": "The design of a priori information about a conditionally automated driving (CAD) function influences the extent of effective usage of this function. The present online study investigated the effects of preliminary reliability and brand information on trust and acceptance for CAD. N = 519 participants were randomly assigned to (1) a reliability condition (high or low) and (2) an original equipment manufacturer (OEM) reputation condition (i.e., above average, average, below average, baseline). To measure the effect of CAD experience, participants were additionally exposed to four short videos of a driver interacting with a CAD function. Study results provide first evidence for an influence of OEM branding and reliability on CAD evaluation. We observed a trend towards more favorable attitudes for high compared to low reliability. This effect depends on the respective OEM reputation. The findings hold implications for the design of communication on automated vehicles to calibrate a priori assessment.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "BMW Group"
            }
          ],
          "personId": 24995
        },
        {
          "affiliations": [
            {
              "institution": "Ulm University"
            }
          ],
          "personId": 25002
        },
        {
          "affiliations": [
            {
              "institution": "University of Wuerzburg"
            }
          ],
          "personId": 23483
        },
        {
          "affiliations": [
            {
              "institution": "Ulm University"
            }
          ],
          "personId": 24952
        }
      ],
      "sessionIds": [
        1209
      ],
      "eventIds": []
    },
    {
      "id": 5629,
      "typeId": 10992,
      "title": "User Interfaces for Public Transport Vehicles: Future Opportunities and Challenges",
      "trackId": 10031,
      "tags": [],
      "keywords": [],
      "abstract": "Mobility is transcending towards flexible sharing, combined transportation modes, increased vehicle automation and digital customer services. User experience and acceptance are highly important criteria for the success of such novel concepts, and consequently their human interface has to be designed with creativity and responsibility. This workshop addresses this need by providing a holistic frame for ideation and discussion of user interface concepts for public transport vehicles. The expected outcome of the workshop is a set of opportunities, design concepts and challenges. These could be the input for a research agenda for the field.   ",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "AIT Austrian Institute of Technology"
            }
          ],
          "personId": 25011
        },
        {
          "affiliations": [
            {
              "institution": "AIT Austrian Institute of Technology"
            }
          ],
          "personId": 13854
        },
        {
          "affiliations": [
            {
              "institution": "Technische Hochschule Ingolstadt (THI)"
            }
          ],
          "personId": 24967
        },
        {
          "affiliations": [
            {
              "institution": "University of Salzburg"
            }
          ],
          "personId": 25003
        },
        {
          "affiliations": [
            {
              "institution": "FHS St.Gallen"
            }
          ],
          "personId": 24997
        }
      ],
      "sessionIds": [
        2066
      ],
      "eventIds": []
    },
    {
      "id": 7037,
      "typeId": 11033,
      "title": "P10 - I See Your Point: Integrating Gaze to Enhance Pointing Gesture Accuracy While Driving",
      "trackId": 10034,
      "tags": [],
      "keywords": [],
      "abstract": "Mid-air pointing gestures enable drivers to interact with a wide range of vehicle functions, without requiring drivers to learn a specific set of gestures. A sufficient pointing accuracy is needed, so that targeted elements can be correctly identified. However, people make relatively large pointing errors, especially in demanding situations such as driving a car. Eye-gaze provides additional information about the drivers' focus of attention that can be used to compensate imprecise pointing. We present a practical implementation of an algorithm that integrates gaze data, in order to increase the accuracy of pointing gestures. A user experiment with 91 participants showed that our approach led to an overall increase of pointing accuracy. However, the benefits depended on the participants' initial gesture performance and on the position of the target elements. The results indicate a great potential to support gesture accuracy, but also the need for a more sophisticated fusion algorithm.",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "University of Bamberg"
            },
            {
              "institution": "BMW Group Research, New Technologies, Innovations"
            }
          ],
          "personId": 16303
        },
        {
          "affiliations": [
            {
              "institution": "University of Bamberg"
            }
          ],
          "personId": 14027
        }
      ],
      "sessionIds": [
        1684
      ],
      "eventIds": []
    },
    {
      "id": 5245,
      "typeId": 11057,
      "title": "Steer-By-WiFi: Lateral Vehicle Control for Take-Overs with Nomadic Devices",
      "trackId": 10035,
      "tags": [],
      "keywords": [],
      "abstract": "Automated vehicles could omit traditional steering controls to provide larger spaces for driver-passengers or prevent unnecessary interventions. However, manual control could still be necessary to provide manual driving fun or respond to Take-Over requests (TORs). This paper investigates, whether brought-in consumer devices (in this case a 10.2 inch tablet) can act as input alternative to classical steering wheels in TOR situations. Results of a driving simulator study (n=14) confirm that responding to Take-Overs with nomadic devices can reduce response times in imminent transitions during engagement in Non-Driving Related Tasks (NDRTs), as a change of the 'device in hands' is omitted. Further on, subjective scales addressing user experience show that the approach is well accepted. We conclude that nomadic device integration is a crucial prerequisite for the success of automated vehicles, but for steering input several pivotal issues still need to be solved. ",
      "authors": [
        {
          "affiliations": [
            {
              "institution": "Technische Hochschule Ingolstadt"
            },
            {
              "institution": "Johannes Kepler University"
            }
          ],
          "personId": 24958
        },
        {
          "affiliations": [
            {
              "institution": "Technische Hochschule Ingolstadt"
            },
            {
              "institution": "Johannes Kepler University"
            }
          ],
          "personId": 24996
        },
        {
          "affiliations": [
            {
              "institution": "Technische Hochschule Ingolstadt"
            },
            {
              "institution": "Johannes Kepler University"
            }
          ],
          "personId": 24988
        }
      ],
      "sessionIds": [
        1126
      ],
      "eventIds": []
    }
  ],
  "people": [
    {
      "id": 11777,
      "firstName": "Christopher",
      "lastName": "Hart",
      "middleInitial": "A.",
      "affiliations": []
    },
    {
      "id": 11778,
      "firstName": "Gözel",
      "lastName": "Shakeri",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 12299,
      "firstName": "Sarah",
      "lastName": "Faltaous",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 18956,
      "firstName": "Aiki",
      "lastName": "Marushima",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 9234,
      "firstName": "Hidehiko",
      "lastName": "Komine",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 15896,
      "firstName": "Pedro",
      "lastName": "Santana-Mancilla",
      "middleInitial": "C.",
      "affiliations": []
    },
    {
      "id": 24088,
      "firstName": "Julia",
      "lastName": "Graefe",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 18457,
      "firstName": "Joyita",
      "lastName": "Chakraborty",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 18973,
      "firstName": "Brenda",
      "lastName": "Vrkljan",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 11294,
      "firstName": "Dhanushka",
      "lastName": "Premarathna",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 13854,
      "firstName": "Alexandra",
      "lastName": "Millonig",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 20003,
      "firstName": "George",
      "lastName": "Paravantes",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 14884,
      "firstName": "Benedikt",
      "lastName": "Streitwieser",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 17456,
      "firstName": "Yahui",
      "lastName": "Wang",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 22064,
      "firstName": "Christiane",
      "lastName": "Glatz",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 15934,
      "firstName": "Ramona",
      "lastName": "Schödel",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 19006,
      "firstName": "Berry",
      "lastName": "Eggen",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 16447,
      "firstName": "Stefan",
      "lastName": "Beckmann",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 16961,
      "firstName": "Sean",
      "lastName": "Seaman",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 12866,
      "firstName": "Felix",
      "lastName": "Ros",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 19011,
      "firstName": "Naoki",
      "lastName": "Takahashi",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 20548,
      "firstName": "Chloe",
      "lastName": "Chung",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 12357,
      "firstName": "Mikael B.",
      "lastName": "Skov",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 22087,
      "firstName": "Firdose",
      "lastName": "Saeik",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 11336,
      "firstName": "Marwa",
      "lastName": "Mahmoud",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 21065,
      "firstName": "Zane",
      "lastName": "Amiralis",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 9297,
      "firstName": "Jennifer",
      "lastName": "Healey",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 20056,
      "firstName": "Andreas",
      "lastName": "Sackl",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 9816,
      "firstName": "Sumeet",
      "lastName": "Iyer",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 23131,
      "firstName": "Josh",
      "lastName": "Ekandem",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 15970,
      "firstName": "Joanne",
      "lastName": "Harbluk",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 17506,
      "firstName": "Ercan",
      "lastName": "Tunca",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 16484,
      "firstName": "Conrado Mateu",
      "lastName": "Gisbert",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 13412,
      "firstName": "Clemens",
      "lastName": "Stachl",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 14455,
      "firstName": "Lawrence",
      "lastName": "Domingo",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 19581,
      "firstName": "Lisa",
      "lastName": "Diamond",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 15999,
      "firstName": "Nick",
      "lastName": "Gang",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 23680,
      "firstName": "Bihao",
      "lastName": "Wang",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 16517,
      "firstName": "Do Hyong",
      "lastName": "Koh",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 21637,
      "firstName": "Hirotaka",
      "lastName": "Kamimura",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 9350,
      "firstName": "Simon",
      "lastName": "Weiser",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 13446,
      "firstName": "Maria",
      "lastName": "Vo",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 22665,
      "firstName": "Niels",
      "lastName": "Henze",
      "affiliations": []
    },
    {
      "id": 15500,
      "firstName": "Motoki",
      "lastName": "Shino",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 15501,
      "firstName": "Heinrich H.",
      "lastName": "Bülthoff",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 13969,
      "firstName": "Paul",
      "lastName": "Kaufmann",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 15510,
      "firstName": "Heiko",
      "lastName": "Wersing",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24215,
      "firstName": "David H.",
      "lastName": "Junker",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 13979,
      "firstName": "Jeffrey",
      "lastName": "Greenberg",
      "affiliations": []
    },
    {
      "id": 10908,
      "firstName": "Martin",
      "lastName": "Lavallière",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 11420,
      "firstName": "Sam",
      "lastName": "Johnson",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 9888,
      "firstName": "Anna",
      "lastName": "Schieben",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 15011,
      "firstName": "Stavros",
      "lastName": "Tasoudis",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 20647,
      "firstName": "Don",
      "lastName": "Clucas",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 10923,
      "firstName": "Yu",
      "lastName": "Zhang",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 19628,
      "firstName": "Pietro",
      "lastName": "Lungaro",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 13486,
      "firstName": "Lars",
      "lastName": "Reisig",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 14510,
      "firstName": "Hanneke",
      "lastName": "Hooft van Huysduynen",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 8370,
      "firstName": "Chia-Ming",
      "lastName": "Chang",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 8882,
      "firstName": "Satoshi",
      "lastName": "Kitazaki",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 15027,
      "firstName": "Mark",
      "lastName": "Perry",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 11955,
      "firstName": "Stewart",
      "lastName": "Birrell",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 22197,
      "firstName": "Peter",
      "lastName": "Lotz",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 8374,
      "firstName": "Bobbie",
      "lastName": "Seppelt",
      "affiliations": []
    },
    {
      "id": 13496,
      "firstName": "Stuart",
      "lastName": "White",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 8890,
      "firstName": "Carlos",
      "lastName": "Arce-Lopera",
      "middleInitial": "A",
      "affiliations": []
    },
    {
      "id": 14016,
      "firstName": "Satomi",
      "lastName": "Takahashi",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 20682,
      "firstName": "Patrick",
      "lastName": "Langdon",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 15050,
      "firstName": "Birsen",
      "lastName": "Donmez",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 14027,
      "firstName": "Tom",
      "lastName": "Gross",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 10955,
      "firstName": "Selin",
      "lastName": "Zileli",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 11468,
      "firstName": "Russell",
      "lastName": "Flinchum",
      "middleInitial": "Alan",
      "affiliations": []
    },
    {
      "id": 21709,
      "firstName": "Hideo",
      "lastName": "Tsurushima",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 22734,
      "firstName": "Samantha",
      "lastName": "Reig",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 20687,
      "firstName": "Marie",
      "lastName": "Lahmer",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 11472,
      "firstName": "Susanne",
      "lastName": "Kuhnert",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 10961,
      "firstName": "Romain",
      "lastName": "Michon",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 13521,
      "firstName": "Dimitrios",
      "lastName": "Raptis",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 11990,
      "firstName": "Byungsoo",
      "lastName": "Kim",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 23769,
      "firstName": "Selena",
      "lastName": "Norman",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 23257,
      "firstName": "Jesus",
      "lastName": "Garcia-Mancilla",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 9945,
      "firstName": "Fabian",
      "lastName": "Lasso",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 15578,
      "firstName": "Snigdha",
      "lastName": "Petluru",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 21217,
      "firstName": "Bashar",
      "lastName": "Ahmad",
      "middleInitial": "I.",
      "affiliations": []
    },
    {
      "id": 13540,
      "firstName": "Brian",
      "lastName": "Mok",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 23271,
      "firstName": "Hana",
      "lastName": "Abbas",
      "middleInitial": "Hussein",
      "affiliations": []
    },
    {
      "id": 18665,
      "firstName": "Thomas",
      "lastName": "Voehringer-Kuhnt",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 19689,
      "firstName": "Briana",
      "lastName": "lindsay",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 12013,
      "firstName": "Srinath",
      "lastName": "Sibi",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 8942,
      "firstName": "Winnie",
      "lastName": "Chen",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 12016,
      "firstName": "Jacob",
      "lastName": "Luton",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 12531,
      "firstName": "Yuanting",
      "lastName": "Liu",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 19188,
      "firstName": "Verena",
      "lastName": "Seibold",
      "middleInitial": "Carola",
      "affiliations": []
    },
    {
      "id": 16118,
      "firstName": "Hüseyin",
      "lastName": "Avsar",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 17149,
      "firstName": "Sharon",
      "lastName": "Joines",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 19198,
      "firstName": "Saurabh",
      "lastName": "Srivastava",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 22272,
      "firstName": "Dion",
      "lastName": "Woolley",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 16640,
      "firstName": "Petra",
      "lastName": "Grimm",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 20228,
      "firstName": "Paul",
      "lastName": "Jennings",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 23302,
      "firstName": "Kien",
      "lastName": "T. P. Tran",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 14601,
      "firstName": "Dennis",
      "lastName": "Kappen",
      "middleInitial": "L.",
      "affiliations": []
    },
    {
      "id": 13582,
      "firstName": "Jongseong",
      "lastName": "Gwak",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 18192,
      "firstName": "Jing",
      "lastName": "Feng",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 11541,
      "firstName": "Myounghoon",
      "lastName": "Jeon",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 18199,
      "firstName": "Chris",
      "lastName": "Chafe",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 19737,
      "firstName": "Stefan",
      "lastName": "Schneegass",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 10014,
      "firstName": "Te-ping",
      "lastName": "Kiang",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 20767,
      "firstName": "Yasuhiro",
      "lastName": "Hatori",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 9504,
      "firstName": "Shaohua",
      "lastName": "Jia",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 16675,
      "firstName": "Samadrita",
      "lastName": "Das",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 22310,
      "firstName": "Renate",
      "lastName": "Haeuslschmid",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 21800,
      "firstName": "JohnRobert",
      "lastName": "Wilson",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 22824,
      "firstName": "Catherine",
      "lastName": "Burns",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 19752,
      "firstName": "Lee",
      "lastName": "Lisle",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 8489,
      "firstName": "Cat",
      "lastName": "Rayburn",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 18730,
      "firstName": "Victor",
      "lastName": "Gonzalez",
      "middleInitial": "Manuel",
      "affiliations": []
    },
    {
      "id": 17709,
      "firstName": "John",
      "lastName": "Williamson",
      "middleInitial": "H",
      "affiliations": []
    },
    {
      "id": 14126,
      "firstName": "Thana",
      "lastName": "Hussein",
      "middleInitial": "G",
      "affiliations": []
    },
    {
      "id": 14642,
      "firstName": "Divya",
      "lastName": "Seshadri",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 23349,
      "firstName": "Benjamin",
      "lastName": "Reaves",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 19771,
      "firstName": "Christiane B.",
      "lastName": "Wiebel-Herboth",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 20289,
      "firstName": "Maria",
      "lastName": "Klingegård",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 16196,
      "firstName": "Bettina",
      "lastName": "Leuchtenberg",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 15684,
      "firstName": "Linda",
      "lastName": "Angell",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 8517,
      "firstName": "Carl",
      "lastName": "Gutwin",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 18759,
      "firstName": "Cecilia",
      "lastName": "Morales",
      "middleInitial": "G.",
      "affiliations": []
    },
    {
      "id": 10570,
      "firstName": "Katharina",
      "lastName": "Wiedemann",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 9036,
      "firstName": "Mads",
      "lastName": "Mårtensson",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 11596,
      "firstName": "Issam",
      "lastName": "Kraiem",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 12113,
      "firstName": "Eric",
      "lastName": "Vasey",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 19281,
      "firstName": "Nicole",
      "lastName": "Perterer",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 21336,
      "firstName": "Steven",
      "lastName": "Landry",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 19292,
      "firstName": "Shailie",
      "lastName": "Thakkar",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 20828,
      "firstName": "Hannah",
      "lastName": "Close",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 11104,
      "firstName": "Sonia",
      "lastName": "Baltodano",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 15201,
      "firstName": "Chrisminder",
      "lastName": "Hare",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24931,
      "firstName": "Thomas",
      "lastName": "Franke",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24932,
      "firstName": "Stella",
      "lastName": "Donker",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 19300,
      "firstName": "Alessandro",
      "lastName": "Nesti",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 23397,
      "firstName": "Yasuhiro",
      "lastName": "Kobayashi",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24933,
      "firstName": "Frank",
      "lastName": "Flemisch",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24934,
      "firstName": "Alexandros",
      "lastName": "Mouzakitis",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 10598,
      "firstName": "Thomas A. Cano",
      "lastName": "Hald",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24935,
      "firstName": "Andreas",
      "lastName": "Löcken",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24936,
      "firstName": "Joseph",
      "lastName": "Gabbard",
      "middleInitial": "L",
      "affiliations": []
    },
    {
      "id": 24937,
      "firstName": "Marcel",
      "lastName": "Walch",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24938,
      "firstName": "Stephen",
      "lastName": "Brewster",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24939,
      "firstName": "Victor",
      "lastName": "Malmsten Lundgren",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24940,
      "firstName": "Sanna",
      "lastName": "Pampel",
      "middleInitial": "M",
      "affiliations": []
    },
    {
      "id": 24941,
      "firstName": "Matti",
      "lastName": "Krüger",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 13166,
      "firstName": "Nadja",
      "lastName": "Schoemig",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24942,
      "firstName": "Sven",
      "lastName": "Mayer",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24943,
      "firstName": "Alex",
      "lastName": "Mihailidis",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 23919,
      "firstName": "Frank",
      "lastName": "van Valkenhoef",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24944,
      "firstName": "Ronald",
      "lastName": "Schroeter",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24945,
      "firstName": "Marieke",
      "lastName": "Martens",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 18801,
      "firstName": "Katrine",
      "lastName": "Hesseldahl",
      "middleInitial": "Dalum",
      "affiliations": []
    },
    {
      "id": 24946,
      "firstName": "Ignacio",
      "lastName": "Alvarez",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 22387,
      "firstName": "Margaret",
      "lastName": "Tiong",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24947,
      "firstName": "Michael",
      "lastName": "Oehl",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 19316,
      "firstName": "Aaron",
      "lastName": "Steinfeld",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24948,
      "firstName": "Russell",
      "lastName": "Marshall",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 11124,
      "firstName": "Kei",
      "lastName": "Ishii",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 20853,
      "firstName": "Simon J.",
      "lastName": "Godsill",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24949,
      "firstName": "Jennifer",
      "lastName": "Campos",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24950,
      "firstName": "Shabnam",
      "lastName": "Haghzare",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24951,
      "firstName": "Chao",
      "lastName": "Wang",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24952,
      "firstName": "Martin",
      "lastName": "Baumann",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24953,
      "firstName": "Lewis",
      "lastName": "Chuang",
      "middleInitial": "L",
      "affiliations": []
    },
    {
      "id": 24954,
      "firstName": "Philipp",
      "lastName": "Hock",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24955,
      "firstName": "Bruce",
      "lastName": "Walker",
      "middleInitial": "N.",
      "affiliations": []
    },
    {
      "id": 24956,
      "firstName": "Azra",
      "lastName": "Habibovic",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 18300,
      "firstName": "Quentin",
      "lastName": "Stafford-Fraser",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 17788,
      "firstName": "Ingo",
      "lastName": "Zoller",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24957,
      "firstName": "Michael",
      "lastName": "Gerber",
      "middleInitial": "A.",
      "affiliations": []
    },
    {
      "id": 13693,
      "firstName": "Luis",
      "lastName": "Oliveira",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24958,
      "firstName": "Clemens",
      "lastName": "Schartmüller",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 14206,
      "firstName": "Christine",
      "lastName": "Haupt",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24959,
      "firstName": "Gary",
      "lastName": "Burnett",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24960,
      "firstName": "Bethan",
      "lastName": "Topliss",
      "middleInitial": "Hannah",
      "affiliations": []
    },
    {
      "id": 24961,
      "firstName": "Enrico",
      "lastName": "Rukzio",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24962,
      "firstName": "Andreas",
      "lastName": "Riegler",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24963,
      "firstName": "Manfred",
      "lastName": "Tscheligi",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24964,
      "firstName": "Susanne",
      "lastName": "Boll",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24965,
      "firstName": "Ashleigh",
      "lastName": "Filtness",
      "middleInitial": "J",
      "affiliations": []
    },
    {
      "id": 15238,
      "firstName": "Jodi",
      "lastName": "Forlizzi",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24966,
      "firstName": "David R.",
      "lastName": "Large",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24967,
      "firstName": "Anna-Katharina",
      "lastName": "Frison",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 21895,
      "firstName": "Esther",
      "lastName": "Bosch",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 13192,
      "firstName": "Jiayu",
      "lastName": "Wu",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24968,
      "firstName": "Shan",
      "lastName": "Bao",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24969,
      "firstName": "Michael",
      "lastName": "Braun",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24970,
      "firstName": "Andrew",
      "lastName": "Kun",
      "middleInitial": "L",
      "affiliations": []
    },
    {
      "id": 10635,
      "firstName": "Laura",
      "lastName": "Aigner",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24971,
      "firstName": "Huy Viet",
      "lastName": "Le",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24972,
      "firstName": "Heinrich",
      "lastName": "Hussmann",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 19853,
      "firstName": "Alexandra",
      "lastName": "Neukum",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24973,
      "firstName": "Florian",
      "lastName": "Weidner",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24974,
      "firstName": "Wolfgang",
      "lastName": "Broll",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24975,
      "firstName": "Debargha",
      "lastName": "Dey",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 12687,
      "firstName": "Nikoletta",
      "lastName": "Sofra",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24976,
      "firstName": "Roderick",
      "lastName": "McCall",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 19344,
      "firstName": "Lewis L.",
      "lastName": "Chuang",
      "affiliations": []
    },
    {
      "id": 24977,
      "firstName": "Gesa",
      "lastName": "Wiegand",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24978,
      "firstName": "Jonas",
      "lastName": "Andersson",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24979,
      "firstName": "Takeo",
      "lastName": "Igarashi",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24980,
      "firstName": "Christian",
      "lastName": "Janssen",
      "middleInitial": "P.",
      "affiliations": []
    },
    {
      "id": 10644,
      "firstName": "Frank",
      "lastName": "Pollick",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24981,
      "firstName": "Richard",
      "lastName": "Romano",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24982,
      "firstName": "Lee",
      "lastName": "Skrypchuk",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 11670,
      "firstName": "Yvonne",
      "lastName": "Brueck",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24983,
      "firstName": "Sarah",
      "lastName": "Völkel",
      "middleInitial": "Theres",
      "affiliations": []
    },
    {
      "id": 24984,
      "firstName": "Uwe",
      "lastName": "Gruenefeld",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24985,
      "firstName": "Orestis",
      "lastName": "Georgiou",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24986,
      "firstName": "Wendy",
      "lastName": "Ju",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24987,
      "firstName": "Marcel",
      "lastName": "Baltzer",
      "middleInitial": "C. A.",
      "affiliations": []
    },
    {
      "id": 24988,
      "firstName": "Philipp",
      "lastName": "Wintersberger",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24989,
      "firstName": "Rebecca",
      "lastName": "Currano",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 10653,
      "firstName": "Patrizia",
      "lastName": "Di Campli San Vito",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24990,
      "firstName": "Sangjin",
      "lastName": "Ko",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 9119,
      "firstName": "Marc",
      "lastName": "Pomplun",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24991,
      "firstName": "Matthias",
      "lastName": "Arend",
      "middleInitial": "G.",
      "affiliations": []
    },
    {
      "id": 24992,
      "firstName": "Sebastian",
      "lastName": "Hergeth",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24993,
      "firstName": "Florian",
      "lastName": "Alt",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24994,
      "firstName": "Klemens",
      "lastName": "Weigl",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24995,
      "firstName": "Yannick",
      "lastName": "Forster",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24996,
      "firstName": "Andreas",
      "lastName": "Riener",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24997,
      "firstName": "Matthias",
      "lastName": "Baldauf",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 21926,
      "firstName": "Josef",
      "lastName": "Krems",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24998,
      "firstName": "Simon",
      "lastName": "Hoermann",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 15271,
      "firstName": "Motoyuki",
      "lastName": "Akamatsu",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 24999,
      "firstName": "Paul",
      "lastName": "Green",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 25000,
      "firstName": "Kyle",
      "lastName": "Harrington",
      "middleInitial": "James",
      "affiliations": []
    },
    {
      "id": 25001,
      "firstName": "Alexander",
      "lastName": "Kunze",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 25002,
      "firstName": "Johannes",
      "lastName": "Kraus",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 19882,
      "firstName": "Rishabh",
      "lastName": "Singh",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 25003,
      "firstName": "Sandra",
      "lastName": "Trösterer",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 19883,
      "firstName": "Hyungil",
      "lastName": "Kim",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 21932,
      "firstName": "Andrea",
      "lastName": "Furlan",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 25004,
      "firstName": "Christian",
      "lastName": "Mai",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 25005,
      "firstName": "Shadan",
      "lastName": "Sadeghian Borojeni",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 25006,
      "firstName": "Alexander",
      "lastName": "Meschtscherjakov",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 16303,
      "firstName": "Florian",
      "lastName": "Roider",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 25007,
      "firstName": "Doug",
      "lastName": "Bowman",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 25008,
      "firstName": "Harpreet",
      "lastName": "Singh",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 25009,
      "firstName": "Franziska",
      "lastName": "Babel",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 23985,
      "firstName": "Andrea",
      "lastName": "Johnson",
      "middleInitial": "E",
      "affiliations": []
    },
    {
      "id": 11186,
      "firstName": "Murat",
      "lastName": "Dikmen",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 25010,
      "firstName": "Arber",
      "lastName": "Shabani",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 25011,
      "firstName": "Peter",
      "lastName": "Fröhlich",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 25012,
      "firstName": "Rainer",
      "lastName": "Erbach",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 25013,
      "firstName": "Steffen",
      "lastName": "Maurer",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 21942,
      "firstName": "Martina",
      "lastName": "Risteska",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 25014,
      "firstName": "Jacques",
      "lastName": "Terken",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 25015,
      "firstName": "Alexander",
      "lastName": "Mirnig",
      "middleInitial": "G.",
      "affiliations": []
    },
    {
      "id": 25016,
      "firstName": "Stephen",
      "lastName": "Summerskill",
      "middleInitial": "J",
      "affiliations": []
    },
    {
      "id": 10680,
      "firstName": "Dan",
      "lastName": "Quinlan",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 19385,
      "firstName": "Frederik",
      "lastName": "Naujoks",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 25017,
      "firstName": "Brittany",
      "lastName": "Holthausen",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 25018,
      "firstName": "Bastian",
      "lastName": "Pfleging",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 23483,
      "firstName": "Sophie",
      "lastName": "Feinauer",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 19904,
      "firstName": "Dale",
      "lastName": "Harrow",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 10178,
      "firstName": "So Yeon",
      "lastName": "Park",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 12739,
      "firstName": "Angela",
      "lastName": "Schoellig",
      "affiliations": []
    },
    {
      "id": 20931,
      "firstName": "Kyle",
      "lastName": "Tanous",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 19908,
      "firstName": "Koki",
      "lastName": "Toda",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 15816,
      "firstName": "Susanne",
      "lastName": "Meerwald-Stadler",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 13262,
      "firstName": "Ignacio",
      "lastName": "Alvarez",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 23505,
      "firstName": "Masahiro",
      "lastName": "Miyata",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 17361,
      "firstName": "Yeti",
      "lastName": "Li",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 8657,
      "firstName": "S. Tarek",
      "lastName": "Shahriar",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 14292,
      "firstName": "Juan",
      "lastName": "Madrid",
      "middleInitial": "Manuel",
      "affiliations": []
    },
    {
      "id": 15317,
      "firstName": "Konrad",
      "lastName": "Tollmar",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 18399,
      "firstName": "Jessica",
      "lastName": "Babineau",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 14303,
      "firstName": "Gaël",
      "lastName": "Dubus",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 15329,
      "firstName": "Javier",
      "lastName": "Echevarría Cuesta",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 23010,
      "firstName": "Thomas",
      "lastName": "Kundinger",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 23016,
      "firstName": "Chris",
      "lastName": "Burns",
      "middleInitial": "G",
      "affiliations": []
    },
    {
      "id": 22507,
      "firstName": "Andy",
      "lastName": "Cockburn",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 16875,
      "firstName": "Kazuo",
      "lastName": "Okamura",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 21997,
      "firstName": "Peter",
      "lastName": "Robinson",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 14832,
      "firstName": "Sitara",
      "lastName": "Shah",
      "middleInitial": "Kamal",
      "affiliations": []
    },
    {
      "id": 21488,
      "firstName": "Quay",
      "lastName": "Au",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 18418,
      "firstName": "Christophe",
      "lastName": "JALLAIS",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 22004,
      "firstName": "Wilko",
      "lastName": "Heuten",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 13815,
      "firstName": "Seiji",
      "lastName": "Yamada",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 11774,
      "firstName": "Hilary",
      "lastName": "Leehane",
      "middleInitial": "",
      "affiliations": []
    },
    {
      "id": 16894,
      "firstName": "Tara",
      "lastName": "Kajaks",
      "middleInitial": "",
      "affiliations": []
    }
  ],
  "recognitions": [],
  "publicationInfo": {
    "hideLinksBeforeConference": false,
    "version": 18,
    "publicationStatus": "PUBLISHED",
    "isProgramEnabled": true,
    "isDraft": false,
    "isRegistrationEnabled": false,
    "publicationDate": "2021-02-10 13:49:55+00"
  }
}